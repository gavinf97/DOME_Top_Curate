{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139277be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aef963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FILTERING AND UPDATING JSON METADATA (Block 5.0)\n",
      "============================================================\n",
      "Reading TSV: Positive_PMC_TSV_Files/positive_entries_status.tsv\n",
      "Found 1012 JSON files in Copilot_1000_v0_Processed_2026-01-15\n",
      "Entries matching JSON files: 1012\n",
      "Saved filtered TSV to: Positive_PMC_TSV_Files/positive_entries_pmid_pmcid_filtered.tsv\n",
      "Updating JSON files with publication IDs (checking order)...\n",
      "Successfully updated 1012 JSON files.\n"
     ]
    }
   ],
   "source": [
    "# Block 5.0: Filter IDs based on Copilot Processed folder and update JSONs\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FILTERING AND UPDATING JSON METADATA (Block 5.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Define paths\n",
    "input_tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "json_folder_path = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "filtered_tsv_output = 'Positive_PMC_TSV_Files/positive_entries_pmid_pmcid_filtered.tsv'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(input_tsv_path) and os.path.exists(json_folder_path):\n",
    "        # 2. Read TSV\n",
    "        print(f\"Reading TSV: {input_tsv_path}\")\n",
    "        df = pd.read_csv(input_tsv_path, sep='\\t')\n",
    "        \n",
    "        # 3. Extract and Clean IDs\n",
    "        # We need PMCID and PMID. Note: PMID might be float from previous steps\n",
    "        # Create a simplified copy\n",
    "        df_ids = df[['PMID', 'PMCID']].copy()\n",
    "        \n",
    "        def clean_pmid(val):\n",
    "            if pd.isna(val) or val == '':\n",
    "                return None\n",
    "            try:\n",
    "                # Convert to float then int to drop decimal, then string\n",
    "                return str(int(float(val)))\n",
    "            except:\n",
    "                return str(val)\n",
    "\n",
    "        df_ids['PMID'] = df_ids['PMID'].apply(clean_pmid)\n",
    "        df_ids['PMCID'] = df_ids['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        # 4. Get list of JSON files to filter against\n",
    "        json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "        # Create a set of PMCIDs from filenames (remove .json extension)\n",
    "        # Assuming filenames are like \"PMC12345.json\"\n",
    "        json_pmcids = set(f.replace('.json', '') for f in json_files)\n",
    "        \n",
    "        print(f\"Found {len(json_pmcids)} JSON files in {json_folder_path}\")\n",
    "        \n",
    "        # 5. Filter the DataFrame\n",
    "        # Keep row if its PMCID matches one in the folder\n",
    "        df_filtered = df_ids[df_ids['PMCID'].isin(json_pmcids)].copy()\n",
    "        \n",
    "        count = len(df_filtered)\n",
    "        print(f\"Entries matching JSON files: {count}\")\n",
    "        \n",
    "        # 6. Save the filtered TSV\n",
    "        df_filtered.to_csv(filtered_tsv_output, sep='\\t', index=False)\n",
    "        print(f\"Saved filtered TSV to: {filtered_tsv_output}\")\n",
    "        \n",
    "        # 7. Update JSON files\n",
    "        print(\"Updating JSON files with publication IDs (checking order)...\")\n",
    "        updated_count = 0\n",
    "        \n",
    "        for index, row in df_filtered.iterrows():\n",
    "            pmcid = row['PMCID']\n",
    "            pmid = row['PMID']\n",
    "            \n",
    "            if not pmcid:\n",
    "                continue\n",
    "                \n",
    "            json_file_path = os.path.join(json_folder_path, f\"{pmcid}.json\")\n",
    "            \n",
    "            if os.path.exists(json_file_path):\n",
    "                try:\n",
    "                    with open(json_file_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    # Prepare new data dict to preserve/enforce order\n",
    "                    # Target order: ..., publication/year, publication/pmid, publication/pmcid, publication/doi ...\n",
    "                    new_data = {}\n",
    "                    inserted = False\n",
    "                    \n",
    "                    pmid_val = pmid if pmid else \"\"\n",
    "                    pmcid_val = pmcid\n",
    "                    \n",
    "                    # If pmid/pmcid keys already exist in data, skip them during iteration\n",
    "                    keys_to_skip = ['publication/pmid', 'publication/pmcid']\n",
    "                    \n",
    "                    for key, value in data.items():\n",
    "                        if key in keys_to_skip:\n",
    "                            continue\n",
    "                            \n",
    "                        new_data[key] = value\n",
    "                        \n",
    "                        # Insert new keys immediately after publication/year\n",
    "                        if key == 'publication/year':\n",
    "                            new_data['publication/pmid'] = pmid_val\n",
    "                            new_data['publication/pmcid'] = pmcid_val\n",
    "                            inserted = True\n",
    "                            \n",
    "                    # Fallback: if 'publication/year' was not found, add them at the end\n",
    "                    if not inserted:\n",
    "                        new_data['publication/pmid'] = pmid_val\n",
    "                        new_data['publication/pmcid'] = pmcid_val\n",
    "                    \n",
    "                    with open(json_file_path, 'w') as f:\n",
    "                        json.dump(new_data, f, indent=2)\n",
    "                        \n",
    "                    updated_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error updating {pmcid}.json: {e}\")\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        print(f\"Successfully updated {updated_count} JSON files.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Input file or folder not found.\")\n",
    "        print(f\"TSV: {os.path.exists(input_tsv_path)}\")\n",
    "        print(f\"Folder: {os.path.exists(json_folder_path)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e9c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c938f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYZING METADATA DIFFERENCES (Block 6.0)\n",
      "============================================================\n",
      "Loading TSV...\n",
      "Comparing files...\n",
      "\n",
      "----------------------------------------\n",
      "SUMMARY METRICS\n",
      "----------------------------------------\n",
      "Total JSON files found: 1012\n",
      "JSONs matched to TSV rows: 1012\n",
      "\n",
      "Field Mismatch Counts (Values differ between JSON and TSV):\n",
      "  - publication/title: 1001 mismatch(es) (98.9%)\n",
      "  - publication/authors: 1012 mismatch(es) (100.0%)\n",
      "  - publication/journal: 964 mismatch(es) (95.3%)\n",
      "  - publication/year: 180 mismatch(es) (17.8%)\n",
      "  - publication/doi: 679 mismatch(es) (67.1%)\n",
      "\n",
      "Title Difference Breakdown:\n",
      "  - Exact Matches: 11\n",
      "  - Case-only Differences: 0\n",
      "  - Minor Differences (>80% similarity): 471\n",
      "  - Major Differences (<80% similarity): 530\n",
      "\n",
      "Examples of Major Title Differences (first 5):\n",
      "  [PMC4407517]\n",
      "    JSON: Applying Machine Learning Techniques in Detecting Bacterial Vaginosis\n",
      "    TSV : APPLYING MACHINE LEARNING TECHNIQUES IN DETECTING BACTERIAL VAGINOSIS.\n",
      "    Sim : 0.20\n",
      "  [PMC9347213]\n",
      "    JSON: Not enough information is available.\n",
      "    TSV : End-to-End Deep Learning Model to Predict and Design Secondary Structure Content of Structural Proteins.\n",
      "    Sim : 0.10\n",
      "  [PMC11865635]\n",
      "    JSON: Automatic Gallbladder Identification on CT\n",
      "    TSV : Automated CT image prescription of the gallbladder using deep learning: Development, evaluation, and health promotion.\n",
      "    Sim : 0.41\n",
      "  [PMC11806858]\n",
      "    JSON: Cardiovascular risk prediction in Chinese patients with type 2 diabetes mellitus using a machine learning-based dynamic prediction model\n",
      "    TSV : Predicting cardiovascular outcomes in Chinese patients with type 2 diabetes by combining risk factor trajectories and machine learning algorithm: a cohort study.\n",
      "    Sim : 0.57\n",
      "  [PMC11874791]\n",
      "    JSON: Fluids and Barriers of the CNS\n",
      "    TSV : Applying machine learning to high-dimensional proteomics datasets for the identification of Alzheimer's disease biomarkers.\n",
      "    Sim : 0.21\n"
     ]
    }
   ],
   "source": [
    "# Block 6.0: Analyze Metadata Differences (TSV vs JSON)\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import difflib\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYZING METADATA DIFFERENCES (Block 6.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths\n",
    "tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "json_folder = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "\n",
    "# Field mapping: JSON key -> TSV column\n",
    "field_map = {\n",
    "    'publication/title': 'Title',\n",
    "    'publication/authors': 'Authors',\n",
    "    'publication/journal': 'Journal',\n",
    "    'publication/year': 'Year',\n",
    "    'publication/doi': 'DOI'\n",
    "}\n",
    "\n",
    "try:\n",
    "    if os.path.exists(tsv_path) and os.path.exists(json_folder):\n",
    "        print(\"Loading TSV...\")\n",
    "        df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        \n",
    "        # Helper to normalize TSV PMCID for matching\n",
    "        df['PMCID_clean'] = df['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        # Metrics storage\n",
    "        total_jsons = 0\n",
    "        matched_jsons = 0\n",
    "        diff_counts = {k: 0 for k in field_map.keys()}\n",
    "        title_diff_types = {\n",
    "            'exact': 0,\n",
    "            'case_only': 0,\n",
    "            'minor_diffs': 0, # High similarity\n",
    "            'major_diffs': 0  # Low similarity / completely different\n",
    "        }\n",
    "        major_title_diffs = []\n",
    "\n",
    "        print(\"Comparing files...\")\n",
    "        \n",
    "        json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "        total_jsons = len(json_files)\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            pmcid = json_file.replace('.json', '')\n",
    "            \n",
    "            # Find row\n",
    "            row = df[df['PMCID_clean'] == pmcid]\n",
    "            \n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            \n",
    "            matched_jsons += 1\n",
    "            row = row.iloc[0]\n",
    "            \n",
    "            # Load JSON\n",
    "            with open(os.path.join(json_folder, json_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            # Compare fields\n",
    "            for json_key, tsv_col in field_map.items():\n",
    "                json_val = str(data.get(json_key, \"\")).strip()\n",
    "                \n",
    "                # Get TSV val and clean\n",
    "                tsv_val = row[tsv_col]\n",
    "                if pd.isna(tsv_val):\n",
    "                    tsv_val = \"\"\n",
    "                \n",
    "                # Handle Year specialized cleaning (float -> int -> str)\n",
    "                if tsv_col == 'Year' and tsv_val != \"\":\n",
    "                    try:\n",
    "                        tsv_val = str(int(float(tsv_val)))\n",
    "                    except:\n",
    "                        tsv_val = str(tsv_val)\n",
    "                else:\n",
    "                    tsv_val = str(tsv_val).strip()\n",
    "                \n",
    "                # Comparison\n",
    "                if json_val != tsv_val:\n",
    "                    diff_counts[json_key] += 1\n",
    "                    \n",
    "                    # Deep dive for Title\n",
    "                    if json_key == 'publication/title':\n",
    "                        # Case insensitive check\n",
    "                        if json_val.lower() == tsv_val.lower():\n",
    "                            title_diff_types['case_only'] += 1\n",
    "                        else:\n",
    "                            # Sequence Matcher for similarity\n",
    "                            matcher = difflib.SequenceMatcher(None, json_val, tsv_val)\n",
    "                            ratio = matcher.ratio()\n",
    "                            \n",
    "                            if ratio > 0.8:\n",
    "                                title_diff_types['minor_diffs'] += 1\n",
    "                            else:\n",
    "                                title_diff_types['major_diffs'] += 1\n",
    "                                major_title_diffs.append({\n",
    "                                    'PMCID': pmcid,\n",
    "                                    'JSON_Title': json_val,\n",
    "                                    'TSV_Title': tsv_val,\n",
    "                                    'Similarity': f\"{ratio:.2f}\"\n",
    "                                })\n",
    "                    else:\n",
    "                        # Non-title fields logic (simple mismatch counted above)\n",
    "                        pass\n",
    "                else:\n",
    "                    if json_key == 'publication/title':\n",
    "                        title_diff_types['exact'] += 1\n",
    "\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(\"SUMMARY METRICS\")\n",
    "        print(\"-\"*40)\n",
    "        print(f\"Total JSON files found: {total_jsons}\")\n",
    "        print(f\"JSONs matched to TSV rows: {matched_jsons}\")\n",
    "        \n",
    "        print(\"\\nField Mismatch Counts (Values differ between JSON and TSV):\")\n",
    "        for key, count in diff_counts.items():\n",
    "            print(f\"  - {key}: {count} mismatch(es) ({(count/matched_jsons)*100:.1f}%)\")\n",
    "\n",
    "        print(\"\\nTitle Difference Breakdown:\")\n",
    "        print(f\"  - Exact Matches: {title_diff_types['exact']}\")\n",
    "        print(f\"  - Case-only Differences: {title_diff_types['case_only']}\")\n",
    "        print(f\"  - Minor Differences (>80% similarity): {title_diff_types['minor_diffs']}\")\n",
    "        print(f\"  - Major Differences (<80% similarity): {title_diff_types['major_diffs']}\")\n",
    "        \n",
    "        if len(major_title_diffs) > 0:\n",
    "            print(\"\\nExamples of Major Title Differences (first 5):\")\n",
    "            for item in major_title_diffs[:5]:\n",
    "                print(f\"  [{item['PMCID']}]\")\n",
    "                print(f\"    JSON: {item['JSON_Title']}\")\n",
    "                print(f\"    TSV : {item['TSV_Title']}\")\n",
    "                print(f\"    Sim : {item['Similarity']}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Input paths do not exist.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba70532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKING FOR MISSING TITLES IN JSON (Block 6.5)\n",
      "============================================================\n",
      "Scanning 1012 JSON files...\n",
      "----------------------------------------\n",
      "Files with title 'Not enough information is available': 25\n",
      "----------------------------------------\n",
      "Files listed:\n",
      "  - PMC8080676.json\n",
      "  - PMC11148103.json\n",
      "  - PMC4368063.json\n",
      "  - PMC3205469.json\n",
      "  - PMC9420706.json\n",
      "  - PMC7988437.json\n",
      "  - PMC7874964.json\n",
      "  - PMC10052279.json\n",
      "  - PMC10365090.json\n",
      "  - PMC6992687.json\n",
      "  - PMC7821214.json\n",
      "  - PMC10785655.json\n",
      "  - PMC9086604.json\n",
      "  - PMC10046420.json\n",
      "  - PMC11140654.json\n",
      "  - PMC10239131.json\n",
      "  - PMC10791584.json\n",
      "  - PMC2846370.json\n",
      "  - PMC11110913.json\n",
      "  - PMC11127166.json\n",
      "  - PMC10235219.json\n",
      "  - PMC6924628.json\n",
      "  - PMC10060474.json\n",
      "  - PMC5685313.json\n",
      "  - PMC9869541.json\n"
     ]
    }
   ],
   "source": [
    "# Block 6.5: Check for \"Not enough information is available\" in Title\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CHECKING FOR MISSING TITLES IN JSON (Block 6.5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "json_folder_path = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "target_string = \"Not enough information is available\"\n",
    "missing_title_count = 0\n",
    "missing_title_files = []\n",
    "\n",
    "try:\n",
    "    if os.path.exists(json_folder_path):\n",
    "        json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "        total_files = len(json_files)\n",
    "        \n",
    "        print(f\"Scanning {total_files} JSON files...\")\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            file_path = os.path.join(json_folder_path, json_file)\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                title = data.get('publication/title', '')\n",
    "                \n",
    "                # Check for specific phrase\n",
    "                if title == target_string:\n",
    "                    missing_title_count += 1\n",
    "                    missing_title_files.append(json_file)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {json_file}: {e}\")\n",
    "                \n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Files with title '{target_string}': {missing_title_count}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if missing_title_count > 0:\n",
    "            print(\"Files listed:\")\n",
    "            for f in missing_title_files:\n",
    "                print(f\"  - {f}\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"Folder not found: {json_folder_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469b3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING UPDATED JSONS IN NEW FOLDER (Block 7.0)\n",
      "============================================================\n",
      "Created directory: Copilot_1000_v0_Processed_2026-01-15_Updated_Metadata\n",
      "Loading TSV reference data...\n",
      "Processing 1012 files...\n",
      "Completed.\n",
      "Total files processed: 1012\n",
      "Files with metadata updates: 1012\n",
      "All files saved to: Copilot_1000_v0_Processed_2026-01-15_Updated_Metadata\n"
     ]
    }
   ],
   "source": [
    "# Block 7.0: Create Updated JSONs with Corrected Metadata\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING UPDATED JSONS IN NEW FOLDER (Block 7.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths\n",
    "source_json_folder = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "target_json_folder = 'Copilot_1000_v0_Processed_2026-01-15_Updated_Metadata'\n",
    "tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "\n",
    "# Field mapping: JSON key -> TSV column\n",
    "field_map = {\n",
    "    'publication/title': 'Title',\n",
    "    'publication/authors': 'Authors',\n",
    "    'publication/journal': 'Journal',\n",
    "    'publication/year': 'Year',\n",
    "    'publication/doi': 'DOI'\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 1. Create target directory\n",
    "    if not os.path.exists(target_json_folder):\n",
    "        os.makedirs(target_json_folder)\n",
    "        print(f\"Created directory: {target_json_folder}\")\n",
    "    else:\n",
    "        print(f\"Directory exists: {target_json_folder}\")\n",
    "\n",
    "    if os.path.exists(tsv_path) and os.path.exists(source_json_folder):\n",
    "        print(\"Loading TSV reference data...\")\n",
    "        df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        df['PMCID_clean'] = df['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        updated_files_count = 0\n",
    "        \n",
    "        json_files = [f for f in os.listdir(source_json_folder) if f.endswith('.json')]\n",
    "        total_files = len(json_files)\n",
    "        \n",
    "        print(f\"Processing {total_files} files...\")\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            pmcid = json_file.replace('.json', '')\n",
    "            \n",
    "            # Find TSV row\n",
    "            row = df[df['PMCID_clean'] == pmcid]\n",
    "            \n",
    "            # Load original JSON\n",
    "            source_path = os.path.join(source_json_folder, json_file)\n",
    "            target_path = os.path.join(target_json_folder, json_file)\n",
    "            \n",
    "            with open(source_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # If we have TSV data, update fields if different\n",
    "            if len(row) > 0:\n",
    "                row = row.iloc[0]\n",
    "                \n",
    "                changes_made = False\n",
    "                \n",
    "                for json_key, tsv_col in field_map.items():\n",
    "                    current_val = str(data.get(json_key, \"\")).strip()\n",
    "                    \n",
    "                    # Prepare new value\n",
    "                    new_val_raw = row[tsv_col]\n",
    "                    if pd.isna(new_val_raw):\n",
    "                        new_val = \"\"\n",
    "                    else:\n",
    "                        if tsv_col == 'Year':\n",
    "                            try:\n",
    "                                new_val = str(int(float(new_val_raw)))\n",
    "                            except:\n",
    "                                new_val = str(new_val_raw)\n",
    "                        else:\n",
    "                            new_val = str(new_val_raw).strip()\n",
    "                    \n",
    "                    # Check difference\n",
    "                    if current_val != new_val:\n",
    "                        data[json_key] = new_val\n",
    "                        changes_made = True\n",
    "                \n",
    "                if changes_made:\n",
    "                    updated_files_count += 1\n",
    "            \n",
    "            # Save to new location (either updated or original copy)\n",
    "            with open(target_path, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "                \n",
    "        print(f\"Completed.\")\n",
    "        print(f\"Total files processed: {total_files}\")\n",
    "        print(f\"Files with metadata updates: {updated_files_count}\")\n",
    "        print(f\"All files saved to: {target_json_folder}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Source data not found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a353c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adafe302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### High Similarity (>=80%) | Similarity: 1.00"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"background-color: #e8e8e8; padding: 12px; border-radius: 4px; border-left: 5px solid #007acc; font-family: sans-serif;\">\n",
       "                <span style=\"font-weight: bold; margin-right: 10px;\">IDS:</span>\n",
       "                <a href=\"https://europepmc.org/search?query=PMC10692030\" target=\"_blank\" style=\"text-decoration: none; font-weight: bold; color: #0066cc; margin-right: 20px; font-size: 1.1em;\">PMC10692030 ↗</a>\n",
       "                <a href=\"https://europepmc.org/search?query=36961673\" target=\"_blank\" style=\"text-decoration: none; font-weight: bold; color: #0066cc; font-size: 1.1em;\">PMID:36961673 ↗</a>\n",
       "            </div>\n",
       "            <br>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ [Title]\n",
      "  JSON: A novel method for assessing cardiac function in patients with coronary heart disease based on wrist pulse analysis\n",
      "  TSV : A novel method for assessing cardiac function in patients with coronary heart disease based on wrist pulse analysis.\n",
      "------------------------------------------------------------\n",
      "❌ [Authors]\n",
      "  JSON: Not enough information is available.\n",
      "  TSV : Wu WJ, Chen R, Guo R, Yan JJ, Zhang CK, Wang YQ, Yan HX, Zhang YQ\n",
      "------------------------------------------------------------\n",
      "❌ [Journal]\n",
      "  JSON: Irish Journal of Medical Science\n",
      "  TSV : Irish journal of medical science\n",
      "------------------------------------------------------------\n",
      "✅ [Year]\n",
      "  2023\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>❌ [DOI]</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "&nbsp;&nbsp;JSON: <a href=\"https://doi.org/10.4103/1673-5374.233433\" target=\"_blank\" style=\"text-decoration: underline; color: #0066cc;\">10.4103/1673-5374.233433 ↗</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "&nbsp;&nbsp;TSV : <a href=\"https://doi.org/10.1007/s11845-023-03341-6\" target=\"_blank\" style=\"text-decoration: underline; color: #0066cc;\">10.1007/s11845-023-03341-6 ↗</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <br>\n",
       "                <details style=\"border: 1px solid #ddd; border-radius: 4px; padding: 10px; background-color: #fafafa;\">\n",
       "                    <summary style=\"cursor: pointer; color: #555; font-weight: bold; padding: 5px;\">\n",
       "                        ▶ Show Remaining JSON Data (24 fields)\n",
       "                    </summary>\n",
       "                    <pre style=\"margin-top: 10px; background-color: #fff; padding: 10px; border: 1px solid #eee; border-radius: 4px; overflow-x: auto;\">{\n",
       "  &quot;publication/pmid&quot;: &quot;36961673&quot;,\n",
       "  &quot;publication/pmcid&quot;: &quot;PMC10692030&quot;,\n",
       "  &quot;publication/tags&quot;: &quot;- Machine Learning\\n- Cardiovascular Disease\\n- Pulse Diagnosis\\n- Multiscale Entropy\\n- Decision Trees\\n- Random Forests\\n- Medical Diagnosis\\n- Signal Processing\\n- Time-Series Analysis\\n- Traditional Chinese Medicine&quot;,\n",
       "  &quot;dataset/provenance&quot;: &quot;The dataset used in this study was derived from pulse samples collected for the purpose of classifying BNP (B-type natriuretic peptide) level groups. A total of 419 samples were utilized to train and test the models. Initially, the three groups had different sample sizes, but the synthetic minority oversampling technique (SMOTE) algorithm was employed to equalize the sample size, resulting in 249 samples for each group.\\n\\nThe input datasets for modeling were structured as follows:\\n\\n1. **Dataset1**: This dataset contained time-domain features and general information.\\n2. **Dataset2**: This dataset included MSE (Mean Squared Error) features and general information.\\n3. **Dataset3**: This dataset combined time-domain features, MSE features, and general information.\\n\\nThe general information among the BNP level groups included factors such as gender distribution, age, and BMI (Body Mass Index). Specific time-domain features and MSE features were also compared among the groups to understand their distributions and differences.\\n\\nThe models were validated through fivefold cross-validation, where 80% of the pulse samples were used for training, and the remaining 20% were used for testing. This approach ensured that the models were robust and generalizable.\\n\\nThe datasets were not explicitly mentioned to have been used in previous papers or by the community, but the methods and techniques applied, such as SMOTE for handling imbalanced data and the use of machine learning algorithms like Decision Trees (DT) and Random Forests (RF), are well-established in the field of medical data classification.&quot;,\n",
       "  &quot;dataset/splits&quot;: &quot;In our study, we utilized three distinct datasets for modeling purposes. These datasets were designed to incorporate different types of features to enhance the classification of BNP level groups.\\n\\nThe first dataset, Dataset1, included time-domain features and general information. The second dataset, Dataset2, contained MSE features and general information. The third dataset, Dataset3, combined both time-domain features and MSE features along with general information.\\n\\nFor model validation, we employed a fivefold cross-validation approach. This method involved splitting the data into five parts. In each iteration, 80% of the pulse samples were used for training the models, while the remaining 20% were reserved for testing. This process was repeated five times, ensuring that each subset of data was used for both training and testing, thereby providing a robust evaluation of the models&#x27; performance.&quot;,\n",
       "  &quot;dataset/redundancy&quot;: &quot;In our study, we utilized three distinct datasets to construct and validate our machine learning models. These datasets were designed to include various features that could aid in the classification of BNP level groups.\\n\\nThe datasets were split such that 80% of the pulse samples were used for training the models, while the remaining 20% were reserved for testing. This split was enforced through a fivefold cross-validation process, ensuring that the training and test sets were independent in each fold. This method helps to avoid overfitting and provides a more robust evaluation of the models&#x27; performance.\\n\\nThe distribution of the datasets in our study is comparable to previously published machine learning datasets in the medical field. We ensured that the sample sizes of the three groups were balanced, which is crucial for maintaining the integrity of the classification results. This balance was achieved by employing the synthetic minority oversampling technique (SMOTE) algorithm, which equalized the sample size across the groups.\\n\\nBy maintaining independent training and test sets and ensuring a balanced distribution, we aimed to create a reliable and generalizable model for classifying BNP level groups. This approach aligns with best practices in machine learning and medical data analysis, ensuring that our findings are both valid and reproducible.&quot;,\n",
       "  &quot;dataset/availability&quot;: &quot;Not enough information is available.&quot;,\n",
       "  &quot;optimization/algorithm&quot;: &quot;The machine-learning algorithms used in this study are Decision Trees (DT) and Random Forests (RF). These are well-established algorithms in the field of machine learning and are not new. They were chosen for their effectiveness in classification tasks and their ability to handle various types of data features.\\n\\nDTs are tree-like regression classifiers where nodes represent attributes, links represent decision rules, and leaf nodes represent output classes. They achieve optimal classification by constructing a tree-like structure for feature input and creating a unique output for every leaf.\\n\\nRFs, on the other hand, are ensemble learning algorithms constructed from a series of decision trees with low reciprocal correlation. The class output by the most decision trees is the class output by the RF. This algorithm uses features randomly selected through bootstrap aggregation to obtain precise and stable classifications and predictions.\\n\\nThe reason these algorithms were not published in a machine-learning journal is that they are standard methods widely used across various fields, including medical science. The focus of this study is on applying these algorithms to classify BNP levels using pulse signal features, rather than introducing a new machine-learning algorithm. The study demonstrates the potential of combining wearable pulse detection technology with AI to assess cardiac function outside of hospitals.&quot;,\n",
       "  &quot;optimization/meta&quot;: &quot;The models constructed in this study do not use data from other machine-learning algorithms as input. Instead, they utilize three distinct datasets: Dataset1, which contains time-domain features and general information; Dataset2, which includes MSE features and general information; and Dataset3, which combines time-domain features, MSE features, and general information. These datasets were used to train and validate classification models using Decision Tree (DT) and Random Forest (RF) algorithms.\\n\\nThe RF algorithm, in particular, is an ensemble learning method that constructs multiple decision trees with low reciprocal correlation. The final classification is determined by the output of the majority of these decision trees. This approach enhances the precision and stability of the classifications and predictions.\\n\\nThe training data for these models was derived from 419 samples, with the synthetic minority oversampling technique (SMOTE) employed to equalize the sample sizes across the three groups. This ensures that the training data is independent and balanced, which is crucial for the reliability of the models.\\n\\nThe models were validated through fivefold cross-validation, where 80% of the pulse samples were used for training, and the remaining 20% were used for testing. This validation process helps to ensure that the models generalize well to new, unseen data.&quot;,\n",
       "  &quot;optimization/encoding&quot;: &quot;In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms used for classifying BNP level groups. We utilized three distinct datasets to train and validate our models. The first dataset, Dataset1, included time-domain features and general information. The second dataset, Dataset2, comprised MSE features and general information. The third dataset, Dataset3, combined time-domain features, MSE features, and general information, providing a comprehensive view of the data.\\n\\nTo address the imbalance in sample sizes among the three groups, we employed the synthetic minority oversampling technique (SMOTE) algorithm. This technique equalized the sample size to 249 for each group, ensuring that the models were trained on a balanced dataset. This step was essential to prevent bias and improve the generalization of the models.\\n\\nThe time-domain features selected for analysis included duration and proportional features, which objectively reflect pathophysiological morphological changes in the pulse waveform. These features were chosen for their ability to provide insights into various physiological states, such as the left ventricular diastolic period, cardiac cycle, peripheral resistance, and ejection function of the heart.\\n\\nAdditionally, we extracted MSE features from the pulse signals across multiple temporal scales. The MSE method, an improvement over traditional entropy-based methods, quantifies the complexity of the signals by constructing coarse-grained time series at specific scales. For each scale factor (s = 1, 2, 3, 4, 5), the sample entropy of the coarse-grained time series was calculated, providing a detailed characterization of the signal&#x27;s complexity.\\n\\nThe general information included in the datasets comprised demographic data such as sex distributions, age, and body mass index (BMI). These variables were compared using appropriate statistical tests, with continuous variables analyzed using the nonparametric Wilcoxon\\u2013Mann\\u2013Whitney test and categorical data using the chi-square test.\\n\\nIn summary, the data encoding and preprocessing involved the creation of three datasets with varying combinations of time-domain features, MSE features, and general information. The use of SMOTE ensured balanced sample sizes, and the selection of relevant features provided a robust foundation for the machine-learning algorithms. This meticulous preprocessing enabled the construction of accurate and reliable classification models for BNP level groups.&quot;,\n",
       "  &quot;optimization/parameters&quot;: &quot;In our study, we utilized three distinct datasets to construct our models. Each dataset incorporated different types of features along with general information.\\n\\nThe first dataset, Dataset1, included time-domain features and general information. The second dataset, Dataset2, comprised MSE features and general information. The third dataset, Dataset3, combined both time-domain features and MSE features with general information.\\n\\nFor the selection of parameters, we employed decision tree (DT) and random forest (RF) algorithms to build classification models based on all three datasets. To ensure the robustness of our models, we validated them through fivefold cross-validation. In this process, 80% of the pulse samples were used for training, while the remaining 20% were reserved for testing.\\n\\nThe performance of the models was evaluated using metrics such as accuracy, average precision, recall, and F1-score. Notably, the model based on Dataset3, which included both time-domain and MSE features, demonstrated the best performance. This indicates that combining different types of pulse features provides more comprehensive cardiovascular information, leading to more effective classification.\\n\\nIn summary, the number of parameters used in the model varied depending on the dataset, with Dataset3 incorporating the most parameters due to the inclusion of both time-domain and MSE features. The selection of parameters was guided by the goal of achieving the highest classification performance, as evidenced by the superior metrics obtained with Dataset3.&quot;,\n",
       "  &quot;optimization/features&quot;: &quot;In the optimization process, three distinct datasets were utilized, each containing different combinations of features. The first dataset, Dataset1, included time-domain features and general information. The second dataset, Dataset2, comprised MSE features and general information. The third dataset, Dataset3, encompassed both time-domain features and MSE features, along with general information.\\n\\nThe time-domain features selected for analysis included duration and proportional features, which are known to reflect pathological and physiological changes in pulse waveforms. These features were chosen for their ability to provide insights into various aspects of cardiovascular function, such as the left ventricular diastolic period, cardiac cycle, peripheral resistance, and the duration of elevated aortic pressure.\\n\\nMSE features were also incorporated to measure the complexity of pulse signals across multiple scales. These features complement the time-domain features by offering a nonlinear approach to assessing the intricacy of biological systems.\\n\\nFeature selection was implicitly performed by choosing specific time-domain and MSE features that were deemed relevant based on their ability to reflect significant physiological and pathological changes. This selection process was conducted using the entire dataset, ensuring that the chosen features were representative of the underlying patterns in the data.\\n\\nThe general information included in all datasets comprised demographic and anthropometric data, such as age, sex, and body mass index (BMI). These variables were included to provide a comprehensive overview of the study population and to account for potential confounding factors that could influence the classification of BNP levels.\\n\\nIn summary, the input features consisted of a combination of time-domain features, MSE features, and general information. Feature selection was performed based on the relevance of the features to the classification task, and the process was conducted using the entire dataset to ensure robustness and generalizability.&quot;,\n",
       "  &quot;optimization/fitting&quot;: &quot;In our study, we employed three distinct datasets to construct classification models using Decision Tree (DT) and Random Forest (RF) algorithms. These datasets included time-domain features, Mean Square Error (MSE) features, and a combination of both, along with general information.\\n\\nTo address the potential issue of overfitting, we utilized fivefold cross-validation. This technique involved training the models on 80% of the pulse samples and testing them on the remaining 20%. By doing so, we ensured that the models were evaluated on data they had not seen during training, providing a more reliable estimate of their performance on unseen data.\\n\\nThe datasets were designed to include a variety of features that capture different aspects of the pulse data. Dataset1 contained time-domain features and general information, Dataset2 included MSE features and general information, and Dataset3 combined both time-domain and MSE features with general information. This approach helped in capturing a comprehensive set of characteristics, reducing the risk of underfitting by ensuring that the models had access to a rich set of predictive variables.\\n\\nThe performance of the models was assessed using metrics such as precision, recall, and F1-score. The model based on Dataset3 consistently showed the best performance across these metrics, indicating that the combination of different feature types provided the most informative input for classification. This suggests that the models were neither overfitting nor underfitting, as they demonstrated strong generalization capabilities on the test data.\\n\\nIn summary, the use of cross-validation and a diverse set of features helped in mitigating the risks of both overfitting and underfitting, ensuring that the models were robust and generalizable.&quot;,\n",
       "  &quot;optimization/regularization&quot;: &quot;In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was fivefold cross-validation. This involved dividing the dataset into five subsets, where four subsets were used for training and the remaining one for testing. This process was repeated five times, with each subset serving as the test set once. This approach helped to ensure that the model&#x27;s performance was consistent and not merely a result of overfitting to a specific subset of the data.\\n\\nAdditionally, we utilized the synthetic minority oversampling technique (SMOTE) to address class imbalance. By generating synthetic samples for the minority classes, we balanced the dataset, which helped in preventing the model from being biased towards the majority class and thus reduced the risk of overfitting.\\n\\nFurthermore, we constructed models using two different machine learning algorithms: Decision Trees (DT) and Random Forests (RF). The RF algorithm, in particular, is known for its ability to reduce overfitting by averaging the results of multiple decision trees, each trained on a different subset of the data. This ensemble approach enhances the model&#x27;s generalization capability and robustness.&quot;,\n",
       "  &quot;optimization/config&quot;: &quot;Not enough information is available.&quot;,\n",
       "  &quot;model/interpretability&quot;: &quot;The models employed in this study include Decision Trees (DT) and Random Forests (RF), both of which offer varying degrees of interpretability.\\n\\nDecision Trees are inherently interpretable. They operate by splitting data into subsets based on feature values, creating a tree-like structure where each node represents a decision rule. The paths from the root to the leaves illustrate the decision-making process, making it straightforward to understand how predictions are made. For instance, a DT model might decide whether a patient belongs to a certain BNP level group based on specific thresholds of time-domain features or MSE features. This transparency allows clinicians to trace back the reasoning behind a classification, enhancing trust in the model&#x27;s predictions.\\n\\nRandom Forests, while slightly more complex, also provide interpretability through their ensemble nature. An RF model consists of multiple decision trees, each trained on a different subset of the data. The final prediction is made by aggregating the outputs of these trees. Although individual trees in an RF can be interpreted similarly to a single DT, the overall model&#x27;s decision process is less transparent due to the aggregation of many trees. However, feature importance can still be extracted from an RF model, indicating which features contribute most to the predictions. For example, the model might reveal that certain time-domain features and MSE features are crucial for classifying BNP levels, providing insights into the underlying physiological mechanisms.\\n\\nIn summary, while Decision Trees offer clear, straightforward interpretability, Random Forests provide a more nuanced view through feature importance, balancing complexity and transparency. This makes both models suitable for medical applications where understanding the decision-making process is crucial.&quot;,\n",
       "  &quot;model/output&quot;: &quot;The model developed in this study is a classification model. It is designed to classify BNP (B-type Natriuretic Peptide) level groups based on features extracted from wrist pulse signals. The model utilizes both time-domain features and Multiscale Entropy (MSE) features to achieve this classification. Three datasets were used: Dataset1 containing time-domain features and general information, Dataset2 containing MSE features and general information, and Dataset3 containing both time-domain and MSE features along with general information.\\n\\nThe classification performance was evaluated using Decision Tree (DT) and Random Forest (RF) algorithms. The models were validated through fivefold cross-validation, where 80% of the pulse samples were used for training and the remaining 20% for testing. The results showed that the RF models outperformed the DT models in terms of accuracy, average precision, average recall, and average F1-score. Specifically, the RF model based on Dataset3 achieved the highest performance metrics: an accuracy of 90.9%, average precision of 91.048%, average recall of 90.897%, and an average F1-score of 90.797%.\\n\\nThe superior performance of the RF model, particularly when using Dataset3, indicates that combining different types of pulse features provides more comprehensive cardiovascular information, leading to more effective classification. This study demonstrates the potential of integrating wearable pulse detection technology with AI to assess cardiac function outside of hospital settings. Future work may involve exploring additional pulse features, larger datasets, and deep learning techniques to further enhance the model&#x27;s performance.&quot;,\n",
       "  &quot;model/duration&quot;: &quot;Not enough information is available.&quot;,\n",
       "  &quot;model/availability&quot;: &quot;Not enough information is available.&quot;,\n",
       "  &quot;evaluation/method&quot;: &quot;The evaluation of the models involved a rigorous process to ensure their performance and reliability. The models were constructed based on three different datasets, each containing varying types of features. Dataset1 included time-domain features and general information, Dataset2 comprised MSE features and general information, and Dataset3 combined time-domain features, MSE features, and general information.\\n\\nTo validate the models, a fivefold cross-validation technique was employed. This method involved splitting the pulse samples into training and testing sets, with 80% of the data used for training and the remaining 20% reserved for testing. This approach helped in assessing the models&#x27; ability to generalize to unseen data.\\n\\nThe performance of the models was evaluated using several key metrics: accuracy, precision, recall, and F1-score. Accuracy measured the proportion of correct predictions out of the total predictions. Precision indicated the proportion of true positive predictions among all positive predictions. Recall, also known as sensitivity, measured the proportion of true positive predictions among all actual positives. The F1-score provided a harmonic mean of precision and recall, offering a balanced view of the model&#x27;s performance.\\n\\nThe models were constructed using two machine learning algorithms: Decision Trees (DT) and Random Forests (RF). The RF models consistently outperformed the DT models across all evaluation metrics, indicating that the RF algorithm was more suitable for this classification task. The best-performing model was based on Dataset3, which included a combination of time-domain features, MSE features, and general information. This combination provided a more comprehensive set of features, reflecting different aspects of cardiovascular information and yielding more useful insights.\\n\\nThe evaluation process also involved comparing the performance of the models across different datasets and algorithms. The results showed that the RF models had higher accuracy, average precision, average recall, and average F1-score compared to the DT models. This comprehensive evaluation ensured that the models were robust and reliable for classifying BNP level groups.&quot;,\n",
       "  &quot;evaluation/measure&quot;: &quot;In our study, we evaluated the performance of our classification models using several key metrics to ensure a comprehensive assessment. The primary metrics reported include accuracy, precision, recall, and the F1-score. These metrics are widely recognized and used in the literature for evaluating the performance of machine learning models, particularly in classification tasks.\\n\\nAccuracy measures the overall correctness of the model&#x27;s predictions by calculating the ratio of correct predictions to the total number of predictions made. Precision focuses on the correctness of positive predictions, indicating the proportion of true positive predictions among all positive predictions. Recall, also known as sensitivity, assesses the model&#x27;s ability to identify all relevant instances by calculating the proportion of true positive predictions among all actual positives. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns, especially useful when dealing with imbalanced datasets.\\n\\nThese metrics were chosen because they provide a well-rounded view of the model&#x27;s performance. Accuracy gives a general sense of how well the model is performing, while precision and recall offer insights into the model&#x27;s performance on specific classes. The F1-score is particularly useful as it combines precision and recall into a single value, making it easier to compare models, especially when dealing with imbalanced datasets.\\n\\nIn addition to these metrics, we also reported the average values of precision, recall, and F1-score across all classes. This approach ensures that the performance evaluation is not biased towards any particular class and provides a more holistic view of the model&#x27;s effectiveness. The use of these metrics aligns with standard practices in the field, ensuring that our results are comparable with other studies in the literature.&quot;,\n",
       "  &quot;evaluation/comparison&quot;: &quot;In our study, we employed two common machine learning algorithms\\u2014the Decision Tree (DT) and Random Forest (RF) algorithms\\u2014to construct models for classifying patients into three groups based on their BNP levels. The input data sets for modeling were:\\n\\n1. Dataset1, containing time-domain features and general information.\\n2. Dataset2, containing Multiscale Entropy (MSE) features and general information.\\n3. Dataset3, containing time-domain features, MSE features, and general information.\\n\\nThe models were validated through fivefold cross-validation, where 80% of the pulse samples were used for training, and the remaining 20% were used for testing. This approach ensured that our models were robust and generalizable.\\n\\nTo evaluate the performance of our models, we calculated various metrics, including accuracy, precision, recall, and F1-score. These metrics provided a comprehensive assessment of the models&#x27; effectiveness in classifying the BNP level groups.\\n\\nThe DT and RF algorithms were chosen for their widespread use and effectiveness in medical data classification. The RF algorithm, in particular, is known for its ability to handle large datasets and provide accurate and stable classifications. By comparing the performance of these two algorithms, we aimed to identify the most suitable method for our specific classification task.\\n\\nThe comparison of the DT and RF models revealed that all RF models outperformed all DT models in terms of accuracy, average precision, average recall, and average F1-score. This indicates that the RF algorithm is more suitable for modeling BNP level groups. The best performance among the RF models was achieved by the model based on Dataset3, which included a combination of time-domain features, MSE features, and general information. This suggests that integrating different types of pulse features can yield more useful information for classification, as they reflect various aspects of cardiovascular information.\\n\\nIn summary, our study involved a thorough comparison of DT and RF algorithms using different datasets to classify BNP level groups. The RF algorithm, particularly when using Dataset3, demonstrated superior performance, highlighting its potential for medical data classification tasks.&quot;,\n",
       "  &quot;evaluation/confidence&quot;: &quot;The evaluation of the models in this study involved calculating several performance metrics, including accuracy, precision, recall, and F1-score. These metrics were computed for models based on three different datasets, each containing various features and general information. The models were constructed using two machine learning algorithms: Decision Trees (DT) and Random Forests (RF).\\n\\nThe performance metrics for the DT models based on Dataset1, Dataset2, and Dataset3 are presented in tables. Similarly, the performance metrics for the RF models based on the same datasets are also provided. The models were validated through fivefold cross-validation, ensuring that the results are robust and not due to overfitting.\\n\\nThe statistical significance of the differences in performance metrics among the groups was assessed using appropriate statistical tests. For instance, the Wilcoxon\\u2013Mann\\u2013Whitney test was used to compare continuous variables, and the chi-square test was used for categorical data. These tests helped determine whether the observed differences in performance metrics were statistically significant.\\n\\nThe results indicate that the model based on Dataset3, which includes time-domain features, MSE features, and general information, had the best performance. This model achieved the highest average precision, recall, and F1-score. The differences in performance metrics among the models were statistically significant, suggesting that the method is superior to others and baselines.\\n\\nIn summary, the performance metrics have confidence intervals, and the results are statistically significant. This provides a strong basis for claiming that the method is effective and superior to other approaches.&quot;,\n",
       "  &quot;evaluation/availability&quot;: &quot;Not enough information is available.&quot;\n",
       "}</pre>\n",
       "                </details>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Run cell again [Ctrl+Enter] to flip category next time)\n"
     ]
    }
   ],
   "source": [
    "# Block 8.0: Manual Visual Inspection Interface (Alternating High/Low Sim)\n",
    "# Run this cell repeatedly (Ctrl+Enter) to view entries.\n",
    "# It will alternate between High Similarity mismatches (>=80%) and Low Similarity (<=20%).\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import difflib\n",
    "import random\n",
    "import html\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "\n",
    "# Global toggle for alternation (persists across cell runs)\n",
    "# Initialize only if not present\n",
    "if 'inspection_mode_high' not in globals():\n",
    "    inspection_mode_high = True # True=High, False=Low\n",
    "\n",
    "source_json_folder = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(tsv_path) and os.path.exists(source_json_folder):\n",
    "        # Load Data\n",
    "        df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        df['PMCID_clean'] = df['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        # Helper to clean numeric strings\n",
    "        def clean_val(v):\n",
    "            if pd.isna(v) or v == '': return \"\"\n",
    "            try: return str(int(float(v)))\n",
    "            except: return str(v).strip()\n",
    "\n",
    "        high_sim = [] \n",
    "        low_sim = []\n",
    "        \n",
    "        json_files = [f for f in os.listdir(source_json_folder) if f.endswith('.json')]\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            pmcid = json_file.replace('.json', '')\n",
    "            row = df[df['PMCID_clean'] == pmcid]\n",
    "            if len(row) == 0: continue\n",
    "            row = row.iloc[0]\n",
    "            \n",
    "            with open(os.path.join(source_json_folder, json_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            j_title = str(data.get('publication/title', \"\")).strip()\n",
    "            t_title = str(row['Title']).strip() if pd.notna(row['Title']) else \"\"\n",
    "            \n",
    "            if j_title != t_title:\n",
    "                ratio = difflib.SequenceMatcher(None, j_title, t_title).ratio()\n",
    "                \n",
    "                entry = {\n",
    "                    'pmcid': pmcid,\n",
    "                    'json': data,\n",
    "                    'tsv': row,\n",
    "                    'ratio': ratio\n",
    "                }\n",
    "                \n",
    "                if ratio >= 0.8: high_sim.append(entry)\n",
    "                elif ratio <= 0.2: low_sim.append(entry)\n",
    "\n",
    "        # Toggle Selection Logic\n",
    "        target_pool = []\n",
    "        mode_str = \"\"\n",
    "        \n",
    "        # Try to respect toggle, but fallback if one pool is empty\n",
    "        if inspection_mode_high:\n",
    "            if high_sim: \n",
    "                target_pool = high_sim\n",
    "                mode_str = \"High Similarity (>=80%)\"\n",
    "            elif low_sim:\n",
    "                target_pool = low_sim\n",
    "                mode_str = \"Low Similarity (<=20%) [High list empty]\"\n",
    "        else:\n",
    "            if low_sim:\n",
    "                target_pool = low_sim\n",
    "                mode_str = \"Low Similarity (<=20%)\"\n",
    "            elif high_sim:\n",
    "                target_pool = high_sim\n",
    "                mode_str = \"High Similarity (>=80%) [Low list empty]\"\n",
    "        \n",
    "        # Flip toggle for next run\n",
    "        inspection_mode_high = not inspection_mode_high\n",
    "        \n",
    "        if not target_pool:\n",
    "            print(\"No mismatches found in either category.\")\n",
    "        else:\n",
    "            item = random.choice(target_pool)\n",
    "            \n",
    "            # Prepare IDs for Link\n",
    "            curr_pmcid = item['pmcid']\n",
    "            curr_pmid = clean_val(item['tsv']['PMID'])\n",
    "            \n",
    "            # --- DISPLAY SECTION ---\n",
    "            \n",
    "            # Using display() ensures rich output isn't hidden/truncated easily by text buffer limits\n",
    "            display(Markdown(f\"### {mode_str} | Similarity: {item['ratio']:.2f}\"))\n",
    "            \n",
    "            # Create HTML links to Europe PMC Search\n",
    "            url_pmcid = f\"https://europepmc.org/search?query={curr_pmcid}\"\n",
    "            url_pmid = f\"https://europepmc.org/search?query={curr_pmid}\" if curr_pmid else \"#\"\n",
    "            \n",
    "            # Render Links\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style=\"background-color: #e8e8e8; padding: 12px; border-radius: 4px; border-left: 5px solid #007acc; font-family: sans-serif;\">\n",
    "                <span style=\"font-weight: bold; margin-right: 10px;\">IDS:</span>\n",
    "                <a href=\"{url_pmcid}\" target=\"_blank\" style=\"text-decoration: none; font-weight: bold; color: #0066cc; margin-right: 20px; font-size: 1.1em;\">{curr_pmcid} ↗</a>\n",
    "                <a href=\"{url_pmid}\" target=\"_blank\" style=\"text-decoration: none; font-weight: bold; color: #0066cc; font-size: 1.1em;\">PMID:{curr_pmid} ↗</a>\n",
    "            </div>\n",
    "            <br>\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Comparison Loop\n",
    "            fields = [\n",
    "                ('Title', 'publication/title', 'Title'),\n",
    "                ('Authors', 'publication/authors', 'Authors'),\n",
    "                ('Journal', 'publication/journal', 'Journal'),\n",
    "                ('Year', 'publication/year', 'Year'),\n",
    "                ('DOI', 'publication/doi', 'DOI')\n",
    "            ]\n",
    "            \n",
    "            for label, k_json, k_tsv in fields:\n",
    "                v_json = str(item['json'].get(k_json, \"\")).strip()\n",
    "                v_tsv = item['tsv'][k_tsv]\n",
    "                \n",
    "                # Special clean for display\n",
    "                if k_tsv == 'Year': v_tsv = clean_val(v_tsv)\n",
    "                else: v_tsv = str(v_tsv).strip() if pd.notna(v_tsv) else \"\"\n",
    "                \n",
    "                match = v_json == v_tsv\n",
    "                symbol = \"✅\" if match else \"❌\"\n",
    "                \n",
    "                if label == 'DOI':\n",
    "                    # Special HTML handling for clickable DOI\n",
    "                    def make_doi_link(v):\n",
    "                        if not v: return \"<em>(empty)</em>\"\n",
    "                        # Simple cleanup if formatted strangely, but usually just the DOI string\n",
    "                        return f'<a href=\"https://doi.org/{v}\" target=\"_blank\" style=\"text-decoration: underline; color: #0066cc;\">{v} ↗</a>'\n",
    "                    \n",
    "                    display(HTML(f\"<strong>{symbol} [{label}]</strong>\"))\n",
    "                    if not match:\n",
    "                        display(HTML(f\"&nbsp;&nbsp;JSON: {make_doi_link(v_json)}\"))\n",
    "                        display(HTML(f\"&nbsp;&nbsp;TSV : {make_doi_link(v_tsv)}\"))\n",
    "                    else:\n",
    "                        display(HTML(f\"&nbsp;&nbsp;{make_doi_link(v_json)}\"))\n",
    "                    print(\"-\" * 60)\n",
    "                else:\n",
    "                    # Use print for content to avoid HTML rendering issues with weird chars\n",
    "                    print(f\"{symbol} [{label}]\")\n",
    "                    if not match:\n",
    "                        print(f\"  JSON: {v_json}\")\n",
    "                        print(f\"  TSV : {v_tsv}\")\n",
    "                    else:\n",
    "                        print(f\"  {v_json}\")\n",
    "                    print(\"-\" * 60)\n",
    "            \n",
    "            # --- EXPANDABLE REST OF DATA ---\n",
    "            # Identify keys already shown\n",
    "            shown_keys = [f[1] for f in fields]\n",
    "            \n",
    "            # Collect remaining data\n",
    "            remaining_data = {k: v for k, v in item['json'].items() if k not in shown_keys}\n",
    "            \n",
    "            if remaining_data:\n",
    "                # Format to JSON string and escape for HTML\n",
    "                json_str = json.dumps(remaining_data, indent=2)\n",
    "                safe_json_str = html.escape(json_str)\n",
    "                \n",
    "                display(HTML(f\"\"\"\n",
    "                <br>\n",
    "                <details style=\"border: 1px solid #ddd; border-radius: 4px; padding: 10px; background-color: #fafafa;\">\n",
    "                    <summary style=\"cursor: pointer; color: #555; font-weight: bold; padding: 5px;\">\n",
    "                        ▶ Show Remaining JSON Data ({len(remaining_data)} fields)\n",
    "                    </summary>\n",
    "                    <pre style=\"margin-top: 10px; background-color: #fff; padding: 10px; border: 1px solid #eee; border-radius: 4px; overflow-x: auto;\">{safe_json_str}</pre>\n",
    "                </details>\n",
    "                \"\"\"))\n",
    "            \n",
    "            print(\"\\n(Run cell again [Ctrl+Enter] to flip category next time)\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Files not found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
