{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139277be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aef963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FILTERING AND UPDATING JSON METADATA (Block 5.0)\n",
      "============================================================\n",
      "Reading TSV: Positive_PMC_TSV_Files/positive_entries_status.tsv\n",
      "Found 1012 JSON files in Copilot_1000_v0_Processed_2026-01-15\n",
      "Entries matching JSON files: 1012\n",
      "Saved filtered TSV to: Positive_PMC_TSV_Files/positive_entries_pmid_pmcid_filtered.tsv\n",
      "Updating JSON files with publication IDs (checking order)...\n",
      "Successfully updated 1012 JSON files.\n"
     ]
    }
   ],
   "source": [
    "# Block 5.0: Filter IDs based on Copilot Processed folder and update JSONs\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FILTERING AND UPDATING JSON METADATA (Block 5.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Define paths\n",
    "input_tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "json_folder_path = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "filtered_tsv_output = 'Positive_PMC_TSV_Files/positive_entries_pmid_pmcid_filtered.tsv'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(input_tsv_path) and os.path.exists(json_folder_path):\n",
    "        # 2. Read TSV\n",
    "        print(f\"Reading TSV: {input_tsv_path}\")\n",
    "        df = pd.read_csv(input_tsv_path, sep='\\t')\n",
    "        \n",
    "        # 3. Extract and Clean IDs\n",
    "        # We need PMCID and PMID. Note: PMID might be float from previous steps\n",
    "        # Create a simplified copy\n",
    "        df_ids = df[['PMID', 'PMCID']].copy()\n",
    "        \n",
    "        def clean_pmid(val):\n",
    "            if pd.isna(val) or val == '':\n",
    "                return None\n",
    "            try:\n",
    "                # Convert to float then int to drop decimal, then string\n",
    "                return str(int(float(val)))\n",
    "            except:\n",
    "                return str(val)\n",
    "\n",
    "        df_ids['PMID'] = df_ids['PMID'].apply(clean_pmid)\n",
    "        df_ids['PMCID'] = df_ids['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        # 4. Get list of JSON files to filter against\n",
    "        json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "        # Create a set of PMCIDs from filenames (remove .json extension)\n",
    "        # Assuming filenames are like \"PMC12345.json\"\n",
    "        json_pmcids = set(f.replace('.json', '') for f in json_files)\n",
    "        \n",
    "        print(f\"Found {len(json_pmcids)} JSON files in {json_folder_path}\")\n",
    "        \n",
    "        # 5. Filter the DataFrame\n",
    "        # Keep row if its PMCID matches one in the folder\n",
    "        df_filtered = df_ids[df_ids['PMCID'].isin(json_pmcids)].copy()\n",
    "        \n",
    "        count = len(df_filtered)\n",
    "        print(f\"Entries matching JSON files: {count}\")\n",
    "        \n",
    "        # 6. Save the filtered TSV\n",
    "        df_filtered.to_csv(filtered_tsv_output, sep='\\t', index=False)\n",
    "        print(f\"Saved filtered TSV to: {filtered_tsv_output}\")\n",
    "        \n",
    "        # 7. Update JSON files\n",
    "        print(\"Updating JSON files with publication IDs (checking order)...\")\n",
    "        updated_count = 0\n",
    "        \n",
    "        for index, row in df_filtered.iterrows():\n",
    "            pmcid = row['PMCID']\n",
    "            pmid = row['PMID']\n",
    "            \n",
    "            if not pmcid:\n",
    "                continue\n",
    "                \n",
    "            json_file_path = os.path.join(json_folder_path, f\"{pmcid}.json\")\n",
    "            \n",
    "            if os.path.exists(json_file_path):\n",
    "                try:\n",
    "                    with open(json_file_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    # Prepare new data dict to preserve/enforce order\n",
    "                    # Target order: ..., publication/year, publication/pmid, publication/pmcid, publication/doi ...\n",
    "                    new_data = {}\n",
    "                    inserted = False\n",
    "                    \n",
    "                    pmid_val = pmid if pmid else \"\"\n",
    "                    pmcid_val = pmcid\n",
    "                    \n",
    "                    # If pmid/pmcid keys already exist in data, skip them during iteration\n",
    "                    keys_to_skip = ['publication/pmid', 'publication/pmcid']\n",
    "                    \n",
    "                    for key, value in data.items():\n",
    "                        if key in keys_to_skip:\n",
    "                            continue\n",
    "                            \n",
    "                        new_data[key] = value\n",
    "                        \n",
    "                        # Insert new keys immediately after publication/year\n",
    "                        if key == 'publication/year':\n",
    "                            new_data['publication/pmid'] = pmid_val\n",
    "                            new_data['publication/pmcid'] = pmcid_val\n",
    "                            inserted = True\n",
    "                            \n",
    "                    # Fallback: if 'publication/year' was not found, add them at the end\n",
    "                    if not inserted:\n",
    "                        new_data['publication/pmid'] = pmid_val\n",
    "                        new_data['publication/pmcid'] = pmcid_val\n",
    "                    \n",
    "                    with open(json_file_path, 'w') as f:\n",
    "                        json.dump(new_data, f, indent=2)\n",
    "                        \n",
    "                    updated_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error updating {pmcid}.json: {e}\")\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        print(f\"Successfully updated {updated_count} JSON files.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Input file or folder not found.\")\n",
    "        print(f\"TSV: {os.path.exists(input_tsv_path)}\")\n",
    "        print(f\"Folder: {os.path.exists(json_folder_path)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e9c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c938f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYZING METADATA DIFFERENCES (Block 6.0)\n",
      "============================================================\n",
      "Loading TSV...\n",
      "Comparing files...\n",
      "\n",
      "----------------------------------------\n",
      "SUMMARY METRICS\n",
      "----------------------------------------\n",
      "Total JSON files found: 1012\n",
      "JSONs matched to TSV rows: 1012\n",
      "\n",
      "Field Mismatch Counts (Values differ between JSON and TSV):\n",
      "  - publication/title: 1001 mismatch(es) (98.9%)\n",
      "  - publication/authors: 1012 mismatch(es) (100.0%)\n",
      "  - publication/journal: 964 mismatch(es) (95.3%)\n",
      "  - publication/year: 180 mismatch(es) (17.8%)\n",
      "  - publication/doi: 679 mismatch(es) (67.1%)\n",
      "\n",
      "Title Difference Breakdown:\n",
      "  - Exact Matches: 11\n",
      "  - Case-only Differences: 0\n",
      "  - Minor Differences (>80% similarity): 471\n",
      "  - Major Differences (<80% similarity): 530\n",
      "\n",
      "Examples of Major Title Differences (first 5):\n",
      "  [PMC4407517]\n",
      "    JSON: Applying Machine Learning Techniques in Detecting Bacterial Vaginosis\n",
      "    TSV : APPLYING MACHINE LEARNING TECHNIQUES IN DETECTING BACTERIAL VAGINOSIS.\n",
      "    Sim : 0.20\n",
      "  [PMC9347213]\n",
      "    JSON: Not enough information is available.\n",
      "    TSV : End-to-End Deep Learning Model to Predict and Design Secondary Structure Content of Structural Proteins.\n",
      "    Sim : 0.10\n",
      "  [PMC11865635]\n",
      "    JSON: Automatic Gallbladder Identification on CT\n",
      "    TSV : Automated CT image prescription of the gallbladder using deep learning: Development, evaluation, and health promotion.\n",
      "    Sim : 0.41\n",
      "  [PMC11806858]\n",
      "    JSON: Cardiovascular risk prediction in Chinese patients with type 2 diabetes mellitus using a machine learning-based dynamic prediction model\n",
      "    TSV : Predicting cardiovascular outcomes in Chinese patients with type 2 diabetes by combining risk factor trajectories and machine learning algorithm: a cohort study.\n",
      "    Sim : 0.57\n",
      "  [PMC11874791]\n",
      "    JSON: Fluids and Barriers of the CNS\n",
      "    TSV : Applying machine learning to high-dimensional proteomics datasets for the identification of Alzheimer's disease biomarkers.\n",
      "    Sim : 0.21\n"
     ]
    }
   ],
   "source": [
    "# Block 6.0: Analyze Metadata Differences (TSV vs JSON)\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import difflib\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYZING METADATA DIFFERENCES (Block 6.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths\n",
    "tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "json_folder = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "\n",
    "# Field mapping: JSON key -> TSV column\n",
    "field_map = {\n",
    "    'publication/title': 'Title',\n",
    "    'publication/authors': 'Authors',\n",
    "    'publication/journal': 'Journal',\n",
    "    'publication/year': 'Year',\n",
    "    'publication/doi': 'DOI'\n",
    "}\n",
    "\n",
    "try:\n",
    "    if os.path.exists(tsv_path) and os.path.exists(json_folder):\n",
    "        print(\"Loading TSV...\")\n",
    "        df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        \n",
    "        # Helper to normalize TSV PMCID for matching\n",
    "        df['PMCID_clean'] = df['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        # Metrics storage\n",
    "        total_jsons = 0\n",
    "        matched_jsons = 0\n",
    "        diff_counts = {k: 0 for k in field_map.keys()}\n",
    "        title_diff_types = {\n",
    "            'exact': 0,\n",
    "            'case_only': 0,\n",
    "            'minor_diffs': 0, # High similarity\n",
    "            'major_diffs': 0  # Low similarity / completely different\n",
    "        }\n",
    "        major_title_diffs = []\n",
    "\n",
    "        print(\"Comparing files...\")\n",
    "        \n",
    "        json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "        total_jsons = len(json_files)\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            pmcid = json_file.replace('.json', '')\n",
    "            \n",
    "            # Find row\n",
    "            row = df[df['PMCID_clean'] == pmcid]\n",
    "            \n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            \n",
    "            matched_jsons += 1\n",
    "            row = row.iloc[0]\n",
    "            \n",
    "            # Load JSON\n",
    "            with open(os.path.join(json_folder, json_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            # Compare fields\n",
    "            for json_key, tsv_col in field_map.items():\n",
    "                json_val = str(data.get(json_key, \"\")).strip()\n",
    "                \n",
    "                # Get TSV val and clean\n",
    "                tsv_val = row[tsv_col]\n",
    "                if pd.isna(tsv_val):\n",
    "                    tsv_val = \"\"\n",
    "                \n",
    "                # Handle Year specialized cleaning (float -> int -> str)\n",
    "                if tsv_col == 'Year' and tsv_val != \"\":\n",
    "                    try:\n",
    "                        tsv_val = str(int(float(tsv_val)))\n",
    "                    except:\n",
    "                        tsv_val = str(tsv_val)\n",
    "                else:\n",
    "                    tsv_val = str(tsv_val).strip()\n",
    "                \n",
    "                # Comparison\n",
    "                if json_val != tsv_val:\n",
    "                    diff_counts[json_key] += 1\n",
    "                    \n",
    "                    # Deep dive for Title\n",
    "                    if json_key == 'publication/title':\n",
    "                        # Case insensitive check\n",
    "                        if json_val.lower() == tsv_val.lower():\n",
    "                            title_diff_types['case_only'] += 1\n",
    "                        else:\n",
    "                            # Sequence Matcher for similarity\n",
    "                            matcher = difflib.SequenceMatcher(None, json_val, tsv_val)\n",
    "                            ratio = matcher.ratio()\n",
    "                            \n",
    "                            if ratio > 0.8:\n",
    "                                title_diff_types['minor_diffs'] += 1\n",
    "                            else:\n",
    "                                title_diff_types['major_diffs'] += 1\n",
    "                                major_title_diffs.append({\n",
    "                                    'PMCID': pmcid,\n",
    "                                    'JSON_Title': json_val,\n",
    "                                    'TSV_Title': tsv_val,\n",
    "                                    'Similarity': f\"{ratio:.2f}\"\n",
    "                                })\n",
    "                    else:\n",
    "                        # Non-title fields logic (simple mismatch counted above)\n",
    "                        pass\n",
    "                else:\n",
    "                    if json_key == 'publication/title':\n",
    "                        title_diff_types['exact'] += 1\n",
    "\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(\"SUMMARY METRICS\")\n",
    "        print(\"-\"*40)\n",
    "        print(f\"Total JSON files found: {total_jsons}\")\n",
    "        print(f\"JSONs matched to TSV rows: {matched_jsons}\")\n",
    "        \n",
    "        print(\"\\nField Mismatch Counts (Values differ between JSON and TSV):\")\n",
    "        for key, count in diff_counts.items():\n",
    "            print(f\"  - {key}: {count} mismatch(es) ({(count/matched_jsons)*100:.1f}%)\")\n",
    "\n",
    "        print(\"\\nTitle Difference Breakdown:\")\n",
    "        print(f\"  - Exact Matches: {title_diff_types['exact']}\")\n",
    "        print(f\"  - Case-only Differences: {title_diff_types['case_only']}\")\n",
    "        print(f\"  - Minor Differences (>80% similarity): {title_diff_types['minor_diffs']}\")\n",
    "        print(f\"  - Major Differences (<80% similarity): {title_diff_types['major_diffs']}\")\n",
    "        \n",
    "        if len(major_title_diffs) > 0:\n",
    "            print(\"\\nExamples of Major Title Differences (first 5):\")\n",
    "            for item in major_title_diffs[:5]:\n",
    "                print(f\"  [{item['PMCID']}]\")\n",
    "                print(f\"    JSON: {item['JSON_Title']}\")\n",
    "                print(f\"    TSV : {item['TSV_Title']}\")\n",
    "                print(f\"    Sim : {item['Similarity']}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Input paths do not exist.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba70532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHECKING FOR MISSING TITLES IN JSON (Block 6.5)\n",
      "============================================================\n",
      "Scanning 1012 JSON files...\n",
      "----------------------------------------\n",
      "Files with title 'Not enough information is available': 25\n",
      "----------------------------------------\n",
      "Files listed:\n",
      "  - PMC8080676.json\n",
      "  - PMC11148103.json\n",
      "  - PMC4368063.json\n",
      "  - PMC3205469.json\n",
      "  - PMC9420706.json\n",
      "  - PMC7988437.json\n",
      "  - PMC7874964.json\n",
      "  - PMC10052279.json\n",
      "  - PMC10365090.json\n",
      "  - PMC6992687.json\n",
      "  - PMC7821214.json\n",
      "  - PMC10785655.json\n",
      "  - PMC9086604.json\n",
      "  - PMC10046420.json\n",
      "  - PMC11140654.json\n",
      "  - PMC10239131.json\n",
      "  - PMC10791584.json\n",
      "  - PMC2846370.json\n",
      "  - PMC11110913.json\n",
      "  - PMC11127166.json\n",
      "  - PMC10235219.json\n",
      "  - PMC6924628.json\n",
      "  - PMC10060474.json\n",
      "  - PMC5685313.json\n",
      "  - PMC9869541.json\n"
     ]
    }
   ],
   "source": [
    "# Block 6.5: Check for \"Not enough information is available\" in Title\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CHECKING FOR MISSING TITLES IN JSON (Block 6.5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "json_folder_path = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "target_string = \"Not enough information is available\"\n",
    "missing_title_count = 0\n",
    "missing_title_files = []\n",
    "\n",
    "try:\n",
    "    if os.path.exists(json_folder_path):\n",
    "        json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "        total_files = len(json_files)\n",
    "        \n",
    "        print(f\"Scanning {total_files} JSON files...\")\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            file_path = os.path.join(json_folder_path, json_file)\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                title = data.get('publication/title', '')\n",
    "                \n",
    "                # Check for specific phrase\n",
    "                if title == target_string:\n",
    "                    missing_title_count += 1\n",
    "                    missing_title_files.append(json_file)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {json_file}: {e}\")\n",
    "                \n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Files with title '{target_string}': {missing_title_count}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if missing_title_count > 0:\n",
    "            print(\"Files listed:\")\n",
    "            for f in missing_title_files:\n",
    "                print(f\"  - {f}\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"Folder not found: {json_folder_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469b3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING UPDATED JSONS IN NEW FOLDER (Block 7.0)\n",
      "============================================================\n",
      "Created directory: Copilot_1000_v0_Processed_2026-01-15_Updated_Metadata\n",
      "Loading TSV reference data...\n",
      "Processing 1012 files...\n",
      "Completed.\n",
      "Total files processed: 1012\n",
      "Files with metadata updates: 1012\n",
      "All files saved to: Copilot_1000_v0_Processed_2026-01-15_Updated_Metadata\n"
     ]
    }
   ],
   "source": [
    "# Block 7.0: Create Updated JSONs with Corrected Metadata\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING UPDATED JSONS IN NEW FOLDER (Block 7.0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths\n",
    "source_json_folder = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "target_json_folder = 'Copilot_1000_v0_Processed_2026-01-15_Updated_Metadata'\n",
    "tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "\n",
    "# Field mapping: JSON key -> TSV column\n",
    "field_map = {\n",
    "    'publication/title': 'Title',\n",
    "    'publication/authors': 'Authors',\n",
    "    'publication/journal': 'Journal',\n",
    "    'publication/year': 'Year',\n",
    "    'publication/doi': 'DOI'\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 1. Create target directory\n",
    "    if not os.path.exists(target_json_folder):\n",
    "        os.makedirs(target_json_folder)\n",
    "        print(f\"Created directory: {target_json_folder}\")\n",
    "    else:\n",
    "        print(f\"Directory exists: {target_json_folder}\")\n",
    "\n",
    "    if os.path.exists(tsv_path) and os.path.exists(source_json_folder):\n",
    "        print(\"Loading TSV reference data...\")\n",
    "        df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        df['PMCID_clean'] = df['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        updated_files_count = 0\n",
    "        \n",
    "        json_files = [f for f in os.listdir(source_json_folder) if f.endswith('.json')]\n",
    "        total_files = len(json_files)\n",
    "        \n",
    "        print(f\"Processing {total_files} files...\")\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            pmcid = json_file.replace('.json', '')\n",
    "            \n",
    "            # Find TSV row\n",
    "            row = df[df['PMCID_clean'] == pmcid]\n",
    "            \n",
    "            # Load original JSON\n",
    "            source_path = os.path.join(source_json_folder, json_file)\n",
    "            target_path = os.path.join(target_json_folder, json_file)\n",
    "            \n",
    "            with open(source_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # If we have TSV data, update fields if different\n",
    "            if len(row) > 0:\n",
    "                row = row.iloc[0]\n",
    "                \n",
    "                changes_made = False\n",
    "                \n",
    "                for json_key, tsv_col in field_map.items():\n",
    "                    current_val = str(data.get(json_key, \"\")).strip()\n",
    "                    \n",
    "                    # Prepare new value\n",
    "                    new_val_raw = row[tsv_col]\n",
    "                    if pd.isna(new_val_raw):\n",
    "                        new_val = \"\"\n",
    "                    else:\n",
    "                        if tsv_col == 'Year':\n",
    "                            try:\n",
    "                                new_val = str(int(float(new_val_raw)))\n",
    "                            except:\n",
    "                                new_val = str(new_val_raw)\n",
    "                        else:\n",
    "                            new_val = str(new_val_raw).strip()\n",
    "                    \n",
    "                    # Check difference\n",
    "                    if current_val != new_val:\n",
    "                        data[json_key] = new_val\n",
    "                        changes_made = True\n",
    "                \n",
    "                if changes_made:\n",
    "                    updated_files_count += 1\n",
    "            \n",
    "            # Save to new location (either updated or original copy)\n",
    "            with open(target_path, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "                \n",
    "        print(f\"Completed.\")\n",
    "        print(f\"Total files processed: {total_files}\")\n",
    "        print(f\"Files with metadata updates: {updated_files_count}\")\n",
    "        print(f\"All files saved to: {target_json_folder}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Source data not found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a353c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafe302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MANUAL VISUAL INSPECTION - SINGLE RANDOM ENTRY (Block 8.0)\n",
      "============================================================\n",
      "Pool Size: 570 mismatches (High Sim: 471, Low Sim: 99)\n",
      "\n",
      "################################################################################\n",
      "PMCID: PMC11404989\n",
      "Category: High Similarity (>=80%) | Title Similarity: 0.99\n",
      "################################################################################\n",
      "\n",
      "✅ [PMID]\n",
      "  39292083\n",
      "\n",
      "✅ [PMCID]\n",
      "  PMC11404989\n",
      "\n",
      "❌ [Title]\n",
      "  JSON: Investigating artificial intelligence models for predicting joint pain from serum biochemistry\n",
      "  TSV : Investigating artificial intelligence models for predicting joint pain from serum biochemistry.\n",
      "\n",
      "❌ [Authors]\n",
      "  JSON: The authors who contributed to this article are:\n",
      "\n",
      "- Shahid S, who was involved in conceptualization, formal analysis, investigation, software development, supervision, and writing the original draft.\n",
      "- AJ, who contributed to data curation, investigation, and reviewing and editing the manuscript.\n",
      "- UA, who was responsible for data curation, resources, and validation.\n",
      "- JR, who contributed to formal analysis, software development, and visualization.\n",
      "  TSV : Shahid S, Javaid A, Amjad U, Rasheed J\n",
      "\n",
      "❌ [Journal]\n",
      "  JSON: Revista da Associação Médica Brasileira\n",
      "  TSV : Revista da Associacao Medica Brasileira (1992)\n",
      "\n",
      "✅ [Year]\n",
      "  2024\n",
      "\n",
      "❌ [DOI]\n",
      "  JSON: 10.1371/journal.pone.0252289\n",
      "  TSV : 10.1590/1806-9282.20240381\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      ">>> RUN THIS CELL AGAIN (Ctrl+Enter) TO SEE ANOTHER RANDOM ENTRY <<<\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Block 8.0: Manual Visual Inspection Interface (Alternating High/Low Sim)\n",
    "# Run this cell repeatedly (Ctrl+Enter) to view entries.\n",
    "# It will alternate between High Similarity mismatches (>=80%) and Low Similarity (<=20%).\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import difflib\n",
    "import random\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "\n",
    "# Global toggle for alternation (persists across cell runs)\n",
    "# Initialize only if not present\n",
    "if 'inspection_mode_high' not in globals():\n",
    "    inspection_mode_high = True # True=High, False=Low\n",
    "\n",
    "source_json_folder = 'Copilot_1000_v0_Processed_2026-01-15'\n",
    "tsv_path = 'Positive_PMC_TSV_Files/positive_entries_status.tsv'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(tsv_path) and os.path.exists(source_json_folder):\n",
    "        # Load Data\n",
    "        df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        df['PMCID_clean'] = df['PMCID'].apply(lambda x: str(x).strip() if pd.notna(x) else None)\n",
    "        \n",
    "        # Helper to clean numeric strings\n",
    "        def clean_val(v):\n",
    "            if pd.isna(v) or v == '': return \"\"\n",
    "            try: return str(int(float(v)))\n",
    "            except: return str(v).strip()\n",
    "\n",
    "        high_sim = [] \n",
    "        low_sim = []\n",
    "        \n",
    "        json_files = [f for f in os.listdir(source_json_folder) if f.endswith('.json')]\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            pmcid = json_file.replace('.json', '')\n",
    "            row = df[df['PMCID_clean'] == pmcid]\n",
    "            if len(row) == 0: continue\n",
    "            row = row.iloc[0]\n",
    "            \n",
    "            with open(os.path.join(source_json_folder, json_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            j_title = str(data.get('publication/title', \"\")).strip()\n",
    "            t_title = str(row['Title']).strip() if pd.notna(row['Title']) else \"\"\n",
    "            \n",
    "            if j_title != t_title:\n",
    "                ratio = difflib.SequenceMatcher(None, j_title, t_title).ratio()\n",
    "                \n",
    "                entry = {\n",
    "                    'pmcid': pmcid,\n",
    "                    'json': data,\n",
    "                    'tsv': row,\n",
    "                    'ratio': ratio\n",
    "                }\n",
    "                \n",
    "                if ratio >= 0.8: high_sim.append(entry)\n",
    "                elif ratio <= 0.2: low_sim.append(entry)\n",
    "\n",
    "        # Toggle Selection Logic\n",
    "        target_pool = []\n",
    "        mode_str = \"\"\n",
    "        \n",
    "        # Try to respect toggle, but fallback if one pool is empty\n",
    "        if inspection_mode_high:\n",
    "            if high_sim: \n",
    "                target_pool = high_sim\n",
    "                mode_str = \"High Similarity (>=80%)\"\n",
    "            elif low_sim:\n",
    "                target_pool = low_sim\n",
    "                mode_str = \"Low Similarity (<=20%) [High list empty]\"\n",
    "        else:\n",
    "            if low_sim:\n",
    "                target_pool = low_sim\n",
    "                mode_str = \"Low Similarity (<=20%)\"\n",
    "            elif high_sim:\n",
    "                target_pool = high_sim\n",
    "                mode_str = \"High Similarity (>=80%) [Low list empty]\"\n",
    "        \n",
    "        # Flip toggle for next run\n",
    "        inspection_mode_high = not inspection_mode_high\n",
    "        \n",
    "        if not target_pool:\n",
    "            print(\"No mismatches found in either category.\")\n",
    "        else:\n",
    "            item = random.choice(target_pool)\n",
    "            \n",
    "            # Prepare IDs for Link\n",
    "            curr_pmcid = item['pmcid']\n",
    "            curr_pmid = clean_val(item['tsv']['PMID'])\n",
    "            \n",
    "            # --- DISPLAY SECTION ---\n",
    "            \n",
    "            # Using display() ensures rich output isn't hidden/truncated easily by text buffer limits\n",
    "            display(Markdown(f\"### {mode_str} | Similarity: {item['ratio']:.2f}\"))\n",
    "            \n",
    "            # Create HTML links to Europe PMC Search\n",
    "            url_pmcid = f\"https://europepmc.org/search?query={curr_pmcid}\"\n",
    "            url_pmid = f\"https://europepmc.org/search?query={curr_pmid}\" if curr_pmid else \"#\"\n",
    "            \n",
    "            # Render Links\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style=\"background-color: #e8e8e8; padding: 12px; border-radius: 4px; border-left: 5px solid #007acc; font-family: sans-serif;\">\n",
    "                <span style=\"font-weight: bold; margin-right: 10px;\">IDS:</span>\n",
    "                <a href=\"{url_pmcid}\" target=\"_blank\" style=\"text-decoration: none; font-weight: bold; color: #0066cc; margin-right: 20px; font-size: 1.1em;\">{curr_pmcid} ↗</a>\n",
    "                <a href=\"{url_pmid}\" target=\"_blank\" style=\"text-decoration: none; font-weight: bold; color: #0066cc; font-size: 1.1em;\">PMID:{curr_pmid} ↗</a>\n",
    "            </div>\n",
    "            <br>\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Comparison Loop\n",
    "            fields = [\n",
    "                ('Title', 'publication/title', 'Title'),\n",
    "                ('Authors', 'publication/authors', 'Authors'),\n",
    "                ('Journal', 'publication/journal', 'Journal'),\n",
    "                ('Year', 'publication/year', 'Year'),\n",
    "                ('DOI', 'publication/doi', 'DOI')\n",
    "            ]\n",
    "            \n",
    "            for label, k_json, k_tsv in fields:\n",
    "                v_json = str(item['json'].get(k_json, \"\")).strip()\n",
    "                v_tsv = item['tsv'][k_tsv]\n",
    "                \n",
    "                # Special clean for display\n",
    "                if k_tsv == 'Year': v_tsv = clean_val(v_tsv)\n",
    "                else: v_tsv = str(v_tsv).strip() if pd.notna(v_tsv) else \"\"\n",
    "                \n",
    "                match = v_json == v_tsv\n",
    "                symbol = \"✅\" if match else \"❌\"\n",
    "                \n",
    "                # Use print for content to avoid HTML rendering issues with weird chars\n",
    "                print(f\"{symbol} [{label}]\")\n",
    "                if not match:\n",
    "                    print(f\"  JSON: {v_json}\")\n",
    "                    print(f\"  TSV : {v_tsv}\")\n",
    "                else:\n",
    "                    print(f\"  {v_json}\")\n",
    "                print(\"-\" * 60)\n",
    "            \n",
    "            print(\"\\n(Run cell again [Ctrl+Enter] to flip category next time)\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Files not found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
