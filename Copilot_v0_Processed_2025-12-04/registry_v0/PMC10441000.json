{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are C.M., Z.Z., and D.K. They were responsible for drafting the manuscript. All authors read and approved the final manuscript. Additionally, the authors would like to acknowledge Dr. Jared Roach from the Institute for Systems Biology for his assistance in manually evaluating the biological realism of the model-predicted paths in a double-blind manner. The RTX-KG2 team, including Stephen Ramsey, Amy Glen, E. C. Wood, and Lili Acevedo, is also acknowledged for their guidance in building RTX-KG2 and resolving any issues that arose.",
  "publication/journal": "GigaScience",
  "publication/year": "2023",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Drug repurposing\n- Mechanism of action\n- Reinforcement learning\n- Knowledge graphs\n- Biomedical data\n- Machine learning\n- Pathfinding algorithms\n- Drug discovery\n- Genetic diseases\n- Model evaluation",
  "dataset/provenance": "To train the KGML-xDTD framework for drug repurposing prediction and its mechanism of action (MOA) explanation, four high-quality, NLP-derived training datasets were utilized. These datasets are MyChem Data, SemMedDB Data, NDF-RT Data, and RepoDB Data.\n\nMyChem Data is provided by the BioThings API collection, containing up-to-date annotations regarding indications and contraindications for chemicals collected from 11 reliable data resources. Drug-disease pairs with the relation \"indication\" are used as true positives, while those with \"contraindication\" are used as true negatives.\n\nSemMedDB Data is provided by the Semantic MEDLINE Database, which leverages NLP techniques to extract semantic triples with \"treats\" and \"negatively treats\" relations from PubMed abstracts. Drug-disease pairs with the relation \"treats\" are used as true positives, and those with \"negatively treats\" are used as true negatives.\n\nNDF-RT Data is provided by the National Drug File–Reference Terminology from the Veterans Health Administration, containing FDA-approved information on drug interactions, indications, and contraindications. Drug-disease pairs with the therapeutics label \"indications\" are used as true positives, and those with \"contraindications\" are used as true negatives.\n\nRepoDB Data is a standard set of successful and failed drug-disease pairs in clinical trials collected by the Blavatnik Institute at Harvard Medical School. Drug-disease pairs with the status \"approved\" are used as true positives, and those with \"terminated\" are used as true negatives.\n\nThe datasets are pooled together and processed by mapping the raw identifiers of drugs and diseases to the identifiers used in the customized biomedical knowledge graph (BKG) and removing duplicate drug-disease pairs in both the true-positive and true-negative sets. The drug-disease pair counts from each data source after data processing are shown in a table, with a total of 21,437 true-positive pairs and 33,189 true-negative pairs.\n\nAdditionally, DrugMechDB is mentioned as the first human-curated path-based database for explaining the MOA from a drug to a disease in an indication, with 3,593 MOA paths for 3,327 unique drug-disease pairs. These paths are extracted from free-text descriptions from DrugBank, Wikipedia, and other literature sources and then curated by subject matter experts.",
  "dataset/splits": "The dataset was split into three distinct sets: training, validation, and test sets. The drug–disease pairs for each unique drug were randomly split according to an 8/1/1 ratio. For instance, if a drug is known to treat 10 diseases, 8 of these drug–disease pairs would be allocated to the training set, 1 to the validation set, and 1 to the test set. This method ensures that the model is exposed to every drug in the training set, facilitating the prediction of new indications for known drugs and their potential mechanisms of action based on known target diseases.",
  "dataset/redundancy": "The datasets used for training and testing the KGML-xDTD framework were carefully split to ensure independence between the training and test sets. For each drug, known drug-disease pairs were randomly divided, with most pairs allocated to the training set, a smaller portion to the validation set, and one pair to the test set. This method ensures that the model is exposed to every drug in the training set, aligning with the goal of predicting new indications for known drugs based on the mechanisms of action (MOAs) of known target diseases.\n\nTo enforce independence, all known true-positive drug-disease pairs were excluded from the replacement pairs used in the test set. This means that for each true-positive drug-disease pair in the test set, replacement pairs were generated by replacing the drug or disease with others not known to have a true-positive relationship. This approach helps in evaluating the model's ability to generalize and predict new indications accurately.\n\nThe distribution of drug classes in the true-positive drug-disease pairs between the training and test sets was compared. The training set includes a broader range of drug classes, with 2,238 drug classes represented, while the test set includes 718 drug classes. For visualization purposes, only the top 10 drug classes in each set are shown, with the rest classified into an \"Others\" category. This comparison helps in understanding the diversity and representativeness of the datasets used.\n\nThe datasets were pooled together and processed by mapping raw identifiers of drugs and diseases to those used in the customized biomedical knowledge graph (BKG). Duplicate drug-disease pairs were removed from both the true-positive and true-negative sets to ensure data integrity and reduce redundancy. This preprocessing step is crucial for maintaining the quality and reliability of the datasets used in training and testing the model.",
  "dataset/availability": "The datasets supporting the results of this article are publicly available in the Zenodo repository. All supporting data and materials are also available in the GigaScience GigaDB database. The data is released under several licenses, including the MIT license, DrugBank academic license, Apache 2.0 license, UMLS Metathesaurus license, and CC-BY 4.0 license. These licenses ensure that the data can be accessed, used, and shared by the research community while respecting the original contributors' rights.\n\nThe data availability was enforced by making the datasets openly accessible through reputable repositories. This ensures transparency and reproducibility in research, allowing other scientists to verify the findings and build upon them. The use of standardized licenses further facilitates the legal and ethical use of the data.\n\nThe data splits used in the study, including the training, validation, and test sets, are part of the publicly available datasets. This includes the drug–disease pairs used for model training and evaluation, ensuring that the methodology can be replicated by other researchers. The data preprocessing steps, such as mapping raw identifiers and removing duplicates, are also documented to maintain consistency and reproducibility.",
  "optimization/algorithm": "The optimization algorithm employed in our work is based on reinforcement learning (RL), specifically an adversarial actor–critic framework. This class of algorithms is well-established in the machine learning community and is used for sequential decision-making problems.\n\nThe algorithm is not entirely new; it builds upon existing RL techniques, particularly the actor–critic method, which combines value-based and policy-based approaches. The actor network learns a policy to select actions, while the critic network evaluates the value of these actions. The adversarial component involves path and meta-path discriminators that guide the RL agent using demonstration paths, providing intermediate rewards to encourage biologically reasonable path-finding.\n\nThe reason this algorithm is presented in a biomedical journal rather than a machine-learning journal is that the primary focus of our work is on its application to drug repurposing and mechanism of action prediction. The innovation lies in the application of these RL techniques to a complex biomedical knowledge graph, rather than in the development of a new RL algorithm. The adversarial actor–critic framework is tailored to handle the specific challenges of path-finding in large, sparse biomedical knowledge graphs, making it a novel contribution to the field of computational biology and drug discovery.",
  "optimization/meta": "The model employs a meta-predictor framework that integrates multiple machine learning components to enhance its performance. Specifically, it uses a path discriminator network and a meta-path discriminator network to guide the reinforcement learning agent. These discriminators act as binary classifiers, distinguishing between demonstration paths and actor-generated paths. The path discriminator focuses on individual path segments, while the meta-path discriminator evaluates the overall structure of the paths, ensuring they align with biologically reasonable trajectories.\n\nThe model leverages data from these discriminators to provide intermediate rewards, which help in optimizing the actor and critic networks. The actor network learns a policy to guide the agent's actions based on the current state, while the critic network estimates the expected reward for these actions. The integration of these components allows the model to effectively navigate the complex search space and identify biologically relevant paths.\n\nThe training process involves initializing the actor network using behavior cloning, followed by training the discriminators and then jointly optimizing the actor and critic networks. This multi-stage training ensures that the model benefits from both demonstration paths and the exploration capabilities of the reinforcement learning agent.\n\nRegarding the independence of training data, the model splits drug-disease pairs into training, validation, and test sets based on unique drugs, ensuring that each drug appears in the training set. This approach helps in predicting new indications for known drugs and their potential mechanisms of action, leveraging the known target diseases' mechanisms of action.",
  "optimization/encoding": "For the machine-learning algorithm, data encoding and preprocessing involved several key steps. Initially, four high-quality datasets were utilized, each containing drug-disease pairs with specific relations. These datasets were filtered and processed to ensure high-quality data. Drug-disease pairs with relations such as \"indication\" and \"treats\" were labeled as true positives, while those with \"contraindication\" and \"negatively treats\" were labeled as true negatives.\n\nThe datasets were pooled together and underwent further preprocessing. This included mapping raw identifiers of drugs and diseases to identifiers used in a customized knowledge graph. Duplicate drug-disease pairs were removed from both the true-positive and true-negative sets to ensure data integrity.\n\nTo capture node attributes, the PubMedBERT model, a pre-trained language model designed for biomedical texts, was employed. This model generated node attribute embeddings for each node based on the concatenation of the node's name and category. These embeddings were then compressed to 100 dimensions using Principal Component Analysis (PCA) to reduce memory usage. These compressed embeddings served as the initial node features for GraphSAGE, ensuring that the final embeddings contained information about both graph topology and node attributes.\n\nFor the link prediction problem, GraphSAGE was used to calculate embeddings for each node. The model was optimized to encourage neighbor nodes to have similar embeddings and non-neighbor nodes to have distinct embeddings. This was achieved through random walks to collect neighborhood information and training the model to maximize a node's similarity with its neighbor nodes.\n\nAdditionally, \"unknown\" drug-disease pairs were generated through negative sampling. This involved replacing the drug or disease identifier in each \"treat\" drug-disease pair with a random drug or disease identifier, creating new pairs that did not appear in the \"treat\" or \"not treat\" classes. This process helped in creating a more robust training dataset.\n\nThe final step involved concatenating the GraphSAGE embeddings of drug-disease pairs and using them as input for a random forest model. This model classified each drug-disease pair into one of the \"not treat,\" \"treat,\" or \"unknown\" classes, providing a comprehensive framework for drug repurposing prediction and mechanism of action (MOA) explanation.",
  "optimization/parameters": "In the optimization process of our model, several parameters play crucial roles. The model utilizes hyperparameters αp and αm, which are both within the range of [0, 1]. αp controls the influence of the demonstration meta-path distribution, while αm governs the actor-generated non-demonstration meta-path distribution. These hyperparameters are essential for balancing the contributions of different path distributions in the reward calculation.\n\nAdditionally, the decay coefficient γ is used in the integrated intermediate reward calculation. This coefficient helps in adjusting the importance of future rewards, ensuring that the model considers long-term benefits during the path-finding process.\n\nThe actor network is optimized using the REINFORCE algorithm, which involves an entropy weight α. This weight encourages diverse exploration by adding an entropy regularization term to the loss function, promoting the discovery of more varied and potentially effective paths.\n\nThe model also includes parameters for the multi-layer perceptron (MLP) subnetworks, which are shared across different components but have distinct parameters. These parameters include weights and biases for linear transformations, as well as batch normalization and activation functions.\n\nThe selection of these parameters was guided by empirical observations and tuning. The specific values for αp, αm, γ, and α were chosen based on their performance in preliminary experiments, aiming to achieve a balance between exploration and exploitation. The MLP parameters were initialized and adjusted during the training process to optimize the model's performance.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The optimization process for the KGML-xDTD model involves several key steps to ensure both overfitting and underfitting are addressed effectively.\n\nThe model employs an adversarial actor–critic reinforcement learning (RL) framework, which includes an actor network, a critic network, and two discriminator networks. The actor network is initially trained using behavior cloning with a mean square error (MSE) loss, leveraging demonstration paths to guide the agent's sampling. This approach helps in reducing the risk of overfitting by providing a strong initial policy based on expert demonstrations.\n\nDuring the training process, the actor and critic networks are frozen for the first few epochs while the path discriminator and meta-path discriminator networks are trained. This staged training method helps in stabilizing the learning process and prevents the actor network from overfitting to the critic's evaluations too early.\n\nTo further mitigate overfitting, the model incorporates an entropy regularization term in the actor network's loss function. This encourages more diverse exploration of paths, reducing the likelihood of the model becoming too specialized to the training data.\n\nThe critic network is optimized by minimizing the temporal difference (TD) error, which helps in providing accurate value estimates for the states and actions. This ensures that the critic network does not overfit to the immediate rewards but rather learns to estimate long-term rewards accurately.\n\nThe model's performance is evaluated using ranking metrics such as Mean Reciprocal Rank (MRR) and Hit@K, calculated over multiple independent sets of non-true-positive drug–disease candidates. This evaluation method helps in assessing the model's generalization capability and ensures that it does not underfit by performing poorly on unseen data.\n\nAdditionally, the model's ability to handle unseen drug classes and its performance on the test set, which includes drugs and diseases not seen during training, further validates that underfitting is not a concern. The use of high-quality, NLP-derived training datasets and the careful preprocessing of drug–disease pairs also contribute to the robustness of the model.\n\nIn summary, the optimization process includes several mechanisms to prevent overfitting and underfitting, ensuring that the model generalizes well to new data and performs effectively in drug repurposing predictions.",
  "optimization/regularization": "To encourage more diverse exploration in finding paths, an entropy regularization term was incorporated. This term is based on the action probability distribution derived from the actor policy. By optimizing the actor network with this stochastic gradient of the loss function, the model is guided to explore a wider range of possible paths, rather than converging too quickly to a single solution. This helps in preventing overfitting and ensures that the model considers various potential paths, leading to more robust and generalizable results. Additionally, the use of demonstration paths and meta-path discriminators provides intermediate rewards, further aiding in the exploration process and preventing the model from getting stuck in local optima.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not directly available in the publication. However, the source code for the KGML-xDTD model framework is publicly accessible on GitHub under the MIT license. This repository includes scripts and details that outline the training steps, parameter settings, and resource requirements necessary for reproducing the experiments.\n\nThe GitHub repository provides comprehensive information on the hardware performance and parameter settings used during the training and inference steps. It specifies that the training process requires a Linux (Ubuntu) system with at least 8 CPU cores, 800 GB of VRAM, and a 48 GB GPU card. The inference step can be performed on a similar system but with at least 50 GB of VRAM, although a GPU card is not strictly necessary.\n\nAdditionally, the repository includes supplementary sections that provide further implementation details, such as the preprocessing of the biomedical knowledge graph and the extraction of demonstration paths. These details are crucial for understanding the optimization process and the configurations used.\n\nFor those interested in the specific hyper-parameters and optimization schedules, the GitHub repository is the primary resource. It contains all the necessary scripts and configuration files to replicate the experiments described in the publication. The repository also includes information on additional requirements, such as specific versions of software and libraries, ensuring that users can set up the environment correctly.\n\nIn summary, while the publication does not provide explicit details on hyper-parameter configurations and optimization schedules, the GitHub repository offers a comprehensive set of resources and instructions for reproducing the results. The repository is licensed under the MIT license, making it accessible for both academic and commercial use.",
  "model/interpretability": "The KGML-xDTD model framework is designed with a focus on interpretability, making it more transparent than many black-box models. This transparency is achieved through the use of biologically reasonable mechanism of action (MOA) paths. The model identifies these paths from a complex biomedical knowledge graph, providing clear and interpretable explanations for its predictions.\n\nOne of the key features that enhance the interpretability of KGML-xDTD is the use of demonstration paths. These paths guide the model's path-finding process, helping it to identify biologically relevant MOA paths more effectively. By incorporating these demonstration paths, the model can navigate the vast and complex search space more efficiently, reducing the likelihood of false positives.\n\nThe model's performance in identifying MOA paths is evaluated using ranking-based metrics such as Mean Percentile Rank (MPR), Mean Reciprocal Rank (MRR), and Hit@K. These metrics provide a quantitative measure of the model's ability to rank the correct MOA paths higher than incorrect ones. Additionally, case studies on rare genetic diseases like hemophilia B and Huntington’s disease further illustrate the model's capability to identify biologically plausible MOA paths.\n\nFor instance, in the case of hemophilia B, the model predicts the top 10 drugs/treatments along with their probabilities and supporting publications. The paths generated by the model can be visualized and aligned with real drug action regulatory networks, providing a clear biological explanation for the predicted \"treats\" relationship. This level of detail and transparency is crucial for understanding the model's decisions and for validating its predictions in real-world applications.\n\nFurthermore, the model's use of node attribute embeddings and negative sampling techniques enhances its ability to generate more accurate and interpretable predictions. The node attribute embeddings capture the semantic information of the entities in the knowledge graph, while negative sampling helps in reducing false positives by generating \"unknown\" drug-disease pairs for training.\n\nIn summary, the KGML-xDTD model is not a black-box but a transparent framework that provides clear, biologically reasonable explanations for its predictions. This transparency is achieved through the use of demonstration paths, ranking-based metrics, and detailed case studies, making the model's decisions interpretable and validated against real-world biological data.",
  "model/output": "The model is primarily a classification model. It predicts the probability that a given drug can be used to treat a specific disease, categorizing each drug-disease pair into one of three classes: \"not treat,\" \"treat,\" or \"unknown.\" This classification is achieved using a random forest model that takes concatenated GraphSAGE embeddings of drug-disease pairs as input. The embeddings capture both node attributes and neighborhood information, providing a comprehensive basis for the classification task.\n\nThe model also includes a mechanism of action (MOA) prediction module, which employs a reinforcement learning (RL) approach to predict biologically plausible paths from drug nodes to disease nodes on a knowledge graph. These paths serve as explanations for the predicted treatment relationships, describing the underlying biological processes.\n\nAdditionally, the model uses demonstration paths to guide the RL agent in finding biologically reasonable paths, enhancing the interpretability and reliability of the predictions. The demonstration paths are sets of biologically likely paths that explain why a drug can treat a disease, helping the model to terminate the path searching at the expected diseases through a reasonable biological route.\n\nThe model's performance is evaluated using both classification-based metrics (such as accuracy and macro F1 score) and ranking-based metrics (such as mean reciprocal rank and Hit@K). The evaluation shows that the model outperforms most baseline models in these metrics, indicating its effectiveness in classifying known drug-disease pairs and identifying new indications for existing drugs.",
  "model/duration": "The execution time for the model varies depending on the stage of the process. The training step for the KGML-xDTD model framework takes approximately 2 weeks. This estimate is based on the hardware performance and parameter settings used in our study. The inference step, on the other hand, is much faster, taking about 25.42 seconds for a single drug-disease pair with 3,320 potential paths. These time estimates can vary depending on the hardware performance, parameter settings, and the number of potential paths for a given drug-disease pair. The model was trained on a Linux (Ubuntu) system with at least 8 CPU cores, 800 GB of VRAM, and a 48 GB GPU card. For inference, a system with at least 8 CPU cores and 50 GB of VRAM is required. While a GPU card is not necessary for inference, if used, it should have at least 24 GB of VRAM.",
  "model/availability": "The source code for the KGML-xDTD model framework is publicly available. It can be accessed via the project's homepage on GitHub. The project is licensed under the MIT license, which allows for free use, modification, and distribution of the software, subject to the terms of the license.\n\nThe software is designed to run on a Linux (Ubuntu) operating system. For the training step, a system with at least 8 CPU cores, 800 GB of VRAM, and a 48 GB GPU card is recommended. For the inference step, a system with at least 8 CPU cores and 50 GB of VRAM is sufficient, although a GPU card with at least 24 GB VRAM can be used to speed up the process.\n\nThe programming language used is Shell Script (Bash) with Python 3.8.12. Additional requirements include Python 3.8.12 with GPU/CPU support, neo4j-community 3.5.26, and miniconda 4.8.2. More detailed requirements can be found in the yaml files under the “envs” folder in the GitHub repository.\n\nThe training step takes approximately 2 weeks, while the inference step takes about 25.42 seconds for one drug–disease pair with 3,320 potential paths. These time estimates may vary depending on the hardware performance, parameter settings, and the number of potential paths of a given drug–disease pair.",
  "evaluation/method": "The evaluation of the proposed framework, KGML-xDTD, was conducted using two primary tasks: drug repurposing prediction and mechanism of action (MOA) prediction. For drug repurposing prediction, the framework's performance was assessed using both classification accuracy-based metrics and ranking-based metrics. The classification accuracy-based metrics included accuracy (ACC) and macro F1 score (Macro-F1). These metrics measured the correctness of the model's predictions and the balance between precision and recall across different classes, respectively. The ranking-based metrics, mean reciprocal rank (MRR) and Hit@K, were used to evaluate the model's ability to reduce false positives by ranking true-positive drug–disease pairs higher among possible candidates.\n\nTo generate non-true-positive drug–disease candidates for the ranking-based metrics, three \"complete\" replacement methods were employed: drug rank-based replacement, disease rank-based replacement, and combined replacement. These methods involved replacing the drug or disease entity in true-positive pairs with other entities from the knowledge graph while excluding known true-positive pairs. Due to computational constraints, a subset of 1,000 random drug–disease pairs was used for some baseline models. The robustness of the results was enhanced by generating 10 independent sets of random pairs and calculating the mean and standard deviation of the ranking-based metrics.\n\nFor MOA prediction, the evaluation focused on the model's ability to identify biologically meaningful paths from a large number of possible paths in the knowledge graph. The ranking-based metrics used for this task were mean percentile rank (MPR), MRR, and Hit@K. The ground-truth data for MOA paths was obtained from DrugMechDB, and the path scores were calculated using a path-finding policy learned from an adversarial actor–critic reinforcement learning model. The model's performance was compared with baseline models using these metrics to demonstrate its capability in identifying biologically reasonable MOA paths with a low false positive rate. Additionally, two case studies were conducted to further evaluate the effectiveness of the model in this task.",
  "evaluation/measure": "In the evaluation of our framework, we report a comprehensive set of performance metrics to assess both the accuracy and the ranking capability of our drug repurposing prediction model. The metrics we utilize include accuracy (ACC) and macro F1 score, which measure the classification performance of our model. These metrics are crucial for evaluating how well our model can distinguish between true-positive and true-negative drug-disease pairs.\n\nAdditionally, we employ ranking-based metrics such as mean reciprocal rank (MRR) and Hit@K (where K can be 1, 3, or 5). These metrics are essential for assessing the model's ability to rank true-positive drug-disease pairs higher among a large number of possible candidates, thereby reducing false positives. The MRR provides the average inverse rank of true-positive pairs, while Hit@K measures the proportion of true-positive pairs that are ranked within the top K positions.\n\nThe use of these metrics is representative of current practices in the literature, as they are commonly used to evaluate the performance of drug repurposing models. Accuracy and macro F1 score are standard classification metrics that provide a clear indication of the model's predictive power. Meanwhile, MRR and Hit@K are particularly relevant for tasks that involve ranking a large number of candidates, making them suitable for our drug repurposing prediction task.\n\nBy reporting these metrics, we aim to provide a thorough evaluation of our model's performance, demonstrating its effectiveness in both classification and ranking tasks. This set of metrics ensures that our evaluation is comprehensive and aligned with established practices in the field.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our proposed model, KGML-xDTD, against various baseline models using benchmark datasets. The comparison included both state-of-the-art (SOTA) models and simpler baselines to ensure a comprehensive assessment.\n\nFor drug repurposing prediction, we compared KGML-xDTD with several SOTA models such as TransE, TransR, RotatE, DistMult, ComplEx, ANALOGY, and SimplE. Additionally, we included simpler baselines like GAT, GraphSAGE-link, GraphSAGE + logistic, and GraphSAGE + SVM. The performance metrics used for this comparison included accuracy, macro F1 score, MRR, and Hit@K. The results, presented in Table 2, demonstrated that KGML-xDTD outperformed most of the baseline models in ranking-based metrics, showcasing its superiority in identifying new drug indications with relatively low false positives.\n\nFor mechanism of action (MOA) prediction, we compared KGML-xDTD with the MultiHop reinforcement learning model and an ablated version of our own model, KGML-xDTD w/o DP. The metrics used for this comparison included MPR, MRR, and Hit@K. The results, shown in Table 3, indicated that KGML-xDTD achieved significantly better performance in identifying biologically meaningful paths compared to the baseline models. This comparison highlighted the effectiveness of using demonstration paths in guiding the path-finding process.\n\nFurthermore, we conducted ablation studies to evaluate the impact of specific components within our model. For instance, we compared KGML-xDTD with and without node attribute embeddings (NAEs) to demonstrate the importance of NAEs in improving repurposing prediction. Similarly, we modified the drug repurposing prediction module for 2-class classification to support the rationality of setting an \"unknown\" class through negative sampling.\n\nIn summary, our evaluation involved a thorough comparison with publicly available methods and simpler baselines on benchmark datasets. This comprehensive assessment underscored the effectiveness and superiority of the KGML-xDTD model in both drug repurposing prediction and MOA prediction tasks.",
  "evaluation/confidence": "The evaluation of the proposed framework, KGML-xDTD, includes the calculation of ranking metrics such as Mean Reciprocal Rank (MRR) and Hit@K, which are presented as the mean along with the standard deviation. This approach provides a measure of confidence in the performance metrics by indicating the variability of the results across 10 independent sets of non-true-positive drug–disease candidates. The use of standard deviation helps to understand the consistency and reliability of the model's performance.\n\nThe statistical significance of the results is demonstrated through the comparison of KGML-xDTD with various baseline models. The framework consistently outperforms most baseline models in both classification-based metrics (e.g., accuracy, macro F1 score) and ranking-based metrics. This superior performance across different evaluation methods and metrics suggests that the results are statistically significant and that the method is indeed superior to the compared baselines.\n\nAdditionally, the ablation experiments conducted, such as replacing node attribute embeddings with random embeddings and modifying the drug repurposing prediction module for 2-class classification, further support the statistical significance of the results. These experiments highlight the effectiveness of specific components within the KGML-xDTD framework, reinforcing the claim that the method is robust and reliable.\n\nThe evaluation also includes the use of different replacement methods to generate non-true-positive drug–disease candidates, ensuring that the performance metrics are calculated under various conditions. This comprehensive evaluation approach strengthens the confidence in the results and the claim that KGML-xDTD is superior to other methods and baselines.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being available. However, the datasets supporting the results of this article are publicly available in the Zenodo repository. All supporting data and materials are also available in the GigaScience GigaDB database. The project's source code is available on GitHub under the MIT license, along with other licenses such as the DrugBank academic license, Apache 2.0 license, UMLS Metathesaurus license, and CC-BY 4.0 license. For specific details on the data and materials, including how to access them, you can refer to the provided repositories and databases."
}