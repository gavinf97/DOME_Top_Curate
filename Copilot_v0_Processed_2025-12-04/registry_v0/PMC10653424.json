{
  "publication/title": "A deep learning approach to predict condition-specific gene expression in fungi",
  "publication/authors": "The authors who contributed to this article are Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov.\n\nAnanthan Nambiar, Veronika Dubinkina, and Sergei Maslov were involved in the conceptualization of the study. Veronika Dubinkina was responsible for data curation. Sergei Maslov acquired the funding for the research. Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov conducted the investigation. The methodology was developed by Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov. Sergei Maslov oversaw the project administration. Ananthan Nambiar and Simon Liu developed the software. Visualization was handled by Ananthan Nambiar, Veronika Dubinkina, and Simon Liu. The original draft of the manuscript was written by Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov. All authors contributed to the review and editing of the manuscript.",
  "publication/journal": "PLOS Computational Biology",
  "publication/year": "2023",
  "publication/doi": "10.1371/journal.pcbi.1011563",
  "publication/tags": "- Deep Learning\n- Gene Expression\n- Fungi\n- Hyperparameter Optimization\n- Computational Biology\n- Bioinformatics\n- Machine Learning\n- Gene Regulation\n- Biological Networks\n- Predictive Modeling",
  "dataset/provenance": "The datasets used in this study were collected from previously published RNA-seq datasets for different fungal species. Specifically, we gathered datasets for *Saccharomyces cerevisiae*, *Neurospora crassa*, and *Issatchenkia orientalis*.\n\nThe *S. cerevisiae* dataset included 6482 genes, 208 transcription factors (TFs), and 295 different stress conditions. The *N. crassa* dataset comprised 9400 genes, 325 TFs, and 80 different combinations of growth on various carbon sources and strains with gene knockouts. The *I. orientalis* dataset was the smallest, with 4742 genes, 183 TFs, and 12 conditions of growth on different carbon sources.\n\nThese datasets have been used in previous studies and are well-known within the community. The compiled datasets provide a comprehensive resource for analyzing gene expression under various conditions, enabling the development and evaluation of predictive models like FUN-PROSE.",
  "dataset/splits": "In our study, we employed several dataset splits to rigorously evaluate the performance of the FUN-PROSE model. The primary split involved withholding 10%/20% of conditions for testing and validation, ensuring that the model had never seen these conditions during training. This setup was designed to simulate practical scenarios where the model predicts gene expression in new, untested conditions or conditions with manipulated transcription factor (TF) expression levels.\n\nAdditionally, we created a more stringent split by clustering conditions and ensuring that the test set contained conditions from clusters not represented in the training or validation sets. This approach tested the model's ability to make accurate predictions for conditions that do not resemble any in the training data.\n\nAnother split involved completely withholding some gene promoters during training. This was done to assess the model's performance in predicting the expression of novel genes with synthetic or mutated promoter sequences. This setup was the least accurate among the splits, with Pearson correlation coefficients of 0.36 for S. cerevisiae, 0.33 for N. crassa, and 0.58 for I. orientalis.\n\nFor N. crassa, we also focused on TF-knockout data to explore another potential experimental use-case of FUN-PROSE. The model's predictions for TF-knockouts were almost as accurate as its predictions for novel conditions in general.\n\nThe distribution of data points in each split varied depending on the specific evaluation scenario. For the condition-withholding split, 10%/20% of the conditions were reserved for testing and validation, while the rest were used for training. The promoter-withholding split involved withholding a subset of gene promoters, and the clustered split ensured that the test set conditions were from clusters not present in the training or validation sets.\n\nThe exact number of data points in each split is not specified here, as it depends on the specific dataset and the conditions being evaluated. However, the splits were designed to provide a comprehensive assessment of the model's performance across different scenarios.",
  "dataset/redundancy": "The datasets used in our study were split using several strategies to evaluate the performance of the FUN-PROSE model under different scenarios. One of the splits involved withholding 10%/20% of conditions for testing and validation, ensuring that the model had never seen these conditions during training. This setup was designed to mimic practical scenarios where the model predicts gene expression in new, unseen conditions or when transcription factor (TF) expression levels have been manipulated. The performance of the model in this scenario was maintained for S. cerevisiae and slightly dropped for N. crassa and I. orientalis, indicating that the model's performance depends on the similarity between the new condition and the training conditions.\n\nAnother split involved clustering the conditions and ensuring that no condition in the test set was in the same cluster as any condition in the training or validation sets. This was done to test the model's ability to make accurate predictions on conditions that do not resemble any of its training conditions. Although this clustered split showed a slight decrease in accuracy, the model still retained most of its accuracy, demonstrating its robustness.\n\nAdditionally, a split was created to completely withhold some gene promoters during training. This allowed us to assess how well the model would perform in predicting the expression of a novel gene in a given condition set. This scenario is relevant for predicting the expression of genes with synthetic or mutated promoter sequences. The performance in this setup was the least accurate, highlighting the challenge of predicting gene expression for completely novel promoters.\n\nThe distribution of the datasets used in our study is comparable to previously published machine learning datasets in the field of gene expression prediction. The datasets for S. cerevisiae, N. crassa, and I. orientalis included a diverse range of genes, transcription factors, and conditions, providing a comprehensive basis for training and evaluating the model. The clustering of conditions and the withholding of specific conditions or promoters ensured that the training and test sets were independent, enforcing the model's ability to generalize to new, unseen data.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study is a combination of Bayesian optimization and the Async Successive Halving Algorithm (ASHA) scheduler. This approach falls under the class of hyperparameter optimization techniques, which are widely used in machine learning to fine-tune model parameters for improved performance.\n\nThe algorithms used are not new; they are established methods in the field of machine learning and hyperparameter optimization. Bayesian optimization is a probabilistic model-based approach that aims to find the optimal hyperparameters by building a surrogate model of the objective function and using it to make decisions about where to sample next. ASHA, on the other hand, is a resource-efficient scheduling algorithm that dynamically allocates resources to different configurations based on their performance, allowing for more efficient hyperparameter tuning.\n\nThese algorithms were chosen for their effectiveness in handling complex search spaces and their ability to efficiently explore and exploit the hyperparameter landscape. The combination of Bayesian optimization and ASHA allows for a balanced approach, where Bayesian optimization provides a probabilistic framework for selecting promising hyperparameter configurations, and ASHA ensures that computational resources are allocated efficiently.\n\nThe focus of our publication is on the application of these optimization techniques to a specific biological problem, rather than the development of new machine-learning algorithms. Therefore, it is appropriate for this work to be published in a computational biology journal, as it demonstrates the practical application of established machine-learning methods to advance biological research.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it is a deep learning approach that directly predicts condition-specific gene expression in fungi. The model integrates promoter sequences and transcription factor expression levels to make its predictions.\n\nThe architecture consists of three main modules:\n\n1. A convolutional neural network that processes the promoter sequence.\n2. A feed-forward layer that handles the transcription factor expression levels.\n3. A multi-layer feed-forward neural network that combines the outputs of the first two modules to predict gene expression.\n\nThe convolutional neural network module includes two convolutional layers followed by max pooling, ReLU activation, dropout, and batch normalization. The feed-forward layer processes transcription factor expression levels with an ELU activation function. The final module concatenates the outputs from the previous two modules and passes them through fully-connected layers with ELU activation, dropout, and batch normalization to produce the final gene expression predictions.\n\nThe model was trained using a combination of Bayesian optimization and the Async Successive Halving Algorithm (ASHA) scheduler. The hyperparameter search was conducted on a dataset from N. crassa, and the optimal hyperparameters were then applied to other species without further tuning due to computational constraints. The model's performance was evaluated using various splits of the data, including withholding conditions and gene promoters, to assess its generalization capabilities.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, the gene-condition data was split into training, validation, and test sets. This was done by randomly withholding 10% of the elements for the validation set and 20% for the test set. The remaining 70% was used for training.\n\nThe promoter sequences, which are 1kb in length, were processed using a convolutional neural network module. This module consisted of two convolutional layers. The first layer had 256 filters with a kernel size of 9 base pairs, designed to capture relevant sequence motifs. The second layer had 64 filters with a kernel size of 13 base pairs, aimed at capturing more complex sequence patterns. Both layers used ReLU activation functions, dropout for regularization, and batch normalization.\n\nFor the transcription factor (TF) expression levels, a fully-connected layer with an ELU activation function was used. This layer processed the TF expression data, which was then concatenated with the output from the convolutional module.\n\nThe final model combined the outputs from both the promoter sequence module and the TF expression module. This concatenated output was passed through a multi-layer feed-forward neural network with three fully-connected layers, each using ELU activation, dropout, and batch normalization. The final layer predicted the expression of a particular gene.\n\nThe loss function used during training was the mean squared error of the gene expression level predictions. The AdamW optimizer was employed to minimize this loss. Hyperparameter optimization was performed using Bayesian optimization combined with the Async Successive Halving Algorithm (ASHA) scheduler, with a maximum of 250 trials. The optimal hyperparameters were selected based on the highest correlation on the withheld genes data for N. crassa. These hyperparameters were then applied to the other species without further tuning due to computational constraints.",
  "optimization/parameters": "The model's input parameters were optimized using Bayesian optimization combined with the Async Successive Halving Algorithm (ASHA) scheduler. A total of 250 trials were conducted to identify the configuration that yielded the highest correlation on the withheld genes data for N. crassa. The hyperparameter search was performed on this dataset because it was the weakest performing result.\n\nThe dataset was split into training, validation, and test sets by randomly withholding 10% of the elements for validation and 20% for testing. The optimal hyperparameters found through this search were then applied to all other species and train/test splits without further tuning due to computational constraints. Interestingly, the hyperparameters optimized for N. crassa also performed well for the other two species, suggesting the model's applicability across different fungal species.\n\nThe final model's promoter module consists of two convolutional layers. The first layer has 256 filters of 9-bp length to capture relevant sequence motifs, followed by a second layer with 64 filters of 13-bp length to capture more complex sequence patterns. The optimal kernel size for the first convolutional filter was found to be on the smaller side of the search space, while the pool kernel size for the first layer was on the larger side. This indicates that the first layer of the neural network looks for multiple short motifs and connects them over a longer range. The use of the entire 1kb sequence was determined to be the best option, suggesting that the model looks for short motifs throughout the entire promoter sequence.\n\nFor the transcription factor (TF)-processing fully-connected layer, a hidden size of 1024 was found to be optimal prior to concatenation with the convolution output. Applying dropout to both the convolutional and fully-connected layers improved the network's performance. Although some optimized hyperparameter values are at the high end of the search range, it is believed that these ranges should not be increased. For example, exceeding the 1000-bp sequence length for the promoter module is not recommended.",
  "optimization/features": "The input features for our model consist of two main types: promoter sequences and transcription factor (TF) expression levels.\n\nFor the promoter sequences, we use the entire 1kb sequence upstream of the gene's transcription start site. This sequence is processed by a convolutional neural network module designed to capture relevant sequence motifs and complex patterns.\n\nRegarding the transcription factor expression levels, we consider all putative TFs identified in the genome. Specifically, we identified 325 putative TFs in N. crassa, 208 in S. cerevisiae, and 183 in I. orientalis. These TF expression levels are fed into a fully-connected layer within our model.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, we relied on biological knowledge to define the set of TFs, using annotations from databases like DNA-binding domain database (DBD) and Fungal Transcription Factor Database (FTFD). The promoter sequence length was determined through hyperparameter optimization, where we evaluated different sequence lengths and found that using the whole 1kb sequence yielded the best results.\n\nThe hyperparameter search was conducted using a dataset from N. crassa, which was our weakest performing result. We split the gene-condition data into train, validation, and test sets by randomly withholding 10% of the elements for the validation set and 20% for the test set. The optimal hyperparameters found through this search were then applied to the other species without further tuning due to computational limitations. This approach ensured that the feature selection and hyperparameter optimization were done using the training set only, maintaining the integrity of the validation and test sets.",
  "optimization/fitting": "The model architecture and fitting method were designed to balance complexity and generalization to avoid both overfitting and underfitting. The neural network consists of three main modules: a convolutional neural network for processing promoter sequences, a feed-forward layer for transcription factor expression levels, and a multi-layer feed-forward neural network for combining these inputs. The convolutional layers have 256 and 64 filters respectively, with kernel sizes of 9 and 13, followed by max-pooling layers. Dropout and batch normalization were applied to both convolutional and fully-connected layers to mitigate overfitting.\n\nTo ensure the model did not underfit, we performed extensive hyperparameter optimization using Bayesian optimization combined with the Async Successive Halving Algorithm (ASHA) scheduler. This process involved 250 trials, selecting the configuration with the highest correlation on the withheld genes data for N. crassa. The optimal hyperparameters were then applied to other species without further tuning due to computational constraints, demonstrating the model's generalizability.\n\nEarly stopping was implemented during training to prevent overfitting. Training was halted if the validation correlation coefficient did not improve for 5 consecutive epochs. Additionally, trials were stopped early if they reached a plateau, defined by a standard deviation of the validation correlation coefficient not exceeding 0.01 in the final 5 epochs. This approach ensured that the model did not memorize the training data but rather learned general patterns.\n\nThe dataset was split into training, validation, and test sets by randomly withholding 10% for validation and 20% for testing. This split helped in evaluating the model's performance on unseen data, further ensuring that the model generalized well. The use of dropout and batch normalization, along with early stopping and thorough hyperparameter tuning, collectively helped in managing the risk of overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and improve the generalization of our model. One of the key methods used was dropout, which was applied to both the convolutional and fully-connected layers. Dropout works by randomly setting a fraction of the layer's outputs to zero during training, which helps to prevent the model from becoming too reliant on any single neuron and encourages it to learn more robust features.\n\nAdditionally, we used batch normalization, which normalizes the inputs of each layer to have a mean of zero and a standard deviation of one. This technique helps to stabilize and accelerate the training process, and it also acts as a form of regularization by reducing the internal covariate shift.\n\nWe also utilized early stopping during both the hyperparameter optimization and the final model training. Early stopping monitors the validation performance and halts the training process if the performance does not improve for a specified number of epochs. This helps to prevent the model from overfitting to the training data by stopping the training process at the point of optimal generalization.\n\nFurthermore, we employed the AdamW optimizer, which includes weight decay as a form of regularization. Weight decay adds a penalty term to the loss function that is proportional to the magnitude of the weights, encouraging the model to learn smaller weights and thereby reducing the risk of overfitting.",
  "optimization/config": "The hyperparameter configurations and optimization schedule used in our study are reported in detail. The search space and the best hyperparameters identified are provided in a table, which includes ranges and specific values for various parameters such as promoter sequence length, batch size, learning rate, weight decay, kernel sizes, and dropout rates. This information is crucial for reproducibility and allows other researchers to understand the optimization process.\n\nThe model architecture, including the convolutional and fully-connected layers, is described comprehensively. The final model's promoter module consists of two convolutional layers with specified kernel sizes and numbers, followed by pooling layers, activation functions, dropout, and batch normalization. The feed-forward layer processes transcription factor expression levels, and the final module concatenates the outputs of the previous modules to predict gene expression.\n\nRegarding the availability of model files and optimization parameters, specific details about the software and hardware used during hyperparameter optimization and model training are provided. This includes the use of Ray, PyTorch, and CUDA, as well as the types of GPUs employed. However, the actual model files and optimization parameters are not explicitly mentioned as being available for download. The study focuses on describing the methods and results rather than providing direct access to the files.\n\nThe license under which the configurations and schedules are made available is not specified. Typically, scientific publications do not include explicit licensing information for the methods and results described, as they are intended to be used for research purposes without restriction. Researchers interested in replicating the study would need to refer to the methods section and any supplementary materials provided.",
  "model/interpretability": "Our model, FUN-PROSE, is designed with interpretability in mind, making it more transparent than a typical black-box model. We have incorporated several mechanisms to extract and understand the biological information used by the model to make predictions.\n\nFirstly, we have used convolutional neural network (CNN) layers to process promoter sequences. These layers are particularly useful for identifying sequence motifs, which are short DNA sequences that are recognized by transcription factors (TFs). By examining the filters in the first convolutional layer, we can infer the promoter motifs that the model has learned. These motifs are analogous to transcription factor binding motifs (TFBMs) and can provide insights into the regulatory mechanisms of gene expression.\n\nSecondly, we have employed a technique called Integrated Gradients to interpret the fully-connected layers of our model. This technique allows us to attribute the model's predictions to its inputs, in this case, the expression levels of TFs. By doing so, we can generate a list of TF-target gene interactions, effectively constructing a gene regulatory network (GRN) for each species. This GRN can help us understand the role of different TFs in regulating gene expression under specific conditions.\n\nMoreover, we have compared the sequence motifs and regulatory interactions discovered by our model to existing biological knowledge, particularly for the well-studied species Saccharomyces cerevisiae. A significant fraction of our predictions overlapped with known TF binding sites or regulatory interactions, which suggests that our model is using biologically relevant information to make its predictions.\n\nIn addition, we have shown that our model can be used to generate novel biological hypotheses for less studied species. For instance, we independently discovered sequence motifs similar to those recognized by the TF Azf1 in all three species we studied. Azf1 is known to be involved in carbon metabolism and energy production, which is consistent with the conditions used for our model training.\n\nFurthermore, we have demonstrated that including 3’-UTR sequences as an additional input to our model can improve its accuracy. This suggests that our model can capture complex regulatory mechanisms, including those involving mRNA degradation.\n\nIn summary, while our model is complex and involves deep learning techniques, it is not a black-box. We have incorporated several interpretability mechanisms that allow us to understand the biological information used by the model to make predictions. This makes our model a valuable tool for both extracting new biological knowledge and for practical applications, such as manipulating gene expression levels.",
  "model/output": "The model, FUN-PROSE, is designed for regression rather than classification. It predicts the relative expression level of a gene in a specific condition, which is a continuous value. The output is the deviation of gene expression in a particular condition from the average expression level of that gene, standardized to have a mean of 0 and a standard deviation of 1. This is achieved by predicting the Z-score of the log-transformed gene expression calculated across all conditions in the dataset. The model's performance is evaluated using the Pearson correlation coefficient between the predicted and true gene expression levels, indicating its effectiveness in regression tasks. The model's architecture, which includes convolutional and fully-connected layers, is tailored to process promoter sequences and transcription factor expression levels to make these continuous predictions.",
  "model/duration": "The execution time for our model varied depending on the stage of the process. During hyperparameter optimization, each trial was allowed a maximum of 20 epochs, with a minimum of 5 epochs before stopping. Trials could also be stopped early if they reached a plateau, defined by the standard deviation of the validation correlation coefficient not exceeding 0.01 in the final 5 epochs. This optimization process involved 250 trials and was conducted using an NVIDIA V100 GPU with 16GB of RAM, utilizing automatic mixed-precision training to enhance efficiency.\n\nFor the final model training, we allowed a maximum of 60 epochs, with early stopping triggered if the validation correlation coefficient did not improve for 5 consecutive epochs. This training phase was performed on a NVIDIA GeForce GTX 1080 Ti GPU. The specific execution time for each epoch would depend on the dataset size and the complexity of the model, but the use of powerful GPUs and mixed-precision training helped to accelerate the process.",
  "model/availability": "The source code for the simulations used in this manuscript is publicly available. It can be accessed on GitHub at the repository named FUN-PROSE, maintained by the maslov-group. This repository contains all the code and processed data necessary for running the simulations. The software is distributed under the terms of the Creative Commons Attribution License, which allows for unrestricted use, distribution, and reproduction, provided that the original authors and source are credited.",
  "evaluation/method": "The evaluation of FUN-PROSE involved several rigorous methods to assess its performance in predicting condition-specific gene expression in fungi. Initially, the model's performance was evaluated using a standard split where 10%/20% of conditions were withheld for testing and validation. This setup allowed the model to predict gene expression in new, unseen conditions, simulating practical scenarios where the model is applied to conditions not previously tested experimentally. The performance metrics, specifically the Pearson correlation between predicted and observed gene expression, were reported for three species: S. cerevisiae, N. crassa, and I. orientalis.\n\nTo further challenge the model, an additional split was created where conditions were clustered, and the test set was ensured to contain conditions that did not resemble any in the training set. This clustered split demonstrated the model's ability to generalize to entirely new conditions, although a slight decrease in accuracy was observed. The correlation coefficients for this split were also reported, showing that FUN-PROSE maintained a significant level of accuracy despite the more stringent evaluation.\n\nAnother evaluation method involved completely withholding some gene promoters during training. This approach assessed the model's capability to predict the expression of novel genes with synthetic or mutated promoter sequences. This setup was the least accurate among the evaluated splits, with reported Pearson correlation coefficients for each species.\n\nAdditionally, the model's performance was compared to a simpler Nearest Neighbor Regression model, which achieved lower correlation coefficients, highlighting FUN-PROSE's superior predictive power. The evaluation also included an analysis of the model's performance on TF-knockout data, showing that FUN-PROSE could predict the effects of TF-knockouts almost as well as it predicted the effects of novel conditions.\n\nOverall, the evaluation methods provided a comprehensive assessment of FUN-PROSE's performance, demonstrating its robustness and accuracy in predicting condition-specific gene expression across different fungal species and experimental scenarios.",
  "evaluation/measure": "In our evaluation of FUN-PROSE, we primarily focused on the Pearson correlation coefficient between predicted and observed gene expression levels. This metric is widely used in the literature for evaluating the performance of predictive models in gene expression studies, making it a representative and comparable measure.\n\nWe reported the Pearson correlation coefficients for different train/test splits to assess the model's performance under various conditions. These splits included scenarios where a portion of the conditions or gene promoters were withheld from the training set, simulating practical situations where the model predicts gene expression in new, unseen conditions or for novel genes.\n\nAdditionally, we compared FUN-PROSE's performance to a simpler Nearest Neighbor Regression model, which achieved lower correlation coefficients. This comparison further highlights the effectiveness of our model.\n\nTo provide a baseline for what a very good model would achieve, we plotted a scatterplot comparing replicates of the N. crassa data, finding a correlation of 0.79. This serves as a benchmark for evaluating the upper limit of predictive performance.\n\nIn summary, the Pearson correlation coefficient is our main performance metric, and it is complemented by comparisons to simpler models and baseline correlations from replicate data. This set of metrics is representative and aligns with standard practices in the field.",
  "evaluation/comparison": "In our evaluation, we compared the performance of FUN-PROSE to a simpler baseline model, specifically a Nearest Neighbor Regression model. This comparison was conducted to provide a benchmark for what a very good model would achieve. The Nearest Neighbor Regression model achieved correlation coefficients of 0.39 for S. cerevisiae and 0.31 for N. crassa. These results highlight the superior performance of FUN-PROSE, which achieved correlation coefficients of 0.85 for S. cerevisiae, 0.72 for N. crassa, and 0.81 for I. orientalis. This comparison demonstrates that FUN-PROSE significantly outperforms simpler baselines, indicating its robustness and effectiveness in predicting condition-specific gene expression across different fungal species.\n\nAdditionally, we evaluated FUN-PROSE under more stringent conditions to assess its generalizability. One such evaluation involved withholding 10%/20% of conditions for test and validation, ensuring that the model had never seen these conditions during training. This setup allowed us to evaluate how well FUN-PROSE performs in practical scenarios where it predicts gene expression in new, unseen conditions. The model's performance remained consistent for S. cerevisiae and showed a slight drop to 0.68 and 0.58 Pearson correlation for N. crassa and I. orientalis, respectively. This drop in performance is expected to depend on how different the new, unseen conditions are from those used in the training set.\n\nFurthermore, we created an additional split to test FUN-PROSE's ability to predict the expression of unseen conditions that do not resemble any of its training conditions. We clustered the conditions and ensured that no condition in the test set was in the same cluster as any condition in the train or validation sets. Although this clustered split showed a slight decrease in accuracy, FUN-PROSE still maintained most of its accuracy with correlation coefficients of 0.70 for S. cerevisiae and 0.56 for N. crassa. This evaluation underscores FUN-PROSE's capability to generalize to new, unseen conditions, even when they differ significantly from the training data.",
  "evaluation/confidence": "In our evaluation, we employed several statistical methods to ensure the confidence and significance of our results. We used a hypergeometric statistical test to assess the significance of our findings, with a Benjamini-Hochberg false discovery rate (FDR) correction applied to maintain a significance level of α = 0.05. This approach helps to control for false positives, providing a robust measure of statistical significance.\n\nTo evaluate the performance of our model, FUN-PROSE, we compared it against a baseline Nearest Neighbor Regression model. The results showed that FUN-PROSE significantly outperformed the baseline model across different species. For instance, FUN-PROSE achieved correlation coefficients of 0.70 and 0.56 for Saccharomyces cerevisiae and Neurospora crassa, respectively, compared to the baseline model's coefficients of 0.39 and 0.31. These differences are statistically significant, indicating that FUN-PROSE's performance is superior.\n\nWe also conducted rigorous splits of the data to evaluate model performance under various conditions. One such split involved withholding 10%/20% of conditions for testing and validation, ensuring that the model had never seen these conditions during training. This setup allowed us to assess how well FUN-PROSE generalizes to new, unseen conditions. The model's performance remained consistent for S. cerevisiae and showed a slight drop for N. crassa and Issatchenkia orientalis, which is expected given the variability in the new conditions.\n\nAdditionally, we performed a clustered split where conditions in the test set were ensured to be from different clusters than those in the training set. This further tested the model's ability to predict gene expression in conditions that do not resemble any in the training set. Despite a slight decrease in accuracy, FUN-PROSE maintained a high level of performance, demonstrating its robustness.\n\nIn summary, our evaluation metrics are supported by statistical tests that ensure the significance of our results. The performance of FUN-PROSE is not only superior to baseline models but also consistent across different evaluation scenarios, providing confidence in its predictive capabilities.",
  "evaluation/availability": "The raw evaluation files are not directly available. However, all code and processed data for simulations used in this manuscript can be found on GitHub. This includes the necessary information to reproduce the evaluations and results presented in the publication. The data is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. This ensures that researchers can access and utilize the data for further studies or validations."
}