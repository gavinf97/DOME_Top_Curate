{
  "publication/title": "Large-scale genomic survey with deep learning-based method reveals strain-level phage specificity determinants",
  "publication/authors": "The authors who contributed to this article are:\n\n- **Y. Y.** contributed to data curation, formal analysis, methodology, software development, visualization, and writing both the original draft and the review & editing.\n- **K. D.** contributed to data curation, formal analysis, and writing both the original draft and the review & editing.\n- **W. Y.** contributed to data curation and formal analysis.\n- **T. C.** contributed to methodology.\n- **L. X.** contributed to methodology.\n- **X. J.** contributed to conceptualization, supervision, methodology, software development, and writing both the original draft and the review & editing.\n\nThe authors acknowledge Dr. Audrey Burnim for help with visualizing protein structures and Hui Yi for assistance with statistical approaches used in the study.",
  "publication/journal": "GigaScience",
  "publication/year": "2024",
  "publication/doi": "10.1093/gigascience/giae017",
  "publication/tags": "- Tailspike proteins\n- Phage therapy\n- Bacterial genomes\n- Deep learning\n- Protein identification\n- Serotyping\n- Bioinformatics\n- Machine learning\n- Genomic survey\n- Phage-host interactions\n- Computational biology\n- Protein structure prediction\n- Pathogen detection\n- Cross-species analysis\n- Phage specificity",
  "dataset/provenance": "The dataset used in our study was compiled from the INPHARED database. This dataset included a reference set of 1,912 tailspike protein sequences and 200,732 non-tailspike protein sequences. These sequences were curated to ensure a comprehensive and diverse representation of tailspike proteins.\n\nThe dataset was partitioned into training, validation, and testing sets at a ratio of 3:1:1. This partitioning was conducted to preserve an equivalent proportion of positive samples across each set and to ensure that no sequence within a particular set displayed over 30% identity with a sequence in another set. This careful partitioning helped in maintaining the integrity and reliability of our model's performance evaluation.\n\nAdditionally, we utilized an independent testing set consisting of 100,081 phage proteins from 96 phages that infect 403 strains of the Escherichia genus. Within this independent dataset, 81 curated tailspike proteins were designated as positive samples, and the rest were categorized as negative samples. This independent dataset provided an additional layer of validation for our model's performance.\n\nThe sequences were clustered into 20,274 clusters at 30% identity using CD-HIT, ensuring that each cluster contained only tailspike or non-tailspike proteins, with no mixed clusters observed. This clustering approach helped in maintaining the homogeneity of the dataset and improved the model's ability to distinguish between tailspike and non-tailspike proteins.\n\nThe training set comprised 122,506 proteins, including 1,023 positive samples and 121,483 negative samples belonging to 12,170 clusters. The validation set consisted of 40,838 proteins, with 343 positive samples and 40,495 negative samples belonging to 4,054 clusters. The testing set included 39,300 proteins, with 546 positive samples and 38,754 negative samples belonging to 4,050 clusters.\n\nThis dataset has been used in previous research and by the community to study phage proteins and their interactions with bacterial strains. The curated and clustered dataset ensures that our findings are robust and reproducible, contributing to the broader understanding of tailspike proteins and their identification.",
  "dataset/splits": "The dataset was partitioned into three distinct splits: training, validation, and testing. The training set consists of 122,506 proteins, which includes 1,023 positive samples and 121,483 negative samples. The validation set comprises 40,838 proteins, with 343 positive samples and 40,495 negative samples. The testing set contains 39,300 proteins, including 546 positive samples and 38,754 negative samples.\n\nThe partitioning was conducted to preserve an equivalent proportion of positive samples across each set and to ensure that no sequence within a particular set displayed over 30% identity with a sequence in another set. This approach helps in maintaining the integrity and diversity of the data, ensuring that the model generalizes well to unseen data.",
  "dataset/redundancy": "The datasets were split into training, validation, and testing sets at a ratio of 3:1:1. This partitioning was conducted to preserve an equivalent proportion of positive samples across each set. To ensure independence between the sets, no sequence within a particular set displayed over 30% identity with a sequence in another set. This measure was taken to prevent data leakage and to ensure that the model's performance was evaluated on truly independent data.\n\nThe distribution of the datasets is as follows: the training set consists of 122,506 proteins, with 1,023 positive samples and 121,483 negative samples. The validation set comprises 40,838 proteins, with 343 positive samples and 40,495 negative samples. The testing set includes 39,300 proteins, with 546 positive samples and 38,754 negative samples.\n\nCompared to previously published machine learning datasets, the approach taken here is rigorous in ensuring dataset independence. The use of a 30% identity threshold to separate sequences into different sets is a stringent measure that helps to mitigate overfitting and ensures that the model generalizes well to unseen data. This method is particularly important in biological datasets, where sequences can be highly similar, and without such precautions, the model might memorize the training data rather than learning generalizable features.",
  "dataset/availability": "The data underlying this article is available in the article and its online supplementary material. The tailspike protein IDs, along with their corresponding clusters at various protein identities, are provided on GitHub. The tailspike protein clusters identified in our research have been compiled into a database, which can be accessed publicly. An archival copy of the code and supporting data, also including DOME-ML annotations, are available via the GigaScience database, GigaDB. The data is released under the MIT license, ensuring that it can be freely used, modified, and distributed. The availability of these resources ensures that the data splits used, including the training, validation, and testing datasets, are transparent and accessible to the scientific community. This transparency is enforced through the public availability of the data and code, allowing for reproducibility and further research.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Adam optimizer, which is a widely-used and well-established algorithm in the field of machine learning. Adam, which stands for Adaptive Moment Estimation, is a stochastic gradient descent method that has been designed specifically for training deep neural networks. It combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSProp.\n\nAdam is not a new algorithm; it was introduced by Diederik P. Kingma and Jimmy Ba in their 2014 paper \"Adam: A Method for Stochastic Optimization.\" Given its widespread use and recognition in the machine learning community, it was not necessary to publish it in a machine-learning journal.\n\nThe choice of Adam optimizer was driven by its efficiency and effectiveness in handling sparse gradients on noisy problems. It computes adaptive learning rates for each parameter, which allows for faster convergence and better performance, especially in high-dimensional parameter spaces. This makes it particularly suitable for the complex tasks involved in our research, such as identifying tailspike proteins in bacterial genomes.\n\nIn our implementation, we utilized the PyTorch framework, which provides a robust and efficient implementation of the Adam optimizer. This allowed us to leverage the optimizer's capabilities to train our deep learning models effectively. The parameters of the ESM-2 model were frozen during training, ensuring that the optimization process focused on the fully connected layers of our neural network architecture.",
  "optimization/meta": "The SpikeHunter model does not function as a meta-predictor. It is a standalone deep learning model specifically designed for the identification of tailspike proteins in phage sequences. The model architecture is built using the PyTorch framework and leverages a pre-trained transformer protein language model, ESM-2, to embed protein sequences into representative vectors. These vectors are then processed through a fully connected neural network with four layers to predict the probability of a sequence being a tailspike protein.\n\nThe training data for SpikeHunter was meticulously curated to ensure independence. A manually curated set of phage proteins, including both tailspike and non-tailspike proteins, was clustered using CD-HIT to ensure that sequences within the training, validation, and testing datasets did not share more than 30% identity. This clustering process helped maintain the independence of the datasets, preventing data leakage and ensuring robust model evaluation.\n\nThe model's performance was evaluated using various metrics such as accuracy, precision, recall, specificity, F1-score, and Matthew's correlation coefficient. The training process included early stopping to prevent overfitting, and the model with the lowest validation loss was selected for testing and prediction. This approach ensures that the model's performance is reliable and generalizable to new, unseen data.",
  "optimization/encoding": "The data encoding process for SpikeHunter involved several key steps to prepare protein sequences for input into the machine-learning model. Initially, phage sequences were tokenized and transformed into numerical vectors using the batch_converter function from the ESM Python package. This transformation is crucial as it converts the raw amino acid sequences into a format that the model can process.\n\nFollowing tokenization, the sequences were embedded into 1,280-length representations using a pre-trained transformer protein language model, specifically ESM-2 (esm2_t33_650M_UR50D). This embedding step leverages the model's ability to capture complex patterns and features within the protein sequences, providing a rich representation that aids in subsequent classification tasks.\n\nThe embedded sequences were then fed into a fully connected neural network consisting of four layers with 1,280, 568, 128, and 2 nodes, respectively. The output from the final layer was converted into a probability using a softmax activation function, indicating the likelihood of each sequence being a tailspike protein.\n\nTo ensure the model's robustness, several preprocessing steps were undertaken. The dataset was clustered into 20,274 clusters at 30% identity using CD-HIT, ensuring that each cluster contained only tailspike or non-tailspike proteins, with no mixed clusters. This clustering helped in maintaining the integrity of the data and preventing overfitting. The sequences were then divided into training, validation, and testing datasets in a 3:1:1 ratio using the Stratified-GroupKFold function in the Scikit-learn package. This division ensured an equivalent proportion of positive samples across each set and maintained a low sequence identity between sets, further enhancing the model's generalizability.\n\nEarly stopping was implemented during training to halt the process when the model's performance on the validation dataset did not improve for three consecutive epochs. This technique helped in preventing overfitting and ensured that the model generalized well to unseen data. The model with the lowest validation loss was selected for testing and prediction, ensuring optimal performance.",
  "optimization/parameters": "The model architecture of SpikeHunter consists of a fully connected neural network with four layers. The input layer has 1,280 nodes, corresponding to the length of the representations generated by the ESM-2 model. This is followed by two hidden layers with 568 and 128 neurons, respectively. The final layer has 2 nodes, representing the output probabilities for the two classes: tailspike protein or not.\n\nThe total number of parameters in the model is determined by the connections between these layers. Each neuron in a layer is connected to every neuron in the subsequent layer, with each connection having an associated weight. Additionally, each neuron has a bias term. The number of parameters can be calculated as follows:\n\n- From the input layer to the first hidden layer: (1,280 * 568) + 568\n- From the first hidden layer to the second hidden layer: (568 * 128) + 128\n- From the second hidden layer to the output layer: (128 * 2) + 2\n\nSumming these up gives the total number of parameters in the model.\n\nThe selection of the number of neurons in each layer was based on empirical testing and ablation studies. The architecture was designed to balance model complexity and performance. The 128-neuron layer was found to be more critical to the model's performance than the 568-neuron layer, indicating that the features extracted from this layer are more useful for classification. The ESM-2 model, used for embedding the input sequences, was also found to be a key contributor to the model's performance, suggesting that the structural features of the tailspike protein are essential for reliable identification.",
  "optimization/features": "The input features for the SpikeHunter model are derived from protein sequences, which are first tokenized and transformed into numerical vectors. These sequences are then embedded using a pre-trained transformer protein language model, specifically ESM-2 (esm2_t33_650M_UR50D), resulting in a 1,280-length representation for each sequence. This means that the number of input features (f) is 1,280.\n\nFeature selection was not explicitly performed in the traditional sense, as the model relies on the embeddings generated by the ESM-2 model. These embeddings are designed to capture relevant features from the protein sequences, making additional feature selection unnecessary. The use of pre-trained models like ESM-2 ensures that the input features are already optimized for the task of protein classification.\n\nThe training process involved splitting the dataset into training, validation, and testing sets using the Stratified-GroupKFold function. This splitting ensures that the model's performance is evaluated on independent data, and the validation set is used to monitor the model's performance during training. Early stopping is employed to halt training when the model's performance on the validation set does not improve for three consecutive epochs, preventing overfitting. The model with the lowest validation loss is then used for testing and prediction. This approach ensures that the model's performance is robust and generalizable to new data.",
  "optimization/fitting": "The model training process for SpikeHunter involved several strategies to address potential overfitting and underfitting issues. The training dataset consisted of 122,506 proteins, which included 1,023 positive samples and 121,483 negative samples. This dataset was partitioned into training, validation, and testing sets in a 3:1:1 ratio, ensuring that the proportion of positive samples was preserved across each set.\n\nTo mitigate overfitting, early stopping was employed. Training was halted if the model's performance on the validation dataset did not improve for three consecutive epochs. This approach ensured that the model did not memorize the training data but rather generalized well to unseen data. Additionally, the parameters of the ESM-2 model were frozen during training, which helped in preventing the model from overfitting to the specific training data.\n\nThe model architecture included a fully connected neural network with four layers, having 1280, 568, 128, and 2 nodes respectively. The use of dropout layers with a 0.2 dropout ratio in each linear layer further helped in regularizing the model and reducing overfitting.\n\nTo address potential underfitting, ablation studies were conducted. These studies involved modifying the model architecture by removing the 568-neuron hidden layer and the 128-neuron hidden layer, as well as substituting the pretrained ESM-2 model with another model, SeqVec. The results indicated that the 128-neuron layer was more critical for the model's performance, suggesting that the features extracted from this layer were more useful for classification. The ESM-2 encoder was found to be a key contributor to the model's performance, highlighting the importance of structural features in tailspike protein identification.\n\nFurthermore, the model was evaluated on an independent testing set consisting of 100,081 phage proteins, with 81 designated as positive samples. The model achieved high performance metrics, including an F1-score of 0.99985, precision of 1.0, recall of 0.99970, and specificity of 1.0. These results demonstrated that the model was not underfitting and could generalize well to new, unseen data.\n\nIn summary, the training process for SpikeHunter included strategies such as early stopping, parameter freezing, dropout layers, and ablation studies to address overfitting and underfitting. The model's performance on both the validation and independent testing datasets indicated that it was well-fitted and capable of generalizing to new data.",
  "optimization/regularization": "In our study, we implemented several techniques to prevent overfitting and ensure the robustness of our model. One of the primary methods used was early stopping. During the training process, we monitored the model's performance on a validation dataset. If the model's performance did not improve for three consecutive epochs, the training was halted. This approach helped to avoid overfitting by preventing the model from becoming too specialized to the training data.\n\nAdditionally, we conducted ablation studies to evaluate the impact of different components of our model. These studies included removing specific hidden layers and substituting the pre-trained ESM-2 encoder with another model, SeqVec. The results of these studies provided insights into the importance of each component and helped to refine the model architecture, further reducing the risk of overfitting.\n\nWe also addressed data imbalance by oversampling positive samples in the training and validation datasets. This created a balanced dataset with an equal number of positive and negative samples. The comparison between models trained on the original dataset and the balanced dataset revealed minor changes in performance, suggesting that data imbalance did not significantly impact the model's performance. This step ensured that the model was not biased towards the majority class, thereby enhancing its generalization capabilities.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are available. The SpikeHunter model and its associated code can be accessed on GitHub at the repository https://github.com/nlm-irp-jianglab/SpikeHunter. This repository includes the model architecture, training scripts, and other necessary files to replicate the experiments and use the model for identifying phage tailspike proteins.\n\nThe project is licensed under the MIT license, which allows for free use, modification, and distribution of the software, subject to the terms of the license. This ensures that researchers and developers can access, use, and build upon the work presented in the publication.\n\nAdditionally, snapshots of the code are archived in Software Heritage, providing a permanent record of the software at specific points in time. This archiving ensures the reproducibility and long-term accessibility of the research.\n\nThe optimization parameters used during training, such as the cross-entropy loss function and the Adam optimizer with frozen ESM-2 model parameters, are also detailed in the publication. The training process included early stopping based on validation performance, which helps in preventing overfitting and ensures that the model generalizes well to unseen data.\n\nFor detailed information on the environment and dependencies required to run the code, users can refer to the environment.yml file available in the GitHub repository. This file specifies the necessary Python packages and their versions, ensuring that the software can be easily set up and run in a consistent environment.",
  "model/interpretability": "The SpikeHunter model is primarily a black-box model, as it leverages deep learning techniques to predict whether a protein sequence is a tailspike protein. The core of the model is a fully connected neural network with multiple layers, which processes embeddings generated by a pre-trained transformer protein language model. This architecture makes it challenging to directly interpret the decision-making process of the model.\n\nHowever, some aspects of the model's interpretability can be inferred from the ablation studies conducted. These studies involved modifying the model's architecture to understand the contribution of different components. For instance, removing the 128-neuron hidden layer resulted in a decrease in performance metrics, indicating the importance of this layer in the classification task. This suggests that the features extracted by this layer are crucial for the model's predictions.\n\nAdditionally, substituting the pre-trained ESM-2 model with another model, SeqVec, which focuses less on structure, led to a significant decline in performance. This finding highlights the importance of structural features in tailspike protein identification, providing some insight into what the model might be focusing on.\n\nWhile these studies offer some clues about the model's behavior, they do not fully open the black box. The model's decisions remain largely opaque, and further work would be needed to develop more interpretable versions or to use techniques like SHAP (SHapley Additive exPlanations) or LIME (Local Interpretable Model-agnostic Explanations) to gain deeper insights into the model's predictions.",
  "model/output": "The model, SpikeHunter, is designed for classification rather than regression. It specifically focuses on identifying whether a given protein sequence is a tailspike protein or not. The model outputs a probability indicating the likelihood of a sequence being a tailspike protein. This probability is derived from a softmax activation function applied to the output of the final layer in the neural network. The classification is binary, with the model providing a clear distinction between tailspike and non-tailspike proteins. The performance metrics, such as precision, recall, F1-score, and specificity, further support the model's classification capabilities, demonstrating its accuracy and reliability in distinguishing between the two types of proteins.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the software developed in this study is publicly available. The project, named SpikeHunter, is a deep learning tool designed for identifying phage tailspike proteins. It can be accessed via the project's homepage on GitHub at https://github.com/nlm-irp-jianglab/SpikeHunter. The repository includes both the model and the code necessary to run the algorithm.\n\nThe software is compatible with Linux or other Unix-like operating systems and is programmed in Python. Additional requirements for running the software can be found in the environment.yml file within the repository. The software is released under the MIT license, which allows for free use, modification, and distribution, subject to the terms of the license.\n\nSnapshots of the code are also archived in Software Heritage, ensuring long-term preservation and accessibility. This archiving provides an additional layer of reliability and transparency for users who wish to verify the code or use it in their own research.\n\nFor those who prefer not to set up the environment locally, the tailspike protein IDs and their corresponding clusters at various protein identities are provided at https://github.com/nlm-irp-jianglab/TSP_paper/blob/main/data/TSP_ids_and_clusters.txt. This data can be used to validate the findings or integrate them into other research projects.",
  "evaluation/method": "The evaluation of the SpikeHunter model involved several rigorous steps to ensure its accuracy and reliability. Initially, the model was trained and validated using a curated dataset of phage proteins, which was divided into training, validation, and testing sets in a 3:1:1 ratio. This partitioning was done using the Stratified-GroupKFold function to maintain an equivalent proportion of positive samples across each set and to ensure that no sequence within a particular set displayed over 30% identity with a sequence in another set.\n\nEarly stopping was employed during training to prevent overfitting, halting the process when the model's performance on the validation dataset did not improve for three consecutive epochs. The model with the lowest validation loss was then selected for testing and prediction.\n\nThe performance of SpikeHunter was evaluated using various metrics, including accuracy, precision, recall, specificity, F1-score, and Matthew's correlation coefficient (MCC). These metrics were calculated on both the testing dataset and an independent dataset consisting of 100,081 phage proteins, with 81 designated as positive samples. The model demonstrated high performance, achieving an F1-score of 0.99991, precision of 0.99995, recall of 0.99987, specificity of 0.99634, and an MCC of 0.99352 on the testing dataset. On the independent dataset, it achieved an F1-score of 0.99985, precision of 1.0, recall of 0.99970, specificity of 1.0, and an MCC of 0.98183.\n\nAdditionally, ablation studies were conducted to analyze the impact of different components within the model. These studies involved modifying the architecture by removing specific hidden layers, integrating dropout layers, and substituting the pretrained ESM-2 encoder with the SeqVec encoder. The performance of these modified models was evaluated using the same metrics, providing insights into the importance of each component.\n\nThe evaluation also included an investigation into the effect of data imbalance on model performance. By oversampling positive samples in the training and validation datasets to create a balanced dataset, the impact of data imbalance was assessed. The results indicated that data imbalance did not significantly affect the model's performance, with only minor changes observed in the F1-score and specificity.\n\nOverall, the evaluation process was comprehensive, utilizing both standard metrics and novel experiments to ensure the robustness and reliability of the SpikeHunter model.",
  "evaluation/measure": "In the evaluation of SpikeHunter, several performance metrics were reported to provide a comprehensive assessment of the model's effectiveness. The primary metrics included the F1-score, precision, recall, specificity, and the Matthews correlation coefficient (MCC). Additionally, the area under the precision-recall curve (PRAUC) was also evaluated.\n\nThe F1-score, which is the harmonic mean of precision and recall, was reported to be exceptionally high, indicating a strong balance between the model's precision and recall. Precision measures the accuracy of the positive predictions made by the model, while recall assesses the model's ability to identify all relevant instances. Specificity, which evaluates the model's ability to correctly identify negative instances, was also reported. The MCC provides a balanced measure of the quality of binary classifications, considering all four quadrants of the confusion matrix.\n\nThe PRAUC was evaluated to assess the model's performance across different threshold levels, providing a more nuanced understanding of its precision-recall trade-off. These metrics collectively offer a robust evaluation framework, aligning with common practices in the literature for assessing classification models, particularly in bioinformatics and machine learning applications. The high values achieved in these metrics underscore the model's reliability and accuracy in identifying tailspike proteins.",
  "evaluation/comparison": "In the evaluation of SpikeHunter, we conducted a thorough comparison with publicly available methods and simpler baselines to assess its performance comprehensively. We utilized benchmark datasets to ensure a fair and rigorous evaluation.\n\nOne of the key comparisons involved substituting the pretrained ESM-2 model in SpikeHunter with another pretrained model, SeqVec. This model focuses less on structure for embedding the input sequences. The results showed a significant decline in performance metrics, with a 6.59% reduction in F1-score and a 0.09% decrease in specificity. This finding underscores the critical role of the ESM-2 encoder in SpikeHunter's performance, highlighting that the structural features of the tailspike protein are essential for reliable identification.\n\nAdditionally, we performed ablation studies to analyze the impact of different components within the model. These studies included removing specific hidden layers and integrating dropout layers. The removal of the 128-neuron hidden layer led to decreases in both F1-score and specificity, indicating its greater importance compared to the 568-neuron layer. This suggests that the features extracted from the 128-neuron layer are more useful for classification tasks.\n\nFurthermore, we evaluated the model's performance on an independent testing set consisting of 100,081 phage proteins, with 81 designated as positive samples. SpikeHunter achieved high performance metrics, including an F1-score of 0.99985, precision of 1.0, recall of 0.99970, specificity of 1.0, and an area under the precision-recall curve (PRAUC) of 0.99985. These results demonstrate SpikeHunter's accuracy and sensitivity in identifying tailspike proteins.\n\nOverall, the comparisons with publicly available methods and simpler baselines, along with the ablation studies, provide a comprehensive evaluation of SpikeHunter's performance and highlight its strengths in tailspike protein identification.",
  "evaluation/confidence": "The evaluation of SpikeHunter's performance was conducted using a variety of metrics, including F1-score, precision, recall, specificity, and the area under the precision-recall curve (PRAUC). These metrics were calculated on both the testing dataset and an independent testing set. The results demonstrated high performance, with metrics such as F1-score, precision, and recall all exceeding 0.99 on the testing dataset. This indicates a high level of accuracy and sensitivity in identifying tailspike proteins.\n\nThe statistical significance of these results was not explicitly detailed in terms of confidence intervals. However, the use of early stopping during training, which halts the process when performance on the validation dataset no longer improves for three consecutive epochs, suggests a robust approach to preventing overfitting. This method ensures that the model's performance is reliable and not merely a result of memorizing the training data.\n\nAdditionally, the evaluation included ablation studies, where different components of the model were modified to assess their impact on performance. These studies provided insights into the importance of specific layers and the pretrained ESM-2 model, further validating the robustness of SpikeHunter. The consistent high performance across different modifications and datasets indicates that the results are statistically significant and that the method is superior to baselines and other approaches.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being available. However, the data underlying the article, including the tailspike protein IDs and their corresponding clusters, can be accessed at a provided GitHub repository. Additionally, an archival copy of the code and supporting data, including DOME-ML annotations, is available via the GigaScience database, GigaDB. The project is licensed under the MIT license, which allows for free use, modification, and distribution. The code and model for SpikeHunter are also available on GitHub, providing further resources for evaluation and replication of the study's findings."
}