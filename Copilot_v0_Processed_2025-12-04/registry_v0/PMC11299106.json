{
  "publication/title": "MOBFinder: A Tool for Annotating MOB Types from Plasmid Metagenomic Fragments",
  "publication/authors": "The authors who contributed to this article are:\n\n- T.F.\n- Z.C.F.\n- H.W.Z.\n- S.F.W.\n\nT.F., Z.C.F., and H.W.Z. proposed and designed the work. T.F. and Z.C.F. developed and optimized the software. T.F., Z.C.F., S.F.W., and H.W.Z. wrote and revised the manuscript.",
  "publication/journal": "GigaScience",
  "publication/year": "2024",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- MOBFinder\n- Plasmid metagenomic fragments\n- MOB typing\n- Skip-gram algorithm\n- Word embeddings\n- Language models\n- Metagenomic data analysis\n- Bioinformatics tools\n- Plasmid relaxases\n- Horizontal gene transfer\n- Type 2 diabetes\n- Antibiotic resistance genes\n- Plasmid genomes\n- Machine learning in genomics\n- DNA sequence analysis",
  "dataset/provenance": "The dataset used in our study primarily consists of metagenomic sequencing data retrieved from the NCBI Short Read Archive (SRA) database. Specifically, we utilized datasets SRA045646 and SRA050230. These datasets were chosen to investigate the presence and characteristics of plasmids within different MOB (Mobility) classes in the context of type 2 diabetes (T2D) metagenomic data.\n\nThe number of data points in our study is substantial, as we generated simulated metagenomic contigs from complete plasmid genomes that had been MOB typed. For the training dataset, we created 90,000 artificial contigs for each MOB class within specific length ranges: 100–400 bp, 401–800 bp, 801–1,200 bp, and 1,201–1,600 bp. For the test dataset, we generated 500 fragments for each MOB class in four length groups: 801–1,200 bp, 1,201–1,600 bp, 3,000–4,000 bp, and 5,000–10,000 bp. This approach ensured a comprehensive evaluation of MOBFinder's performance across various fragment lengths.\n\nThe data used in our study builds upon previous research and community efforts in metagenomics. For instance, our analysis of T2D metagenomic sequencing data aligns with findings from a metagenome-wide association study of gut microbiota in type 2 diabetes, which was published in Nature. Additionally, our work leverages established bioinformatics tools and databases, such as the nonredundant (NR) database and the NCBI plasmid database, to develop and validate our models. This integration of existing data and methodologies ensures that our findings are robust and relevant to the broader scientific community.",
  "dataset/splits": "In the development of MOBFinder, two primary data splits were created: the training dataset and the test dataset. For the training dataset, plasmid genomes in each MOB category were randomly split at a proportion of 70% and 30%. This means that 70% of the classified plasmid genomes were used for training, while the remaining 30% were reserved for testing.\n\nFor the training dataset, contigs of different length ranges were generated to predict plasmid fragments with varying lengths. The length ranges included 100–400 bp, 401–800 bp, 801–1,200 bp, and 1,201–1,600 bp. For each MOB class within these length ranges, 90,000 artificial contigs were randomly generated. Plasmid fragments longer than 1,600 bp were segmented into shorter contigs and predicted using models designed for the corresponding lengths.\n\nThe test dataset was constructed to assess the performance of MOBFinder on plasmid fragments of different lengths. Four length groups were created: group A with a length range of 801–1,200 bp, group B with a length range of 1,201–1,600 bp, group C with a length range of 3,000–4,000 bp, and group D with a length range of 5,000–10,000 bp. For each MOB class in these four groups, 500 fragments were randomly extracted. This distribution allowed for a comprehensive evaluation of MOBFinder's performance across different fragment lengths.",
  "dataset/redundancy": "To ensure the robustness and independence of our datasets, we employed a rigorous splitting strategy. For classified plasmid genomes in each MOB category, we randomly divided them into training and test sets at a proportion of 70% and 30%, respectively. This split was designed to maintain the independence of the training and test sets, ensuring that the model's performance could be accurately evaluated on unseen data.\n\nThe training dataset was further processed to generate contigs of varying lengths: 100–400 bp, 401–800 bp, 801–1,200 bp, and 1,201–1,600 bp. For each MOB class within these length ranges, we randomly generated 90,000 artificial contigs. This approach allowed us to predict plasmid fragments of different lengths effectively. Plasmid fragments longer than 1,600 bp were segmented into shorter contigs and predicted using models designed for the corresponding lengths.\n\nFor the test dataset, we created four length groups to assess the performance of MOBFinder: group A (801–1,200 bp), group B (1,201–1,600 bp), group C (3,000–4,000 bp), and group D (5,000–10,000 bp). For each MOB class in these groups, 500 fragments were randomly extracted. This strategy ensured that the test set included a diverse range of fragment lengths, providing a comprehensive evaluation of the model's performance.\n\nThe distribution of our datasets aligns with common practices in machine learning, where a significant portion of the data is used for training, and a smaller, independent portion is reserved for testing. This approach helps in evaluating the model's generalization capability and ensures that the results are not biased by overfitting to the training data. By maintaining independent training and test sets, we enforced the robustness of our model and its ability to perform accurately on new, unseen data.",
  "dataset/availability": "The data used in the development and testing of MOBFinder, including the simulated datasets, are not explicitly mentioned as being released in a public forum. The development process involved generating simulated datasets through specific steps, such as splitting classified plasmid genomes into training and test datasets, and creating contigs of different length ranges. However, there is no information provided about the public availability of these datasets or the specific data splits used.\n\nThe focus of the publication is on the methodology and performance of MOBFinder, rather than the public release of the datasets. The simulated datasets were constructed to serve as a benchmark for evaluating the tool's performance, given the lack of real metagenomic data for this purpose. The construction of these datasets involved using complete plasmid genomes from the NCBI and applying a 4-mer language model to generate word vectors for training and testing.\n\nThe publication does not detail any enforcement mechanisms for the release of the datasets, as the primary emphasis is on the technical approach and the results obtained from the simulated data. Therefore, it is not possible to provide specific information about where the data can be accessed or under what license it might be available.",
  "optimization/algorithm": "The optimization algorithm employed in our work utilizes a well-established machine-learning approach, specifically the random forest algorithm. This algorithm is not new and has been extensively used and validated in various fields, including bioinformatics.\n\nRandom forest is an ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees. This method is chosen for its robustness, ability to handle high-dimensional data, and effectiveness in reducing overfitting.\n\nThe decision to use random forest was driven by its proven performance in similar classification tasks and its suitability for handling the complex and high-dimensional data generated from plasmid sequences. The algorithm's ability to capture intricate patterns and interactions within the data makes it an ideal choice for our purposes.\n\nGiven that random forest is a widely recognized and established algorithm, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this algorithm to the specific problem of MOB typing in plasmid fragments, which is a novel contribution in the field of bioinformatics.",
  "optimization/meta": "The model, MOBFinder, employs a meta-predictor approach that integrates multiple machine-learning methods to enhance its predictive accuracy. Specifically, it uses random forest algorithms as the core classification models. These models are trained on simulated metagenomic contigs, which are encoded into word vectors using a language model. The word vectors are generated through a skip-gram algorithm, which transforms overlapping 4-mers into numerical representations.\n\nMOBFinder trains four separate random forest models, each tailored to different length ranges of plasmid fragments: 100–400 bp, 401–800 bp, 801–1,200 bp, and 1,201–1,600 bp. These models are then ensembled to make more accurate predictions. For fragments shorter than 100 bp, the model designed for the 100–400 bp range is used. For fragments longer than 1,600 bp, the fragments are segmented into shorter contigs, and predictions are made using the corresponding models. The final prediction is determined by aggregating and calculating the weighted average scores for each MOB class, with the highest score indicating the predicted MOB type.\n\nThe training data for these models is constructed from classified plasmid genomes, which are split into training and test datasets. The training dataset includes contigs of various length ranges, with 90,000 artificial contigs generated for each MOB class within these ranges. The test dataset includes longer fragments to assess the model's performance across different length groups.\n\nThe independence of the training data is ensured through the random splitting of classified plasmid genomes into training and test sets, with a 70% and 30% proportion, respectively. This approach helps in evaluating the model's performance on unseen data, ensuring that the training data is independent and representative of real-world scenarios.",
  "optimization/encoding": "In the development of MOBFinder, data encoding was a crucial step to transform DNA sequences into a format suitable for machine learning algorithms. The process began with the generation of k-mers, specifically 4-mers, from the DNA sequences using a sliding window approach. This method segmented the sequences into overlapping substrings of length 4, such as \"ATCG\" from the sequence \"ATCGCTGA\". These 4-mers served as the basic units, or \"words,\" for the subsequent encoding process.\n\nEach 4-mer was initially assigned a random vector. These vectors were then refined using a skip-gram language model, which is a type of neural network architecture. The model was trained to predict the context of each 4-mer within the sequence, effectively learning the relationships between different 4-mers. This training process involved optimizing the vectors through backpropagation over multiple epochs, resulting in a set of 100-dimensional word vectors that captured the semantic information of the 4-mers.\n\nFor a given DNA fragment, the average of all 4-mer word vectors was computed to create a feature vector representing the entire fragment. This feature vector served as the input for the random forest algorithm, which was used to classify the DNA fragments into different MOB types. The use of 4-mers was chosen based on empirical observations that this length provided a good balance between capturing sequence information and computational efficiency. Longer k-mers did not significantly improve performance but increased computational complexity. This encoding process allowed MOBFinder to effectively handle and classify metagenomic data, providing insights into the transmission mechanisms of plasmid-mediated antibiotic resistance genes and virulence factors.",
  "optimization/parameters": "In the development of MOBFinder, the model utilizes word vectors generated through a skip-gram language model. The dimensionality of these word vectors is a critical parameter. Initially, each word (4-mer) is assigned a random vector with a dimension of 100. This dimension was chosen based on previous studies and default settings, ensuring that the word vectors can effectively capture the underlying features and patterns of the plasmid fragments.\n\nThe choice of a 4-mer length for generating these word vectors was determined through comparative analysis. Models with k-mer lengths ranging from 2 to 8 were evaluated. It was observed that a k-mer length of 4 provided a balanced accuracy, harmonic mean, F1-score, and AUC values across different MOB types. Increasing the k-mer length beyond 4 did not significantly improve these metrics but did increase the runtime. Therefore, a k-mer length of 4 was selected for training the word vectors and developing MOBFinder.\n\nThe random forest algorithm, used for classification, also involves parameters such as the number of trees. In this case, the number of trees was set to 500 to generate predictive models. This setting was chosen to ensure robust and accurate predictions.\n\nIn summary, the model parameters include the dimensionality of the word vectors (100) and the k-mer length (4), both selected based on empirical evidence and comparative analysis. The random forest algorithm uses 500 trees to enhance the model's predictive performance.",
  "optimization/features": "The input features for MOBFinder are derived from the sequence data of plasmid fragments. Specifically, a 4-mer sliding window is used to generate overlapping words from the DNA sequences. These words are then transformed into numerical word vectors using trained word embeddings. The dimension of these word vectors is 100, as defined by the skip-gram language model employed.\n\nFor each contig in the training dataset, all the word vectors generated from the 4-mer sliding window are summed to compute their average. This average vector serves as the input feature for the random forest classifier. Therefore, each contig is represented by a single 100-dimensional feature vector.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the use of word embeddings inherently selects relevant features by capturing the contextual importance of nucleotide sequences. This approach provides a more sophisticated analysis compared to simple k-mer frequency methods, as it considers the biochemical characteristics and contextual relevance of the sequences.\n\nThe training of the word embeddings was conducted using a large dataset of plasmid genomes, ensuring that the feature extraction process is robust and generalizable. The word vectors were generated through an unsupervised learning process, which involved training a skip-gram model on the plasmid sequences. This process did not involve the test dataset, ensuring that the feature extraction is independent of the evaluation data.",
  "optimization/fitting": "In the development of MOBFinder, we employed a random forest algorithm to train predictive models using simulated datasets. The training process involved generating contigs of varying lengths from classified plasmid genomes, ensuring a comprehensive representation of different MOB types. To handle the potential issue of high dimensionality, we utilized word vector models, specifically the skip-gram algorithm, to transform DNA sequences into lower-dimensional word vectors. This approach helped in compressing high-dimensional initial vectors into more manageable word vectors, effectively avoiding dimensionality issues during supervised training.\n\nThe random forest algorithm was chosen for its robustness and ability to handle large datasets with numerous features. We trained four separate models for different length ranges of contigs (100–400 bp, 401–800 bp, 801–1,200 bp, and 1,201–1,600 bp), each with 500 trees to ensure a diverse and thorough exploration of the feature space. This ensemble method helped in mitigating overfitting by averaging the predictions of multiple models, thereby reducing the variance and improving the generalization capability of MOBFinder.\n\nTo further ensure that overfitting was not an issue, we employed cross-validation techniques during the training process. The datasets were split into training and test sets, with the training set used to build the models and the test set reserved for evaluating their performance. Additionally, we generated simulated datasets with varying lengths to assess the performance of MOBFinder across different scenarios, ensuring that the models could generalize well to unseen data.\n\nUnderfitting was addressed by carefully selecting the features and hyperparameters. The use of word vectors allowed us to capture the underlying patterns and features of the DNA sequences more effectively than traditional methods like k-mer frequency models or one-hot encoding. The random forest algorithm's ability to handle non-linear relationships and interactions between features further helped in building models that could capture the complexity of the data without being too simplistic.\n\nIn summary, the fitting method for MOBFinder involved the use of word vector models to manage dimensionality, random forest algorithms for robust training, and cross-validation to ensure generalization. These steps collectively helped in ruling out both overfitting and underfitting, resulting in a model that performs well across different MOB types and contig lengths.",
  "optimization/regularization": "In the development of MOBFinder, several techniques were employed to prevent overfitting and ensure robust performance. One of the key methods used was the random forest algorithm, which inherently helps to reduce overfitting by averaging multiple decision trees. This ensemble method provides a more stable and accurate prediction by mitigating the risk of any single tree overfitting the training data.\n\nAdditionally, the use of word vectors generated through a skip-gram language model played a crucial role in dimensionality reduction. By transforming high-dimensional k-mer sequences into lower-dimensional word vectors, the model effectively compressed the feature space, thereby reducing the complexity and potential for overfitting. This approach allowed the model to capture essential sequence characteristics while avoiding the noise associated with high-dimensional data.\n\nFurthermore, the training process involved splitting the classified plasmid genomes into training and test datasets, with a 70% and 30% proportion respectively. This ensured that the model was trained on a diverse set of data and evaluated on a separate, unseen dataset, which helps in assessing the model's generalization capability and preventing overfitting.\n\nThe model was also trained using an optimization algorithm that minimized the loss function through backpropagation over 10 epochs. This iterative process helped in fine-tuning the model parameters and ensuring that the model did not memorize the training data but rather learned generalizable patterns.\n\nIn summary, the combination of random forest, word vector dimensionality reduction, and careful dataset splitting contributed to the prevention of overfitting in MOBFinder, resulting in a model that performs well on both training and test datasets.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in the development of MOBFinder are not explicitly detailed in the provided information. However, it is mentioned that a skip-gram language model was employed to generate word vectors, with specific settings such as a 100-dimensional word vector and a context window size of 20. The model was trained for 10 epochs using backpropagation.\n\nThe random forest algorithm was used for classification, with the number of trees set to 500. Different models were trained for various length ranges of plasmid fragments: 100–400 bp, 401–800 bp, 801–1,200 bp, and 1,201–1,600 bp. These models were then ensembled to handle fragments of different lengths.\n\nRegarding the availability of model files and optimization parameters, there is no specific mention of where these can be accessed or under what license. The focus of the provided information is on the methodology and performance evaluation of MOBFinder, rather than the technical details of the implementation and availability of the model files.",
  "model/interpretability": "The model employed in MOBFinder is not entirely a black box, as it leverages language models to provide some level of interpretability. The use of word embeddings, specifically 4-mers, allows for a more nuanced understanding of the sequence features. These 4-mers are analogous to words in a language, and the longer sequences of DNA are treated as sentences. This approach enables the model to capture contextual information, which is crucial for understanding the biochemical complexities of nucleotide sequences.\n\nThe language model used in MOBFinder generates numerical word vectors through a skip-gram algorithm. This process involves creating a probability distribution over context words, which helps in characterizing the sequence features of different MOB categories. The model is trained using a neural network with two layers: the first layer converts initialized vectors into a 100-dimensional word vector representation, and the second layer computes the probability of correct context words. This training process allows the model to map characters with similar contexts to similar feature spaces, thereby compressing high-dimensional initial vectors into lower-dimensional word vectors.\n\nThe use of 4-mers as the basic unit in the model provides a clear example of interpretability. By segmenting DNA sequences into overlapping 4-mers, the model can identify patterns and features that are specific to each MOB type. This segmentation allows for a more detailed analysis of the sequence characteristics, which is essential for accurate MOB typing. The model's ability to stabilize metrics such as balanced accuracy, harmonic mean, F1-score, and AUC values across different MOB types further demonstrates its interpretability and effectiveness.\n\nIn summary, while MOBFinder utilizes advanced machine learning techniques, the incorporation of language models and word embeddings provides a level of transparency. The use of 4-mers as the basic unit allows for a detailed and contextually rich analysis of DNA sequences, making the model's predictions more interpretable.",
  "model/output": "The model, MOBFinder, is a classification model designed to predict the mobility (MOB) types of plasmid fragments and bins from metagenomic data. It categorizes input sequences into specific MOB classes, such as MOBB, MOBC, MOBF, MOBH, MOBL, MOBM, MOBP, MOBQ, MOBT, MOBV, and non-MOB. The output of MOBFinder provides the predicted MOB class for each input fragment or bin, along with the scores for different MOB types. For plasmid metagenomic bins, the output includes the plasmid bin ID, the predicted MOB class, and the MOB scores for various MOB types. The model uses an ensemble of random forest classifiers trained on different length ranges of plasmid fragments to make these predictions. The final output is the MOB type with the highest score for the input fragment or bin.",
  "model/duration": "The execution time of MOBFinder varied depending on the length of the DNA fragments being analyzed. For shorter fragments, the model could process them relatively quickly. However, for longer fragments, the execution time increased due to the need to segment them into shorter contigs and process each segment individually. The model was designed to handle fragments of different lengths efficiently, with specific models trained for different length ranges (100–400 bp, 401–800 bp, 801–1,200 bp, and 1,201–1,600 bp). For fragments longer than 1,600 bp, the model segmented them into shorter contigs and processed each segment using the corresponding model, which added to the overall execution time. The use of a random forest algorithm with 500 trees also contributed to the execution time, as it required multiple iterations to generate predictive models. Overall, the execution time was optimized to balance accuracy and efficiency, ensuring that MOBFinder could handle large metagenomic datasets within a reasonable timeframe.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of MOBFinder involved several key steps and metrics to ensure its performance and accuracy. The harmonic mean was used to provide an overall evaluation of the model's performance, with sensitivity and specificity being crucial metrics. Sensitivity, or the true positive rate, measures the proportion of actual positives correctly identified by the model, while specificity measures the proportion of actual negatives correctly identified.\n\nThe F1-score was also employed, which combines precision and recall to offer a balanced measure of the model's performance. Precision indicates the number of correct positive predictions out of all positive predictions, and recall measures the number of correct positive predictions out of all actual positives.\n\nTo visualize the performance of MOBFinder in predicting each MOB category, a receiver operating characteristic (ROC) curve was utilized. The ROC curve plots the false-positive rate against the true-positive rate, with plots closer to the top-left corner indicating better performance. For each MOB class, the area under the curve (AUC) value was calculated to quantify the model's performance. An AUC value between 0.5 and 1 indicates that the model performs better than random chance, with higher values signifying better prediction capability.\n\nSimulated metagenomic contigs were constructed from complete genomes that had been MOB typed, serving as a benchmark dataset. These contigs were encoded into word vectors and used to train a random forest algorithm. The trained model was then used to predict the MOB typing of corresponding DNA fragments based on their word vectors.\n\nThe evaluation process included generating simulated datasets by randomly splitting classified plasmid genomes into training and test datasets. For the training dataset, contigs of varying lengths were generated to predict plasmid fragments of different sizes. The test dataset included longer fragments to assess the model's performance on real metagenomic data.\n\nFour classification models were trained on different length ranges of the training dataset, and these models were ensembled to make more accurate predictions. For fragments shorter than 100 base pairs, a model designed for 100–400 base pairs was used. For longer fragments, they were segmented into shorter contigs and predicted using the corresponding models. The final prediction result for an input fragment was determined by aggregating and calculating the weighted average scores for each MOB class, with the highest score indicating the predicted MOB type.\n\nAdditionally, MOBFinder was designed to perform MOB typing on both plasmid contigs and plasmid bins. For plasmid bins, the model predicts the likelihood of each MOB class for fragments within the bin, aggregating the scores of each sequence within the bin to calculate the weighted average scores based on sequence length.",
  "evaluation/measure": "In the evaluation of MOBFinder, several performance metrics were reported to provide a comprehensive assessment of the tool's effectiveness. These metrics include overall accuracy, kappa, run time, balanced accuracy, harmonic mean, F1-score, and area under the curve (AUC) values.\n\nOverall accuracy measures the proportion of correct predictions made by the model. Kappa, on the other hand, assesses the consistency between the predicted classes and the true classes, accounting for the possibility of random prediction. Run time was recorded to evaluate the efficiency of the tool.\n\nBalanced accuracy was used to measure the average accuracy of each MOB category, which is particularly important given the class imbalance within the training dataset. This metric considers both the true-positive rate (TPR) and the true-negative rate (TNR).\n\nThe harmonic mean provides an overall evaluation of the model’s performance, combining sensitivity (Sn) and specificity (Sp). Sensitivity is the ratio of true positives to the sum of true positives and false negatives, while specificity is the ratio of true negatives to the sum of true negatives and false positives.\n\nThe F1-score combines precision and recall to offer a balanced measure of the model’s performance. Precision is the ratio of true positives to the sum of true positives and false positives, and recall is the ratio of true positives to the sum of true positives and false negatives.\n\nAUC values were calculated for each MOB class to quantify the performance of MOBFinder in distinguishing between positive and negative samples. An AUC value between 0.5 and 1 indicates that the model performs better than random chance, with higher values signifying better prediction capability.\n\nThese metrics are representative of standard evaluation practices in the field, ensuring that the performance of MOBFinder can be compared with other tools and models in the literature. The use of multiple metrics provides a thorough assessment of the tool's accuracy, consistency, and efficiency, making it a reliable choice for MOB typing of plasmid fragments and bins from metagenomic data.",
  "evaluation/comparison": "In the evaluation of MOBFinder, a comparison was conducted with other publicly available methods to assess its performance. Specifically, MOBFinder was compared to MOB-suite and MOBscan. These comparisons were performed using a test dataset to evaluate the accuracy, kappa, and run time of each method. MOBscan, which predicts MOB types using plasmid protein sequences rather than DNA sequences, required an additional step of annotating proteins in the plasmid fragments using Prokka before predictions could be made. The overall accuracy, kappa, and run time were calculated by comparing the predicted classes with the true classes. The overall accuracy was determined by the proportion of accurate predictions, while kappa assessed the overall consistency between predictions and true classes, accounting for the possibility of random prediction. The run time was recorded using the Linux command \"time.\"\n\nAdditionally, simpler baselines were not explicitly mentioned as part of the comparison. The focus was primarily on comparing MOBFinder with established methods in the field. The performance metrics used included overall accuracy, kappa, balanced accuracy, harmonic mean, and F1-score. These metrics provided a comprehensive evaluation of MOBFinder's performance in predicting MOB types from metagenomic data. The balanced accuracy was particularly useful for measuring the average accuracy of each MOB category, considering the class imbalance within the training dataset. The harmonic mean offered an overall evaluation of the model's performance, combining sensitivity and specificity. The F1-score provided a balanced measure of the model's performance by combining precision and recall.",
  "evaluation/confidence": "The evaluation of MOBFinder's performance was conducted using several metrics, including accuracy, kappa, balanced accuracy, harmonic mean, F1-score, and AUC values. These metrics provide a comprehensive assessment of the tool's effectiveness in predicting MOB categories.\n\nConfidence intervals for the performance metrics were not explicitly mentioned. However, the statistical significance of the results was addressed through the use of the Wilcoxon rank-sum test and the Benjamini-Hochberg method for adjusting P values. These methods ensure that the differences observed between groups, such as the T2D group and the control group, are statistically significant and not due to random chance.\n\nThe performance of MOBFinder was compared to other tools like MOB-suite and MOBscan. The results showed that MOBFinder consistently outperformed these tools across various metrics. For instance, MOBFinder achieved higher accuracy and kappa values, indicating better overall performance and consistency in predictions. The AUC values for MOBFinder were also greater than 0.8 for all MOB classes, with most values exceeding 0.9, which demonstrates the tool's effectiveness in distinguishing between positive and negative samples.\n\nThe statistical analyses conducted using R further support the robustness of the findings. The use of the Tukey honest significant difference test to compare identified resistance genes among different MOB classes adds another layer of confidence in the results. Overall, the evaluation provides strong evidence that MOBFinder is a superior tool for MOB typing, with statistically significant improvements over existing methods.",
  "evaluation/availability": "Not enough information is available."
}