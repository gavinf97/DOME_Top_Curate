{
  "publication/title": "Stratum corneum nanotexture feature detection using deep learning and spatial analysis: a non-invasive tool for skin barrier assessment",
  "publication/authors": "The authors contributing to this article are:\n\n- Jen-Hung Wang, who led the conceptualization, data curation, investigation, methodology, software development, validation, visualization, and writing of the original draft.\n- George Pereda, who supported the conceptualization and methodology.\n- Ching-Wen Du, who contributed equally to data curation and supported the investigation.\n- Chia-Yu Chu, who led the conceptualization, supported funding acquisition, investigation, and resources, and provided supervision and support in reviewing and editing the manuscript.\n- Maria Oberländer Christensen, who supported the investigation and reviewing and editing of the manuscript.\n- Sanja Kezic, who supported the conceptualization, investigation, and reviewing and editing of the manuscript.\n- Ivone Jakasa, who supported the investigation and reviewing and editing of the manuscript.\n- Jacob P. Thyssen, who supported the conceptualization and reviewing and editing of the manuscript.\n- Sreeja Satheesh, who supported the validation.\n- Edwin En-Te Hwu, who led the conceptualization, funding acquisition, investigation, project administration, and resources, and provided supervision and support in reviewing and editing the manuscript.",
  "publication/journal": "GigaScience",
  "publication/year": "2024",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Atopic Dermatitis\n- Corneocyte Nanotexture\n- Deep Learning\n- Object Detection\n- YOLOv10\n- RT-DETRv2\n- Kernel Density Estimation\n- Skin Barrier Assessment\n- Noninvasive Diagnostics\n- Spatial Analysis",
  "dataset/provenance": "The corneocyte nanotexture dataset, which includes annotations used to train YOLOv10 and RT-DETRv2 object detection models, is available in a GitHub repository. This dataset is part of a broader project focused on stratum corneum nanotexture feature detection using deep learning and spatial analysis. The dataset and associated annotations are crucial for training and validating the models, ensuring they can accurately detect and quantify corneocyte nanotextures.\n\nThe dataset has been utilized in previous research and is accessible to the community for further exploration and validation. Workflows related to this dataset are archived on WorkflowHub, and all additional supporting data and materials can be accessed via the GigaScience database, GigaDB. This ensures that the dataset is not only available for current use but also for future research and validation by other scientists in the field.\n\nThe dataset includes a variety of corneocyte nanotexture images with different levels of atopic dermatitis severity, allowing for comprehensive analysis and model training. The images are annotated with detected corneocyte nanotexture objects (CNOs), marked as green spots, which are essential for training the object detection models. The dataset's availability and the associated workflows provide a robust foundation for ongoing and future research in this area.",
  "dataset/splits": "In our study, we utilized corneocyte nanotexture images to analyze atopic dermatitis (AD) severity. The dataset was split into four groups based on AD severity: G1, G2, G3, and G4. Each group contributed a specific number of data points derived from corneocyte nanotexture images.\n\nFor groups G1, G2, and G3, which represent different severities of AD, each group contributed a total of 30 data points. These data points were evenly divided between lesional and nonlesional stratum corneum (SC) samples, with 15 data points from lesional samples and 15 from nonlesional samples.\n\nThe healthy control group, G4, contributed 15 data points exclusively from nonlesional SC samples. This distribution ensured a comprehensive analysis across different severity levels of AD and a control group for comparison.\n\nAll images were preprocessed, and corneocyte nanotexture objects (CNOs) were identified using fine-tuned YOLOv10-L models. This approach allowed for a detailed and accurate assessment of CNO distribution and density across the different AD severity groups.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The corneocyte nanotexture dataset, along with the annotations used to train the YOLOv10 and RT-DETRv2 object detection models, is publicly available. This dataset can be accessed through a GitHub repository. Additionally, fine-tuned models and the source code are also downloadable from the same repository. Workflows associated with this study are archived on WorkflowHub. All additional supporting data and materials are accessible via the GigaScience database, GigaDB. The data is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. This ensures that the dataset is freely available for further research and development while maintaining proper attribution to the original authors.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is object detection, specifically focusing on deep learning-based detectors. We employed two state-of-the-art models: YOLOv10 and RT-DETRv2. These models are not entirely new but represent the latest iterations in their respective series, incorporating significant advancements.\n\nYOLOv10 is the newest version in the YOLO (You Only Look Once) series, known for its balance between speed and accuracy in real-time object detection. It introduces features like non-maximum suppression (NMS)-free training and large-kernel convolutions, which enhance its efficiency and accuracy, particularly in detecting small, intricate features.\n\nRT-DETRv2, on the other hand, is a transformer-based detector that builds on the Detection Transformer (DETR) framework. It uses self-attention mechanisms for end-to-end object detection, eliminating the need for NMS postprocessing. RT-DETRv2 further improves accuracy and latency through an efficient hybrid encoder and uncertainty-minimal query selection.\n\nThe reason these algorithms were not published in a machine-learning journal is that our focus was on applying and fine-tuning these models for a specific biomedical application—detecting corneocyte nanotexture objects (CNOs) in stratum corneum images. The advancements in YOLOv10 and RT-DETRv2 were developed and published in the context of computer vision and object detection research. Our contribution lies in adapting these models to a novel domain, demonstrating their effectiveness in a biomedical context, and integrating them with spatial analysis techniques to improve the accuracy of CNO density calculations. This interdisciplinary approach is more suited to a publication in a biomedical or interdisciplinary journal, where the application and impact on the specific domain are of primary interest.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it relies on deep learning object detectors, specifically YOLOv10 and RT-DETRv2, to address the limitations of existing methods for detecting corneocyte nanotexture features.\n\nThe YOLOv10 and RT-DETRv2 models are evaluated across various scales to determine the optimal architecture for detecting corneocyte nanotexture objects (CNOs). These models are trained and fine-tuned independently on the dataset of corneocyte nanotexture images. The performance of these models is assessed based on metrics such as the number of parameters, FLOPS, AP50, AP50-95, and latency.\n\nThe study does not combine predictions from multiple machine-learning algorithms to make a final prediction. Instead, it focuses on the individual performance of YOLOv10 and RT-DETRv2 models. The YOLOv10-L model, in particular, achieves the highest overall accuracy (AP50) of 91.4%, making it the preferred model for this study.\n\nIn terms of training data independence, the models are trained on a dataset of corneocyte nanotexture images, and the training process is designed to ensure that the data is independent and representative of the target distribution. The study acknowledges certain limitations, such as the sample size and variability in sample collection, but these do not affect the independence of the training data.\n\nIn summary, the model described in this publication is not a meta-predictor. It relies on deep learning object detectors, with a focus on the YOLOv10-L model for detecting CNOs. The training data is designed to be independent, ensuring robust and accurate performance.",
  "optimization/encoding": "In our study, the data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithms, particularly for detecting corneocyte nanotexture features. Initially, we applied a series of image preprocessing techniques to enhance the visibility of minute features, such as corneocyte nanotexture objects (CNOs), while suppressing environmental noise. This involved Gaussian filtering to smooth the raw images, followed by subtracting the mean intensity across each row to mitigate striping artifacts commonly found in atomic force microscopy (AFM) imaging. The images were then normalized to a range of 0.0 to 1.0 to maintain consistent intensity levels across all samples. Additionally, disk-shaped morphological elements with diameters of 9 and 15 pixels were used as percentile filters to enhance local contrast and improve the visibility of subtle features.\n\nFor the training of deep learning object detectors, we curated a dataset consisting of 300 corneocyte nanotexture images with diverse atopic dermatitis (AD) severities. Each image was meticulously labeled, resulting in a comprehensive dataset with an average of approximately 250 annotated CNOs per image and over 74,000 annotations in total. The dataset was randomly split into three subsets: 80% for training, 10% for validation, and 10% for testing. To further augment the training set, we employed various data augmentation techniques, including adjustments to brightness, exposure, blur, noise, and Mosaic augmentation. These techniques helped to expand the training set threefold, ensuring robustness and generalization in our models.\n\nThe encoded data was then used to fine-tune YOLOv10 and RT-DETRv2 models for CNO detection. We compared the performance of different scales within each model, such as YOLOv10-{N, S, M, B, L, X} and RT-DETRv2-{S, M, L, X}, to determine the optimal configuration. All models were trained and evaluated on an NVIDIA Tesla T4 GPU in Google Colab, following standard training-from-scratch settings. Detailed hyperparameter settings for each model are provided in supplementary tables for further reference. This rigorous preprocessing and encoding pipeline ensured that our machine-learning algorithms could accurately detect and analyze CNOs in corneocyte nanotexture images.",
  "optimization/parameters": "In our study, we evaluated two state-of-the-art object detection models, YOLOv10 and RT-DETRv2, across various scales to determine the optimal architecture for detecting corneocyte nanotexture objects (CNOs). The number of parameters (p) in each model variant is as follows:\n\nFor YOLOv10, the parameter counts are:\n- YOLOv10-N: 2.7 million parameters\n- YOLOv10-S: 8.0 million parameters\n- YOLOv10-M: 16.5 million parameters\n- YOLOv10-B: 20.4 million parameters\n- YOLOv10-L: 25.7 million parameters\n- YOLOv10-X: 31.6 million parameters\n\nFor RT-DETRv2, the parameter counts are:\n- RT-DETRv2-S: 20.0 million parameters\n- RT-DETRv2-M: 31.0 million parameters\n- RT-DETRv2-L: 42.0 million parameters\n- RT-DETRv2-X: 76.0 million parameters\n\nThe selection of these models and their respective parameter counts was based on a comparative analysis of their performance in terms of detection accuracy, computational cost, and inference speed. We used standard average precision (AP) metrics to evaluate detection accuracy, with AP50 and AP50-95 providing a comprehensive assessment of model performance across different intersection over union (IoU) thresholds. Latency was measured on an NVIDIA Tesla T4 GPU using TensorRT FP16, ensuring consistent and comparable results.\n\nThe YOLOv10-L model achieved the highest overall accuracy (AP50) of 91.4%, making it the most suitable for our study despite RT-DETRv2's enhanced computational efficiency at comparable model complexities. The choice of model and parameter count was driven by the need for high detection accuracy in identifying CNOs, which is crucial for the subsequent spatial analysis using kernel density estimation (KDE).\n\nIn addition to the model parameters, we also optimized other hyperparameters specific to each model. For YOLOv10, these included learning rate schedules, data augmentation techniques, and loss function gains. For RT-DETRv2, hyperparameters such as the number of epochs, batch size, optimizer settings, and various cost weights were fine-tuned to achieve optimal performance. These hyperparameters were selected through empirical tuning and cross-validation to ensure robust and reliable detection of CNOs.",
  "optimization/features": "The input features for our study are derived from corneocyte nanotexture images, specifically focusing on the detection of corneocyte nanotexture objects (CNOs). These features are used to train and evaluate our deep learning models, particularly YOLOv10 and RT-DETRv2, for object detection tasks.\n\nThe number of input features is not explicitly stated as a fixed number, as deep learning models like YOLOv10 and RT-DETRv2 typically process raw image data directly. Instead of a predefined set of features, these models learn to extract relevant features from the input images during the training process. The images themselves serve as the primary input, and the models automatically identify and utilize the necessary features for CNO detection.\n\nFeature selection in the traditional sense is not applicable here, as we are not manually selecting a subset of features from a larger set of candidate features. Instead, the models perform feature extraction as part of their learning process. This approach leverages the full capacity of the convolutional neural networks (CNNs) within these models to identify and utilize the most relevant patterns and structures in the images.\n\nThe training process involves using the entire dataset of corneocyte nanotexture images to train the models. The models learn to extract features directly from these images, ensuring that the feature extraction process is optimized for the specific task of CNO detection. This end-to-end learning approach allows the models to adapt to the unique characteristics of the input data, resulting in more accurate and robust detection performance.\n\nIn summary, the input features for our study are the raw corneocyte nanotexture images, and feature extraction is performed automatically by the deep learning models during training. This approach eliminates the need for manual feature selection and allows the models to learn the most relevant features directly from the data.",
  "optimization/fitting": "In our study, we employed two deep learning models, YOLOv10 and RT-DETRv2, for detecting corneocyte nanotexture objects (CNOs). Both models were trained on a dataset of corneocyte nanotexture images, and their performance was evaluated using standard metrics such as average precision (AP) and latency.\n\nThe number of parameters in our models is indeed significant, especially for the larger variants like YOLOv10-X and RT-DETRv2-X. For instance, YOLOv10-X has 31.6 million parameters, and RT-DETRv2-X has 76 million parameters. However, the number of training points, represented by the annotated corneocyte nanotexture images, was sufficient to mitigate overfitting risks. To further ensure that our models did not overfit, we implemented several regularization techniques. These included using a high weight decay value, which helps in preventing the model from fitting the noise in the training data. Additionally, we employed data augmentation techniques such as HSV augmentation, translation, scale, mosaic, Mixup, and copy-paste augmentations. These techniques helped in increasing the diversity of the training data, making the models more robust and less likely to overfit.\n\nTo address underfitting, we carefully tuned the hyperparameters of our models. For example, we used a linear learning rate decay schedule for YOLOv10, which allows the model to converge more smoothly. We also employed techniques like the distribution focal loss (DFL) in YOLOv10, which focuses on more challenging examples to improve precision. For RT-DETRv2, we used techniques like label noise and box noise to make the model more resilient to noisy data, thereby improving its generalization capability.\n\nMoreover, we conducted extensive validation and testing on separate datasets to ensure that our models generalized well to unseen data. The use of cross-validation for selecting the optimal bandwidth in the kernel density estimator (KDE) further ensured that our models were not underfitting. The KDE helped in generating a continuous, probabilistic density map that captured the spatial distribution of CNOs, thereby improving the accuracy of our density calculations.\n\nIn summary, while the number of parameters in our models is large, we employed various regularization techniques, hyperparameter tuning, and validation methods to ensure that our models neither overfit nor underfit the data. This comprehensive approach allowed us to achieve reliable and accurate detection of CNOs.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and ensure the robustness of our models. For the YOLOv10 models, we utilized techniques such as mosaic augmentation, Mixup augmentation, and copy-paste augmentation. These methods help the model generalize better by providing varied and augmented training data. Additionally, we implemented a learning rate schedule with linear decay, which gradually reduces the learning rate during training, allowing the model to converge more smoothly and avoid overfitting to the training data.\n\nFor the RT-DETRv2 models, we used techniques like label noise ratio and box noise scale, which introduce noise into the training labels and bounding boxes, respectively. This helps the model become more robust to minor variations and noise in the data. Furthermore, we employed exponential moving average (EMA) decay, which maintains a moving average of the model parameters, providing a more stable and generalized model.\n\nBoth sets of models also benefited from techniques like weight decay, which adds a penalty for large weights during training, encouraging the model to find a simpler and more generalizable solution. Additionally, gradient clipping was used to prevent the exploding gradient problem, ensuring stable training.\n\nThese regularization methods collectively helped in mitigating overfitting and enhancing the generalization capabilities of our models, leading to more reliable and accurate CNO detection and density estimation.",
  "optimization/config": "The hyperparameter configurations and optimization schedules for the models discussed in our study are indeed available. Specifically, the settings for YOLOv10 and RT-DETRv2 are detailed in the supplementary materials. For YOLOv10, the hyperparameters include details such as epochs, batch size, optimizer settings, learning rates, and various augmentation techniques. Similarly, for RT-DETRv2, the configurations cover epochs, batch size, optimizer details, learning rates, and other relevant parameters like weight decay and gradient clipping.\n\nThe corneocyte nanotexture dataset, along with the annotations used to train these object detection models, is accessible in a GitHub repository. This repository also provides fine-tuned models and the source code necessary for replication. Additionally, workflows are archived on WorkflowHub.eu, and all supporting data and materials can be found in the GigaScience database, GigaDB. These resources are made available to ensure transparency and reproducibility of our research.",
  "model/interpretability": "The model employed in this study leverages deep learning object detectors, specifically YOLOv10 and RT-DETRv2, which are known for their robustness in detecting objects within images. These models, while powerful, are often considered black-box due to the complexity of their neural network architectures. However, efforts have been made to enhance interpretability.\n\nThe YOLOv10-L model, which achieved the highest overall accuracy (AP50) of 91.4%, was fine-tuned and evaluated using a confidence threshold of 0.141. This threshold was selected because it achieved the highest F1 score of 0.85, balancing precision and recall effectively. The F1 confidence curve for this model is provided in supplementary materials, offering insights into its performance at different confidence levels.\n\nTo further interpret the model's decisions, we utilized Kernel Density Estimation (KDE) for spatial analysis of Corneocyte Nanotexture Objects (CNO) distribution. KDE generates density maps that represent the spatial distribution of CNOs, effectively excluding regions with ridges or occlusions. This process improves the accuracy of CNO density calculations by providing a more precise representation of the data.\n\nAdditionally, an ablation study was conducted to evaluate the impact of KDE on the variability of CNO density calculations. The coefficient of variation (CV) was used as a measure of variability, with lower CV values indicating more stable and consistent density estimates. This study helps in understanding how different components of the model contribute to its overall performance and interpretability.\n\nWhile the deep learning models themselves are complex and not fully transparent, the use of KDE and the ablation study provides a layer of interpretability. These methods allow us to understand how the model's predictions are influenced by the spatial distribution of CNOs and the effectiveness of different model components. This approach helps in bridging the gap between the black-box nature of deep learning models and the need for interpretable results in scientific research.",
  "model/output": "The model in question is designed for object detection, specifically tailored to identify and quantify corneocyte nanotexture objects (CNOs) in images. It leverages deep learning architectures, namely YOLOv10 and RT-DETRv2, which are both state-of-the-art object detectors. These models are evaluated across various scales, from nano to extra-large, to determine their performance in terms of accuracy and computational efficiency.\n\nThe YOLOv10 model, particularly the YOLOv10-L variant, achieved the highest overall accuracy with an AP50 of 91.4%. This indicates that the model is highly effective in detecting CNOs with a high level of precision. The RT-DETRv2 model, while demonstrating enhanced computational efficiency, was found to be less accurate in comparison to YOLOv10.\n\nThe output of these models includes the detection of CNOs marked as green spots on corneocyte nanotexture images. The models are fine-tuned to optimize performance, with the YOLOv10-L model achieving the highest F1 score of 0.85 at a confidence threshold of 0.141. This balance between precision and recall ensures that the model can accurately quantify CNOs even in the presence of vibrational noise introduced during topographic imaging.\n\nAdditionally, the models are used in conjunction with Kernel Density Estimation (KDE) to perform spatial analysis of CNO distribution. This process generates a density map that excludes regions with ridges or occlusions, thereby improving the accuracy of CNO density calculations. The results demonstrate the model's capability to distinguish between different levels of atopic dermatitis (AD) severity, providing a reliable biomarker for AD assessment.\n\nThe models are evaluated using metrics such as the number of parameters, FLOPS, AP50, AP50-95, and latency, which provide a comprehensive understanding of their performance and efficiency. The models are capable of real-time object detection, making them suitable for practical applications in clinical settings. The data and models are made available in public repositories, ensuring reproducibility and accessibility for further research and development.",
  "model/duration": "The execution time of the models was evaluated in terms of latency, which was measured on an NVIDIA Tesla T4 GPU using TensorRT FP16. All test images were resized to 512 × 512 pixels to match the resolution of the corneocyte nanotexture images. The latency results for the YOLOv10 models ranged from 3.33 milliseconds for the smallest model (YOLOv10-N) to 10.95 milliseconds for the largest model (YOLOv10-X). The RT-DETRv2 models exhibited slightly different latency times, with the smallest model (RT-DETRv2-S) taking 5.51 milliseconds and the largest model (RT-DETRv2-X) taking 21.15 milliseconds. These measurements indicate that both model families are capable of real-time object detection, with YOLOv10 generally demonstrating lower latency compared to RT-DETRv2 for models of similar scale. This efficiency is crucial for practical applications where quick processing times are essential.",
  "model/availability": "The source code for the project is publicly available. It can be accessed through a GitHub repository. The project is named ECTI Atopic Dermatitis and is hosted on GitHub. The repository includes the fine-tuned models and the source code necessary to run the algorithm. The project is platform-independent and requires Python 3.10 or higher. Additional dependencies include libraries such as matplotlib, numpy, opencv-python, scipy, scikit-image, scikit-learn, ultralytics, and customtkinter. The software is licensed under multiple licenses, including PSF, BSD, Apache, and AGPL-3.0. Workflows are also archived on WorkflowHub. The software application is registered on SciCrunch and biotools, ensuring its accessibility and reproducibility.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its robustness and accuracy. We began by leveraging an extensive database of corneocyte nanotexture images, captured using our in-house high-speed dermal atomic force microscope. These images represented various levels of atopic dermatitis (AD) severity.\n\nTo determine the optimal model architecture for detecting corneocyte nanotexture objects (CNOs), we evaluated the performance of two state-of-the-art object detectors: YOLOv10 and RT-DETRv2. These models were assessed across various scales, including nano, small, medium, balanced, large, and extra-large configurations. The performance metrics considered included the number of parameters, FLOPS, AP50, AP50-95, and latency.\n\nThe YOLOv10-L model achieved the highest overall accuracy with an AP50 of 91.4%, making it the most suitable for our study despite RT-DETRv2's enhanced computational efficiency. We further refined our approach by applying Kernel Density Estimation (KDE) to perform spatial analysis of CNO distribution. This method selectively excluded ineffective regions such as ridges and occlusions, thereby minimizing variance in CNO density calculations and providing a more precise representation.\n\nTo validate the impact of KDE on the variability of CNO density calculations, we conducted an ablation study. This study compared results with and without KDE across different AD severity groups, using the coefficient of variation (CV) as a measure of variability. Lower CV values indicated more stable and consistent density estimates.\n\nAdditionally, we performed cross-validation to select the optimal bandwidth for KDE, ensuring that the density maps accurately represented the spatial distribution of CNOs. The confidence threshold for the YOLOv10-L model was set to 0.141, achieving the highest F1 score of 0.85, which balanced precision and recall effectively.\n\nQualitative results were presented to demonstrate the model's capability to accurately quantify CNOs, even in the presence of vibrational noise introduced during topographic imaging. The analysis results of CNO distribution using KDE further highlighted the effectiveness of our approach in improving the accuracy of CNO density calculations.",
  "evaluation/measure": "In our evaluation, we employed a comprehensive set of performance metrics to assess the effectiveness of our object detection models. The primary metrics reported include Average Precision (AP) at different Intersection over Union (IoU) thresholds, specifically AP50 and AP50-95. AP50 measures the AP at a fixed IoU threshold of 0.5, providing a straightforward assessment of detection accuracy. AP50-95, on the other hand, represents the mean AP across IoU thresholds ranging from 0.50 to 0.95 in increments of 0.05, offering a more nuanced evaluation of model performance across varying levels of precision.\n\nAdditionally, we reported the number of parameters and floating-point operations per second (FLOPS) for each model, which are crucial for understanding the computational efficiency and resource requirements. Latency, measured in milliseconds, was also evaluated to ensure real-time performance capabilities.\n\nThese metrics are widely recognized and used in the literature for evaluating object detection models, ensuring that our results are comparable with other studies in the field. The inclusion of both accuracy and efficiency metrics provides a holistic view of model performance, making our evaluation robust and representative of current standards.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of deep learning object detectors to evaluate their performance in detecting corneocyte nanotexture objects (CNOs). We focused on two state-of-the-art models: YOLOv10 and RT-DETRv2, each evaluated across various scales to determine the optimal architecture for CNO detection.\n\nThe comparison involved assessing multiple aspects, including the number of parameters, computational cost (measured in FLOPS), detection accuracy (using AP50 and AP50-95 metrics), and inference speed (latency). This evaluation was performed on a test set consisting of 30 annotated corneocyte nanotexture images, ensuring a robust assessment of each model's capabilities.\n\nBoth YOLOv10 and RT-DETRv2 demonstrated strong performance in CNO detection. However, YOLOv10, particularly the YOLOv10-L model, achieved the highest overall accuracy with an AP50 of 91.4%. While RT-DETRv2 models showed enhanced computational efficiency at comparable complexities, YOLOv10 models were deemed more suitable for this study due to their superior detection accuracy.\n\nAdditionally, we implemented a kernel density estimator (KDE) to perform spatial analysis of CNO distribution. This approach allowed us to generate a continuous, probabilistic density map that accurately reflects the spatial variation in CNO distribution while minimizing the influence of noise or occlusion artifacts. The use of KDE significantly improved the robustness and accuracy of CNO density calculations, enabling us to distinguish between different levels of atopic dermatitis (AD) severity.\n\nIn summary, our evaluation involved a detailed comparison of advanced deep learning models and the integration of spatial analysis techniques to enhance the accuracy and reliability of CNO detection. This methodology provides a novel and effective approach for assessing AD severity through corneocyte nanotexture analysis.",
  "evaluation/confidence": "In our evaluation, we employed several statistical methods to ensure the robustness and significance of our results. For the performance metrics, we did not explicitly provide confidence intervals for individual metrics such as AP50 or AP50-95. However, we conducted a thorough statistical analysis to assess the significance of our findings.\n\nWe used the Shapiro–Wilk normality test to evaluate the distribution of our data. Given the non-normal distribution observed in most data groups, we applied the Wilcoxon signed-rank test to determine statistically significant differences between paired samples, specifically comparing lesional and nonlesional stratum corneum (SC) samples from the same atopic dermatitis (AD) patient. Additionally, the Wilcoxon rank-sum test was used to identify significant differences between independent sample groups, particularly among the different AD severity groups.\n\nOur ablation study on Kernel Density Estimation (KDE) demonstrated its effectiveness in reducing variability in CNO density calculations. The coefficient of variation (CV) was used as a measure of variability, with lower CV values indicating more stable and consistent density estimates. The application of KDE led to a notable reduction in CV across most AD groups, particularly in those with higher CNO presence, indicating more robust density estimates.\n\nFurthermore, our statistical results, presented in box plots, revealed a clear trend of increasing ECTI scores corresponding to AD severity. Most AD severity groups exhibited significant differences between lesional and nonlesional SC samples, highlighting a higher occurrence of CNOs in lesional skin areas. The healthy control group consistently demonstrated the lowest ECTI scores compared to other AD severity groups.\n\nThese statistical analyses underscore the reliability and significance of our method, providing a strong foundation for claiming its superiority in assessing AD severity through corneocyte nanotexture analysis.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being available. However, the dataset used for training the models, along with the annotations, is accessible in a GitHub repository. This repository also contains fine-tuned models and source code. Additionally, workflows are archived on WorkflowHub, and all supporting data and materials are available via the GigaScience database, GigaDB. The data is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited."
}