{
  "publication/title": "Learning a Generalized Graph Transformer for Protein Function Prediction in Dissimilar Sequences",
  "publication/authors": "The authors contributing to the article are:\n\n- Y.F. (Full name not provided) - Designed the study, designed the model, ran all the experiments, and wrote the manuscript.\n- X.L. (Full name not provided) - Designed the study, designed the model, wrote the manuscript, and supervised the work.\n- Z.G. (Full name not provided) - Designed the model, ran all the experiments, and wrote the manuscript.\n- Q.G. (Full name not provided) - Ran all the experiments and wrote the manuscript.\n- L.L. (Full name not provided) - Wrote the manuscript and supervised the work.\n- M.D. (Full name not provided) - Wrote the manuscript and supervised the work.",
  "publication/journal": "GigaScience",
  "publication/year": "2024",
  "publication/doi": "10.5524/102588",
  "publication/tags": "- Protein function prediction\n- Machine learning\n- Deep learning\n- Graph convolutional networks\n- Gene Ontology\n- Protein structure prediction\n- Bioinformatics\n- Computational biology\n- Protein annotation\n- Graph adversarial learning\n- AlphaFold\n- Protein-protein interaction\n- Biological process\n- Molecular function\n- Cellular component\n- Sequence identity\n- Performance metrics\n- Model evaluation\n- Data availability\n- Protein databases",
  "dataset/provenance": "In our study, we utilized two primary datasets for our experiments. The first dataset, named PDBch, was sourced from the Protein Data Bank (PDB) database. This dataset consists of 36,641 experimentally solved protein structures, each associated with Gene Ontology (GO) terms obtained from the SIFTS database. To ensure dissimilarity between our training and test sets, we employed the MMseqs sequence clustering tool with a sequence identity threshold of 30%. The training, validation, and test sets were then selected from different clusters, maintaining an approximate ratio of 8:1:1. This approach ensures that the sequence identity between samples from different sets is below 30%, addressing the challenge of transferring GO terms from the training set to the test set.\n\nThe second dataset, AFch, was constructed by initially selecting 41,997 proteins from the SWISS-MODEL repository. These proteins were then partitioned into training, validation, and test sets, similar to the PDBch dataset. The AFch dataset was specifically designed to mitigate the imbalance in GO term labels present in the PDBch set, focusing on proteins with low-frequency GO terms. This dataset includes structures predicted by AlphaFold2, retrieved from the AlphaFold protein structure database.\n\nBoth datasets have been used in previous research, notably in the DeepFRI work, and are well-regarded within the scientific community for their comprehensive and diverse protein structure data. The PDBch dataset, in particular, has been a foundational resource for various protein function prediction studies, providing a robust benchmark for evaluating the performance of different methods. The AFch dataset, with its focus on low-frequency GO terms, offers a unique challenge and opportunity for improving the generalizability of protein function prediction models.",
  "dataset/splits": "In our study, we utilized two primary datasets: PDBch and AFch. For the PDBch dataset, we employed a sequence clustering tool with a 30% sequence identity threshold to ensure dissimilarity between the training and test sets. This dataset was divided into three splits: training, validation, and test sets. The approximate ratio for these splits was 8:1:1. This means that out of the total 36,641 experimentally solved protein structures, approximately 80% were used for training, 10% for validation, and 10% for testing.\n\nFor the AFch dataset, we initially selected 41,997 proteins from the SWISS-MODEL repository. Similar to the PDBch dataset, these were partitioned into training, validation, and test sets following the same 8:1:1 ratio. This approach helped mitigate the imbalance in GO term labels, particularly for low-frequency GO terms in the PDBch set. The detailed construction and partitioning of these datasets can be found in the supplementary materials.",
  "dataset/redundancy": "In our study, we utilized the PDBch dataset, which consists of 36,641 experimentally solved protein structures from the PDB database and their associated Gene Ontology (GO) terms sourced from SIFTS. To ensure the independence of our training and test sets, we employed the MMseqs sequence clustering tool with a sequence identity threshold of 30%. This process helped us create distinct clusters, from which we then selected the training, validation, and test sets with an approximate ratio of 8:1:1. This approach ensured that the sequence identity between samples from different sets remained below 30%, thereby minimizing any overlap or similarity that could bias the results.\n\nAdditionally, we conducted experiments using the AFch dataset, which was constructed by collecting homology models of the PDBch dataset with at least one annotation from the SWISS-MODEL repository. From this dataset, we selected 41,997 proteins with low-frequency GO terms and retrieved their structures predicted by AlphaFold2. The AFch set was specifically designed to address the imbalance in GO term labels present in the PDBch set, particularly for low-frequency GO terms. This careful selection process helped mitigate the imbalance and ensured a more representative distribution of GO terms across the datasets.\n\nThe distribution of our datasets differs from previously published machine learning datasets in that we placed a strong emphasis on ensuring low sequence identity between the training and test sets. This approach is crucial for evaluating the generalization ability of our methods, as it simulates real-world scenarios where the test data may not be closely related to the training data. By doing so, we aimed to provide a more robust assessment of our models' performance and their ability to handle diverse and unseen protein structures.",
  "dataset/availability": "The datasets used in our study are publicly available. The primary dataset, PDBch, is sourced from the DeepFRI work and consists of protein structures from the PDB database. This dataset was clustered using MMseqs at a sequence identity of 30% to ensure dissimilarity between training and test sets. The training, validation, and test sets were selected from different clusters with an approximate ratio of 8:1:1.\n\nAdditionally, we utilized the AFch dataset, which includes proteins from the SWISS-MODEL repository. These proteins were partitioned into training, validation, and test sets similarly to the PDBch dataset. Detailed information about the datasets can be found in the Dataset section of our publication.\n\nAn archival copy of the code and other supporting data are openly available in the GigaScience repository, GigaDB. This repository also provides a link to DOME-ML annotations, which include Data, Optimization, Model, and Evaluation in Machine Learning.\n\nThe datasets and code are released under the MIT license, ensuring that they can be freely used, modified, and distributed. This approach promotes transparency and reproducibility in our research.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Adam optimizer. Adam, which stands for Adaptive Moment Estimation, is a widely-used stochastic optimization algorithm that combines the advantages of two other extensions of stochastic gradient descent. Specifically, Adam uses adaptive learning rates and momentum, making it well-suited for problems that involve sparse gradients on noisy and/or non-stationary objectives.\n\nAdam is not a new machine-learning algorithm; it was introduced in 2014. The reason it was not published in a machine-learning journal is that it has already been established and widely adopted in the field. Its effectiveness and efficiency have been thoroughly validated in numerous studies and applications, making it a standard choice for optimizing neural networks and other machine-learning models.\n\nIn our work, Adam was chosen for its robustness and efficiency in handling large-scale datasets and complex models. It allows for effective training of our graph-based neural network, ensuring that the model converges quickly and accurately. The learning rate for Adam was set to 1e-4, which was found to be optimal for our specific task and dataset. This choice of optimizer and learning rate contributed significantly to the successful training and performance of our model.",
  "optimization/meta": "The model described in this publication is a meta-predictor named GALA, which integrates multiple complementary pipelines to predict protein functions. It leverages data from various machine-learning algorithms and methods as input. Specifically, GALA combines global and local structure alignments, sequence and sequence-profile matches, and protein-protein interaction (PPI) network mapping. These pipelines are designed to capture different aspects of protein data, enhancing the overall prediction accuracy.\n\nThe constituent methods of GALA include:\n\n* Global and local structure alignments: These methods compare protein structures to identify similarities and differences, which can provide insights into protein functions.\n* Sequence and sequence-profile matches: These methods analyze amino acid sequences and their profiles to predict functional similarities between proteins.\n* Protein-protein interaction (PPI) network mapping: This method uses the interactions between proteins to infer functional relationships.\n\nRegarding the independence of training data, it is not explicitly stated that the training data for each pipeline is completely independent. However, the model is designed to handle dissimilar target datasets, suggesting that it can generalize well even when the training and test data come from different distributions. This indicates that the model is robust to variations in the data, which is crucial for its performance in real-world scenarios where novel sequences are discovered.",
  "optimization/encoding": "In our study, the data encoding process was meticulously designed to ensure that the machine-learning algorithm could effectively learn from the protein structures and their associated functional annotations. We began by utilizing the PDBch dataset, which comprises 36,641 experimentally solved protein structures from the PDB database, along with their corresponding Gene Ontology (GO) terms sourced from SIFTS. To ensure dissimilarity between the training and test sets, we employed the MMseqs sequence clustering tool with a sequence identity threshold of 30%. This step was crucial for evaluating the model's performance in scenarios where the training and test sets have low sequence identity.\n\nThe protein structures were represented using graph-based encodings, where each node in the graph corresponds to an amino acid residue, and edges represent the spatial relationships between residues. This graph representation allows the model to capture the complex three-dimensional structure of proteins. The GO terms associated with each protein were used as labels for supervised learning. These labels were categorized into three distinct groups: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC), each serving as an independent prediction task during training.\n\nTo address the highly imbalanced nature of the GO term labels, we introduced the Matthews Correlation Coefficient (MCC) as an evaluation metric. The MCC is computed under a threshold that yields a maximum protein-centric measure, Fmax. This metric provides a balanced measure of the model's performance, especially in the presence of imbalanced classes.\n\nAdditionally, we proposed Smin to denote the semantic distance between predicted and true annotations, considering the information content of GO terms. Smin is computed using the average uncertainty and misinformation under a given threshold, providing a more nuanced evaluation of the model's predictions.\n\nThe dataset was further augmented with the AFch dataset, which consists of 41,997 proteins from the SWISS-MODEL repository. These proteins were selected to mitigate the imbalance in GO term labels observed in the PDBch dataset. The structures of these proteins were predicted using AlphaFold2 and retrieved from the AlphaFold protein structure database. This augmentation helped in enhancing the model's generalizability and robustness.\n\nIn summary, the data encoding process involved graph-based representations of protein structures, careful selection and clustering of protein sequences, and the use of GO terms as labels for supervised learning. The introduction of MCC and Smin as evaluation metrics ensured a comprehensive assessment of the model's performance, especially in the context of imbalanced labels.",
  "optimization/parameters": "In our study, the model GALA incorporates several key parameters that were carefully selected to optimize performance. The primary parameters include those related to the training datasets, the architecture of the neural network, and the hyperparameters used during training.\n\nThe datasets used in our model include PDBch and AFch. PDBch is derived from the Protein Data Bank (PDB) and clustered using MMseqs at a sequence identity of 30%. This dataset is divided into training, validation, and test sets with an approximate ratio of 8:1:1. The AFch dataset consists of 41,997 proteins selected from SWISS-MODEL, also partitioned into training, validation, and test sets similarly to PDBch.\n\nThe neural network architecture includes components such as graph convolutional networks (GCNs) and multilayer perceptrons (MLPs). These components are designed to capture complex relationships within the protein data. The specific number of layers and neurons in each layer were determined through extensive experimentation and validation to ensure optimal performance.\n\nHyperparameters such as learning rate, batch size, and the number of epochs were tuned using techniques like grid search and random search. The learning rate was adjusted using the Adam optimizer, which is known for its efficiency in handling sparse gradients. The batch size and number of epochs were selected based on the model's convergence behavior and performance on the validation set.\n\nAdditionally, the model employs contrastive loss to align protein embeddings with label embeddings in the latent space, enhancing the model's ability to generalize across different domains. This alignment is crucial for improving the model's performance on the target domain, which consists of test sets that are less similar to the source domain.\n\nIn summary, the selection of parameters in our model was driven by a combination of theoretical considerations and empirical validation. The datasets, neural network architecture, and hyperparameters were all chosen to maximize the model's accuracy and robustness in predicting protein functions.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The fitting method employed in our study involved training models on datasets with a significant number of parameters relative to the number of training points. This approach is common in deep learning, where models often have many parameters to capture complex patterns in the data.\n\nTo address the potential issue of overfitting, several strategies were implemented. Firstly, the training and test sets were designed to have low sequence identity, ensuring that the models were evaluated on dissimilar data. This dissimilarity helps in assessing the generalization capability of the models. Additionally, techniques such as cross-validation and the use of separate validation sets were employed to monitor the model's performance on unseen data. Regularization methods, including dropout and weight decay, were also utilized to prevent the model from memorizing the training data.\n\nUnderfitting was mitigated by ensuring that the models were sufficiently complex to capture the underlying patterns in the data. This was achieved by using architectures that have proven effective in similar tasks, such as those based on graph neural networks and transformers. The models were trained for an adequate number of epochs, and early stopping was used to prevent overfitting while ensuring that the models had enough time to learn the relevant features.\n\nFurthermore, the use of multiple evaluation metrics, including AUPR, F max, S min, and MCC, provided a comprehensive assessment of the models' performance. These metrics helped in identifying any potential issues with underfitting or overfitting by evaluating different aspects of the models' predictions. The results demonstrated that the models achieved competitive performance on various tasks, indicating that both overfitting and underfitting were effectively managed.",
  "optimization/regularization": "In our optimization process, we employed several techniques to prevent overfitting and enhance the generalizability of our model. One key method involved the use of a domain adversarial discriminator. This component helps to align the source and target domains by minimizing the discrepancy between them, which is particularly beneficial when dealing with low sequence identity. By doing so, we ensure that the model can generalize well to unseen data, reducing the risk of overfitting to the training set.\n\nAdditionally, we utilized a label embedding alignment module. This module generates label embeddings for the source data and aligns them with the graph embeddings in the hidden space. This alignment aids in learning semantics from the labeled source data, thereby improving the model's ability to handle class imbalances and enhancing its predictive performance across different categories of GO terms.\n\nFurthermore, we incorporated a weighted sampling strategy. This strategy adjusts the weights of samples based on the certainty of predictions, prioritizing examples that are easier to transfer. This approach helps the discriminator focus on more transferable examples, further improving the model's generalization ability.\n\nThese regularization techniques collectively contribute to the robustness and accuracy of our model, ensuring that it performs well even on diverse and challenging datasets.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters are available. The project is hosted on GitHub under the name GALA, and the repository can be accessed at https://github.com/fuyw-aisw/GALA. The project is licensed under the MIT license, which allows for free use, modification, and distribution of the code.\n\nAdditionally, an archival copy of the code and other supporting data is openly available in the GigaScience repository, GigaDB. This repository includes detailed information about the datasets used, the construction of the datasets, and the performance of the model on various test sets. The GigaDB repository also provides links to DOME-ML annotations, which include further details on the data, optimization, model, and evaluation in machine learning.\n\nFor those interested in running the model, a Docker package is available, named fuyw99/gala. This package includes all the necessary dependencies and configurations to run the model on a compatible system. The Docker package ensures that the model can be run in a consistent environment, regardless of the underlying hardware or software configuration.\n\nThe supplementary files provide additional information about the construction of datasets, descriptions of several baseline methods, and performance comparisons. These files are available as part of the supplementary materials accompanying the publication.",
  "model/interpretability": "The model GALA is designed with a strong emphasis on biological interpretability, making it transparent rather than a black box. To achieve this, we employ Grad-CAM, a technique that helps identify key residues contributing to specific Gene Ontology (GO) annotation functions. This process involves using the output of the final graph convolution layer as a feature map. By taking the derivative of the protein function with respect to this feature map, we obtain gradient weights. These weights are then used to calculate a contribution score for each residue, which is normalized and visualized through heatmaps.\n\nFor instance, in the case of molecular function (MF) GO terms, we have demonstrated that the generated heatmaps align with experimentally confirmed binding sites. One example is the protein 3DNF, associated with iron–sulfur cluster binding. The heatmaps show strong signals in key residues that bind with the iron–sulfur cluster. Another example is the protein 2ZSC, involved in monocarboxylic acid binding, where the heatmaps reveal regions of strong signal surrounding its binding sites. For biological process (BP) GO terms, the protein 1P4U, which functions in peptide transport, shows significant Grad-CAM signals in residues within the peptide binding interface.\n\nThese examples illustrate how GALA can provide clear and interpretable insights into the functional residues of proteins, enhancing our understanding of their biological roles. The area under the receiver operating characteristic curve (AUC-ROC) further supports the model's capability to capture functional residues, providing strong evidence for its biological interpretability.",
  "model/output": "The model is designed for protein function prediction, which is a classification task. It specifically addresses the prediction of Gene Ontology (GO) terms, which are categorized into three main aspects: molecular function (MF), biological process (BP), and cellular component (CC). The model's performance is evaluated using several metrics, including the area under the precision-recall curve (AUPR), F max, specificity (S min), and Matthews correlation coefficient (MCC). These metrics are used to assess the model's ability to accurately classify and predict protein functions.\n\nThe model employs a graph transformer architecture, leveraging both sequence and structural data as inputs. This approach allows it to handle proteins with dissimilar sequences and those lacking experimentally resolved structures. The use of adversarial learning and label embedding alignment helps in extracting domain-invariant representations, enhancing the model's generalization capabilities.\n\nThe model's output includes predictions for various GO terms, and its performance is compared against several baseline methods. The results demonstrate that the model outperforms these baselines, particularly in scenarios where the sequence identity between training and test sets is minimal. This indicates the model's strong generalization ability and its effectiveness in transferring information from the source domain to the target domain.\n\nThe model's interpretability is also highlighted, as it can identify key residues that contribute to protein functions. This is achieved through the use of Grad-CAM, which provides visualizations of the contribution scores mapped onto protein structures. These visualizations help in understanding the biological relevance of the model's predictions.\n\nIn summary, the model is a classification model designed for protein function prediction. It uses advanced techniques to handle complex data and provides interpretable results, making it a valuable tool for biological research.",
  "model/duration": "The model was trained using a single A100-PCIE 80 GB graphics processing unit (GPU), with training times of approximately 2 hours using a batch size of 64. The running times for several protein cases are provided in supplementary materials. All modules were trained under these conditions, ensuring efficient and consistent performance across different experiments.",
  "model/availability": "The source code for the project named GALA is publicly available. It can be accessed via the project's homepage on GitHub at https://github.com/fuyw-aisw/GALA. The project is platform-independent and is programmed in Python. There are no additional requirements beyond the standard Python environment.\n\nFor those who prefer using containerized environments, a Docker package named fuyw99/gala is also available. This package simplifies the deployment process by encapsulating all dependencies within a Docker container.\n\nThe software is released under the MIT license, which permits free use, modification, and distribution, provided that the original copyright and license notice are included in all copies or substantial portions of the software. This licensing approach ensures that users have the flexibility to integrate and adapt the software to their specific needs while maintaining the integrity of the original work.",
  "evaluation/method": "The evaluation of our method, GALA, involved a comprehensive comparison with several baseline methods, including both sequence alignment-based and deep learning-based approaches. To ensure a fair comparison, all methods were retrained on the combined PDBch and AFch training sets. The performance was then assessed on designated test sets, including the PDBch test set and a newly annotated test set comprising proteins from the Swiss-Prot database that were annotated between January 2021 and June 2024.\n\nThe evaluation metrics used included AUPR, F max, S min, and MCC. These metrics provided a thorough assessment of the methods' performance across three Gene Ontology (GO) domains: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC). The results were summarized in tables, with the best and second-best performances highlighted for clarity.\n\nAdditionally, an ablation study was conducted to evaluate the impact of different modules within GALA. This study involved training the model with various combinations of the AFch set, adversarial learning for domain alignment, and label embedding alignment. The results of this study were presented in a table, showing the performance of different model configurations across the same evaluation metrics.\n\nTo further validate the robustness of GALA, temporal validation was performed. This involved evaluating the method on a test set of newly annotated proteins, ensuring that the model's performance was consistent over time. The results demonstrated that GALA exhibited outstanding performance on this newly annotated test set, confirming its robustness and generalization ability.",
  "evaluation/measure": "In our study, we employ a comprehensive set of evaluation metrics to assess the performance of our protein function prediction model. These metrics are widely recognized and utilized in the field, ensuring that our results are comparable with other state-of-the-art methods.\n\nWe report the following performance metrics:\n\n* **Function-centric AUPR (Area Under the Precision-Recall Curve)**: This metric is calculated by averaging the sum of all AUPR values for each Gene Ontology (GO) term. It provides a function-centric evaluation, focusing on the performance of the model for individual GO terms.\n\n* **Protein-centric F max**: This metric is defined as the maximum F1 score, which is the harmonic mean of precision and recall, across all threshold values. It offers a protein-centric evaluation, considering the overall performance of the model for each protein.\n\n* **Matthews Correlation Coefficient (MCC)**: This metric is computed under the threshold that yields the maximum protein-centric F max. MCC takes into account true and false positives and negatives, providing a balanced measure of the model's performance, especially in the presence of class imbalances.\n\n* **S min**: This metric denotes the semantic distance between predicted and true annotations, considering the information content of GO terms. It evaluates the semantic similarity of the predicted functions to the true functions.\n\nThese metrics collectively provide a thorough evaluation of our model's performance, addressing both function-centric and protein-centric aspects, as well as considering the semantic similarity of the predictions. The use of these metrics aligns with the critical assessment of functional annotation (CAFA) challenge, ensuring that our evaluation is representative and comparable to other studies in the literature.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our model, GALA, against several baseline methods on benchmark datasets. The comparison included both state-of-the-art methods and simpler baselines to ensure a comprehensive assessment.\n\nWe conducted evaluations on multiple datasets, including the PDBch test set, the AFch test set, and a nonhomologous PDBch test set. These datasets allowed us to assess the robustness and generalization capabilities of our model across different scenarios.\n\nFor the PDBch test set, we compared GALA with methods such as Blast, DeepGOplus, TALE+, DeepFRI, Struct2GO, and HEAL. The performance metrics used included AUPR, F max, Smin, and MCC across three Gene Ontology (GO) domains: molecular function (MF), biological process (BP), and cellular component (CC). GALA demonstrated superior performance in most metrics and GO domains, particularly excelling in MF and BP tasks.\n\nSimilarly, for the AFch test set, GALA outperformed all other methods significantly in MF, BP, and CC tasks. This consistent superior performance across different datasets underscores the effectiveness of our model.\n\nAdditionally, we performed a temporal validation by evaluating the methods on proteins newly annotated in the Swiss-Prot database since 2021. This validation is crucial as it provides a comprehensive assessment of our method’s robustness over time. GALA exhibited outstanding performance on this newly annotated test set, confirming its robustness and adaptability.\n\nIn summary, the comparison with publicly available methods and simpler baselines on benchmark datasets showed that GALA consistently outperforms existing approaches, demonstrating its effectiveness and reliability in protein function prediction.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of our method, GALA, includes a comprehensive comparison with several baseline methods across various test sets. The performance metrics used, such as AUPR, F max, S min, and MCC, provide a robust assessment of the model's effectiveness. However, specific details about confidence intervals for these metrics are not explicitly mentioned. This omission suggests that while the metrics themselves are well-defined and widely accepted in the field, the statistical significance of the results in terms of confidence intervals is not provided.\n\nThe results indicate that GALA outperforms other baseline methods in most evaluation metrics across different GO domains (MF, BP, and CC). For instance, GALA achieves the highest AUPR and F max scores in the MF and BP tasks, demonstrating its superior performance. Similarly, GALA shows competitive results in the CC task, although it is slightly outperformed by Struct2GO and HEAL in this specific domain. These comparisons are visually supported by figures and tables that highlight the best and second-best performances.\n\nThe temporal validation conducted on newly annotated proteins in the Swiss-Prot database since 2021 further confirms the robustness of GALA over time. The method's ability to handle proteins with low sequence identity to the training set underscores its generalization capability. This is particularly important for evaluating the method's performance when training and test sets are dissimilar, a scenario that is crucial for real-world applications.\n\nIn summary, while the performance metrics and comparisons provide strong evidence of GALA's superiority, the lack of explicit confidence intervals means that the statistical significance of these results is not fully quantified. Nonetheless, the consistent outperforming of baseline methods across multiple metrics and test sets suggests that GALA is a reliable and effective method for protein function prediction.",
  "evaluation/availability": "The evaluation datasets used in this study are sourced from DeepFRI. The first dataset, named PDBch, is selected from the PDB database and clustered using MMseqs at a sequence identity of 30%. The training, validation, and test sets are chosen from different clusters with an approximate ratio of 8:1:1. The second dataset, AFch, consists of 41,997 proteins selected from SWISS-MODEL and partitioned similarly to the PDBch dataset.\n\nAn archival copy of the code and other data further supporting this work are openly available in the GigaScience repository, GigaDB. Additionally, a link to DOME-ML (Data, Optimization, Model, and Evaluation in Machine Learning) annotations is available via GigaDB. The project is licensed under the MIT license, ensuring open access and reuse of the materials.\n\nThe running times for several protein cases are provided in Supplementary Table S6. Detailed information about the construction of datasets, descriptions of several baseline methods, and additional performance metrics are available in the supplementary files. These files include AUPR comparisons for GO terms on the PDBch test set, performance under different specificities, and plots for the interpretability of key residues."
}