{
  "publication/title": "TransHLA: a hybrid transformer model for HLA-presented epitope detection",
  "publication/authors": "The authors who contributed to this article are Tianchi L, Xueying W, and Wan N. The specific contributions of each author to the paper are not detailed.",
  "publication/journal": "GigaScience",
  "publication/year": "2025",
  "publication/doi": "10.1016/j.bbapap.2013.02.011",
  "publication/tags": "- TransHLA\n- HLA-presented epitope detection\n- Hybrid transformer model\n- Binary classification\n- Peptide bioactivity\n- Sequence classification\n- Machine learning\n- Bioinformatics\n- Epitope prediction\n- Protein PLM embeddings",
  "dataset/provenance": "The datasets used in this article were collected from several established databases, including IEDB, CEDAR, VDJdb, ImmunoCode, dbpepneo2.0, and NEPdb. These databases provided a comprehensive set of epitopes and peptide sequences necessary for our research.\n\nThe IEDB database was particularly crucial for constructing the training, validation, and test datasets. Positive samples were collected using specific filtering criteria, such as \"MHC Ligand,\" \"Linear Peptide,\" \"Host\" as Human, and \"Outcome\" as Positive. For negative samples, we employed the diamond tool to blast the positive peptide sequences against the nonredundant (nr) database, ensuring that the selected fragments did not overlap with the positive sequences.\n\nThe datasets were balanced to include an equal number of positive and negative samples. Specifically, for HLA-I epitopes, we had 459,442 positive and 459,442 negative samples. For HLA-II epitopes, the datasets consisted of 312,245 positive and 312,245 negative samples. These datasets were then divided into training, validation, and test sets in a 7:1:2 ratio.\n\nThe other databases—CEDAR, VDJdb, ImmunoCode, and dbpepneo2.0—were utilized exclusively for external testing to assess the generalizability of our models. The NEPdb was specifically used for evaluating the performance on neoepitope prediction, with a focus on epitopes from human hosts that showed positive outcomes in ligand elution/mass spectrometry assays.\n\nAdditionally, the datasets and supporting data, including the training and test data along with the source code of TransHLA, are available via the GigaScience database, GigaDB. The alleles used by the software for predicting HLA-binding affinity are also provided in GigaDB. Furthermore, DOME-ML (Data, Optimization, Model, and Evaluation in Machine Learning) annotations are available in the DOME registry.\n\nThe datasets used in this study have been previously utilized by the community, ensuring that our research builds upon established foundations. The comprehensive and balanced nature of these datasets allows for robust evaluation and validation of our models.",
  "dataset/splits": "The dataset was divided into three splits: training, validation, and test sets. The ratio for these splits was 7:1:2.\n\nFor HLA-I epitopes, there were 459,442 positive samples and an equal number of negative samples. The training set contained the majority of these samples, followed by the test set and then the validation set.\n\nFor HLA-II epitopes, there were 312,245 positive samples and an equal number of negative samples. Similar to HLA-I, the training set had the most samples, with the test set and validation set containing fewer samples.\n\nThe specific number of samples in each split can be calculated based on the given ratio and total sample counts. For HLA-I, the training set would have approximately 321,609 samples, the validation set around 45,944 samples, and the test set about 91,889 samples. For HLA-II, the training set would have around 218,571 samples, the validation set about 31,225 samples, and the test set approximately 62,450 samples.",
  "dataset/redundancy": "The datasets were split into training, validation, and test sets in a ratio of 7:1:2. This ensures that the training set is sufficiently large to train robust models, while the validation and test sets are used to tune hyperparameters and evaluate the model's performance, respectively.\n\nThe training and test sets are independent. To enforce this independence, we used the diamond tool to blast the positive peptide sequences against the nonredundant (nr) database. This process helped us recover the proteins from which the sequences originated. From these proteins, random fragments excluding the positive sequences were selected to ensure non-overlap. For the positive samples, peptides that did not align with any protein in the nr database using diamond were removed. This method ensured that the negative samples are representative of the potential peptide repertoire but do not include the known positive epitopes.\n\nSequence redundancy was removed using CD-HIT with a threshold of 0.8. This step further ensured that the datasets were non-redundant and balanced, with an equal number of positive and negative samples for both HLA-I and HLA-II epitopes.\n\nThe distribution of HLA alleles associated with peptide binding was examined to ascertain the reasonableness of our data distribution. The frequency distribution of HLA alleles demonstrates highly similar characteristics across the training, validation, and test datasets. This similarity indicates that our datasets are well-balanced and representative of the broader population, which is crucial for the generalizability of our models.\n\nIn comparison to previously published machine learning datasets, our approach to ensuring dataset independence and non-redundancy is rigorous. The use of the nr database and CD-HIT for redundancy removal, along with the careful selection of positive and negative samples, sets a high standard for dataset preparation in the field. This meticulous process helps in building reliable and generalizable models for predicting HLA-binding epitopes.",
  "dataset/availability": "The datasets utilized in this article were sourced from several databases, including IEDB, CEDAR, VDJdb, ImmunoCode, dbpepneo2.0, and NEPdb. An archival copy of the code and supporting data is available via the GigaScience database, GigaDB. Additionally, the training and test data, along with the source code of TransHLA, have been submitted to GigaDB. The alleles used by the software for predicting HLA-binding affinity are also provided in GigaDB. Furthermore, DOME-ML (Data, Optimization, Model, and Evaluation in Machine Learning) annotations are available in the DOME registry via accession peuywb6nkx.\n\nThe datasets were divided into training, validation, and test sets in a ratio of 7:1:2. The details can be found in the provided tables. To ensure the reasonableness of the data distribution, the frequencies of HLA alleles associated with peptide binding within the IEDB database were examined. The frequency distribution of HLA alleles demonstrates highly similar characteristics across the training, validation, and test datasets. The training-validation-test data include 258 different HLA-I alleles and 227 different HLA-II alleles.\n\nThe data is publicly available and can be accessed through the GigaScience database, GigaDB, and the DOME registry. The licensing details for the data and code are not specified, but it is implied that they are available for use in accordance with the policies of the respective databases and registries. The enforcement of data availability was ensured by submitting the datasets and code to reputable public repositories, making them accessible for verification and further research.",
  "optimization/algorithm": "The optimization algorithm employed in our work is based on a modified transductive information maximization (TIM) loss function. This approach merges conventional cross-entropy loss with a mutual information component, tailored for empirical analysis. The TIM loss function is designed to enhance the model's generalization in few-shot scenarios without relying on complex meta-learning schemes.\n\nThe TIM loss function integrates several key components:\n\n1. **Empirical Conditional Entropy (ˆH(Y|X))**: This term reduces uncertainty in predictions for unlabeled samples, encouraging the model to output confident predictions.\n2. **Empirical Marginal Entropy (ˆH(Y))**: This term promotes a uniform distribution of labels, preventing bias toward any particular class.\n3. **Cross-Entropy Loss (CE)**: This component measures the difference between the model’s predictions and the actual outcomes.\n\nThe final loss function is defined as:\n\n\\[ \\hat{L}(X;Y) := CE - \\hat{H}(Y) + \\alpha \\hat{H}(Y|X) \\]\n\nwhere \\(\\alpha\\) is a hyperparameter that determines the rate of convergence for each term in the loss function. In our experiments, \\(\\alpha\\) is set to 0.04, considering the standard cross-entropy loss and standard mutual information.\n\nThis algorithm is not entirely new but is adapted from existing work by Boudiaf et al. The reason it was not published in a machine-learning journal is that the focus of our publication is on the application of this algorithm to the specific problem of HLA-presented epitope detection, rather than the development of the algorithm itself. The adaptation and application of the TIM loss function to our specific problem domain is what makes our work novel and significant.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it leverages pre-trained protein language models and structure prediction tools to extract sequence and structure embeddings. These embeddings are then processed using a Transformer encoder module to enhance the extraction of global features. The model is designed to predict HLA-presented epitopes, focusing on both HLA-I and HLA-II classes. The training process involves a loss function that includes cross-entropy loss and mutual information, with specific hyperparameters chosen to ensure fairness and impartiality. The performance of the model is evaluated using various metrics, including accuracy, recall, F1 score, Matthews correlation coefficient, precision, and specificity. Additionally, the model's robustness is validated in real-world scenarios with imbalanced datasets.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithm. We began by addressing the issue of varying epitope lengths. For HLA-I binding epitopes with lengths less than 14 and HLA-II binding epitopes with lengths less than 21, we employed a padding technique. This involved adding ones to the end of the sequences to ensure they met the required lengths, facilitating uniform input for our models.\n\nWe utilized pretrained protein language models, specifically the ESM2 model, to extract sequence embeddings. These embeddings provided intricate representations of the protein sequences, which are essential for accurate classification. Additionally, we predicted structure embeddings for these epitopes using the same model. This dual approach of sequence and structure embedding allowed us to capture both local and global features of the epitopes.\n\nThe extracted embeddings were then processed through a Transformer encoder module. This module leveraged the pretrained sequence features, represented as a matrix, to enhance the extraction of global features. The Transformer encoder utilized multi-head attention mechanisms to independently process each transformed vector, promoting a more compact and effective representation.\n\nFurthermore, we employed Convolutional Neural Networks (CNNs) to enhance feature extraction. Two structurally identical CNNs were used, each consisting of a region embedding layer followed by multiple convolutional layers. These CNNs processed both the pretrained sequence features and the contact map structural features extracted by ESM2. Residual connections were implemented between each module to prevent gradient vanishing and ensure effective training of the deep network structure.\n\nThe region embedding layer provided a dense representation of the sequences, which was then passed through convolutional blocks. These blocks contained multiple convolutional layers, each with a specified number of feature maps. The output from these layers was further processed through pooling layers to reduce the feature map size, followed by additional convolutional blocks to refine the features.\n\nThis comprehensive encoding and preprocessing pipeline ensured that our machine-learning algorithm could effectively learn from the data, leading to improved performance in epitope classification tasks.",
  "optimization/parameters": "In the optimization process of our models, several input parameters were utilized, each playing a crucial role in defining the architecture and performance of the models.\n\nFor the RNN_ATTs model, the key parameters include a vocabulary size of 40, an embedding dimension of 256, and a hidden dimension for the LSTM of 128. The model employs two LSTM layers with bidirectional processing enabled, and a dropout rate of 0.2 is applied to prevent overfitting. Additionally, a second hidden layer with a size of 64 and an output dimension of 2 for binary classification are specified. The padding index is set to 0, ensuring consistent tensor dimensions during processing.\n\nThe TextCNN model, designed for text classification tasks, uses a vocabulary size of 40 tokens and an embedding dimension of 128. It features convolutional layers with varying window sizes of 2, 4, and 3, each with 256 filters. The maximum sequence length is set to 21, and a dropout rate of 0.4 is applied. The model is configured for binary classification with an output dimension of 2.\n\nThe TextRCNN model combines RNN and CNN concepts, utilizing a vocabulary size of 40 tokens and an embedding dimension of 128. The hidden size for the LSTM is set to 50, balancing the capacity to capture sequential dependencies while maintaining computational efficiency.\n\nThe selection of these parameters was guided by empirical experiments and domain knowledge. The vocabulary size and embedding dimensions were chosen to capture the essential features of the input sequences effectively. The number of LSTM layers and the hidden dimensions were tuned to optimize the model's ability to learn from the data without overfitting. The dropout rates were selected to enhance generalization by preventing the model from becoming too reliant on specific patterns in the training data. The window sizes and number of filters in the TextCNN model were chosen to capture both local and global features in the sequences. Overall, these parameters were carefully selected to ensure robust performance across various sequence classification tasks.",
  "optimization/features": "In the optimization process of our model, we utilized several features to predict epitope presentation. The features considered included helix content, aromaticity, flexibility, sheet content, isoelectric point, mean charge at pH 7, coil content, hydrophobicity, mean molecular weight, and instability index.\n\nFeature selection was performed using the XGBoost algorithm on the same dataset as TransHLA. This process identified the top features for HLA-I and HLA-II. For HLA-I, the most important features were helix content, aromaticity, and flexibility. For HLA-II, the top features were aromaticity, helix content, and hydrophobicity.\n\nThe feature selection process was conducted using the training set only, ensuring that the model's performance on the test set was not influenced by the feature selection process. This approach helps in maintaining the integrity of the evaluation metrics and prevents data leakage, which could otherwise lead to overoptimistic performance estimates.",
  "optimization/fitting": "The TransHLA model employs a hybrid transformer architecture, which inherently involves a large number of parameters. This is particularly true when considering the extensive datasets used for training, which include a vast number of HLA-I and HLA-II epitopes and their corresponding negative samples. The model's complexity is further amplified by the inclusion of pretrained embeddings for both sequence and structure, which provide rich representations of the input data.\n\nTo address the potential issue of overfitting, several strategies were implemented. Firstly, the training process utilized a balanced dataset with an equal number of positive and negative samples, ensuring that the model did not become biased towards the majority class. Additionally, the use of a 1:1 ratio of negative samples for training helped in learning the unified features of epitopes, thereby improving the model's ability to generalize. Regularization techniques, such as dropout layers, were also incorporated to prevent the model from memorizing the training data.\n\nThe loss function for TransHLA is designed to balance the cross-entropy loss and mutual information, with a hyperparameter α set to 0.04. This careful tuning of the loss function helps in maintaining a fair and impartial training process, further mitigating the risk of overfitting.\n\nTo rule out underfitting, the model's performance was rigorously evaluated using multiple metrics, including accuracy, recall, F1 score, Matthews correlation coefficient, precision, and specificity. The model demonstrated superior performance across these metrics in benchmark comparisons with other sequence classification models. Furthermore, the use of pretrained embeddings and the hybrid transformer architecture ensured that the model could capture complex patterns in the data, reducing the likelihood of underfitting.\n\nThe ablation study conducted on different modules of the model provided insights into the contributions of each component. The results showed that the inclusion of the transformer module, CNN module, and pretrained embeddings significantly improved the model's performance, indicating that these components were essential for capturing the necessary features from the data.\n\nIn summary, the TransHLA model's architecture and training strategies were designed to address both overfitting and underfitting. The use of balanced datasets, regularization techniques, and a carefully tuned loss function ensured that the model could generalize well to unseen data, while the inclusion of pretrained embeddings and a hybrid transformer architecture helped in capturing the complex patterns necessary for accurate epitope detection.",
  "optimization/regularization": "In our study, we implemented several regularization techniques to prevent overfitting and ensure the robustness of our model. One key method involved the use of a batch normalization layer after the final downsampling layer. This layer helps to reduce internal covariate shift, which can stabilize and accelerate the training process. Additionally, it acts as a regularization technique by adding a small amount of noise to the model, which can help prevent overfitting.\n\nAnother crucial aspect of our regularization strategy is the incorporation of the Transductive Information Maximization (TIM) loss function. This loss function combines cross-entropy loss with mutual information components, which encourages the model to produce confident predictions and maintain a uniform distribution of labels. By doing so, it helps to prevent the model from becoming biased towards any particular class, thereby enhancing its generalization capabilities, especially in few-shot scenarios.\n\nFurthermore, we conducted an ablation study to evaluate the contribution of different components of our model. This study involved testing various configurations, such as removing the transformer module, omitting pretrained embeddings, and changing the loss function to standard cross-entropy. The results of this study highlighted the importance of each component in maintaining the model's performance and preventing overfitting. For instance, the sequence embedding approach was found to be significantly more effective in capturing peptide features compared to extended sequences, which often confused the model due to the loss of distinguishing features.\n\nOverall, these regularization techniques played a vital role in ensuring that our model, TransHLA, achieved high performance metrics across various evaluation criteria, including accuracy, recall, F1 score, and Matthews correlation coefficient.",
  "optimization/config": "The hyper-parameter configurations for several models are detailed in the publication. For the RNN_ATTs model, key hyperparameters include a vocabulary size of 40, an embedding dimension of 256, and a hidden dimension of 128 for the LSTM layers. The TextCNN model specifies a vocabulary size of 40 tokens, an embedding dimension of 128, and window sizes of [2, 4, 3] for the convolutional filters. The TextRCNN model also uses a vocabulary size of 40 tokens and an embedding dimension of 128, with a hidden size of 50 for the LSTM layers.\n\nThe TransHLA model, designed for immunogenetics, incorporates a hybrid architecture with both Transformer and CNN components. Its hyperparameters include a maximum input length of 512, a CNN padding index of 0, and a CNN number of channels of 256. The DPCNN model, used for text classification, has a vocabulary size of 1000 words, an embedding dimension of 256, and 256 channels for convolutional operations.\n\nThe optimization schedule and specific model files are not explicitly detailed in the provided information. However, the publication mentions the use of standard metrics such as accuracy, recall, F1 score, and Matthews correlation coefficient for performance evaluation. The loss function for TransHLA is defined with a hyperparameter α set to 0.04, which balances the convergence rate of the terms in the loss function.\n\nRegarding the availability and licensing of the configurations, optimization schedule, model files, and optimization parameters, specific details are not provided. It is assumed that the configurations reported in the publication are available within the supplementary materials or associated datasets, but the exact licensing terms are not specified. For precise information on accessibility and licensing, readers would need to refer to the original publication or supplementary materials.",
  "model/interpretability": "The TransHLA model, while leveraging advanced transformer architecture for its predictive capabilities, does offer some level of interpretability, though it is not entirely transparent. The model's design allows for the extraction of high-quality peptide embeddings in a low-dimensional space, which can be visualized and analyzed. This feature extraction capability is crucial for understanding how different chemical properties of peptides influence the model's predictions.\n\nFor instance, the model considers various features such as helix content, aromaticity, flexibility, and hydrophobicity, among others, to differentiate between epitopes and non-epitopes. These features are ranked by their importance in the model's decision-making process, providing insights into which properties are most influential for HLA-I and HLA-II classifications. For example, helix content and aromaticity are particularly important for HLA-I, while aromaticity and hydrophobicity play significant roles for HLA-II.\n\nAdditionally, the model's performance is evaluated using metrics like AUROC and AUPRC, which help in understanding its discriminative power and precision-recall trade-off. These evaluations are visualized in figures that compare TransHLA's performance against other models, highlighting its effectiveness in identifying epitopes under imbalanced distributions.\n\nFurthermore, the model's robustness is validated through experiments with varying positive-to-negative sample ratios, demonstrating its ability to maintain high accuracy and specificity even in challenging scenarios. This validation process includes detailed results and supplementary figures that illustrate the distribution of chemical properties across different sample subsets, providing a deeper understanding of the model's behavior.\n\nWhile TransHLA is not a completely transparent model, these interpretability features allow researchers to gain valuable insights into the model's decision-making process and the underlying biological properties that influence epitope prediction.",
  "model/output": "The model is designed for binary classification tasks. This is evident from the use of a binary variable to indicate sequence categorization and the specification of two classes in the output dimension. The final output of the model provides classification scores corresponding to these two classes. Various metrics such as accuracy, recall, F1 score, and Matthews correlation coefficient are employed to evaluate the model's performance, further confirming its classification nature. Additionally, the use of metrics like precision and specificity, along with the area under the ROC and precision-recall curves, underscores the model's focus on classification accuracy. The architecture includes layers and operations tailored for sequence classification, including embedding layers, LSTM layers, and linear layers that map to the final output dimension of two classes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the TransHLA software is publicly available. It can be accessed via the project's GitHub repository, which is located at https://github.com/SkywalkerLuke/TransHLA. The software is platform-independent and is programmed in Python, requiring Python 3.9 or higher and PyTorch 2.0 or higher to run. It is released under the MIT license, which permits free use, modification, and distribution of the software, provided that the original authors are credited.\n\nIn addition to the source code, the datasets used in the article are collected from various databases, including IEDB, CEDAR, VDJdb, ImmunoCode, dbpepneo2.0, and NEPdb. An archival copy of the code and supporting data is available via the GigaScience database, GigaDB. The training and test data, along with the source code of TransHLA, have also been submitted to GigaDB. The alleles used by the software for predicting HLA-binding affinity are also provided in GigaDB. Furthermore, DOME-ML (Data, Optimization, Model, and Evaluation in Machine Learning) annotations are available in the DOME registry via the accession peuywb6nkx.\n\nThe software's performance has been evaluated using various metrics, including accuracy, recall, F1 score, Matthews correlation coefficient, precision, and specificity. The software has shown higher accuracy compared to conventional methods, achieving an accuracy of 90.65% for HLA-I epitopes in a general NeoEpitope dataset verified by TCR experiments. The software's performance metrics, such as AUROC and AUPRC, have been affected by the removal of specific modules for both HLA-I and HLA-II classes, providing insight into the model's architecture and the pivotal elements for its effectiveness across HLA classes.",
  "evaluation/method": "The evaluation of TransHLA involved a comprehensive assessment using various metrics and datasets to ensure robust performance. We employed a binary classification approach, with the binary variable indicating whether a sequence belongs to a specific class. The final loss function for TransHLA was designed to balance convergence rates, with a hyperparameter set to 0.04 to maintain fairness during training.\n\nFor performance evaluation, we used several key metrics: accuracy (ACC), recall, F1 score, Matthews correlation coefficient (MCC), precision, and specificity. These metrics were chosen to provide a thorough assessment of the model's ability to correctly identify true epitopes and filter out negative samples. Additionally, we utilized receiver operating characteristic (ROC) and precision-recall (PR) curves, along with their respective area under the curve (AU-ROC and AU-PRC) values, to quantify overall performance.\n\nThe benchmark results compared TransHLA with state-of-the-art sequence classification models, including TextCNN, TextRCNN, DPCNN, and RNN-ATTs, using independent test sequences from the Immune Epitope Database (IEDB). TransHLA demonstrated superior performance across multiple metrics, particularly in classifying HLA-I epitopes. For HLA-II binding predictions, which are generally more complex, TransHLA still showed robust classification performance, outperforming other models in all evaluation metrics.\n\nFurthermore, we conducted an ablation study to evaluate the contribution of different components of TransHLA. This study involved testing variants of the model with specific modules removed or altered, such as the transformer module, structure pretrained embedding, sequence pretrained embedding, CNN module, and different loss functions. The results highlighted the significance of sequence embedding and the CNN module in capturing peptide features and enhancing performance.\n\nIn addition to these evaluations, we investigated the chemical properties and secondary structure of peptide segments using Biopython. This analysis included properties such as aromaticity, hydrophobicity, flexibility, instability index, isoelectric point, average molecular weight, and mean charge at pH 7. These properties were analyzed to understand their impact on epitope presentation and prediction accuracy.\n\nOverall, the evaluation of TransHLA was thorough and multifaceted, involving a combination of benchmarking against other models, ablation studies, and chemical property analysis. This comprehensive approach ensured that TransHLA's performance was rigorously tested and validated.",
  "evaluation/measure": "In the evaluation of our model, we employed a comprehensive set of performance metrics to ensure a thorough assessment. These metrics include accuracy (ACC), recall, F1 score (F1), and Matthews correlation coefficient (MCC). These are standard metrics used in the literature for evaluating classification models, providing a robust measure of our model's performance.\n\nAdditionally, we augmented our evaluation with precision and specificity, which are crucial for understanding the model's ability to correctly identify negative samples. These metrics are particularly important in the context of epitope prediction, where the correct identification of non-epitopes is as critical as identifying true epitopes.\n\nTo further quantify the overall performance, we utilized the area under the receiver operating characteristic curve (AU-ROC) and the area under the precision-recall curve (AU-PRC). These metrics provide a holistic view of the model's discriminative power and its performance under imbalanced data distributions.\n\nThe inclusion of these metrics ensures that our evaluation is representative of the standards in the field, allowing for a fair comparison with other models and providing a clear understanding of our model's strengths and areas for improvement.",
  "evaluation/comparison": "In the evaluation of our model, TransHLA, we conducted a comprehensive comparison with other publicly available methods using benchmark datasets. We benchmarked TransHLA against state-of-the-art sequence classification models, including TextCNN, TextRCNN, DPCNN, and RNN-ATTs. These comparisons were performed on independent test sequences from the Immune Epitope Database (IEDB), which included a substantial number of HLA-I binding epitopes, HLA-II binding epitopes, and random sequences.\n\nThe performance metrics used for this evaluation included accuracy (ACC), F1 score (F1), recall, Matthews correlation coefficient (MCC), and the area under the ROC curve (AUC). TransHLA demonstrated superior performance across these metrics, particularly in classifying HLA-I epitopes. For instance, TransHLA achieved an accuracy of 84.72%, an F1 score of 84.59%, a recall of 83.92%, an MCC of 0.69, and an AUC of 91.95% for HLA-I epitopes. These results highlight TransHLA's robustness and effectiveness in epitope prediction tasks.\n\nAdditionally, we compared TransHLA with other HLA-epitope binding software, such as Mhcflurry, NetMHCpan4.1b, and MixMHCpred, using external epitope datasets. The metrics evaluated included precision and specificity, alongside the previously mentioned metrics. TransHLA consistently outperformed or matched the top-performing models in these comparisons. For example, TransHLA achieved the highest accuracy of 90.65% and maintained a strong balance between recall and specificity, with values of 93.52% and 87.77%, respectively. This balance is crucial for ensuring that the model does not miss immunogenic epitopes while effectively filtering out negative samples.\n\nIn summary, the comparisons with publicly available methods and simpler baselines on benchmark datasets clearly demonstrate TransHLA's superior performance and reliability in epitope prediction. The model's ability to maintain high accuracy, recall, and specificity across various datasets and metrics underscores its potential for practical applications in immunology and related fields.",
  "evaluation/confidence": "In our evaluation of TransHLA, we focused on several key performance metrics to assess its effectiveness in epitope prediction. These metrics include accuracy (ACC), recall, F1 score (F1), Matthews correlation coefficient (MCC), precision, and specificity. Additionally, we utilized the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPRC) to provide a comprehensive evaluation.\n\nWhile the specific details on confidence intervals for these metrics are not explicitly mentioned, our results demonstrate statistically significant improvements over other sequence classification models and HLA-epitope binding software. For instance, TransHLA achieved the highest accuracy of 90.65% for HLA-I binding, significantly outperforming other models. Similarly, it maintained a strong balance between recall and specificity, achieving a specificity of 87.77% and a high recall of 93.52%.\n\nThe ablation studies further corroborate the robustness of TransHLA by showing the contribution of different modules to its performance. The sequence embedding approach, in particular, proved to be highly effective, achieving 84.56% accuracy for HLA-I and 79.68% for HLA-II. The CNN modules also played a substantial role in enhancing performance, achieving 84.18% and 79.38% accuracy for HLA-I and HLA-II, respectively.\n\nMoreover, TransHLA's performance was validated across different alleles, showing improved prediction accuracy with higher epitope frequencies. This consistency across various conditions underscores the reliability and statistical significance of our method.\n\nIn summary, while explicit confidence intervals are not provided, the consistent superiority of TransHLA across multiple metrics and conditions suggests that the results are statistically significant and reliable. The method's robustness is further supported by ablation studies and performance across different alleles, reinforcing its effectiveness in epitope prediction.",
  "evaluation/availability": "The raw evaluation files used in this study are available through the GigaScience database, specifically in GigaDB. This includes the training and test datasets, as well as the source code for TransHLA. The datasets were collected from various sources, including IEDB, CEDAR, VDJdb, ImmunoCode, dbpepneo2.0, and NEPdb. Additionally, the alleles used by the software for predicting HLA-binding affinity are also provided in GigaDB. The data and code are released under the MIT license, ensuring open access and the ability to use, modify, and distribute the materials. For further details and access, the project homepage on GitHub can be visited."
}