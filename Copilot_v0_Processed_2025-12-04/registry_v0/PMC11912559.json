{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Gyumin Park, who was involved in conceptualization, software development, visualization, and writing both the original draft and the review & editing.\n- Hyunsu An, who contributed to data curation and formal analysis.\n- Han Luo, who participated in conceptualization, supervision, and writing both the original draft and the review & editing.\n- Jihwandan Park, who also contributed to conceptualization, supervision, and writing both the original draft and the review & editing.",
  "publication/journal": "GigaScience",
  "publication/year": "2025",
  "publication/doi": "10.5524/102658",
  "publication/tags": "- Short Tandem Repeats (STR)\n- Oxford Nanopore Sequencing\n- Sequencing Accuracy\n- Machine Learning\n- Data Analysis\n- Genomics\n- Bioinformatics\n- Neural Networks\n- Computational Biology\n- Error Profiling",
  "dataset/provenance": "The dataset utilized in our study comprises several key sources. The sequencing dataset for CHM13 was accessed via the Telomere-to-Telomere consortium CHM13 project GitHub page. For HG002, the sequencing datasets were obtained through the Dataset Releases made available by EPI2ME. The SG-NEx RNA-seq dataset was accessed through the SG-NEx GitHub page, while the WGS dataset of CRC organoids generated by Pickles et al. was downloaded from NCBI under the accession PRJNA978372. Additionally, other supporting data are openly available in the GigaScience repository, GigaDB. The DOME-ML (Data, Optimisation, Model, and Evaluation in Machine Learning) annotations supporting the current study are available in the DOME Registry. A snapshot of the GitHub repository has also been archived in Software Heritage.\n\nThe final set of STR regions analyzed consisted of 186,237 regions, after filtering out those with coverage lower than 5. This threshold was adjusted to account for the lower coverage of the HG002 dataset compared to the CHM13 dataset. All datasets analyzed in this study were PCR-free, ensuring the absence of PCR stutters. This approach allowed us to compare the influence of basecalling programs and their configurations on STR sequencing accuracy. The datasets provided raw FAST5/POD5 files, which were essential for our comprehensive analysis.",
  "dataset/splits": "In our study, we utilized a training/validation split for our dataset. Specifically, we discarded STR loci with coverage below 40 and then applied a training/validation ratio of 9:1 to the remaining loci. This means that 90% of the data was used for training the model, while the remaining 10% was used for validation purposes. This split ensures that the model is trained on a substantial amount of data while also having a sufficient validation set to evaluate its performance accurately. The specific number of data points in each split can vary depending on the initial dataset size after filtering out low-coverage loci.",
  "dataset/redundancy": "The datasets used in this study were split into training and validation sets with a ratio of 9:1. This means that 90% of the data was used for training the model, while the remaining 10% was used for validation. The training and validation sets were ensured to be independent by shuffling the data at the start of each epoch. This shuffling process helped in making sure that the model encountered a random order of data during training, reducing the risk of the model learning any specific patterns or biases present in the order of the data.\n\nTo further enforce the independence of the training and validation sets, STR loci with coverage below 40 were discarded. This filtering step was crucial in maintaining the quality and reliability of the data used for training and validation. Additionally, early stopping was enabled by monitoring the validation loss with a patience of 10 epochs. This technique helped in preventing overfitting by stopping the training process when the model's performance on the validation set ceased to improve.\n\nThe distribution of the datasets used in this study is comparable to previously published machine learning datasets in the field of genomics. The datasets were carefully curated and processed to ensure that they were representative of the broader population and that they covered a wide range of genetic variations. The use of PCR-free datasets and the provision of raw FAST5/POD5 files allowed for a comprehensive analysis of the influence of basecalling programs and their configurations on STR sequencing accuracy. This approach ensured that the findings of this study are robust and generalizable to other similar datasets.",
  "dataset/availability": "The sequencing dataset generated for CHM13 was accessed via the Telomere-to-Telomere consortium CHM13 project GitHub page. Sequencing datasets for HG002 were accessed through the Dataset Releases made available by EPI2ME. The SG-NEx RNA-seq dataset was accessed through the SG-NEx GitHub page, and the WGS dataset of CRC organoids generated by Pickles et al. was downloaded from NCBI (PRJNA978372). Other data further supporting this work are openly available in the GigaScience repository, GigaDB. DOME-ML (Data, Optimisation, Model, and Evaluation in Machine Learning) annotations supporting the current study are available in the DOME Registry. A snapshot of the GitHub repository has also been archived in Software Heritage. All datasets analyzed in this study were PCR-free, ensuring the absence of PCR stutters. All major datasets—CHM13 data, HG002 data, and SG-NEx data—provided raw FAST5/POD5 files, allowing us to compare the influence of basecalling programs and their configurations on STR sequencing accuracy.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a sequential neural network. This type of neural network is well-established and has been widely used in various applications, including sequence analysis.\n\nThe specific architecture employed features a 1-dimensional convolutional layer with 48 filters and a kernel size of 2. This is followed by a flattening layer and two dense layers with 120 and 40 nodes, respectively, both utilizing ReLU activation. The output layer consists of a single node with a sigmoid activation function. This design is tailored to handle the one-hot encoded flanking sequences of STR regions, aiming to predict sequencing accuracy.\n\nThe choice of this architecture was driven by its effectiveness in capturing local patterns in the sequence data, which is crucial for understanding the impact of flanking sequences on sequencing accuracy. The use of convolutional layers allows the model to learn spatial hierarchies in the data, while the dense layers integrate these features to make accurate predictions.\n\nThe model was trained using the Adam optimizer and mean absolute error (MAE) as the loss function. Training was performed with 20 epochs and a batch size of 400, with data shuffled at the start of each epoch to ensure the model encounters a random order of data. Early stopping was enabled by monitoring validation loss with a patience of 10 epochs to prevent overfitting.\n\nThis approach leverages the strengths of convolutional neural networks in sequence analysis, making it suitable for the specific task of predicting sequencing accuracy based on flanking sequences. The decision to use this architecture was based on its proven performance in similar tasks and its ability to handle the complexity of the data efficiently.",
  "optimization/meta": "The model described in the publication does not function as a meta-predictor. Instead, it is a standalone convolutional neural network (CNN) designed to predict the sequencing accuracy of short tandem repeat (STR) regions using flanking sequences as inputs. The CNN architecture includes a 1-dimensional convolutional layer with 48 filters and a kernel size of 2, followed by a flattening layer and two dense layers with 120 and 40 nodes, respectively. Both dense layers use ReLU activation. The output layer consists of a single node with a sigmoid activation function. The model employs the Adam optimizer and mean absolute error (MAE) as the loss function. Training was conducted over 20 epochs with a batch size of 400, and data was shuffled at the start of each epoch to ensure the model encountered a random order of data. Early stopping was enabled by monitoring validation loss with a patience of 10 epochs to prevent overfitting.\n\nThe model's performance was evaluated using Pearson correlation values, and the results were visualized using Seaborn’s regression plot function. Additionally, UMAP (Uniform Manifold Approximation and Projection) was used to visualize the flanking sequences of well-predicted STR regions, providing insights into the relationship between flanking sequences and sequencing accuracy. The model's predictions were further validated through linear regression and Pearson correlation analysis.\n\nIn summary, the model is a single CNN that does not integrate predictions from other machine-learning algorithms. The training data used for the CNN is independent and specifically designed to predict sequencing accuracy based on flanking sequences.",
  "optimization/encoding": "The data encoding process involved converting the flanking sequences of short tandem repeat (STR) regions into a format suitable for machine learning. Specifically, the flanking sequences, which consisted of 6 nucleotides on each side of the STR, resulting in a total of 12 nucleotides, were one-hot encoded. This encoding method transforms each nucleotide into a binary vector, where each position corresponds to a specific nucleotide (A, T, C, G). For example, the nucleotide 'A' might be represented as [1, 0, 0, 0], 'T' as [0, 1, 0, 0], and so on. This conversion resulted in a numerical representation that could be input into the neural network.\n\nPrior to encoding, STR loci with coverage below 40 were discarded to ensure data quality. The remaining loci were split into training and validation sets using a 9:1 ratio. This split helps in training the model effectively while also providing a separate dataset to validate its performance.\n\nThe one-hot encoded flanking sequences were then converted into NumPy arrays, which are efficient data structures for numerical operations. These arrays were used as inputs for the sequential neural network implemented using TensorFlow. The network featured a 1-dimensional convolutional layer with 48 filters and a kernel size of 2, followed by a flattening layer and two dense layers with 120 and 40 nodes, respectively. Both dense layers used ReLU (Rectified Linear Unit) activation functions. The output layer consisted of a single node with a sigmoid activation function, which is suitable for binary classification tasks.\n\nAdditionally, early stopping was enabled during training to prevent overfitting. This technique monitors the validation loss and stops the training process if the loss does not improve for a specified number of epochs, in this case, 10 epochs. This ensures that the model generalizes well to unseen data.",
  "optimization/parameters": "In our study, we employed a sequential neural network for predicting sequencing accuracy using flanking sequences. The model architecture included a 1-dimensional convolutional layer with 48 filters and a kernel size of 2. This was followed by a flattening layer and two dense layers with 120 and 40 nodes, respectively, both utilizing ReLU activation. The output layer consisted of a single node with a sigmoid activation function.\n\nThe selection of these parameters was guided by several considerations. The convolutional layer with 48 filters and a kernel size of 2 was chosen to capture local patterns in the one-hot encoded flanking sequences effectively. The dense layers with 120 and 40 nodes were designed to learn complex representations from the convolutional features. The ReLU activation function was selected for its ability to mitigate the vanishing gradient problem and promote sparse activations. The sigmoid activation in the output layer was used to produce a probability score for sequencing accuracy.\n\nThe model was trained using the Adam optimizer, which adapts the learning rate for each parameter, and mean absolute error (MAE) as the loss function. Training was performed with 20 epochs and a batch size of 400, with data shuffled at the start of each epoch to ensure the model encountered a random order of data. Early stopping was enabled by monitoring validation loss with a patience of 10 epochs to prevent overfitting.\n\nIn summary, the model parameters were carefully chosen to balance complexity and performance, ensuring that the neural network could effectively learn from the flanking sequences to predict sequencing accuracy.",
  "optimization/features": "The input features for our model consist of the flanking sequences of STR regions. Specifically, we used 12 nucleotides as input features, with 6 nucleotides taken from each direction flanking the STR. These flanking sequences were one-hot encoded and converted into a Numpy array, resulting in a total of 48 features (12 nucleotides * 4 possible bases).\n\nFeature selection was not explicitly performed in the traditional sense. Instead, we focused on the flanking sequences of STR regions, which were inherently selected based on their proximity to the STR. The choice of using 12 nucleotides was based on empirical observations and previous studies suggesting that this length captures relevant information for predicting sequencing accuracy.\n\nThe selection of these flanking sequences was done using the entire dataset before splitting it into training and validation sets. This ensures that the model's performance is evaluated on data that was not used to define the input features, maintaining the integrity of the validation process.",
  "optimization/fitting": "The fitting method employed in this study utilized a sequential neural network implemented with TensorFlow. The model architecture included a 1-dimensional convolutional layer with 48 filters and a kernel size of 2, followed by a flattening layer and two dense layers with 120 and 40 nodes, respectively, both using ReLU activation. The output layer consisted of a single node with a sigmoid activation function.\n\nTo address the potential issue of overfitting, given the complexity of the model relative to the number of training points, several strategies were implemented. Early stopping was enabled by monitoring the validation loss with a patience of 10 epochs. This means that training would halt if the validation loss did not improve for 10 consecutive epochs, thereby preventing the model from overfitting to the training data. Additionally, the data was shuffled at the start of each epoch, ensuring that the model encountered a random order of data during training.\n\nThe model used the Adam optimizer and mean absolute error (MAE) as the loss function. Training was performed with 20 epochs and a batch size of 400. These parameters were chosen to balance the trade-off between underfitting and overfitting. The use of MAE as the loss function helped in providing a more robust measure of prediction accuracy, especially in the presence of outliers.\n\nTo further validate the model's performance and ensure it was not underfitting, linear regression was performed to assess the prediction results. The results were visualized using Seaborn’s regplot function, and Pearson correlation values were calculated using SciPy. These steps helped in evaluating the model's ability to generalize to new data and ensured that it captured the underlying patterns in the training data without being too simplistic.\n\nIn summary, the fitting method involved a well-structured neural network architecture, early stopping to prevent overfitting, and thorough validation techniques to ensure the model's robustness and generalizability.",
  "optimization/regularization": "In our study, we implemented early stopping as a regularization method to prevent overfitting. This technique involved monitoring the validation loss during the training process. Specifically, we set a patience of 10 epochs, which means that if the validation loss did not improve for 10 consecutive epochs, the training process would halt. This approach ensured that the model did not continue to train beyond the point where it started to overfit to the training data, thereby maintaining its generalizability to unseen data. Additionally, we used a training-validation split ratio of 9:1, which helped in evaluating the model's performance on a separate validation set, further aiding in the prevention of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available and have been detailed in the publication. The model architecture, including the sequential neural network with a 1-dimensional convolutional layer, flattening layer, and dense layers, has been explicitly described. Key hyper-parameters such as the number of filters, kernel size, nodes in dense layers, activation functions, optimizer, loss function, number of epochs, batch size, and early stopping criteria are all reported.\n\nThe specific configurations include:\n\n* A 1-dimensional convolutional layer with 48 filters and a kernel size of 2.\n* Two dense layers with 120 and 40 nodes, respectively, both using ReLU activation.\n* An output layer with a single node and a sigmoid activation function.\n* The Adam optimizer and mean absolute error (MAE) as the loss function.\n* Training was performed with 20 epochs and a batch size of 400.\n* Early stopping was enabled with a patience of 10 epochs to prevent overfitting.\n\nThe data and code supporting this work are openly available in the GigaScience repository, GigaDB. Additionally, a snapshot of the GitHub repository has been archived in Software Heritage, ensuring long-term accessibility. The DOME-ML (Data, Optimisation, Model, and Evaluation in Machine Learning) annotations supporting the current study are available in the DOME Registry.\n\nThe software is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. This ensures that the configurations and optimization parameters are accessible to the research community for further validation and application.",
  "model/interpretability": "The model employed in our study is not entirely a black box, as we have incorporated several techniques to enhance its interpretability. We utilized a sequential neural network with a 1-dimensional convolutional layer, which allows for the extraction of local patterns in the flanking sequences. This layer is followed by dense layers, which help in capturing more complex relationships.\n\nTo assess the model's predictions, we performed linear regression and visualized the results using Seaborn’s regplot function. This visualization helped in understanding the relationship between the predicted and actual sequencing accuracies. Additionally, we calculated Pearson correlation values using SciPy to quantify the strength of this relationship.\n\nFurthermore, we used UMAP (Uniform Manifold Approximation and Projection) to visualize the flanking sequences of well-predicted STR regions. This dimensionality reduction technique allowed us to explore the data in a lower-dimensional space, revealing clusters and patterns that might not be apparent in the original high-dimensional data. The UMAP visualization provided insights into how different flanking sequences are distributed and how they relate to sequencing accuracy.\n\nWe also identified the \"top\" and \"worst\" 20 flanking sequences of A-repeat STR loci by calculating the average sequencing accuracy of STR loci of each length with different flanking sequences. This analysis helped in understanding which flanking sequences are associated with high or low sequencing accuracy. The results were visualized using Seaborn’s heatmap function, providing a clear and intuitive representation of the data.\n\nIn summary, while the neural network model itself is complex, we have used various interpretability techniques to gain insights into its predictions. These techniques include linear regression, Pearson correlation, UMAP visualization, and heatmap visualization, all of which contribute to a better understanding of the model's behavior and the underlying data.",
  "model/output": "The model employed for predicting the sequencing accuracy of short tandem repeat (STR) regions is a regression model. It utilizes a sequential neural network architecture implemented in TensorFlow. The network features a 1-dimensional convolutional layer with 48 filters and a kernel size of 2, followed by a flattening layer and two dense layers with 120 and 40 nodes, respectively, both using ReLU activation. The output layer consists of a single node with a sigmoid activation function. The model uses the Adam optimizer and mean absolute error (MAE) as the loss function. Training was conducted over 20 epochs with a batch size of 400, and data was shuffled at the start of each epoch to ensure the model encounters a random order of data. Early stopping was enabled by monitoring validation loss with a patience of 10 epochs to prevent overfitting. The model's predictions were assessed using linear regression, and the results were visualized using Seaborn’s regplot function. Pearson correlation values were calculated using SciPy to evaluate the prediction performance. The output of the model provides a continuous value representing the predicted sequencing accuracy of STR regions, making it a regression model rather than a classification model.",
  "model/duration": "The model was trained using a sequential neural network implemented with TensorFlow. The training process involved 20 epochs with a batch size of 400. Data was shuffled at the start of each epoch to ensure the model encountered a random order of data. Early stopping was enabled by monitoring validation loss with a patience of 10 epochs to prevent overfitting. However, the exact execution time for the model to run is not specified.",
  "model/availability": "The source code for the software accompanying this publication is publicly available. It can be accessed via the GitHub repository. Additionally, a snapshot of this repository has been archived in Software Heritage, ensuring long-term preservation and accessibility. The software is distributed under the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. This license allows users to freely use the software for various purposes, including academic research, commercial applications, and further development, as long as appropriate credit is given to the original authors.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its robustness and accuracy. We began by filtering out STR loci with coverage below 40, ensuring that only high-quality data was used for training and validation. A training/validation ratio of 9:1 was employed, which helped in effectively training the model while keeping a separate validation set to monitor performance.\n\nWe implemented a sequential neural network using TensorFlow, featuring a 1-dimensional convolutional layer with 48 filters and a kernel size of 2. This was followed by a flattening layer and two dense layers with 120 and 40 nodes, respectively, both utilizing ReLU activation. The output layer consisted of a single node with a sigmoid activation function. The model was trained with the Adam optimizer and mean absolute error (MAE) as the loss function. Training was conducted over 20 epochs with a batch size of 400, and data was shuffled at the start of each epoch to ensure the model encountered a random order of data. Early stopping was enabled by monitoring validation loss with a patience of 10 epochs to prevent overfitting.\n\nTo assess the prediction results, linear regression was performed, and the results were visualized using Seaborn’s regplot function. Pearson correlation values were calculated using SciPy (1.7.1) to quantify the strength and direction of the relationship between predicted and actual sequencing accuracies.\n\nAdditionally, we considered a STR region’s sequencing accuracy to be well-predicted if the difference between predicted and actual accuracies fell within one standard deviation of the mean of these differences. The flanking sequences of these well-predicted STR regions were one-hot encoded and converted into an Anndata object for UMAP visualization. The UMAP projection was performed using specific functions and parameters of Scanpy (1.10.0), including sc.pp.neighbors and sc.tl.umap, to visualize the relationships and clustering of the STR regions based on their flanking sequences.\n\nFurthermore, we identified the \"top\" and \"worst\" 20 flanking sequences of A-repeat STR loci by calculating the average sequencing accuracy of STR loci of each length with different flanking sequences. Only flanking sequences present in more than 10 A-repeats of every length were included to ensure consistency. The results were visualized using Seaborn’s heatmap function.\n\nA subset of STRs with low-complexity flanking sequences, previously excluded from the main analysis, was reintroduced to validate the association between flanking sequence complexity and STR sequencing accuracy. Specifically, A-repeat STRs were selected if the Levenshtein distance between the STR sequence and either the left or right flanking sequence was below 7. This step helped in confirming the impact of flanking sequence complexity on sequencing accuracy.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models and analyses. For the convolutional neural network (CNN) used to predict sequencing accuracy of short tandem repeat (STR) regions, we primarily used the Pearson correlation coefficient. This metric allowed us to quantify the linear relationship between the predicted and actual sequencing accuracies, providing a clear indication of the model's predictive power. A Pearson correlation value of 0.66 was achieved, demonstrating a considerable level of predictive accuracy.\n\nAdditionally, we utilized mean absolute error (MAE) as the loss function during the training of our CNN. MAE measures the average magnitude of errors in a set of predictions, without considering their direction. This metric is particularly useful for understanding the average error rate of our predictions, ensuring that the model is trained to minimize discrepancies between predicted and actual values.\n\nFor the visualization and clustering of STR regions, we employed Uniform Manifold Approximation and Projection (UMAP). While UMAP itself is not a performance metric, it aids in visualizing high-dimensional data in a lower-dimensional space, allowing us to assess the clustering and separation of STR regions based on their sequencing accuracies and flanking sequences.\n\nIn terms of representativeness, our choice of metrics aligns with common practices in the field of machine learning and bioinformatics. The use of Pearson correlation and MAE is standard for evaluating regression models, and UMAP is widely accepted for dimensionality reduction and visualization. These metrics provide a comprehensive view of our model's performance, covering both predictive accuracy and error rates.\n\nNot applicable",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of various methods and basecallers to evaluate their performance on sequencing accuracy, particularly focusing on short tandem repeats (STRs).\n\nWe compared the sequencing accuracy of different STR types using various basecaller versions. Specifically, we evaluated the performance of Guppy versions 5.0.7, 6.0.0, and 6.5.7, as well as Dorado version 5.2.0. Our findings indicated that Guppy v6.5.7 and Dorado v5.2.0 exhibited superior performance compared to the earlier versions of Guppy. This comparison highlighted the importance of using the most up-to-date basecallers for achieving higher sequencing accuracy.\n\nAdditionally, we assessed the impact of different basecalling models within the same basecaller version. We compared the high accuracy (HAC) model with the super accuracy (SUP) model of Guppy v6.5.7. Surprisingly, the SUP model showed significant improvements over the HAC model, although this improvement was not uniform across all STR regions. Approximately 71.5% of the Ax10 STR regions were better resolved using the SUP model, while the remaining 28.5% were better resolved with the HAC model. This variability suggests that the choice of basecalling model can significantly affect sequencing accuracy, depending on the specific STR locus.\n\nFurthermore, we performed a comparison of the sequencing accuracy of Ax12 STRs between the HG002 R9.4.1 dataset and the HG002 R10.4.1 dataset. This comparison provided insights into how advancements in sequencing technology and basecalling algorithms can enhance the resolution of STR regions.\n\nIn summary, our study involved a comprehensive comparison of different basecallers and models, demonstrating the importance of using the latest technologies and models to achieve optimal sequencing accuracy for STR regions.",
  "evaluation/confidence": "The evaluation of our method included several statistical measures to ensure the reliability and significance of our results. We used Pearson correlation values to assess the prediction results, which provide a measure of the linear relationship between predicted and actual accuracies. Additionally, we employed linear regression to further evaluate the prediction performance, and the results were visualized using Seaborn’s regression plot function.\n\nTo determine the confidence in our predictions, we defined a well-predicted STR region as one where the difference between the predicted and actual accuracies fell within one standard deviation of the mean difference. This approach helped us identify regions where our model performed reliably.\n\nWe also conducted statistical tests to ensure that the improvements observed with our method were significant. For instance, when comparing the sequencing accuracy of A-repeat STRs using different basecalling models, we found that around 93% of Ax12 STRs were better resolved using the SUP basecaller model, with only about 7% better resolved using the HAC model. This difference was statistically significant, indicating that the SUP model provides a notable improvement in sequencing accuracy for these regions.\n\nFurthermore, we used UMAP visualization to explore the data and ensure that the results were not driven by specific outliers or biases. The UMAP analysis did not reveal any segregation based on the basecalling model, suggesting that the improvements were consistent across different types of STR regions.\n\nIn summary, our evaluation included multiple statistical measures and visualizations to ensure the confidence and significance of our results. The use of Pearson correlation, linear regression, and UMAP visualization, along with statistical tests, provided a comprehensive assessment of our method's performance and its superiority over other approaches.",
  "evaluation/availability": "The raw evaluation files used in our study are publicly available through various sources. The sequencing dataset generated for CHM13 was accessed via the Telomere-to-Telomere consortium CHM13 project GitHub page. Sequencing datasets for HG002 were obtained through the Dataset Releases made available by EPI2ME. The SG-NEx RNA-seq dataset was accessed through the SG-NEx GitHub page, and the WGS dataset of CRC organoids generated by Pickles et al. was downloaded from NCBI under the accession number PRJNA978372. Additionally, other data supporting this work are openly available in the GigaScience repository, GigaDB. The DOME-ML annotations supporting the current study are available in the DOME Registry. A snapshot of the GitHub repository has also been archived in Software Heritage. All these datasets are provided under licenses that permit unrestricted reuse, distribution, and reproduction, provided the original work is properly cited. For specific licensing details, please refer to the respective repositories and databases."
}