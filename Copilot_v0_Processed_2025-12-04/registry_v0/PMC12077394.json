{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are:\n\n- Maximilian Wess, who was involved in conceptualization, investigation, formal analysis, software development, methodology, validation, writing the original draft, reviewing and editing, and visualization.\n- Maria K. Andersen, who provided supporting formal analysis and contributed to reviewing and editing the manuscript.\n- Elise Midtbust, who contributed supporting resources and validation.\n- Juan Carlos Cabellos Guillem, who provided supporting validation.\n- Trond Viset, who contributed to data curation.\n- Øystein Størkersen, who also contributed to data curation.\n- Sebastian Krossa, who provided supporting software development and contributed to reviewing and editing the manuscript.\n- Morten Beck Rye, who contributed supporting resources, supervision, and funding acquisition.\n- May-Britt Tessem, who provided equal supervision, contributed to reviewing and editing the manuscript, and was involved in funding acquisition.",
  "publication/journal": "GigaScience",
  "publication/year": "2025",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Spatial transcriptomics\n- Mass spectrometry imaging\n- Multi-omics integration\n- Tissue sectioning\n- Data integration\n- Gene expression analysis\n- Metabolite profiling\n- Histology\n- Bioinformatics\n- Biomedical research",
  "dataset/provenance": "The dataset utilized in this study comprises human prostate tissue samples collected from patients undergoing radical prostatectomy at St. Olav’s Hospital in Trondheim, Norway. The samples were obtained from eight patients between 2008 and 2016, with informed written consent from each participant. The patients included in the study were either relapse-free or had experienced metastasis within three years post-surgery.\n\nFrom each patient, a 2-mm-thick slice was taken from the middle of the prostate, snap-frozen, and stored at -80°C. Each tissue slice yielded between 8 to 13 tissue samples, each 3 mm in diameter, collected using an in-house built drill system. Based on hematoxylin, erythrosine, and saffron (HES)-stained tissue annotations, four sample cores were selected from each patient’s tissue slice. These cores included two samples containing cancer tissue, one sample adjacent to cancer tissue, and one sample from a region far away containing no cancer tissue, resulting in a total of 32 samples.\n\nTissue sections from each sample were cut to a thickness of 10 μm inside a cryostat at -20°C. For this study, sections from various staining methods were selected, totaling 288 sections from all eight patients, with nine sections collected from each tissue core.\n\nThe dataset includes various types of data such as spatial transcriptomics, mass spectrometry data, stained images, and tissue annotations. Parts of this dataset have been used in previous publications by our group. Specifically, HE- and Mason’s trichrome staining (MTS)-stained sections, histopathology on HE-stained sections, and spatial transcriptomics (ST) data have been utilized in previous studies. Additionally, ST data, including HE staining and MALDI-TOF MSI data in negative ion mode, have been featured in other works.\n\nThe spatial transcriptomics data is deposited with the accession number EGAD50000000603 and can be requested through the EGA portal, where data access is processed through a data access committee. Mass spectrometry data, stained images, and tissue annotations are not externally archived due to the lack of a suitable public data repository that meets the required data-sharing criteria. These data can be requested via email to specified contacts.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study include sensitive information and are subject to restricted access due to compliance with the General Data Protection Regulation (GDPR), Norwegian law, and specific patient consent and ethical approval. Therefore, the full dataset is not publicly available.\n\nA reduced and anonymized exemplary test dataset for exploring the use and functionality of the Multi-Omics Imaging Integration Toolset (MIIT) can be found on Zenodo. This dataset is accessible under the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.\n\nRaw and processed transcriptomics data have been deposited at the Federated European Genome-Phenome Archive (FEGA) Norway and are findable on the EGA portal under the study ID EGAS50000000413. The spatial transcriptomics is deposited with the accession number EGAD50000000603. Data access can be requested through the EGA portal, where any data request will be processed through a data access committee.\n\nMass spectrometry data, stained images, and tissue annotations are not externally archived due to the lack of a suitable public data repository that meets the data-sharing criteria postulated by the study’s ethical approval, patient consent, GDPR, and Norwegian law. These data can be requested via email to specific contacts and will be provided only after certain steps have been achieved. These steps include compliance with GDPR regulation, Norwegian law, and specific patient consent; approval by the regional ethical committee (REC) in Norway; revision of the Data Protection Impact Assessment (DPIA) if required; and a signed data transfer agreement between the institution of the data requester and NTNU. Depending on the intended use of the data, a collaboration agreement with NTNU may also be required.",
  "optimization/algorithm": "The optimization algorithm used in our work is not a traditional machine-learning algorithm but rather a nonrigid registration algorithm called GreedyFHist. This algorithm is designed to efficiently register neighboring tissue sections, which is crucial for spatial multi-omics integration.\n\nGreedyFHist is not a new class of machine-learning algorithm; instead, it leverages existing optimization techniques to achieve high accuracy in image registration. The algorithm shares similarities with HistoReg, another state-of-the-art registration algorithm, by utilizing the Greedy algorithm to compute affine and nonrigid registration parameters. However, GreedyFHist implements a novel preprocessing pipeline that enhances its accuracy compared to HistoReg.\n\nThe decision to develop and use GreedyFHist was driven by the need for a lightweight algorithm that can run efficiently on CPU architecture, unlike many current algorithms that rely on computationally intensive deep learning methods. This makes GreedyFHist more accessible and practical for a wider range of applications, particularly in bioimaging analysis.\n\nThe algorithm includes several key steps to improve registration accuracy. These steps include background segmentation to remove noise and center the registration on the tissue region of interest, mean shift filtering to denoise features in tissue images while preserving major histological features, and computing the center-of-mass to improve the initial alignment of the affine registration. These additional steps contribute to GreedyFHist's higher accuracy compared to other algorithms.\n\nGiven that GreedyFHist is not a machine-learning algorithm in the traditional sense, it was not published in a machine-learning journal. Instead, it was developed and optimized for specific bioimaging tasks, making it more suitable for publication in journals focused on bioinformatics, computational biology, or related fields. The algorithm's effectiveness has been demonstrated through rigorous testing on fresh-frozen tissue samples with various types of staining, achieving high accuracy in pairwise and groupwise registration.",
  "optimization/meta": "Not enough information is available.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for ensuring accurate integration and alignment of spatial omics data with stained histology images. Initially, spatial omics data, which include various formats like ST-spots and MSI-pixels, were converted into a reference matrix format. This involved creating an empty matrix with the same resolution as the stained histology image and projecting each spatial data point onto this matrix. This step ensured that spatial omics data could be transformed accurately during nonrigid registration, allowing for fine-grained fusion between different data types.\n\nFor the registration of MSI data to the stained image, a feature image was derived from the first principal component of the MSI data's PCA spectrum. This feature image was then rescaled to match the resolution of the stained image. Both the stained image and the feature image were padded symmetrically to create a uniform shape, with an additional 100 pixels added to allow for deformations during registration. A rigid registration was performed using NiftyReg, which involved translation and rotation to align the images without significant deformation effects on the MSI-pixels.\n\nThe stained images underwent several preprocessing steps to enhance their quality and reduce complexity. This included converting images to the HSV color space, applying mean shift filtering with specific spatial and color window radii, and then converting them back to the RGB color space. The images were also smoothed with a Gaussian kernel to avoid aliasing effects during downsampling and were resampled to a resolution of 1,024 × 1,024 pixels. These preprocessed images were then converted to grayscale and padded with 100 pixels on all sides to accommodate deformations during registration.\n\nFor the affine registration, the Greedy tool was used, which implements the greedy diffeomorphic registration algorithm. This tool was initialized with a transformation that centered both images at their center-of-mass, computed using tissue masks. Greedy performed a random search for a suitable rigid registration, followed by a multiresolution pyramidic approach for the affine registration. The registration was computed on downscaled images and recursively refined on upscaled images until the full resolution was reached. The limited-memory Broyden–Fletcher–Goldfarb–Shanno algorithm was used for optimization, with the NCC kernel metric as the similarity measure.\n\nAfter the affine registration, a nonrigid registration was performed to achieve local alignment between the moving and fixed images. This step involved repeating the tissue segmentation and downscaling processes without denoising, as including all image features resulted in more accurate transformation matrices. The same parameters used for the affine registration were applied, with additional regularization parameters to fine-tune the registration process.",
  "optimization/parameters": "In our study, we utilized a set of fixed parameters for the registration process, which are detailed in Supplementary Table S11. These parameters were carefully selected to ensure optimal performance of the Greedy algorithm during both affine and nonrigid registration steps.\n\nThe selection of these parameters was based on extensive testing and validation to achieve accurate transformation matrices. For the nonrigid registration, we repeated the tissue segmentation and downscaling steps without denoising to capture more accurate image features. The same parameters applied in the affine registration were also used for the nonrigid registration, with additional regularization parameters set to pre-sigma: 5 and post-sigma: 4. These settings were chosen to balance the trade-off between flexibility and stability in the registration process.\n\nThe specific number of parameters used in the model is not explicitly stated, but it is implied that the parameters listed in Supplementary Table S11 are comprehensive for the registration process. The table includes all necessary details for reproducing the registration steps, ensuring consistency and reliability in the results.",
  "optimization/features": "In our study, the input features for the optimization process are derived from the preprocessing steps of the images. Specifically, the images undergo tissue segmentation and downscaling to grayscale without denoising. This preprocessing ensures that all relevant image features are included, which is crucial for generating accurate transformation matrices during the registration process.\n\nThe feature selection process is inherently tied to the image preprocessing steps. By repeating the tissue segmentation and downscaling steps, we ensure that the most relevant features are retained. This approach does not involve a traditional feature selection method but rather focuses on preserving the integrity and relevance of the image data.\n\nThe parameters used for the affine and nonrigid registration are consistent across the dataset, ensuring that the feature selection process is applied uniformly. This consistency is maintained to avoid any bias that could arise from varying parameters, thereby ensuring that the features used are representative of the entire dataset.\n\nThe registration performance is evaluated using the target registration error (TRE), which measures the accuracy of the alignment between serial sections. This evaluation method ensures that the selected features are effective in achieving precise registration.\n\nIn summary, the input features are determined through a rigorous preprocessing pipeline that includes tissue segmentation and downscaling. This approach ensures that all relevant image features are retained, and the feature selection process is applied uniformly across the dataset. The evaluation using TRE further validates the effectiveness of the selected features in achieving accurate registration.",
  "optimization/fitting": "The fitting method employed in our study involves a multi-step registration process using the Greedy algorithm, which is designed to handle high-dimensional image data. The number of parameters in our model is indeed large, given the complexity of the images and the need for both affine and nonrigid registrations. However, overfitting is mitigated through several strategies.\n\nFirstly, the use of a multi-resolution pyramid approach in Greedy ensures that the registration is initially computed on downscaled images, which reduces the number of parameters considered at each stage. This hierarchical approach allows the algorithm to capture both global and local transformations accurately without overfitting to noise in the high-resolution images.\n\nSecondly, regularization parameters are employed during the nonrigid registration step. Specifically, pre-sigma and post-sigma values are set to control the smoothness of the transformation, preventing the model from fitting to spurious details in the images.\n\nAdditionally, the evaluation of registration performance using the target registration error (TRE) provides a quantitative measure of the registration accuracy. This metric is computed based on manually annotated landmarks, ensuring that the registration aligns with biologically relevant features rather than artifacts.\n\nTo address underfitting, the model is initialized with a transformation that centers both images at their center-of-mass, providing a strong starting point for the registration process. Furthermore, the use of the normalized cross-correlation (NCC) kernel metric ensures that the registration is driven by meaningful image features, reducing the likelihood of underfitting.\n\nOverall, the combination of multi-resolution registration, regularization, and robust evaluation metrics helps to balance the model complexity, preventing both overfitting and underfitting.",
  "optimization/regularization": "In our optimization process, we employed regularization techniques to prevent overfitting and ensure robust registration. Specifically, during the nonrigid registration phase, we set two regularization parameters: pre-sigma and post-sigma. The pre-sigma parameter was set to 5, and the post-sigma parameter was set to 4. These parameters help to control the smoothness of the transformation, preventing the model from fitting to noise or minor variations in the data. By incorporating these regularization parameters, we aimed to achieve a balance between flexibility and stability in the registration process, thereby enhancing the generalization of our registration algorithm to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available through the GreedyFHist project. The code, tutorials, and instructions for setting up docker images with examples are hosted on GitHub, providing a comprehensive resource for replication and further exploration. Additionally, an archival copy is available via Software Heritage. The DOME-ML (Data, Optimization, Model, and Evaluation in Machine Learning) annotations are accessible via the DOME registry under the accession vsx18unv9t. These resources ensure that the configurations and parameters are openly available for review and use under the MIT license.",
  "model/interpretability": "The model employed in this study, GreedyFHist, is designed with a focus on interpretability, making it more transparent than typical black-box models. GreedyFHist integrates spatial multi-omics data, allowing for a clear understanding of how different data types contribute to the final output. This transparency is achieved through several key features:\n\nFirstly, the model uses a greedy algorithm that sequentially incorporates data from various omics layers. This step-by-step integration process makes it easier to trace back and understand the contribution of each data type to the final result. For instance, the model can highlight specific genes or metabolites that are significantly associated with particular tissue types or disease states.\n\nSecondly, the visualizations generated by GreedyFHist provide intuitive insights into the data. Supplementary figures, such as those showing sample-wise gene scores and metabolite levels, offer a visual representation of the data integration process. These figures include linear regression lines and significance indicators, making it straightforward to interpret the relationships between different biological markers.\n\nAdditionally, the model's outputs can be linked back to the original data, allowing researchers to verify and interpret the results in the context of their specific biological questions. For example, the spatial transcriptomics data deposited with the accession number EGAD50000000603 can be accessed and analyzed to understand the spatial distribution of gene expression in relation to other omics data.\n\nOverall, GreedyFHist's design and the accompanying visualizations ensure that the model is not a black box. Instead, it provides a transparent and interpretable framework for integrating and analyzing multi-omics data.",
  "model/output": "The model discussed in this publication is primarily focused on spatial multi-omics integration, which involves the alignment and analysis of different types of omics data (such as transcriptomics and mass spectrometry imaging) within a spatial context. This integration allows for the comprehensive study of biological samples by combining various data modalities.\n\nThe model's output includes several key components:\n\n* **Spot-wise distributions**: The model provides detailed spot-wise distributions of various biological markers, such as gland and stroma classifications, citrate, zinc, and spermine levels, and gene scores (e.g., CSGS). These distributions are visualized for different datasets and samples, offering insights into the spatial organization and interaction of these markers within the tissue.\n\n* **Registration accuracy**: The model evaluates the accuracy of spatial registration using metrics like the median of the median target registration error (MM-TRE) and the average of the median target registration error (AM-TRE). These metrics help assess how well different serial sections and omics data are aligned.\n\n* **Correlation analysis**: The model reports Spearman correlation coefficients (ρ) and associated p-values to evaluate the relationships between different datasets and markers. This analysis helps identify significant correlations and the distance between sections, providing a deeper understanding of the data's spatial and biological context.\n\n* **Supplementary figures and tables**: The model's output is supplemented with various figures and tables that provide additional details and validations. These include visualizations of metabolite levels, tissue segmentation, and registration performance, as well as tables summarizing the number of image pairs, staining types, and registration accuracy for different strategies and datasets.\n\n* **Data availability**: The model's output includes information on data availability, with a reduced and anonymized exemplary test dataset available on Zenodo. The full dataset, which contains sensitive information, is subject to restricted access and can be requested through specific channels, complying with relevant regulations and ethical approvals.\n\nIn summary, the model's output is comprehensive, providing a range of visualizations, metrics, and supplementary materials that support the spatial multi-omics integration and analysis of biological samples.",
  "model/duration": "The execution time for the model varied depending on the specific tasks and datasets involved. For tissue segmentation, images were resampled to a resolution of 640 × 640 and converted to grayscale, followed by background segmentation to remove noise. This process was efficient, thanks to the use of total variation denoising methods. The hardware setup, which included an Intel Ice Lake Xeon Processor with 32 cores and 32 threads, ensured that the computations were performed swiftly.\n\nThe preprocessing of stained histology images and the generation of tissue masks for segmentation training were also streamlined. Initial masks were created using a pixel thresholder in QuPath, which significantly sped up the annotation process. These masks were then manually corrected for any misclassified areas, ensuring accuracy. The use of a groovy script to export stained images, tissue masks, and histopathology further optimized the workflow.\n\nFor the spatial transcriptomics, the sequencing libraries were created using the Visium Spatial Gene Expression Slide & Reagent kit, following the manufacturer’s guidelines. This included fixing tissue sections with methanol, HE staining, and scanning at 20× magnification. The capture of mRNA and subsequent amplification of cDNA were performed efficiently, with the amplified libraries quantified using qPCR. Paired-end sequencing was conducted on an Illumina NextSeq 500 instrument, which is known for its high throughput and speed.\n\nThe MALDI-TOF MSI process involved the use of two different matrices, DHB and NEDC, which were applied to the tissue sections using the HTX TM-Sprayer system. The measurements were taken using the rapiFlex MALDI Tissuetyper, which operated at a high frequency of 10 kHz, ensuring rapid data acquisition. The MSI data were then imported into FlexImaging and SCILS Lab for further processing, including baseline correction and normalization.\n\nOverall, the model's execution time was optimized through the use of efficient hardware, streamlined workflows, and advanced software tools. This ensured that the various tasks, from tissue segmentation to spatial transcriptomics and MALDI-TOF MSI, were completed in a timely manner.",
  "model/availability": "The source code for GreedyFHist is publicly available. It can be accessed on GitHub, where code, tutorials, and instructions for setting up Docker images with examples are provided. Additionally, an archival copy is available via Software Heritage. The software is licensed under the MIT license, which allows for free use, modification, and distribution.\n\nFor those who prefer not to set up the software locally, GreedyFHist can also be run using Docker images, making it platform-independent. This ensures that users can run the software efficiently on a CPU architecture without the need for computationally intensive deep learning methods.\n\nThe software is designed to process common formats in bioimaging analysis, such as ome.tiff and geojson, and can apply transformations to various image and pointset data. This makes it compatible with well-known bioimaging software like QuPath and ImageJ. GreedyFHist is available as a separate software package, allowing it to be used via the command line or interactively via an API. This flexibility enables its use outside of the MIIT framework, for example, in 3-dimensional image reconstruction.",
  "evaluation/method": "The evaluation of our method, MIIT, involved several rigorous steps to ensure its robustness and accuracy. Initially, we performed cross-validation of landmarks on serial sections, where a different annotator visually inspected and validated the placements. Consensus was reached in cases of disagreement. The target registration error (TRE) was defined as the Euclidean distance between matching landmarks from warped and fixed images. Each registration pair was evaluated using the median TRE, and the overall dataset accuracy was assessed using the median of median-TRE (MM-TRE) and the average median-TRE (AM-TRE).\n\nTo test the robustness of MIIT, we compared datasets with correct and artificial integration. The artificial integration involved rotating sections by 180 degrees and then integrating them, both with and without tissue type matching. We evaluated these datasets using the mean Spearman correlation coefficient and the number of significant correlations. Correctly integrated datasets consistently performed better, demonstrating the importance of accurate registration. Additionally, the comparison showed that biological heterogeneity exists even within the same tissue type, highlighting the need for precise integration.\n\nSupplementary tables and figures provide detailed results, including cross-validation outcomes for different segmentation methods and staining techniques. The evaluation also included the assessment of YOLO8-based tissue segmentation and the integration of various spatial omics data. Overall, the method was thoroughly evaluated through multiple criteria and comparisons, ensuring its reliability and effectiveness in integrating spatial omics data.",
  "evaluation/measure": "In our evaluation, we primarily focused on the target registration error (TRE) to assess the accuracy of our registration methods. The TRE is defined as the Euclidean distance between matching landmarks in the warped and fixed images. To provide a comprehensive evaluation, we calculated the median TRE for each registration pair. This metric, known as the median TRE, helps to mitigate the influence of outliers.\n\nTo evaluate the accuracy across the entire dataset, we computed two additional metrics: the median of median-TRE (MM-TRE) and the average median-TRE (AM-TRE). The MM-TRE represents the median of the median TRE values across all registration pairs, providing a robust measure of central tendency. The AM-TRE, on the other hand, is the mean of the median TRE values, offering an average performance indicator.\n\nThese metrics are reported in micrometers (μm), ensuring consistency and comparability with other studies in the field. Additionally, we reported the standard deviation for the AM-TRE to indicate the variability in registration accuracy.\n\nOur choice of metrics is aligned with common practices in the literature, ensuring that our evaluation is representative and comparable to other works in the field of image registration. The use of TRE-based metrics is particularly relevant for assessing the accuracy of landmark-based registration methods, as it directly measures the alignment error at specific points of interest.",
  "evaluation/comparison": "In the evaluation of our Multi-omics Imaging Integration Toolset (MIIT), we conducted a thorough comparison with both simpler baselines and deliberately poor integration methods to assess the robustness and accuracy of our approach. We did not compare our method to publicly available methods on benchmark datasets, as our focus was on demonstrating the internal validity and reliability of MIIT through controlled experiments.\n\nTo test the robustness of MIIT, we compared datasets with correct integration against those with artificial poor integration. This artificial integration was achieved by rotating the spatial transcriptomics (ST) sections by 180 degrees after registration, creating two scenarios: one where only spots with the same tissue type were considered (ArtIntMatchHist) and another where all spots were considered (ArtIntWithoutMatchHist). This allowed us to investigate whether poorly integrated spots, even if they matched in tissue type, could yield similar results to correctly integrated spots.\n\nOur evaluation criteria included the mean Spearman correlation coefficient (ρ) and the number of significant correlations for metabolites such as citrate, zinc, and spermine. The results showed that the correctly integrated datasets (IntMatchHist and IntWithoutMatchHist) outperformed the artificially integrated datasets (ArtIntMatchHist and ArtIntWithoutMatchHist). Specifically, IntMatchHist, which considered only matching tissue types, performed the best, followed by IntWithoutMatchHist, which included all spots regardless of tissue type. This indicates that accurate registration is crucial for biological interpretation and that there is significant biological heterogeneity even within the same tissue type.\n\nThe comparison with simpler baselines, such as considering all spots without tissue type matching, highlighted the importance of precise integration. The fact that IntWithoutMatchHist performed better than ArtIntMatchHist underscores the biological heterogeneity within tissue types, demonstrating that poor integration can weaken the biological relevance of the data. This comprehensive evaluation underscores the necessity of accurate and tissue-matched integration for reliable spatial multi-omics analysis.",
  "evaluation/confidence": "The evaluation of our method, MIIT, includes several performance metrics that provide confidence in our results. We report the average of the median target registration error (AM-TRE) with standard deviation, which gives an indication of the variability and reliability of our registration accuracy. This metric is crucial for understanding the precision of our spatial multi-omics integration.\n\nStatistical significance is a key aspect of our evaluation. We use the median target registration error (TRE) to assess the accuracy of each registration pair, and the median of these median-TRE values across the dataset provides a robust measure of overall performance. Additionally, we evaluate the significance of correlations using the Spearman correlation coefficient and report P-values to indicate the statistical significance of these correlations. This ensures that our claims of superior performance are backed by rigorous statistical analysis.\n\nWe also compare our method against baselines, including artificially integrated datasets, to demonstrate the importance of accurate registration. The results show that correctly integrated data perform better than artificially integrated data, highlighting the necessity of proper integration for meaningful biological interpretation. The comparison of different integration methods, with and without tissue type matching, further supports the robustness of our approach.\n\nIn summary, our evaluation includes confidence intervals for performance metrics and statistical significance tests to validate our claims. The results demonstrate that MIIT provides superior and reliable integration of spatial multi-omics data.",
  "evaluation/availability": "The raw evaluation files for our study are not publicly available due to the sensitive nature of the data and the need to comply with the General Data Protection Regulation (GDPR), Norwegian law, and specific patient consent and ethical approval. However, a reduced and anonymized exemplary test dataset for exploring the use and functionality of our Multi-Omics Imaging Integration Toolset (MIIT) is available on Zenodo. This dataset can be accessed via the provided DOI.\n\nFor researchers interested in accessing the full dataset, requests can be made through the EGA portal, where any data request will be processed through a data access committee. It is important to note that access to the data will only be granted after several steps have been achieved, including compliance with GDPR regulations, Norwegian law, and specific patient consent, approval by the regional ethical committee in Norway, and the completion of a Data Protection Impact Assessment (DPIA) if required. Additionally, a signed data transfer agreement between the institution of the data requester and NTNU is mandatory.\n\nFor mass spectrometry data, stained images, and tissue annotations, which are not externally archived, requests can be directed via email to specified contacts. These data types are not stored in a public repository due to the lack of a suitable platform that meets the data-sharing criteria outlined by our study’s ethical approval, patient consent, GDPR, and Norwegian law."
}