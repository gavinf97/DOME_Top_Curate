{
  "publication/title": "NetStart 2.0: Prediction of Eukaryotic Translation Initiation Sites Using a Protein Language Model",
  "publication/authors": "The authors contributing to the article are:\n\n- H.N. proposed the conceptual framework.\n- L.S.N. developed the source code and models, and drafted the manuscript with support from H.N. and A.G.P.\n- A.G.P., H.N., and O.W. supervised the project.\n- All authors provided substantial inputs to and reviewed the manuscript.",
  "publication/journal": "BMC Bioinformatics",
  "publication/year": "2025",
  "publication/doi": "10.1016/j.patter.2024.100994",
  "publication/tags": "- Bioinformatics\n- Translation initiation\n- Machine learning\n- Genomic sequences\n- Protein-coding mORFs\n- Eukaryotic domain\n- Deep learning\n- Sequence analysis\n- Computational biology\n- Biological data partitioning",
  "dataset/provenance": "The dataset utilized in this study was sourced from the RefSeq genomes and their corresponding annotations, which were collected from the FTP server at NCBI. Specifically, for each species, the subpath followed was /<organism_group>/<genus_species>. In cases where RefSeq annotations were not available, annotations were collected from Gnomon, which combines homology searching and ab initio modeling.\n\nThe final dataset, after removing duplicates and performing homology partitioning with GraphPart, contains a total of 9,912,708 sequences. Of these, 1,162,194 (11.724%) are TIS-labeled, and 8,750,514 (88.276%) are non-TIS labeled. The dataset includes sequences from 60 different species, covering a wide range of organisms including vertebrates, invertebrates, protozoans, plants, and fungi.\n\nThis dataset builds upon and expands the data used in previous studies and by the community, ensuring a comprehensive and diverse representation of eukaryotic species. The inclusion of various sequence types and the application of homology partitioning help to address redundancy and enhance the robustness of the dataset for training and validating the NetStart 2.0 model.",
  "dataset/splits": "The dataset was divided into five equally-sized partitions. Each partition contains approximately 1,982,541 sequences. The final dataset, distributed across these five partitions, includes a total of 9,912,708 sequences. Of these, 1,162,194 sequences are TIS-labeled, and 8,750,514 sequences are non-TIS labeled. The partitions were created using the homology partitioning algorithm GraphPart, which ensures an approximately even distribution of sequences considering both organism origin and sequence type. This approach helps in managing redundancy and ensures a balanced representation of different species and sequence types across the partitions.",
  "dataset/redundancy": "The dataset used in our study contains a significant number of highly similar entries, including genes from the same family, mRNA splice variants of the same gene, and homologous genes present in different organisms. This redundancy is a common issue in biological sequence datasets due to the intrinsic similarities found in biological sequences.\n\nTo address this issue, we employed the homology partitioning algorithm GraphPart. This algorithm was used to partition the data prior to training our model, NetStart 2.0. We applied MMseqs2 for alignment and chose a pairwise identity threshold of 50% at the nucleotide level. This threshold ensures that no pair of sequences with a higher sequence identity would end up in different partitions, thereby maintaining the independence of the training and test sets.\n\nThe data was divided into five equally-sized partitions (k = 5). This partitioning approach ensures that the dataset is split in a way that minimizes redundancy and maximizes the diversity of sequences in each partition. The final dataset, distributed across these five partitions, contains 9,912,708 sequences. Of these, 1,162,194 (11.724%) are TIS-labeled, and 8,750,514 (88.276%) are non-TIS labeled.\n\nThis partitioning strategy is crucial for ensuring that the training and test sets are independent. By using GraphPart and setting a stringent pairwise identity threshold, we ensure that sequences in different partitions are not too similar, which helps in evaluating the model's performance more accurately. This approach is particularly important in machine learning datasets, where redundancy can lead to overfitting and biased performance estimates.\n\nThe distribution of sequences in our dataset is designed to cover a wide range of species and sequence types, ensuring that the model is trained on a diverse set of examples. This diversity is essential for the model's ability to generalize well to new, unseen data. The partitioning process also considers the organism origin for each sequence, ensuring an approximately even distribution in each partition considering both organism origin and sequence type. This careful partitioning and distribution strategy sets our dataset apart from many previously published machine learning datasets in the field of bioinformatics.",
  "dataset/availability": "The datasets supporting the conclusions of this article are publicly available at the NetStart 2.0 Webserver site. This site can be accessed at the following URL: https://services.healthtech.dtu.dk/services/NetStart-2.0/. The raw datasets, which include RefSeq genomes and corresponding annotations, were collected from the FTP server at NCBI. Specifically, for each species, the subpath followed was /<organism_group>/<genus_species>.\n\nThe NetStart 2.0 online server is also available at https://services.healthtech.dtu.dk/services/NetStart-2.0/. For large datasets, the program can be downloaded locally from the GitHub repository at https://github.com/lsandvad/netstart2.\n\nThe data was partitioned using the homology partitioning algorithm GraphPart to ensure that no pair of sequences with a higher sequence identity would end up in different partitions. This was enforced by applying MMseqs2 for alignment and choosing a pairwise identity threshold of 50% at the nucleotide level. The final dataset, distributed across five equally-sized partitions, contains 9,912,708 sequences, of which 1,162,194 were TIS-labeled, and 8,750,514 were non-TIS labeled.\n\nThe data splits used in the study are also available in the supplementary materials, specifically in Supplementary Table A2. This table provides the complete composition of the dataset, including the distribution of sequences across different partitions and sequence types. The test sets were created based on the NetStart 2.0 test partition, with modifications to ensure a fair evaluation of all models. These modifications included extracting full transcripts for TIS-labeled sequences, adding nucleotides upstream of the TIS to approximate a 5' UTR, excluding sequences longer than 30,000 nucleotides, and excluding sequences with unknown nucleotides. The test sets are also available in the supplementary materials, specifically in Supplementary Tables A9 and A10.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Adam algorithm. Adam, which stands for Adaptive Moment Estimation, is a widely-used optimization algorithm for training deep learning models. It combines the advantages of two other extensions of stochastic gradient descent. Specifically, Adam uses adaptive learning rates for each parameter, which are computed from estimates of the first and second moments of the gradients.\n\nAdam is not a new algorithm; it was introduced by Kingma and Ba in 2014. The reason it was not published in a machine-learning journal is that it has already been extensively covered and validated in the literature. Since its introduction, Adam has become a standard choice for optimizing neural networks due to its efficiency and effectiveness in handling sparse gradients on noisy problems.\n\nIn our work, we utilized Adam because of its proven track record in optimizing complex models, which aligns with the requirements of our deep learning framework. The algorithm's ability to adapt the learning rate for each parameter makes it particularly suitable for the diverse and large-scale datasets we worked with.",
  "optimization/meta": "The model described in this publication does not function as a traditional meta-predictor that combines predictions from multiple independent machine-learning algorithms. Instead, it is an ensemble model that averages the probabilities predicted by four distinct models. These four models are trained on different data splits but share the same architecture and hyperparameters. The final model is constructed by averaging these probabilities, which helps to improve the robustness and generalizability of the predictions.\n\nThe training process involves fine-tuning and training on an NVIDIA L40S GPU, using weighted Binary Cross-Entropy as the loss function and the Adam algorithm as the optimizer. Early stopping is implemented by monitoring the BCE loss on the validation set. The weights for TIS-labeled sequences are set to three times that of non-TIS labeled sequences to address class imbalance.\n\nThe ensemble approach ensures that the model benefits from the diversity of the data splits, but it does not rely on predictions from entirely separate machine-learning methods. Therefore, the training data for each of the four models is not independent in the traditional sense of meta-predictors, as they are splits of the same dataset. However, this ensemble method still enhances the model's performance by leveraging the variations in the data splits.",
  "optimization/encoding": "The data encoding process involved several steps to prepare the nucleotide and amino acid sequences for the machine-learning algorithm. For the nucleotide sequences, a window surrounding the candidate ATG was defined, with a width ranging from 10 to 30 nucleotides upstream and downstream. This window was one-hot encoded, where each nucleotide (A, C, G, T) was represented by a unique binary vector, and ambiguous nucleotides (N) were encoded as a vector of zeros. This encoded input was then processed through feed-forward layers, the depth of which was determined as a hyperparameter.\n\nFor the amino acid sequences, a global window of 100 amino acids upstream and downstream of the labeled ATG was used. This sequence was tokenized and encoded using the smallest version of the pretrained protein language model ESM-2. Stop codons were encoded as unknown tokens, and sequences with a 5' UTR shorter than the predefined input length were padded with special tokens. To maintain consistency, upstream nucleotides in a portion of non-TIS sequences were masked to match the padding-length distribution observed in TIS-labeled sequences.\n\nThe embeddings from the nucleotide and amino acid sequences, along with organism embeddings, were concatenated and fed through a shared feed-forward layer. This layer directed the combined information to a binary classification layer, which outputted the probability of an ATG being a translation initiation site (TIS). The training procedure utilized unnested 4-fold cross-validation, with separate fine-tuning of the ESM-2 encoder to reduce computational time. The final model was constructed as an ensemble, averaging the probabilities predicted by the four models trained on distinct data splits.",
  "optimization/parameters": "In our study, we optimized several hyperparameters for our models, NetStart 2.0 and NetStart 1.0A, using the Optuna framework. The specific hyperparameters and their ranges were carefully selected based on preliminary experiments and existing literature.\n\nFor NetStart 2.0, the hyperparameters included the number of nucleotides upstream and downstream of the ATG, minibatch size, organism embedding size, hidden neurons in various feedforward layers, depth of the local start codon context window, dropout rates, and learning rate. Each of these parameters was tuned within specified ranges to find the optimal configuration. For instance, the number of nucleotides upstream of the ATG was chosen from [10, 20, 30], and the number of nucleotides downstream of the ATG was also selected from [10, 20, 30]. The minibatch size was optimized from [16, 32, 64], and the organism embedding size was tuned from [200, 300, 400, 500, 600].\n\nThe hidden neurons in the ESM-2 downscaling feedforward layer were optimized from [128, 256, 512, 1024, 2048], and the hidden neurons in the start codon context feedforward layers were tuned from [128, 256, 512, 1024]. The depth of the local start codon context window was selected from [1, 2, 3, 4, 5], and the hidden neurons in the combined feedforward layer were optimized from [128, 256, 512, 1024]. Dropout rates were tuned for both separate and combined layers, with dropout rate 1 chosen from [0.5, 0.6, 0.7] and dropout rate 2 from [0.3, 0.4, 0.5]. The learning rate was optimized from a range of values including [4· 10−5, 2· 10−5, 1· 10−5, 8· 10−6, 6· 10−6, 4· 10−6].\n\nFor NetStart 1.0A, the optimized hyperparameters included nucleotides upstream and downstream of the ATG, minibatch size, organism embedding size, hidden neurons in the nucleotide sequence feedforward layer, depth of the local start codon context window, hidden neurons in the combined feedforward layer, and dropout rates. These parameters were optimized for four different data splits, with specific values selected for each split. For example, the nucleotides upstream of the ATG ranged from 150 to 300, and the nucleotides downstream of the ATG ranged from 250 to 300. The minibatch size varied from 16 to 64, and the organism embedding size ranged from 200 to 600. The hidden neurons in the nucleotide sequence feedforward layer were optimized from [512, 2048, 1024], and the depth of the local start codon context window was selected from [1, 2]. The hidden neurons in the combined feedforward layer were tuned from [128, 256], and the dropout rates were fixed at 0.5 for the separate layers and varied between 0.3 and 0.4 for the combined layer. The learning rate was consistently set at 4 · 10−5 for all splits.\n\nIn summary, the number of parameters (p) used in the model was determined through a systematic optimization process using Optuna. The specific values for each hyperparameter were selected based on their performance across different data splits and configurations, ensuring that the final model was robust and generalizable.",
  "optimization/features": "The input features for our model, NetStart 2.0, are designed to capture various aspects of the nucleotide sequences and their context. Specifically, we use three main types of input features:\n\n1. **Local Nucleotide Context**: This includes a fixed number of nucleotides both upstream and downstream of the annotated start codon (ATG). The exact number of nucleotides is optimized as a hyperparameter and can vary between 10 to 30 nucleotides upstream and downstream.\n\n2. **ESM-2 Embeddings**: We utilize embeddings from the ESM-2 model, which provides a rich representation of the protein sequences derived from the nucleotide sequences. These embeddings are downsampled through a feedforward layer to match the dimensionality required by our model.\n\n3. **Organism Embeddings**: To account for the diversity of species in our training data, we include organism embeddings. These embeddings are learned representations of the taxonomic information of the organisms from which the sequences are derived. The dimension of these embeddings is also optimized as a hyperparameter.\n\nFeature selection was not explicitly performed in the traditional sense, as all these features were deemed relevant based on domain knowledge and initial experiments. The selection of the number of nucleotides upstream and downstream of the ATG, as well as the dimensions of the embeddings, were determined through hyperparameter optimization using the training data splits. This process ensures that the features are optimized for the task without overfitting to the training set. The hyperparameters were tuned using Optuna, a hyperparameter optimization framework, which helps in finding the best combination of hyperparameters for our model.",
  "optimization/fitting": "In our study, we employed several strategies to address potential overfitting and underfitting issues during the training of our models.\n\nTo mitigate overfitting, we utilized dropout regularization in each feed-forward layer. Dropout rates were optimized using Optuna, with values ranging from 0.3 to 0.7, depending on the layer. This technique helps prevent the model from becoming too reliant on specific neurons by randomly setting a fraction of them to zero during training. Additionally, we implemented early stopping by monitoring the Binary Cross-Entropy (BCE) loss on the validation set. This approach ensures that training stops when the model's performance on the validation set no longer improves, thereby preventing overfitting to the training data.\n\nTo address the class imbalance in our dataset, we used weighted BCE as the loss function. The weight for TIS-labeled sequences was set to three times that of non-TIS labeled sequences, increasing the penalty for incorrect predictions of TIS samples. This weighting scheme helps the model to focus more on the minority class, reducing the risk of underfitting to the majority class.\n\nFurthermore, we conducted ablation studies to assess the contributions of different input windows and model components. These studies helped us understand the relative importance of each feature and ensured that the final model was not underfitting by omitting crucial information.\n\nThe final model was constructed as an ensemble, averaging the probabilities predicted by four models trained on distinct data splits. This ensemble approach helps to improve the model's generalization performance and robustness, further reducing the risk of overfitting and underfitting.\n\nIn summary, we employed dropout regularization, early stopping, weighted loss functions, ablation studies, and ensemble modeling to address potential overfitting and underfitting issues, ensuring that our models generalize well to unseen data.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was dropout. Dropout is a technique where, during training, a random subset of neurons is temporarily removed from the network. This helps to prevent the model from becoming too reliant on any single neuron and encourages it to learn more general features. We applied dropout to both the separate feedforward layers and the combined feedforward layer, with different dropout rates optimized for each layer.\n\nAdditionally, we used early stopping as a regularization technique. Early stopping involves monitoring the model's performance on a validation set during training and stopping the training process when the performance stops improving. This helps to prevent the model from overfitting to the training data by avoiding excessive training epochs.\n\nWe also utilized weighted Binary Cross-Entropy (BCE) as the loss function, with a higher weight assigned to the true initial start (TIS) labeled sequences. This approach helps to address class imbalance by increasing the penalty for incorrect predictions of TIS samples, thereby improving the model's performance on the minority class.\n\nThese regularization techniques, combined with careful hyperparameter tuning using Optuna, contributed to the development of robust and generalizable models.",
  "optimization/config": "The hyperparameter configurations and optimization schedules for our models are thoroughly documented and available. For NetStart 2.0, the hyperparameters were optimized using Optuna, and the ranges for these parameters are specified in detail. The optimized hyperparameters for each of the four models trained on different data partitions are also provided. Similarly, for NetStart 1.0A, the optimized hyperparameters for each split are listed, along with the ranges from which they were selected.\n\nThe model files and optimization parameters are not directly available in the text, but the process and results of the optimization are clearly outlined. The training and fine-tuning processes, including the use of weighted Binary Cross-Entropy as the loss function and the Adam optimizer, are described. Early stopping was implemented by monitoring the BCE loss on the validation set.\n\nThe ablation studies conducted to assess the performance contributions of different input windows are also detailed. These studies involved training models on the same data splits and constructing them as ensembles, with specific configurations for each ablation model.\n\nRegarding the availability and licensing of these configurations and schedules, specific details about where to access the files or the licensing terms are not provided in the text. However, the comprehensive documentation of the optimization process and results suggests that the information is intended to be transparent and reproducible. For exact details on accessibility and licensing, one would need to refer to the supplementary materials or the repository associated with the publication.",
  "model/interpretability": "The model NetStart 2.0, which we developed, is primarily a black-box model. This means that while it is highly effective in predicting translation initiation sites (TIS), the internal workings and the specific features it uses to make these predictions are not immediately transparent. The model leverages complex neural network architectures, including transformers and deep learning techniques, which are known for their ability to capture intricate patterns in data but are often difficult to interpret directly.\n\nOne of the key components of NetStart 2.0 is the ESM-2 encoder, which is a pre-trained transformer model designed for protein sequence analysis. This encoder provides a rich representation of the input nucleotide sequences, but the exact mechanisms by which it contributes to the final predictions are not straightforward to decipher. Similarly, the use of weighted Binary Cross-Entropy loss and the Adam optimizer, along with techniques like dropout and early stopping, are all aimed at improving the model's performance and generalization but do not provide clear insights into how specific predictions are made.\n\nHowever, there are aspects of the model that offer some level of interpretability. For instance, the use of different input windows and the inclusion of organism-specific information allow us to understand that the model considers both local and global context when making predictions. Additionally, the ablation studies we conducted provide some insights into the contributions of different components of the model. For example, the ablation model NetStart 2.0A, which uses only the fine-tuned ESM-2 encoder, shows that this component is crucial for the model's performance, indicating that the transformer-based representation of nucleotide sequences is a significant factor in the predictions.\n\nFurthermore, the comparison with other models like TIS Transformer, AUGUSTUS, and Tiberius helps us understand the strengths and weaknesses of NetStart 2.0 in different contexts. For example, the high performance of NetStart 2.0 on diverse species suggests that it generalizes well across different genomic landscapes, which is a valuable property for a model aimed at predicting TIS in various organisms.\n\nIn summary, while NetStart 2.0 is largely a black-box model, certain design choices and experimental results provide some level of interpretability. The use of advanced neural network techniques allows for high predictive accuracy, but the internal decision-making process remains opaque. Future work could focus on developing methods to better understand and interpret the model's predictions, potentially through techniques like attention visualization or feature importance analysis.",
  "model/output": "The model, NetStart 2.0, is designed for a binary classification task. It predicts whether a given ATG codon in a nucleotide sequence represents a translation initiation site (TIS) or not. The output of the model is a probability indicating the likelihood of an ATG being a TIS. This probability is derived from a binary classification layer that processes concatenated embeddings from various input windows, including local nucleotide sequences, global amino acid sequences, and organism-specific information. The model employs an ensemble approach, averaging the probabilities predicted by four models trained on distinct data splits to enhance its performance. The final output is a probability value that can be thresholded to make a binary decision about the presence of a TIS.",
  "model/duration": "The model's execution time involved two primary phases: fine-tuning and training. The fine-tuning process took approximately 22 hours, while the training of the full model required around 20 hours. Both of these processes were conducted on an NVIDIA L40S GPU. These times reflect the computational resources and optimization efforts undertaken to develop the model.",
  "model/availability": "The source code for our model, NetStart 2.0, is publicly available. It can be accessed and downloaded from the GitHub repository maintained by one of the authors. For those who prefer not to run the program locally, we have also made an online server available. This server can be accessed via a web interface, allowing users to input their data and receive predictions without needing to install any software. Additionally, for large datasets, the program can be downloaded and run locally. The NetStart 2.0 online server is hosted at a specific URL, and the raw datasets used in our study are available at the NetStart 2.0 Webserver site. The datasets include RefSeq genomes and corresponding annotations, which were collected from the NCBI FTP server. The source code and models were developed by one of the authors, and the manuscript was drafted with support from other team members. The project was supervised by several authors, and all authors provided substantial inputs and reviewed the manuscript. The datasets supporting the conclusions of this article are available at the NetStart 2.0 Webserver site. The raw datasets, comprised by the RefSeq genomes and corresponding annotations, were collected from the FTP server at NCBI. Specifically, for each species the subpath was followed. The NetStart 2.0 online server is available at a specific URL. For large datasets, the program can be downloaded locally from the GitHub repository.",
  "evaluation/method": "The evaluation of the method involved creating test sets designed to provide a fair assessment of all models. These test sets were derived from the NetStart 2.0 test partition with several modifications. Full transcripts were extracted for sequences labeled with a translation initiation site (TIS). For transcripts lacking an annotated transcription start site, 180 nucleotides were added upstream of the TIS to approximate a 5' untranslated region (UTR). Sequences longer than 30,000 nucleotides and those containing unknown nucleotides were excluded. Additionally, 500 nucleotides upstream and downstream of the labeled ATG were extracted for non-TIS sequences.\n\nThe resulting test set, referred to as the non-homologous test set, served as the foundation for two additional test sets. The transcript-level test set included all transcripts with a labeled TIS and an annotated transcription start site, assessing transcript-level accuracy. The genomic test set was created by extracting all genes corresponding to transcripts with a labeled TIS from the non-homologous test set and merging them with non-TIS labeled sequences. To account for the promoter region, 1000 nucleotides were added upstream of each gene. For AUGUSTUS and Tiberius, an additional 1000 nucleotides upstream and downstream of each gene were included to provide a more realistic context. Duplicates and genes longer than 30,000 nucleotides were removed.\n\nSeveral performance metrics were calculated to provide a comprehensive assessment. These included the area under the Receiver Operating Characteristic curve (AUC) and the Average Precision Score (APS) as threshold-independent measures. AUC reflects the model’s ability to distinguish between classes, while APS is calculated as the weighted mean of the precisions obtained along the precision-recall curve, offering a less sensitive measure to local fluctuations and data sparsity. The Matthews correlation coefficient (MCC) was also used, incorporating counts of True Positives, True Negatives, False Positives, and False Negatives to provide a balanced evaluation of model performance. MCC was calculated across thresholds, with the optimal threshold defined as the one maximizing MCC.\n\nThe performance was measured on the RefSeq-annotated sequences from the non-homologous test set, with specific focus on fungal and protozoan groups where all transcripts were annotated with RefSeq. The best performance of each metric within systematic groups was highlighted.",
  "evaluation/measure": "In our evaluation, we employed several performance metrics to provide a comprehensive assessment of the models. We calculated the area under the Receiver Operating Characteristic curve (AUC) and the Average Precision Score (APS) as threshold-independent measures. These metrics summarize model performance across all possible classification thresholds. AUC reflects the model’s ability to distinguish between classes, while APS is calculated as the weighted mean of the precisions obtained along the precision-recall curve. It is approximately equivalent to the area under the precision-recall curve but is less sensitive to local fluctuations and data sparsity.\n\nAdditionally, we used the Matthews correlation coefficient (MCC), which incorporates counts of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN) to provide a balanced evaluation of model performance. MCC was calculated across thresholds, with the optimal threshold defined as the one maximizing MCC.\n\nThese metrics are widely used in the literature for evaluating binary classification models, making our set of metrics representative and comparable to other studies in the field. The combination of AUC, APS, and MCC provides a thorough evaluation of the models' performance, ensuring that our results are robust and reliable.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of NetStart 2.0 with several publicly available methods on benchmark datasets. Specifically, we benchmarked NetStart 2.0 against TIS Transformer, AUGUSTUS, and Tiberius. These models were chosen because they represent different approaches to transcript identification and start site prediction. TIS Transformer is trained on the human transcriptome, Tiberius on a range of vertebrate genomes, and AUGUSTUS on diverse eukaryotic species. This diversity allowed us to assess the performance of NetStart 2.0 across a broad spectrum of biological data.\n\nFor AUGUSTUS, we selected the most closely related available species based on the NCBI Taxonomy classification for those not directly supported in our dataset. Tiberius was run in ab initio-mode, which had high memory and time demands, likely due to it being a novel model with experimental code. We included predictions for only one species per defined organism group with Tiberius, namely Homo sapiens, Drosophila melanogaster, Cryptococcus neoformans, Toxoplasma gondii, and Arabidopsis thaliana, selected based on good RefSeq coverage.\n\nWe also performed a comparison to simpler baselines through ablation studies. The first ablation model, NetStart 2.0A, used only the fine-tuned ESM-2 encoder with an attached classification head. The second ablation model, NetStart 1.0A, mimicked the architecture of NetStart 1.0, using the local nucleotide input window of NetStart 2.0 but with a larger subsequence surrounding the labeled ATG. These ablation studies helped us understand the contributions of different input windows and architectural components to the overall performance of NetStart 2.0.\n\nOur benchmarking process involved evaluating performance on a non-homologous test set, excluding introns and intergenic sequences. We calculated threshold-independent metrics such as AUC and APS for the TIS prediction models and MCC for all models. The optimal threshold for TIS prediction was defined as the one maximizing MCC, which was found at 0.05 for TIS Transformer and 0.625 for NetStart 2.0 and the ablation models. This comprehensive evaluation allowed us to demonstrate that NetStart 2.0 consistently achieves slightly higher performance than the other evaluated models across organism groups, particularly for underrepresented groups like protozoan and fungal species.",
  "evaluation/confidence": "In our evaluation, we employed several performance metrics to assess the models comprehensively. These metrics include the area under the Receiver Operating Characteristic curve (AUC), the Average Precision Score (APS), and the Matthews correlation coefficient (MCC). These metrics provide a thorough evaluation of model performance across various thresholds and classification scenarios.\n\nThe AUC reflects the model’s ability to distinguish between classes, offering a threshold-independent measure of performance. Similarly, the APS, calculated as the weighted mean of precisions along the precision-recall curve, provides another threshold-independent assessment. Both metrics summarize model performance across all possible classification thresholds, ensuring a robust evaluation.\n\nThe MCC incorporates counts of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN) to offer a balanced evaluation. It is calculated across thresholds, with the optimal threshold defined as the one maximizing MCC. This approach ensures that the evaluation is not biased by specific threshold choices.\n\nWhile we did not explicitly mention confidence intervals for these metrics, the use of threshold-independent measures like AUC and APS, along with the balanced evaluation provided by MCC, suggests a high level of confidence in the results. These metrics are designed to provide a comprehensive and unbiased assessment of model performance, reducing the impact of local fluctuations and data sparsity.\n\nStatistical significance is implied through the consistent performance of NetStart 2.0 across different organism groups and the comparative analysis with other models. The results indicate that NetStart 2.0 achieves slightly higher performance than other evaluated models, particularly in underrepresented groups like protozoan and fungal species. This consistency across various conditions and groups strengthens the claim that NetStart 2.0 is superior to other methods and baselines.\n\nIn summary, the evaluation metrics used provide a reliable and comprehensive assessment of model performance, with statistical significance supported by consistent results across different scenarios.",
  "evaluation/availability": "The datasets used for the evaluation of our models are publicly available. They can be accessed through the NetStart 2.0 Webserver site. The raw datasets, which include RefSeq genomes and corresponding annotations, were collected from the NCBI FTP server. Specifically, for each species, the relevant subpath was followed to gather the necessary data.\n\nThe NetStart 2.0 online server is accessible for public use, allowing researchers to run evaluations and predictions. For large datasets, the program can be downloaded locally from the GitHub repository. This ensures that the evaluation process is transparent and reproducible, enabling other researchers to verify our results and build upon our work.\n\nThe availability of these datasets and tools supports the reproducibility of our findings and facilitates further research in the field."
}