{
  "publication/title": "Group-Specific Discriminant Analysis Enhances Detection of Sex Differences in Brain Functional Network Lateralization",
  "publication/authors": "The authors who contributed to the article are:\n\nShuo Zhou, who was involved in conceptualization, data curation, formal analysis, investigation, methodology, validation, visualization, and writing both the original draft and the review & editing.\n\nJunhao Luo, who contributed equally to conceptualization, data curation, and formal analysis, and led the investigation and methodology. He also contributed equally to visualization and led the writing of the original draft, while supporting the writing of the review & editing.\n\nYaya Jiang, who contributed equally to data curation and led the resources, while supporting the writing of the review & editing.\n\nHaolin Wang, who supported the methodology and the writing of the review & editing.\n\nHaiping Lu, who contributed equally to conceptualization and supported the methodology, project administration, and the writing of the original draft. He also led the writing of the review & editing.\n\nGaolang Gong, who contributed equally to conceptualization and led the funding acquisition. He also supported the methodology and project administration, while contributing to the writing of the review & editing.",
  "publication/journal": "GigaScience",
  "publication/year": "2025",
  "publication/doi": "10.5524/102700",
  "publication/tags": "- Brain Functional Network Lateralization\n- Group-Specific Discriminant Analysis\n- Sex Differences in Brain Connectivity\n- Machine Learning in Neuroscience\n- Logistic Regression\n- Human Connectome Project\n- Brain Genomics Superstruct Project\n- Intrahemispheric Functional Connectivity\n- Classification Accuracy\n- Group Specificity in Models\n- Hyperparameter Tuning\n- Second-Order Classification\n- Pearson Correlation Coefficients\n- Regularization in Machine Learning\n- Sex-Specific Lateralized Connections",
  "dataset/provenance": "The datasets used in our study are sourced from two prominent projects: the Human Connectome Project (HCP) and the Brain Genomics Superstruct Project (GSP). The HCP dataset includes 960 subjects, with 445 males and 515 females. The GSP dataset comprises 1,570 subjects, with 665 males and 905 females. Both datasets include resting-state functional magnetic resonance imaging (rs-fMRI) data, which were acquired using standardized protocols to ensure consistency.\n\nThe HCP data were collected using 3T Siemens Skyra magnetic resonance machines at Washington University in St. Louis. Each subject underwent two rs-fMRI sessions on consecutive days, with each session including two runs with different phase encoding directions. The GSP data, on the other hand, were collected from a larger and more diverse population, providing a broader scope for our analyses.\n\nThese datasets have been widely used in the neuroimaging community for various studies on brain connectivity and functional lateralization. The HCP dataset, in particular, is renowned for its high-quality imaging data and comprehensive demographic information, making it a valuable resource for research in neuroscience. The GSP dataset complements the HCP by offering a larger sample size and additional demographic diversity.\n\nThe data from these projects have been utilized in numerous previous studies, contributing to our understanding of brain function and structure. Our study builds upon this foundation by applying group-specific discriminant analysis to enhance the detection of sex differences in brain functional network lateralization. The use of these well-established datasets ensures the robustness and reliability of our findings, allowing for meaningful comparisons with existing research.",
  "dataset/splits": "In our study, we employed two primary cross-validation strategies for splitting the datasets. The first strategy involved dividing the subjects within each dataset into two equal groups, each comprising 50% of the total subjects. The training set was composed of left hemispheres from the first group and right hemispheres from the second group. The remaining hemispheres (right hemispheres of the first group and left hemispheres of the second group) were used for testing. This approach ensured that no subject contributed both hemispheres to the training set, thereby minimizing potential biases from intrasubject correlations.\n\nThe second strategy involved holding out 20% of the subjects entirely as an additional unseen test set. The training examples were then obtained by applying the same strategy to the remaining 80% of subjects. This method provided an extra layer of validation by testing the models on subjects that were not included in the training process.\n\nFor the Human Connectome Project (HCP) dataset, which includes two scanning sessions per subject on different days, the session not used for training served as an additional test set. This allowed us to evaluate the models' performance on data collected from the same subjects but on different occasions.\n\nEach cross-validation strategy was repeated 1,000 times, generating 1,000 models per learning task. This extensive repetition helped to ensure the robustness and reliability of our findings. The distribution of data points in each split was designed to balance the training and testing sets, with the first strategy using 50% of the subjects for training and 50% for testing, and the second strategy using 80% for training and 20% for testing.",
  "dataset/redundancy": "The datasets used in this study were split using a cross-validation strategy. Specifically, 80% of the subjects were used for training, while the remaining 20% were reserved for testing. This process was repeated 1,000 times to generate 1,000 models per learning task, ensuring robustness and reliability of the results.\n\nFor the Human Connectome Project (HCP) dataset, which includes two scanning sessions per subject on different days, the session not used for training served as an additional test set. This approach ensures that the training and test sets are independent, as they come from different scanning sessions.\n\nThe distribution of the datasets used in this study is comparable to previously published machine learning datasets in the field. The use of cross-validation and the separation of training and test sets by different scanning sessions help to mitigate issues related to dataset redundancy and overfitting. This methodology ensures that the models are evaluated on data that was not seen during training, providing a more accurate assessment of their performance.",
  "dataset/availability": "The data utilized in this study is publicly available through Zenodo archives. Specifically, the Human Connectome Project (HCP) intrahemispheric functional connectivity data can be accessed at [this link](https://doi.org/10.5281/zenodo.10050233), and the Brain Genomics Superstruct Project (GSP) intrahemispheric functional connectivity data is available [here](https://doi.org/10.5281/zenodo.10050234). These datasets are shared under the terms of the Creative Commons Attribution License, which allows for unrestricted reuse, distribution, and reproduction, provided that the original work is properly cited.\n\nThe data splits used in our experiments, including the training and test sets, were generated through stratified random sampling and cross-validation strategies as described in the methodology. These splits were enforced by ensuring that the same strategies were applied consistently across all experiments, with each cross-validation strategy repeated 1,000 times to generate robust and reliable models.\n\nAdditionally, the software code used for the analyses is available on GitHub at [this repository](https://github.com/shuo-zhou/GSDA-Lateralization). A version of record snapshot of the GitHub repository has been archived in the Software Heritage Library with the PID swh:1:snp:495f818df0e3c6d9ac1898b1cc14ec0ea396d98a. This ensures that the code used for the analyses is publicly accessible and can be reproduced by other researchers.",
  "optimization/algorithm": "The optimization algorithm employed in our work is based on gradient descent, a well-established class of machine-learning algorithms. Specifically, we utilize a variant tailored for our Group-Specific Discriminant Analysis with logistic loss (GSDA-Logit) model. The algorithm involves iteratively updating the weight vector to maximize the likelihood function, which incorporates both the logistic loss and a regularization term that accounts for group-specific dependencies.\n\nThe algorithm is not entirely new; it builds upon standard logistic regression techniques. However, the integration of the group-specific discriminant analysis and the use of the Hilbert-Schmidt Independence Criterion (HSIC) for regularization are novel contributions. These modifications allow the model to better capture sex differences in brain functional network lateralization.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of our work is on the application of these techniques to neuroimaging data, rather than the development of new machine-learning algorithms per se. The innovation lies in the application and the specific adaptations made to address the unique challenges of the data and the research questions at hand. The algorithm is designed to enhance the detection of sex differences in brain functional network lateralization, which is a significant contribution to the field of neuroscience and personalized medicine.",
  "optimization/meta": "The model employs a dual-classification framework, which can be considered a form of meta-predictor. In this framework, the first-order classification involves training a linear classifier on the training data to predict whether an unseen brain hemisphere is left or right. This process generates first-order weights, which are the model weights derived from this initial classification.\n\nThe second-order classification uses these first-order weights as input features. A linear classifier is then trained on these weights to differentiate between male-specific and female-specific models. This stage is crucial for identifying weights that show significant differences between the group-specific models. The features with larger weights in the second-order classification are considered to represent stronger sex differences.\n\nThe training data for the second-order classification is derived from the first-order models, ensuring that the input features are independent of the target labels in the second-order classification. This independence is maintained by using stratified random sampling to split the models into training and test sets, repeated with different random seeds for robustness.\n\nThe whole process involves logistic regression for both the first-order and second-order classifications. The first-order classification uses a group-specific discriminant analysis with logistic loss (GSDA-Logit), which is a variant of logistic regression designed for group-dependent learning. The second-order classification also uses logistic regression to differentiate between the male-specific and female-specific models.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithm. The input data matrix, denoted as X, consists of feature vectors representing brain hemispheres. Each row in X corresponds to a sample, and each column represents a specific feature.\n\nThe grouping factor, which in our case is the sex of the subjects, was encoded using one-hot encoding. This process converts categorical variables into a binary matrix, where each column represents a unique category. For instance, if the grouping factor is binary (male or female), it is encoded into a matrix G with a single column, where 0 represents male and 1 represents female.\n\nAdditionally, a centering matrix H was constructed to ensure that the data is centered around the mean. This step is essential for certain types of regularization techniques used in our algorithm.\n\nTo facilitate the optimization process, a row of ones was added to the input data matrix X. This addition allows for the inclusion of a bias term in the model, which is crucial for adjusting the output of the model.\n\nThe target-group label vector, denoted as yt, indicates whether each sample belongs to the target group (e.g., male or female). This vector is used to train the model to differentiate between the target and non-target groups.\n\nOverall, these encoding and preprocessing steps ensure that the data is in a suitable format for the machine-learning algorithm to learn group-specific models effectively.",
  "optimization/parameters": "The model utilizes a feature vector representing a brain hemisphere, with the dimensionality of this vector denoted as p. This dimensionality corresponds to the number of features used to describe each brain hemisphere in the input data matrix X. The specific value of p is determined by the neuroimaging data preprocessing steps, which extract relevant features from the brain scans. These features could include various connectivity measures, regional activations, or other derived metrics from the neuroimaging data. The selection of p is thus inherently tied to the resolution and type of neuroimaging data used, as well as the specific preprocessing pipeline applied to extract meaningful features for the classification task. In the context of our study, p is the number of features that best represent the lateralization patterns in the brain hemispheres, enabling the model to distinguish between left and right hemispheres effectively.",
  "optimization/features": "The input features used in the experiments are 7,503-dimensional feature vectors derived from the BrainNetome Atlas (BNA) for the two hemispheres. These features were used directly without any explicit mention of feature selection. Therefore, it is assumed that all 7,503 features were utilized as input for the models. The feature vectors were obtained for each hemisphere, and no indication was given that feature selection was performed using the training set or otherwise.",
  "optimization/fitting": "The fitting method employed in our study involves a regularized logistic regression framework, specifically designed to handle group-specific discriminant analysis. This approach ensures that the model can effectively learn from the data without overfitting or underfitting.\n\nTo address the potential issue of overfitting, especially when the number of parameters is large relative to the number of training points, we incorporated two regularization terms. The first is an ℓ2 regularization term, which penalizes large weights and helps to prevent the model from becoming too complex. The second is a grouping factor dependence regularization term, which encourages the model to consider the statistical dependence between the grouping factors and the predictions. This dual regularization strategy helps to control the model's complexity and ensures that it generalizes well to unseen data.\n\nTo further mitigate overfitting, we employed cross-validation strategies. Specifically, we repeated each cross-validation strategy 1,000 times, generating 1,000 models per learning task. This extensive cross-validation process helps to ensure that the model's performance is robust and not merely a result of overfitting to a particular subset of the data.\n\nUnderfitting was addressed by carefully selecting the hyperparameters. The hyperparameter λ, which controls the importance of the grouping factor dependence regularization, was tuned to an optimal value of 5. This value was determined through extensive experimentation and was found to provide a good balance between classification accuracy and group specificity. Additionally, the use of logistic loss and maximum likelihood estimation ensures that the model is flexible enough to capture the underlying patterns in the data without being too simplistic.\n\nIn summary, the fitting method combines regularization techniques and extensive cross-validation to prevent overfitting and underfitting, ensuring that the model is both robust and accurate.",
  "optimization/regularization": "In our optimization process, we employed regularization techniques to prevent overfitting and enhance the generalization of our models. Specifically, we utilized ℓ2 regularization, which is also known as ridge regularization. This method adds a penalty term to the loss function proportional to the square of the magnitude of the coefficients. By doing so, it discourages large weights, thereby reducing the model's complexity and helping to prevent overfitting.\n\nAdditionally, we incorporated a grouping factor dependence regularization term. This term, controlled by the hyperparameter λ, ensures that the model takes into account the statistical dependence on grouping factors, such as sex in our experiments. This regularization helps in capturing group-specific patterns in the data, which is crucial for detecting sex differences in brain functional network lateralization.\n\nThe combination of these regularization techniques allows our models to achieve a balance between fitting the training data well and generalizing to unseen data, thereby improving the robustness and reliability of our findings.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail within the publication. Specifically, we utilized a hyperparameter λ set to 5 for the group-specific discriminant analysis (GSDA) models, which was determined to be optimal based on accuracy and group specificity index (GSI) results. This value was chosen as it provided a balanced trade-off between classification accuracy, group specificity, and model complexity.\n\nThe optimization schedule involved training each cross-validation strategy 1,000 times, generating 1,000 models per learning task. For the Human Connectome Project (HCP) dataset, which includes two scanning sessions per subject on different days, the session not used for training served as an additional test set. This approach ensured robust evaluation and validation of our models.\n\nModel files and additional data are hosted in Zenodo archives, accessible via the following DOIs: [10.5281/zenodo.10050233](https://doi.org/10.5281/zenodo.10050233) and [10.5281/zenodo.10050234](https://doi.org/10.5281/zenodo.10050234). The software code is available from the GitHub repository at [https://github.com/shuo-zhou/GSDA-Lateralization](https://github.com/shuo-zhou/GSDA-Lateralization). A version of record snapshot of the GitHub repository has been archived in the Software Heritage Library with the PID swh:1:snp:495f818df0e3c6d9ac1898b1cc14ec0ea396d98a.\n\nAll data and code are made available under open licenses to facilitate reproducibility and further research. The Zenodo archives and GitHub repository provide comprehensive access to the configurations, parameters, and models used in our study, ensuring transparency and reproducibility.",
  "model/interpretability": "The model employed in this study is not a black box but rather a transparent one, as it utilizes a linear classifier for both the first-order and second-order classifications. This transparency allows for the interpretation of the model weights, which indicate the significance or extent of differences between corresponding connections of the left and right brain hemispheres.\n\nIn the first-order classification, the model learns a prediction function that determines whether an unseen brain hemisphere is left or right based on a feature vector. The weights derived from this model can be interpreted as indicators of the significance of differences between the corresponding connections of the left and right brain hemispheres. This means that higher weights correspond to more significant differences, providing insights into which connections are most important for distinguishing between the hemispheres.\n\nThe second-order classification further enhances interpretability by identifying weights that show significant differences between male- and female-specific first-order models. In this stage, a linear classification model is trained on the first-order model weights to predict whether an unseen model is male- or female-specific. The features with larger weights in the second-order classification are considered to represent stronger sex differences. This process allows for the identification of sex-specific lateralized connections, providing a clear and interpretable way to understand how the model differentiates between male and female brain hemispheres.\n\nAdditionally, the use of a dual-classification framework with the GSDA algorithm ensures that the model is not only accurate but also interpretable. The first-order classification builds a group-specific prediction function, while the second-order classification identifies group-specific discriminant weights. This dual approach provides a comprehensive understanding of the model's decision-making process, making it transparent and interpretable.",
  "model/output": "The model primarily focuses on classification tasks. Specifically, it is designed for a dual-classification framework with two main objectives: learning group-specific models and identifying group-specific discriminant weights. The first-order classification involves predicting whether an unseen brain hemisphere is left or right, based on a feature vector. This is a binary classification problem where left hemispheres are labeled as 0 and right hemispheres as 1. The second-order classification aims to differentiate between male- and female-specific models by training a linear classifier on the first-order model weights. This process helps in identifying weights that show significant differences between the group-specific models.\n\nThe model uses a logistic regression classifier for both the first-order and second-order classifications. The first-order classification builds a prediction function to classify brain hemispheres, while the second-order classification identifies sex differences in the model weights. The performance of these classifications is evaluated using metrics such as test accuracy and the Group-Specific Index (GSI).\n\nThe model's performance is assessed through cross-validation strategies, which involve splitting the data into training and test sets multiple times to ensure robustness. For the Human Connectome Project (HCP) dataset, which includes two scanning sessions per subject, the session not used for training serves as an additional test set. This approach helps in validating the model's generalizability and stability.\n\nIn summary, the model is a classification model that uses logistic regression to achieve its objectives. It is designed to handle binary classification problems and is evaluated using standard metrics and cross-validation techniques.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the algorithms discussed in this publication is publicly available. It can be accessed via a GitHub repository. The repository contains the implementation of the Group-Specific Discriminant Analysis (GSDA) algorithm, which is central to the methods described. Additionally, a version of the repository has been archived in the Software Heritage Library, ensuring long-term preservation and accessibility. This archived version provides a snapshot of the code at a specific point in time, which can be useful for reproducibility and future reference. The software is released under the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction, provided that the original work is properly cited. This open-access approach aligns with the principles of transparency and reproducibility in scientific research.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach using cross-validation strategies and second-order classification settings. For the first-order classification, two cross-validation strategies were implemented. The first strategy involved randomly dividing subjects into two equal groups, with the training set consisting of left hemispheres from the first group and right hemispheres from the second group. The remaining hemispheres were used for testing, ensuring that no subject contributed both hemispheres to the training set. This strategy was repeated 1,000 times to generate 1,000 models per learning task. The second strategy held out 20% of subjects as an additional unseen test set, with the training examples obtained from the remaining 80% of subjects using the same strategy. For the HCP dataset, which includes two scanning sessions per subject on different days, the session not used for training served as an additional test set.\n\nIn the second-order classification setting, the first-order models learned for each task were used to perform second-order classification. This involved defining a classification problem of interest, such as comparing male-specific models with female-specific models. The models were then split into 80% training and 20% test sets by stratified random sampling. A standard logistic regression classifier was trained on the training set and evaluated on the test set. This process was repeated with different random seeds for 1,000 splits of training and test sets.\n\nThe evaluation also included comparing group-specific models with multivariate baselines, such as standard logistic regression trained on a mixture of male and female training data. The performance was assessed using metrics like average test accuracy and the gap between accuracy on target and nontarget test sets. The results highlighted the importance of cross-validation in validating the group specificity of statistical analysis results. Additionally, the evaluation considered the correlation between univariate and multivariate baselines, providing insights into the common patterns captured by the models. The sex-specific lateralized regions and connections were also analyzed across datasets, revealing shared connections in both male- and female-specific models.",
  "evaluation/measure": "In the evaluation of our models, we primarily focus on accuracy and the Group Specificity Index (GSI) as our key performance metrics. Accuracy is reported as the average test accuracy percentage, providing a straightforward measure of how often the model's predictions match the actual outcomes. This metric is crucial for understanding the model's overall performance in classifying left versus right brain hemispheres.\n\nThe GSI is a more nuanced metric that we introduced to quantify the specificity of our models to particular groups, such as male or female subjects. It is defined as GSI = 2BAT (BAT − 0.5 −| BANT − 0.5 |), where BAT and BANT represent the balanced accuracy of the target and nontarget groups, respectively. Balanced accuracy is used to mitigate the impact of imbalanced samples, ensuring that the metric is robust even when the number of samples in each class varies. The GSI measures both the absolute accuracy for the target group and the closeness of accuracy for the nontarget group to random chance, providing a comprehensive view of the model's performance and specificity.\n\nThese metrics are representative of the literature in the field of brain hemisphere classification and lateralization studies. Accuracy is a standard metric used across various machine learning applications, including neuroimaging. The GSI, while novel, is designed to address the specific need for evaluating group-specific models, which is a growing area of interest in neuroscience research. By reporting both accuracy and GSI, we aim to provide a clear and comprehensive evaluation of our models' performance, highlighting not only their predictive power but also their ability to capture group-specific patterns.\n\nAdditionally, we report the gap between the accuracy of the target and nontarget groups, which complements the GSI by providing a direct measure of the discrepancy in performance. This gap is particularly informative when evaluating the trade-off between classification accuracy and group specificity, especially as the hyperparameter λ is varied.\n\nIn summary, our performance measures include accuracy, GSI, and the accuracy gap, all of which are essential for evaluating the effectiveness and specificity of our models in classifying brain hemispheres and studying lateralization. These metrics are aligned with established practices in the field and provide a thorough assessment of our models' capabilities.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our methods with both publicly available techniques and simpler baselines to ensure robustness and validity. We employed benchmark datasets, specifically the Human Connectome Project (HCP) and the Brain Genomics Superstruct Project (GSP), to facilitate this comparison.\n\nFor the simpler baselines, we used standard logistic regression models. These models were trained on mixed male and female hemispheres, as well as on data from male and female subjects separately. The performance of these baselines was nearly identical across male and female test sets, indicating a lack of group specificity. This similarity in performance suggests that these models capture general patterns applicable to both sexes, rather than sex-specific characteristics.\n\nIn contrast, our group-specific models, particularly those using GSDA with a hyperparameter λ set to 5, demonstrated a significant difference in accuracy between target and nontarget test sets. This indicates a stronger specificity to sex, as reflected by our Group Specificity Index (GSI) results. The GSI steadily approaches zero without the grouping factor dependence regularization, but maintains around 0.4 when λ is set to 5 or higher. This value of λ was determined to be optimal based on both accuracy and GSI results, providing a good trade-off between classification accuracy, group specificity, and model complexity.\n\nAdditionally, we performed second-order classification to identify sex-specific lateralized connections. This involved training logistic regression models to distinguish between male- and female-specific models learned from the first-order classification. The test accuracy for second-order classification consistently achieved nearly 100% over 1,000 random splits, indicating that the sex differences in the first-order GSDA model weights are generalizable from the training set to the test set.\n\nOverall, our methods showed superior performance in capturing sex-specific patterns compared to simpler baselines and publicly available techniques. This comparison underscores the importance of our approach in understanding sex differences in brain lateralization.",
  "evaluation/confidence": "The evaluation of our models includes performance metrics with confidence intervals, providing a measure of the variability and reliability of the results. For instance, the average test accuracy for different classification methods is presented with standard deviations, indicating the confidence intervals around these metrics. This approach ensures that the reported accuracies are not just point estimates but are accompanied by a range within which the true accuracy is likely to fall.\n\nStatistical significance is a crucial aspect of our evaluation. We employ cross-validation strategies to assess the generalization performance of our models. For example, we repeat each cross-validation strategy 1,000 times, generating 1,000 models per learning task. This extensive cross-validation helps in establishing the statistical significance of our results. Additionally, we use metrics like the Generalization Specificity Index (GSI) to quantify the relative accuracy divergence between target and nontarget groups, further supporting the statistical rigor of our evaluations.\n\nThe performance gaps between target and nontarget groups, as seen in the results, are statistically significant. For instance, the group-specific models (GSDA with λ = 5) show a notable accuracy gap between male and female test sets, indicating strong group specificity. This gap is statistically significant and suggests that our models are effectively capturing sex-specific patterns.\n\nMoreover, the similarity in generalization errors across different groups for baseline models indicates that these models capture general patterns applicable to both males and females. This finding is statistically supported by the low GSI values observed for these baselines, reinforcing the conclusion that our group-specific models outperform the baselines in terms of capturing specific patterns.\n\nIn summary, the performance metrics are accompanied by confidence intervals, and the results are statistically significant. The extensive use of cross-validation and the application of metrics like GSI ensure that our claims of superiority over baselines are robust and reliable.",
  "evaluation/availability": "The raw evaluation files are not directly available. However, additional data files related to the evaluation are hosted in Zenodo archives. These can be accessed via the following DOIs: [10.5281/zenodo.10050233](https://doi.org/10.5281/zenodo.10050233) and [10.5281/zenodo.10050234](https://doi.org/10.5281/zenodo.10050234). These archives contain supplementary data that support the evaluation results presented in the publication.\n\nThe software code used for the evaluations is available on GitHub at [https://github.com/shuo-zhou/GSDA-Lateralization](https://github.com/shuo-zhou/GSDA-Lateralization). A version of record snapshot of the GitHub repository has been archived in the Software Heritage Library with the PID [swh:1:snp:495f818df0e3c6d9ac1898b1cc14ec0ea396d98a](https://archive.softwareheritage.org/swh:1:snp:495f818df0e3c6d9ac1898b1cc14ec0ea396d98a).\n\nThe publication is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. This license ensures that the data and methods used in the evaluation are accessible and can be utilized by other researchers for further studies or validations."
}