{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- M.Y. who conceived the problem and designed the study.\n- Y.Y. who performed bioinformatics analysis and wrote the manuscript.\n- Q.S. who performed bioinformatics analysis and wrote the manuscript.\n- C.X. who performed algorithm design and deep learning experiments and wrote the manuscript.",
  "publication/journal": "GigaScience",
  "publication/year": "2025",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Cross-modal contrastive learning\n- Differential expression analysis\n- Gene ontology enrichment\n- Pseudotime inference\n- Chromatin accessibility\n- Single-cell RNA sequencing\n- Single-cell ATAC sequencing\n- Regulatory network analysis\n- Motif analysis\n- Bioinformatics\n- Machine learning\n- Deep learning\n- Data integration\n- Multimodal data analysis\n- Gene expression patterns",
  "dataset/provenance": "The datasets utilized in this study are publicly accessible, ensuring reproducibility and accessibility for the scientific community. The scRNA-seq and scATAC-seq data for peripheral blood mononuclear cells (PBMC) were obtained from 10x Genomics. This dataset includes 11,909 cells and has been used extensively in the community for various single-cell multiomics studies.\n\nAnother key dataset is the SHARE-seq dataset, which includes data from mouse skin in the late anagen stage. This dataset, comprising 32,231 cells, can be accessed via the NCBI Gene Expression Omnibus (GEO) under the accession number GSE140203.\n\nThe NeurIPS dataset, which includes data from human bone marrow, is also publicly available on GEO under the accession number GSE194122. This dataset has been used in previous competitions and studies to benchmark single-cell multiomics integration methods.\n\nAdditionally, the Greenleaf 2021 dataset, derived from the human brain cortex, is provided through GEO under the accession number GSE162170. This dataset has been utilized in various studies focusing on brain development and disease.\n\nAll datasets utilized in this study are also available via Figshare, including the Attune 10x multiome dataset and the SHARE-seq TAC dataset. These datasets can be accessed through their respective DOIs.\n\nFurthermore, a complete list of all datasets and additional information can be found in Supplementary Table S1. Additional supporting data are available via the GigaScience database, GigaDB. The DOME-ML (Data, Optimization, Model, and Evaluation in Machine Learning) annotations are available via the DOME registry under the accession q1loj0zi07. These resources provide comprehensive access to the data and methodologies used in this study, facilitating further research and validation by the scientific community.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "All datasets utilized in this study are publicly accessible. The scRNA-seq and scATAC-seq data for PBMC are available from 10x Genomics. The SHARE-seq dataset, which includes data from mouse skin in the late anagen stage, can be accessed via NCBI GEO (accession GSE140203). The NeurIPS dataset, comprising data from human bone marrow, is publicly available on GEO (accession GSE194122). The Greenleaf 2021 dataset, derived from human brain cortex, is provided through GEO (accession GSE162170). Data utilized in this study are also available via Figshare (Attune 10x multiome dataset and SHARE-seq TAC dataset). A complete list of all datasets and additional information can be found in Supplementary Table S1. Additional supporting data are available via the GigaScience database, GigaDB. DOME-ML (Data, Optimization, Model and Evaluation in Machine Learning) annotations are available via the DOME registry (accession q1loj0zi07). The data is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages a transformer-based architecture, which is a well-established class of machine-learning algorithms known for their effectiveness in handling sequential and structured data. The transformer model used here is not entirely new but has been adapted and fine-tuned specifically for our multimodal integration tasks.\n\nThe decision to use a transformer was driven by its ability to capture complex regulatory interactions between different layers of genetic information. The cross-attention mechanism within the transformer is particularly adept at revealing these interactions, making it an ideal choice for our objectives.\n\nThe reason this work was published in a scientific journal rather than a machine-learning journal is that the primary focus of our research is on biological applications and the integration of multimodal data in genomics. While the transformer architecture is a key component, the innovation lies in its application to biological data and the specific adaptations made to enhance its performance in this context.\n\nThe optimization process involves fine-tuning the pretrained model using a multilayer perceptron (MLP) for modality prediction tasks. The learning rate for contrastive pretraining varies from 1 × 10−4 to 1 × 10−6, using the Adam optimizer. The model is trained for 20 epochs for contrastive pretraining, 5 epochs for the transformer, and 40 epochs for the modality prediction network. The temperature coefficient in the NT-Xent loss is set to 0.1, with a mini-batch size of 32 and an embedding dimension of 128.\n\nIn summary, while the transformer is a well-known machine-learning algorithm, its application and fine-tuning for multimodal genomic data integration represent a significant contribution to the field of bioinformatics.",
  "optimization/meta": "The meta-predictor in our study leverages a modality prediction network that is fine-tuned on a pretrained model. This network is designed to predict RNA expression levels using a multilayer perceptron (MLP) regression model. The input to this network is the embedding from the ATAC modality, denoted as ZATAC. The network has a single hidden layer with 1,000 units and an output layer with units equal to the number of genes, G. The output of the network is the predicted gene counts, Xpred_counts.\n\nThe training process for the modality prediction network involves using a mean squared error (MSE) loss function, which measures the difference between the predicted gene counts and the actual gene counts. The learning rate for this network varies from 1 × 10−4 to 1 × 10−6 using the Adam optimizer, and it is trained for 40 epochs. The temperature coefficient in the NT-Xent loss is set to 0.1, the mini-batch size is 32, and the dimension of the embedding is 128.\n\nThe meta-predictor does not directly use data from other machine-learning algorithms as input. Instead, it relies on the embeddings generated by the pretrained model, which has been trained using cross-modal contrastive learning. This approach ensures that the training data for the modality prediction network is independent of the data used to train the pretrained model. The embeddings capture the regulatory interactions between genes and peaks, which are then used to predict RNA expression levels.\n\nThe overall architecture of the meta-predictor is designed to integrate multimodal data effectively. The use of a pretrained model followed by fine-tuning with an MLP regression model allows for the capture of complex regulatory interactions and the accurate prediction of RNA expression levels. The independent training of the pretrained model and the modality prediction network ensures that the meta-predictor can generalize well to new data.",
  "optimization/encoding": "The data encoding process for the machine-learning algorithm involved several key steps. Initially, expression and accessibility matrices from matched multimodal single-cell RNA sequencing (scRNA-seq) and single-cell ATAC sequencing (scATAC-seq) data were used as input. For scRNA-seq data, genes expressed in fewer than 5% of cells were filtered out. Each cell count was normalized to 10,000 read counts before applying a log-arithm transformation. Additionally, sex chromosome genes were removed, and 2,000 highly variable genes (HVGs) were selected to balance performance, computational cost, and model stability. For scATAC-seq data, peaks accessed in fewer than 5% of cells were filtered out, and peaks from sex chromosomes were also removed.\n\nThe normalized expression and accessibility matrices were then encoded in the TensorFlow Record (TF-record) format. The scRNA-seq data were encapsulated in one TF-record file, with fields for \"gene index\" and \"gene count,\" while the scATAC-seq data were encapsulated in another file, with fields for \"peak index\" and \"peak count.\" This encoding scheme facilitated the efficient processing and integration of multimodal data within the machine-learning framework.",
  "optimization/parameters": "In the optimization process of our model, several input parameters play crucial roles. The model utilizes a cross-attention weight matrix with dimensions defined by the product of the number of genes (G) and the number of peaks (P). This matrix is derived from the dot product of two attention weight vectors: one for RNA with dimensions N*(P+1) and another for ATAC with dimensions N*(G+1). Here, N represents the number of cells.\n\nThe selection of the number of genes and peaks is a critical aspect of our model's performance. Through extensive experimentation, we determined that using 2,000 highly variable genes (HVGs) provides a reasonable compromise between computational efficiency and model performance. This choice was validated through benchmarks that assessed the integration performance under different gene and peak settings. The size of the dot indicates the number of peaks, and the color indicates the number of genes in these experiments.\n\nAdditionally, the model's architecture includes a modality prediction network fine-tuned on a pretrained model. This network uses a multilayer perceptron with 1,000 hidden layer units and an output layer with G units, corresponding to the number of genes. The input to this network is the embedding from the ATAC modality, and the output is the predicted gene counts.\n\nHyperparameter tuning was conducted to optimize the learning rate, which varied from 1×10^-4 to 1×10^-6 using the Adam optimizer. The model was trained for different epochs depending on the task: 20 epochs for contrastive pretraining, 5 epochs for the transformer, and 40 epochs for the modality prediction network. The temperature coefficient in the NT-Xent loss was set to 0.1, the mini-batch size to 32, and the dimension of the embedding to 128.\n\nThese parameters were carefully selected and tuned to ensure the model's robustness and efficiency in integrating multimodal data and predicting gene expression levels.",
  "optimization/features": "In our study, the input features for the modality prediction network are derived from the ZATAC student embedding, which has a dimension of 128. This embedding is used as the input to a multilayer perceptron with 1,000 hidden layer units. The number of units in the last layer corresponds to the number of genes, denoted as G.\n\nFeature selection was performed to optimize the integration process. Specifically, we evaluated the integration performance under different numbers of gene and peak settings. The size of the dots in the relevant figures indicates the number of peaks, while the color represents the number of genes. This approach ensures that the most relevant features are used, enhancing the model's performance.\n\nThe feature selection process was conducted using the training set only, adhering to best practices to prevent data leakage and ensure the robustness of our results. This meticulous approach to feature selection and optimization contributes to the reliability and effectiveness of our modality prediction network.",
  "optimization/fitting": "In our study, we employed a multilayer perceptron (MLP) for the modality prediction task, which is a relatively simple regression model. The input to this network is the embedding from the ATAC modality, and it consists of 1,000 hidden layer units. The output layer has a number of units equal to the number of genes, predicting gene counts. Given the complexity of the biological data and the number of genes involved, the number of parameters in our model is indeed large compared to the number of training points.\n\nTo address the risk of overfitting, we implemented several strategies. Firstly, we utilized a pretrained model, Attune, which provides a robust starting point for our MLP. This pretraining helps in capturing relevant features from the data, reducing the likelihood of overfitting to the training data. Secondly, we performed hyperparameter tuning, adjusting the learning rate and other parameters to find an optimal balance. The learning rate varied from 1 × 10−4 to 1 × 10−6 using the Adam optimizer, and we trained the model for 40 epochs. Additionally, we used a mini-batch size of 32 and an embedding dimension of 128, which helps in generalizing the model to unseen data.\n\nTo further mitigate overfitting, we conducted comparative experiments and ablation studies. These studies helped us understand the impact of different components of our model and ensured that the improvements in performance were not due to overfitting. We also evaluated our model using various metrics, including mean average precision (MAP), cell-type ASW, neighbor consistency (NC), Seurat alignment score (SAS), Batch ASW, graph connectivity (GC), and FOSCTTM. These metrics provided a comprehensive assessment of our model's performance and helped in identifying any signs of overfitting.\n\nRegarding underfitting, we ensured that our model had sufficient capacity to learn the underlying patterns in the data. The use of a pretrained model and a sufficiently complex MLP architecture helped in capturing the intricate relationships between the modalities. Moreover, the extensive training process, with 40 epochs and careful hyperparameter tuning, allowed the model to learn effectively from the data. The comparative experiments and ablation studies also provided insights into the model's capacity and helped in ruling out underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key approach was the use of cross-modal contrastive learning, which helps the model to learn more generalized features by contrasting different modalities. This method encourages the model to focus on the most relevant features that are consistent across modalities, thereby reducing the risk of overfitting to noise or modality-specific artifacts.\n\nAdditionally, we utilized dropout layers within our multilayer perceptron (MLP) for the modality prediction network. Dropout is a regularization technique that randomly sets a fraction of input units to zero at each update during training time, which helps prevent overfitting by ensuring that the model does not rely too heavily on any single neuron.\n\nWe also conducted hyperparameter tuning to optimize the learning rate and other parameters. For instance, the learning rate in contrastive pretraining varied from 1 × 10−4 to 1 × 10−6 using the Adam optimizer. This range was chosen to find an optimal balance between convergence speed and the prevention of overfitting.\n\nFurthermore, we performed ablation studies to evaluate the impact of different components of our model. These studies helped us understand which parts of the model were crucial for performance and which could be simplified or removed to prevent overfitting. For example, we compared different configurations of the cross-modal contrastive learning module and found that the design involving asymmetric teacher-student networks yielded the best results.\n\nOverall, these regularization techniques and careful tuning of hyperparameters contributed to the robustness and generalizability of our models, ensuring that they performed well on both seen and unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule are reported in the publication. The learning rate for contrastive pretraining ranges from 1 × 10−4 to 1 × 10−6 using the Adam optimizer, with training durations specified for different components: 20 epochs for contrastive pretraining, 5 epochs for the transformer, and 40 epochs for the modality prediction network. The temperature coefficient in NT-Xent loss is set to 0.1, the mini-batch size is 32, and the dimension of the embedding is 128.\n\nThe model files and optimization parameters are not explicitly detailed in the main text, but supplementary materials provide additional comparative experiments and ablation studies. These details can be found in Supplementary Tables S5, S6, S10, S11, and S13, as well as in figures such as Figure 2 and Figure 3. These supplementary materials offer insights into the performance and configuration of different models and settings.\n\nRegarding availability and licensing, the datasets used in this study are publicly accessible. The scRNA-seq and scATAC-seq data for PBMC are available from 10x Genomics. The SHARE-seq dataset, which includes data from mouse skin in the late anagen stage, can be accessed via NCBI GEO (accession GSE140203). The NeurIPS dataset, comprising data from human bone marrow, is publicly available on GEO (accession GSE194122). The Greenleaf 2021 dataset, derived from human brain cortex, is provided through GEO (accession GSE162170). However, specific details about the licensing of the model files and optimization parameters are not provided in the text.",
  "model/interpretability": "The model, Attune, leverages a transformer-based architecture, which inherently provides some level of interpretability due to its attention mechanisms. Unlike black-box models, transformers allow for the examination of attention weights, which indicate the importance of different input features when making predictions. This transparency is particularly useful in understanding regulatory interactions between genes and peaks.\n\nFor instance, the model utilizes attention weights to quantify associations between genes and peaks. By focusing on gene–peak pairs with the highest attention weights, it is possible to identify key regulatory events. In our study, we selected gene–peak pairs with the top 10% of attention weights, resulting in a subset of 8,744 gene–peak pairs. This approach helps in pinpointing dense peak-associated genes (DPAGs), which are genes linked to at least 10 peaks. These DPAGs and their associated peaks are likely involved in crucial regulatory processes.\n\nFurthermore, the model's ability to capture promoter-interacting regions effectively is demonstrated through the use of a Promoter capture Hi-C (PCHi-C) dataset. The attention mechanism in the transformer model, when fine-tuned with Attune’s pretrained model, outperforms other methods in regulatory prediction. This indicates that the model can reveal regulatory interactions by highlighting the relevant regions in the genome.\n\nThe interpretability of the model is also enhanced by the use of global cross-attention weights. These weights contain information from two global CLS tokens’ attention weights, which can be used to define a global attention weight matrix. This matrix provides a comprehensive view of the interactions between different modalities, further aiding in the interpretation of the model's predictions.\n\nIn summary, Attune is not a black-box model. Its transformer-based architecture and the use of attention mechanisms provide a transparent way to interpret the model's decisions. By examining attention weights, it is possible to gain insights into regulatory interactions and identify key genes and peaks involved in these processes.",
  "model/output": "The model encompasses both classification and regression tasks. For classification, the model identifies whether a given pair of gene and peak is positive or negative. This is achieved by feeding gene and peak hidden representations into a transformer, which then uses a classifier on top of the CLS token's embedding to predict a binary label. The probability of prediction is denoted as pmatch.\n\nFor regression, the model predicts RNA expression levels. This is done using a modality prediction network, which is fine-tuned on the pretrained model. The network employs a multilayer perceptron with a single hidden layer containing 1,000 units. The input to this network is the student embedding from the ATAC modality, and the output is the predicted gene counts. The loss function for this regression task is defined as the mean squared error between the true gene counts and the predicted gene counts.\n\nThe model's training involves different epochs for various components. The transformer trains for 5 epochs, while the modality prediction network trains for 40 epochs. The learning rate for contrastive pretraining varies from 1 × 10−4 to 1 × 10−6 using the Adam optimizer. The temperature coefficient in the NT-Xent loss is set to 0.1, and the mini-batch size is 32, with an embedding dimension of 128.",
  "model/duration": "The execution time for the model varied depending on the specific task and dataset. For contrastive pretraining, the model was trained for 20 epochs using a learning rate ranging from 1 × 10−4 to 1 × 10−6 with the Adam optimizer. The transformer component was trained for 5 epochs, while the modality prediction network underwent training for 40 epochs. These training durations were chosen to balance performance and computational efficiency. The mini-batch size was set to 32, and the dimension of the embedding was 128, which also influenced the overall execution time. Comparative experiments and detailed performance metrics are provided in Supplementary Tables S5 and S6. The model's architecture, including the use of teacher-student networks and cross-modal contrastive learning, was designed to handle large-scale datasets efficiently, ensuring that the execution time remained manageable even for complex tasks.",
  "model/availability": "The source code for the project, named Attune, is publicly available. It can be accessed via the project's homepage on GitHub. The project is platform-independent and is written in Python, requiring Python 3.6 or higher and TensorFlow 2.5.0 to run. The software is licensed under the GPL-3.0 License, which permits free use, modification, and distribution under certain conditions. Additionally, an archival copy of the code is available via Software Heritage. The project also has a bio.tools ID, attune, for easier identification and access.",
  "evaluation/method": "The evaluation of our method, Attune, involved a comprehensive assessment using various metrics and datasets to ensure its robustness and effectiveness in integrating multimodal data and performing cross-modal predictions.\n\nWe conducted comparative experiments to demonstrate the benefits of fine-tuning Attune’s pretrained model using a multilayer perceptron (MLP). This included comparing an MLP network with pretraining, an MLP network without pretraining (de novo training), and classical regression methods such as LASSO. Additionally, we performed an ablation study to understand the impact of Attune’s structure on cross-modal prediction performance.\n\nSeveral metrics were utilized to evaluate the integration performance, including mean average precision (MAP), cell-type average silhouette width (ASW), neighbor consistency (NC), Seurat alignment score (SAS), batch ASW, graph connectivity (GC), biology conservation, omics mixing, overall integration score, and fraction of samples closer than the true match (FOSCTTM). These metrics provided a thorough assessment of the congruity between cell types, the preservation of intercellular neighbors, the alignment of modalities, and the overall integration quality.\n\nThe evaluation also involved benchmarking Attune against other methods using datasets such as the 10x Multiome dataset and the SHARE-seq dataset. We assessed the biology conservation score versus omics integration score, overall integration score, and FOSCTTM. The results were visualized using UMAP plots to show the cell embeddings aligned with different integration methods.\n\nFurthermore, we conducted an ablation study on the cross-modal contrastive learning module to establish the intrinsic soundness of our module design. This involved comparing different designs of teacher-student networks and their impact on multimodal integration performance.\n\nIn cross-modal prediction, our objective was to predict all feature values for each cell in scRNA-seq using scATAC-seq. We compared Attune’s performance against state-of-the-art methods using metrics such as gene-wise Pearson correlation coefficient, gene-wise Spearman correlation coefficient, and root mean square error (RMSE). The results highlighted Attune’s superior ability to capture regulatory interactions and achieve accurate predictions.\n\nOverall, the evaluation of Attune demonstrated its effectiveness in integrating multimodal data and performing cross-modal predictions, showcasing its potential for downstream biological applications.",
  "evaluation/measure": "In the evaluation of our proposed solution, we employ a comprehensive array of metrics to assess both integration and modality prediction performance. For integration, we utilize metrics such as mean average precision (MAP), cell-type average silhouette width (ASW), neighbor consistency (NC), Seurat alignment score (SAS), batch ASW, graph connectivity (GC), biology conservation, omics mixing, overall integration score, and FOSCTTM. These metrics collectively provide a robust evaluation of the integration quality across different modalities.\n\nMAP measures the congruity between cell types in neighboring cells, quantifying the accuracy of clustering outcomes with respect to cell-type assignments. Cell-type ASW assesses the silhouette of cell-type labels, scaled between 0 and 1, while batch ASW evaluates the integration among multimodalities by computing cell modality labels, also scaled between 0 and 1. NC measures the degree of intercellular neighbor retention after integrating multimodal data, ranging from 0 to 1, where higher values indicate better preservation. SAS calculates the alignment score to assess how well two or more modalities have been aligned, with values ranging from 0 to 1, where higher values indicate better integration. GC evaluates the proximity of cells with the same identity across different modalities in the embedding, ranging from 0 to 1, with higher values indicating better integration. FOSCTTM measures the accuracy of modal alignment at the single-cell level in paired cells, with a range from 0 to 1, where lower values indicate higher accuracy.\n\nBiology conservation is evaluated through MAP, cell-type ASW, and NC, which collectively assess the biological conservation of integration. These metrics are min-max scaled, and their average is calculated as a single metric for biological conservation. Omics mixing is evaluated using SAS, batch ASW, and GC, which collectively assess the mixing performance of multimodalities. These metrics are also min-max scaled, and their average is calculated as a single metric for omics mixing. The overall integration score is computed as an overall weighted average of omics mixing and biology conservation scores.\n\nFor modality prediction, we report metrics such as the root mean square error (RMSE), gene-wise Pearson correlation coefficient, and gene-wise Spearman correlation coefficient. The RMSE appraises the precision of RNA expression prediction across individual cells, while the gene-wise Pearson or Spearman correlation coefficients gauge the average per-gene correlation.\n\nThese metrics are representative of the current literature and provide a thorough evaluation of both integration and modality prediction performance. The use of multiple metrics ensures that different aspects of the integration and prediction processes are assessed, providing a comprehensive understanding of the method's effectiveness.",
  "evaluation/comparison": "In the evaluation of our method, Attune, we conducted comprehensive benchmarks against several publicly available multimodal integration methods. These comparisons were performed on well-established benchmark datasets, specifically the 10x Multiome dataset and the SHARE-seq dataset. The 10x Multiome dataset consists of 11,909 cells, while the SHARE-seq dataset includes 32,231 cells. These datasets are widely recognized in the field for evaluating the performance of single-cell multi-omics integration methods.\n\nWe benchmarked Attune against methods such as GLUE, LIGER, Seurat, Cobolt, MinNet, scJoint, and MultiVI. The evaluation metrics used included biology conservation score, omics integration score, overall integration score, and the fraction of samples closer than the true match (FOSCTTM). These metrics provide a robust assessment of the integration performance, ensuring that the methods are evaluated on both biological fidelity and the mixing of different omics data.\n\nThe results, as depicted in Figure 2, show that Attune consistently outperforms other methods in terms of balancing omics mixing and biological conservation. For instance, on the 10x Multiome dataset, Attune achieves the highest overall integration score, indicating its superior performance in integrating multi-omics data while preserving biological meaning. Similarly, on the SHARE-seq dataset, Attune demonstrates the lowest FOSCTTM scores, suggesting effective modality matching at the single-cell level.\n\nIn addition to these comparisons, we also performed ablation studies to evaluate the impact of different settings and hyperparameters on Attune's performance. These studies included varying the number of genes and peaks, as well as different dimensional settings for feature embeddings. The results of these ablation studies further validate the robustness and effectiveness of Attune's integration approach.\n\nOverall, the comprehensive benchmarks and comparisons against publicly available methods, along with the ablation studies, provide strong evidence of Attune's superior performance in integrating single-cell RNA sequencing and single-cell ATAC sequencing data.",
  "evaluation/confidence": "In our evaluation, we have taken steps to ensure the reliability and statistical significance of our results. For various performance metrics, we have included confidence intervals to provide a range within which the true value is likely to fall. Specifically, error bars representing the 95% confidence interval are shown in figures comparing different methods and datasets. This approach allows for a clearer understanding of the variability and precision of our measurements.\n\nTo assess the statistical significance of our findings, we have conducted multiple replicates of our experiments. For instance, the integration and cross-modal prediction performance benchmarks were repeated five times with different random seeds. This repetition helps to ensure that our results are robust and not dependent on a particular random initialization.\n\nAdditionally, we have employed statistical tests such as the Wilcoxon rank-sum test to examine differences in performance metrics. These tests help to determine whether observed differences between methods are statistically significant, thereby strengthening our claims about the superiority of our approach over baselines and other methods.\n\nOverall, our evaluation includes confidence intervals and statistical tests to provide a comprehensive and statistically sound assessment of our method's performance.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being available. However, the datasets utilized in this study are publicly accessible. The scRNA-seq and scATAC-seq data for PBMC can be obtained from 10x Genomics. The SHARE-seq dataset, which includes data from mouse skin in the late anagen stage, is available via NCBI GEO under accession GSE140203. The NeurIPS dataset, comprising data from human bone marrow, is publicly available on GEO under accession GSE194122. The Greenleaf 2021 dataset, derived from human brain cortex, is provided through GEO under accession GSE162170. Additionally, data utilized in this study are available via Figshare, including the Attune 10x multiome dataset and the SHARE-seq TAC dataset. A complete list of all datasets and additional information can be found in Supplementary Table S1. Additional supporting data are available via the GigaScience database, GigaDB. DOME-ML annotations are available via the DOME registry under accession q1loj0zi07. The datasets are released under the terms of the Creative Commons Attribution License, which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited."
}