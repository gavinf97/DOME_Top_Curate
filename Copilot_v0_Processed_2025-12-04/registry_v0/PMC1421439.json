{
  "publication/title": "Machine learning approaches to supporting the identification of photoreceptor-enriched genes based on expression data",
  "publication/authors": "The authors who contributed to this article are:\n\n- **S. Blackshaw** - Co-authored a paper that motivated the study.\n- **S. Harpavat** - Contributed to the genomic analysis of mouse retinal development.\n- **J. Trimarchi** - Contributed to the genomic analysis of mouse retinal development.\n- **L. Cai** - Contributed to the genomic analysis of mouse retinal development.\n- **H. Huang** - Contributed to the genomic analysis of mouse retinal development.\n- **W. Kuo** - Contributed to the genomic analysis of mouse retinal development.\n- **K. Lee** - Contributed to the genomic analysis of mouse retinal development.\n- **R. Fraioli** - Contributed to the genomic analysis of mouse retinal development and the identification of candidate retinal disease genes.\n- **S. Cho** - Contributed to the genomic analysis of mouse retinal development.\n- **R. Yung** - Contributed to the genomic analysis of mouse retinal development.\n- **E. Asch** - Contributed to the genomic analysis of mouse retinal development.\n- **W. Wong** - Contributed to the genomic analysis of mouse retinal development.\n- **L. Ohno-Machado** - Contributed to the genomic analysis of mouse retinal development.\n- **G. Weber** - Contributed to the genomic analysis of mouse retinal development.\n- **C. L. Cepko** - Contributed to the genomic analysis of mouse retinal development and the identification of candidate retinal disease genes.\n- **Amit Arora** - Participated in discussions relevant to this paper.\n- **G. Clarke** - Contributed to the molecular basis of inherited photoreceptor degeneration.\n- **E. Heon** - Contributed to the molecular basis of inherited photoreceptor degeneration.\n- **R. R. McInnes** - Contributed to the molecular basis of inherited photoreceptor degeneration.\n- **S. Yoshida** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **A. J. Mears** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **J. S. Friedman** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **T. Carter** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **S. He** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **E. Oh** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **Y. Jing** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **R. Farjo** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **G. Fleury** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **C. Barlow** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **A. O. Hero** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **A. Swaroop** - Contributed to the expression profiling of the developing and mature Nrl-/- mouse retina.\n- **N. Katsanis** - Contributed to the computational/functional genomics approach for the enrichment of the retinal transcriptome.\n- **K. C. Worley** - Contributed to the computational/functional genomics approach for the enrichment of the retinal transcriptome.\n- **G. Gonzaléz** - Contributed to the computational/functional genomics approach for the enrichment of the retinal transcriptome.\n- **S. J. Ansley** - Contributed to the computational/functional genomics approach for the enrichment of the retinal transcriptome.\n- **J. R. Lupski** - Contributed to the computational/functional genomics approach for the enrichment of the retinal transcriptome.\n- **V. E. Velculescu** - Contributed to the serial analysis of gene expression.\n- **L. Zhang** - Contributed to the serial analysis of gene expression.\n- **B. Vogelstein** - Contributed to the serial analysis of gene expression.\n- **K. W. Kinzler** - Contributed to the serial analysis of gene expression.\n- **W. D. Patino** - Contributed to the technical considerations and applications of serial analysis of gene expression to cardiovascular biology.\n- **O. Y. Mian** - Contributed to the technical considerations and applications of serial analysis of gene expression to cardiovascular biology.\n- **P. M. Hwang** - Contributed to the technical considerations and applications of serial analysis of gene expression to cardiovascular biology.\n- **T. Furukawa** - Contributed to the comprehensive analysis of photoreceptor gene expression and the identification of candidate retinal disease genes.\n- **C. Blatt** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **P. Eversole-Cire** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **V. H. Cohn** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **S. Zollman** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **R. E. Fournier** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **L. T. Mohandas** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **M. Nesbitt** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **T. Lugo** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **D. T. Jones** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **R. R. Reed** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **L. P. Weiner** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **R. S. Sparkes** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **M. I. Simon** - Contributed to the chromosomal localization of genes encoding guanine nucleotide-binding protein subunits in mouse and human.\n- **A. Matsuda** - Contributed to the expression of macrophage migration inhibitory factor in rat retina and its immunohistochemical localization.\n- **Y. Tagawa** - Contributed to the expression of macrophage migration inhibitory factor in rat retina and its immunohistochemical localization.\n- **K. Yoshida** - Contributed to the expression of macrophage migration inhibitory factor in rat retina and its immunohistochemical localization.\n- **H. Matsuda** - Contributed to the expression of macrophage migration inhibitory factor in rat retina and its immunohistochemical localization.\n- **J. Nishihira** - Contributed to the expression of macrophage migration inhibitory factor in rat retina and its immunohistochemical localization.\n- **E. M. Morrow** - Contributed to the regulation of multiple functions in the developing neural retina in rodents.\n- **T. Furukawa** - Contributed to the regulation of multiple functions in the developing neural retina in rodents.\n- **J. E. Lee** - Contributed to the regulation of multiple functions in the developing neural retina in rodents.\n- **C. L. Cepko** - Contributed to the regulation of multiple functions in the developing neural retina in rodents.\n- **P. M. D'Cruz** - Contributed to the mutation of the receptor tyrosine kinase gene Mertk in the retinal dystrophic RCS rat.\n- **D. Yasumura** - Contributed to the mutation of the receptor tyrosine kinase gene Mertk in the retinal dystrophic RCS rat.\n- **J. Weir** - Contributed to the mutation of the receptor tyrosine kinase gene Mertk in the retinal dystrophic RCS rat.\n- **M. T. Matthes** - Contributed to the mutation of the receptor tyrosine kinase gene Mertk in the retinal dystrophic RCS rat.\n- **H. Abderrahim** - Contributed to the mutation of the receptor tyrosine kinase gene Mertk in the retinal dystrophic RCS rat.\n- **M. M. LaVail** - Contributed to the mutation of the receptor tyrosine kinase gene Mertk in the retinal dystrophic RCS rat.\n- **D. Vollrath** - Contributed to the mutation of the receptor tyrosine kinase gene Mertk in the retinal dystrophic RCS rat.\n- **R. Agrawal** - Proposed the Apriori algorithm, a well-known association rule learning algorithm.\n- **R. Skrikant** - Proposed the Apriori algorithm, a well-known association rule learning algorithm.\n- **G. Batista** - Studied the behavior of several methods for balancing machine learning training data.\n- **R. Prati** - Studied the behavior of several methods for balancing machine learning training data.\n- **M. Monard** - Studied the behavior of several methods for balancing machine learning training data.\n- **G. C. John** - Developed the K* algorithm, an instance-based learner using an entropic distance measure.\n- **E. T. Leonard** - Developed the K* algorithm, an instance-based learner using an entropic distance measure.\n- **N. Chawla** - Developed the SMOTE algorithm, a synthetic minority over-sampling technique.\n- **K. Bowyer** - Developed the SMOTE algorithm, a synthetic minority over-sampling technique.\n- **L. Hall** - Developed the SMOTE algorithm, a synthetic minority over-sampling technique.\n- **W. Kegelmeyer** - Developed the SMOTE algorithm, a synthetic minority over-sampling technique.\n- **J. Sander** - Developed a methodology for analyzing SAGE libraries for cancer profiling.\n- **R. Tng** - Developed a methodology for analyzing SAGE libraries for cancer profiling.\n- **M. Sleumer** - Developed a methodology for analyzing SAGE libraries for cancer profiling.\n- **M. Yuen** - Developed a methodology for analyzing SAGE libraries for cancer profiling.\n- **S. Jones** - Developed a methodology for analyzing SAGE libraries for cancer profiling.\n- **P. Buckhaults** - Identified tumor origin using a gene expression-based classification map.\n- **Z. Zhang** - Identified tumor origin using a gene expression-based classification map.\n- **Y. C. Chen** - Identified tumor origin using a gene expression-based classification map.\n- **T. L. Wang** - Identified tumor origin using a gene expression-based classification map.\n- **B. S. Croix** - Identified tumor origin using a gene expression-based classification map.\n- **S. Saha** - Identified tumor origin using a gene expression-based classification map.\n- **A. Bardelli** - Identified tumor origin using a gene expression-based classification map.\n- **P. J. Morin** - Identified tumor origin using a gene expression-based classification map.\n- **K. Polyak** - Identified tumor origin using a gene expression-based classification map.\n- **R. H. Hruban** - Identified tumor origin using a gene expression-based classification map.\n- **I. M. Shih** - Identified tumor origin using a gene expression-based classification map.\n- **C. Becquet** - Applied strong-association-rule mining for large-scale gene-expression data analysis.\n- **S. Blachon** - Applied strong-association-rule mining for large-scale gene-expression data analysis.\n- **B. Jeudy** - Applied strong-association-rule mining for large-scale gene-expression data analysis.\n- **J. Boulicaut** - Applied strong-association-rule mining for large-scale gene-expression data analysis.\n- **O. Gandrillon** - Applied strong-association-rule mining for large-scale gene-expression data analysis.\n- **A. I. Saeed** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **V. Sharov** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **J. White** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **J. Li** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **W. Liang** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **N. Bhagabati** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **J. Braisted** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **M. Klapa** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **T. Currier** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **M. Thiagarajan** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **A. Sturn** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **M. Snuffin** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **A. Rezantsev** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **D. Popov** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **A. Ryltsov** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **E. Kostukovich** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **I. Borisovsky** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **Z. Liu** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **A. Vinsavich** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **V. Trush** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **J. Quackenbush** - Developed TM4, a free, open-source system for microarray data management and analysis.\n- **I. H. Witten** - Authored the book \"Data Mining: Practical machine learning tools and techniques.\"\n- **E. Frank** - Authored the book \"Data Mining: Practical machine learning tools and techniques.\"\n- **G. Batista** - Balanced training data for automated annotation of keywords.\n- **A. Bazzan** - Balanced training data for automated annotation of keywords.\n- **M. C. Monard** - Balanced training data for automated annotation of keywords.\n- **G. E. A. P. A. Batista** - Studied learning with skewed class distribution.\n- **M. C. Monard** - Studied learning with skewed class distribution.",
  "publication/journal": "BMC Bioinformatics",
  "publication/year": "2006",
  "publication/doi": "10.1186/1471-2105-7-116",
  "publication/tags": "- Photoreceptor genes\n- SAGE libraries\n- Machine learning classifiers\n- Gene expression data\n- Functional gene classification\n- Computational biology\n- Bioinformatics\n- Data mining\n- Pattern recognition\n- Retinal development",
  "dataset/provenance": "The dataset used in our study was generated by the Cepko group at Harvard Medical School. It comprises a total of 14 murine Serial Analysis of Gene Expression (SAGE) libraries from various tissues and developmental stages. These libraries include samples from mouse NIH-3T3 fibroblast cells, adult hypothalamus, developing retina at 2-day intervals from embryonic day (E) 12.5 to postnatal day (P) 6.5, P10.5 retinas from the paired-homeodomain gene crx knockout mouse (crx-/-) and from wild-type (crx+/+) littermates, adult retina, and microdissected outer nuclear layer (ONL). Each tissue library contains between 50,000 and 60,000 tags, resulting in a comprehensive dataset that encompasses all genes expressed at moderate or high levels in photoreceptor cells.\n\nTo control for sampling variability and to facilitate expression examination via in situ hybridization (ISH), we focused on 1,118 tags whose abundance levels represent at least 0.01% of the total mRNA expression in the ONL library. This approach was previously used by Blackshaw et al. The distribution of these tags within the two retinal functional classes is detailed in our study.\n\nThe dataset has been used in previous research, notably by Blackshaw et al., who validated certain genes using ISH. Our study builds upon this work, utilizing the same dataset to explore functional predictions and classification methods in the retina. The dataset's size and diversity make it a valuable resource for studying gene expression and retinal development.",
  "dataset/splits": "In our study, we utilized a dataset comprising 14 murine SAGE libraries from various tissues and developmental stages. To control for sampling variability and facilitate expression examination via in situ hybridization, we focused on 1118 tags whose abundance levels represent at least 0.01% of the total mRNA expression in the outer nuclear layer (ONL) library.\n\nFor the classification tasks, we employed a 10-fold cross-validation procedure to estimate the true classification error. This method involves splitting the dataset into 10 subsets, or folds, of approximately equal size. The model is then trained on 9 of these folds and tested on the remaining fold. This process is repeated 10 times, with each fold serving as the test set once. This approach ensures that every data point is used for both training and testing, providing a robust estimate of the model's performance.\n\nAdditionally, we investigated the effect of class distribution on the classifier's performance by varying the class distribution using data over-sampling techniques. We created several resampled datasets with different ratios of PR-enriched to non-PR-enriched tags, specifically 1:1, 2:1, 3:1, and 4:1. In all resampled datasets, the number of PR-enriched tags was kept equal to 261, which is the number of PR-enriched tags in the original dataset. The number of non-PR-enriched tags was adjusted accordingly to achieve the desired ratios.\n\nThe original dataset consists of 261 PR-enriched tags and 63 non-PR-enriched tags. For the over-sampling method, the total number of SAGE tags analyzed was 522. For the under-sampling method, the total number of SAGE tags analyzed was 126, with 63 being PR-enriched.",
  "dataset/redundancy": "Not applicable",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm class used in our study is association rule learning. Specifically, we employed the Apriori algorithm, which is a well-known method in this class. The Apriori algorithm is not new; it was proposed by Agrawal and Srikant. It is capable of generating association rules from a dataset, provided that the rules meet user-specified support and confidence levels.\n\nThe reason this algorithm was not published in a machine-learning journal is that it is a established method that has been widely used and discussed in the literature since its introduction. Our focus was on applying this algorithm to extract association rules from SAGE data to study significant associations between functional classes and specific criteria.\n\nAdditionally, we implemented and assessed three supervised classification models using the Weka package: KStar, C4.5 decision tree, and multilayer perceptron (MLP) neural network. The KStar model, an instance-based classifier, performed significantly better than the more complex algorithms, such as neural networks. This performance is partly due to the limited amount of SAGE data available, which may not be sufficient for neural network-based algorithms to perform optimally.",
  "optimization/meta": "The study does not explicitly discuss a meta-predictor. However, it does involve the use of multiple machine learning algorithms to assess their performance in predicting functional associations from SAGE data. Three supervised classification models were implemented: KStar, C4.5 decision tree, and multilayer perceptron (MLP) neural network model. These models were evaluated using random over-sampling and under-sampling methods to address the imbalanced class distribution in the SAGE data.\n\nThe KStar model, an instance-based classifier, uses an entropy-based distance function to compute similarity between cases. The C4.5 decision tree algorithm involves parameters such as a confidence factor for pruning and a minimum number of instances per leaf. The MLP neural network model was tested with different architectures, and the results reported used a model with one hidden layer consisting of 8 neurons.\n\nThe performance of these classifiers was assessed using metrics such as precision, true negative rate, true positive rate, and ROC graphs. The results indicated that the KStar model performed significantly better than the more complex algorithms, such as neural networks. This performance difference may be attributed to the limited amount of SAGE data available, which neural network-based algorithms typically require in larger quantities and of higher quality.\n\nThe study also explored the use of re-sampling techniques to handle the imbalanced class distribution in the SAGE data. Over-sampling strategies were found to provide more accurate predictions than under-sampling methods. This finding suggests that under-sampling may discard potentially useful data, which could be relevant for classification.\n\nIn summary, while the study does not explicitly define a meta-predictor, it utilizes multiple machine learning algorithms to evaluate their effectiveness in predicting functional associations from SAGE data. The performance of these algorithms was compared using various metrics, and the KStar model was found to be the most effective among the tested methods.",
  "optimization/encoding": "In our study, the data encoding process was crucial for enabling the machine-learning algorithms to effectively analyze the SAGE data. We began by focusing on a subset of 1118 tags, which were selected based on their abundance levels representing at least 0.01% of the total mRNA expression in the outer nuclear layer (ONL) library. This threshold was chosen to control for sampling variability and to ensure that the tags were relevant for expression examination via in situ hybridization (ISH).\n\nTo encode the SAGE dataset, we utilized four specific criteria to identify photoreceptor-enriched (PR-enriched) tags. These criteria were designed to capture key features of the gene expression data:\n\n1. **Criterion 1**: Tags were present at a higher number in the ONL library compared to the whole adult retina library.\n2. **Criterion 2**: Tags were present at a higher number in the ONL library compared to the adult retina library.\n3. **Criterion 3**: Tags were present at a higher number in the ONL library compared to the adult retina library.\n4. **Criterion 4**: Tags were present at an equal or greater number in the ONL library compared to the whole adult retina library.\n\nThese criteria were applied to encode the dataset, allowing us to study significant associations between the two functional classes of genes (PR-enriched and non-PR-enriched) and these criteria. The Apriori algorithm, a well-known association rule learning algorithm, was then applied to extract association rules from the SAGE data. This algorithm generates association rules that have support and confidence levels greater than user-specified values, providing a robust basis for further analysis.\n\nThe encoded data was then used to train and evaluate various machine-learning classifiers. We employed random over-sampling and under-sampling techniques to address the imbalanced class distribution in the dataset. The results indicated that over-sampling strategies provided more accurate predictions than under-sampling methods, likely because under-sampling may discard potentially useful data. The KStar algorithm, a relatively simple instance-based model, outperformed more complex algorithms such as neural networks, demonstrating its effectiveness in handling the encoded data.",
  "optimization/parameters": "In our study, the selection of input parameters was crucial for the performance of our models. We implemented three different classification models using the Weka package: KStar, C4.5 decision tree, and a multilayer perceptron (MLP) neural network model. Each of these models has its own set of parameters.\n\nFor the KStar model, the primary parameter is the entropy-based distance function, which is used to compute the similarity between cases. This model does not require extensive parameter tuning, making it relatively straightforward to implement.\n\nThe C4.5 decision tree algorithm has several parameters, but one of the key parameters we adjusted was the minimum number of instances per leaf, which we set to 2. This parameter helps in controlling the complexity of the tree and preventing overfitting.\n\nThe MLP neural network model had more parameters to consider. We tested various architectures and found that a model with one hidden layer consisting of 8 neurons performed well. The learning epochs for the MLP were set to 500. This architecture was chosen based on empirical testing, where different configurations were evaluated, and the reported results showed consistent performance.\n\nIn summary, the number of parameters (p) varied depending on the model. The KStar model had fewer parameters, primarily relying on the entropy-based distance function. The C4.5 decision tree had a few key parameters, with the minimum number of instances per leaf being crucial. The MLP model had more parameters, including the number of neurons in the hidden layer and the number of learning epochs, which were selected based on extensive testing and validation.",
  "optimization/features": "The study utilized SAGE data, which was encoded using four specific criteria to identify photoreceptor-enriched (PR-enriched) and non-PR-enriched genes. These criteria were used to derive features from the SAGE tags. The exact number of features (f) used as input is not explicitly stated, but it is implied that the features are derived from the SAGE libraries and the tags' compliance with the four criteria.\n\nFeature selection was not explicitly mentioned as a separate step in the process. However, the use of the Apriori algorithm to extract association rules from the SAGE data suggests that some form of feature importance or relevance was considered. The criteria used for encoding the SAGE dataset were likely chosen based on their relevance to the classification task.\n\nThe process of encoding the SAGE dataset using the four criteria and applying the Apriori algorithm was performed on the entire dataset, not just the training set. This approach ensures that the features and association rules are consistent across all data, but it does not guarantee that the feature selection is independent of the test set. However, the use of 10-fold cross-validation in the classification models helps to mitigate the risk of overfitting and ensures that the models are evaluated on unseen data.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "The study did not explicitly focus on regularization methods as part of the optimization process. However, the use of cross-validation techniques, such as 10-fold cross-validation, inherently helps in preventing overfitting by ensuring that the model is evaluated on different subsets of the data. This approach helps in assessing the model's performance and generalizability.\n\nAdditionally, the comparison of different classifiers, including the KStar model, C4.5, and MLP, provides insights into which models are more robust and less prone to overfitting. The KStar model, in particular, was found to perform better than more complex models like neural networks, suggesting that simpler models might be less likely to overfit the data.\n\nThe use of re-sampling techniques, such as random over-sampling and under-sampling, also plays a role in mitigating overfitting. Over-sampling helps in balancing the class distribution, which can improve the model's ability to generalize to unseen data. The study found that over-sampling strategies provided more accurate predictions than under-sampling methods, further supporting the use of these techniques to enhance model performance and prevent overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail. For the KStar classifier, the global blend parameter was set to 5. For the C4.5 decision tree algorithm, the confidence factor for pruning was set to 0.25, and the minimum number of instances per leaf was set to 2. The multilayer perceptron (MLP) neural network model had a learning rate of 0.3 and a momentum of 0.2 applied to the weights during updating. The MLP model consisted of one hidden layer with 8 neurons, and the learning epochs were set to 500.\n\nThe specific configurations and learning parameters for these models can be found in the additional files provided with the publication. These files include detailed descriptions of the learning parameters and the results of the 10-fold cross-validation procedures used to estimate the true classification error. The additional files are available for further reference and can be accessed under the same licensing terms as the main publication.\n\nThe model files and optimization parameters are not explicitly mentioned as being available for download, but the detailed descriptions and results provided in the additional files should allow for replication of the experiments and further analysis. The publication and its supplementary materials are freely available, ensuring that the methods and findings can be reproduced and built upon by other researchers in the field.",
  "model/interpretability": "The models employed in this study include KStar, C4.5 decision tree, and multilayer perceptron (MLP) neural network. Among these, KStar and C4.5 decision tree are relatively transparent models, while the MLP neural network is more of a black-box model.\n\nKStar is an instance-based classifier that uses an entropy-based distance function to compute the similarity between cases. This approach provides a clear and interpretable way to understand how predictions are made, as it relies on the similarity to known instances. For example, if a new gene tag is being classified, KStar will compare it to the training data and determine its class based on the similarity to other tags. This makes it easier to trace back the reasoning behind a prediction.\n\nThe C4.5 decision tree is another transparent model. It builds a tree structure where each internal node represents a decision based on an attribute, and each leaf node represents a class label. This tree can be visualized and interpreted, showing the decision-making process step by step. For instance, a decision tree might first check if a tag meets a certain criterion, then based on that, check another criterion, and so on, until it reaches a leaf node with a class label. This makes it straightforward to understand how the model arrives at its predictions.\n\nIn contrast, the MLP neural network is more opaque. It consists of layers of neurons that process input data through weighted connections and activation functions. The relationships and decisions made within the network are not easily interpretable, as they are encoded in the weights and biases of the neurons. While the MLP can capture complex patterns in the data, it is challenging to explain why a particular prediction was made.\n\nIn summary, KStar and C4.5 decision tree offer clear interpretability, allowing for a straightforward understanding of the decision-making process. The MLP, however, is a black-box model where the internal workings are not easily interpretable.",
  "model/output": "The model implemented in this study is a classification model. Three different supervised classification methods were employed: KStar, C4.5 decision tree, and multilayer perceptron (MLP) neural network. These models were used to classify genes into two functional classes: PR-enriched and non-PR-enriched, based on patterns in the SAGE data.\n\nThe KStar model is an instance-based classifier that uses an entropy-based distance function to compute the similarity between cases. This approach is robust for handling different types of attributes, such as symbolic and real-valued data. The C4.5 decision tree algorithm was configured with a minimum number of instances per leaf set to 2. The MLP neural network model was tested with various architectures, and the representative results were obtained from a model with one hidden layer consisting of 8 neurons. The learning epochs for the MLP were set to 500.\n\nThe performance of these classifiers was evaluated using metrics such as precision, true negative rate (specificity), true positive rate (sensitivity), and Receiver Operating Characteristic (ROC) graphs. The ROC curves characterize the performance of classifiers across all possible predictive trade-offs between false negative and false positive rates. The closer the ROC curve follows the left-hand border and then the top border of the ROC space, the better the classifier performs.\n\nThe study also explored the effect of class distribution on the classifier by varying the class distribution using data oversampling techniques. A 10-fold cross-validation procedure was carried out to estimate the true classification error. The KStar classifier with a balanced class sample distribution achieved the best results. Additionally, a 100-run permutation test was implemented to assess the statistical significance of the computational approaches and their predictive performance. The results of the permutation test strongly indicated that the relationship between the data and the labels could be reliably learned by the proposed classifiers.\n\nIn summary, the model is a classification model designed to distinguish PR-enriched genes from non-PR-enriched genes based on SAGE data. The performance of the classifiers was thoroughly evaluated, and the results demonstrated the feasibility of using machine learning-based approaches for this classification task.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the PoissonC algorithm, which models SAGE data using Poisson statistics and implements Poisson-based distances into the k-means clustering procedure, is publicly available. This algorithm is part of an open-source implementation provided by the Institute for Genomic Research (TIGR).\n\nAdditionally, three different classification models—KStar, C4.5 decision tree, and multilayer perceptron (MLP) neural network—were implemented using the freely available Weka package. These models are also open-source and can be accessed through the Weka software, which is widely used for data mining and machine learning tasks.\n\nThe Weka package, along with the specific parameters and configurations used in our study, can be found in the additional files associated with this publication. These files provide detailed descriptions of the learning parameters and other relevant information necessary to replicate the experiments and results presented in this paper.\n\nFor those interested in using these tools, the Weka package is distributed under the GNU General Public License, which allows for free use, modification, and distribution of the software. This ensures that researchers and developers can access and utilize these algorithms without any restrictions, fostering further advancements in the field of bioinformatics and machine learning.",
  "evaluation/method": "To evaluate the performance of our computational approaches, we employed a 10-fold cross-validation procedure to estimate the true classification error rate. This method involved dividing the dataset into 10 subsets, training the classifier on 9 subsets, and testing it on the remaining subset. This process was repeated 10 times, with each subset serving as the test set once.\n\nAdditionally, we conducted 100-run permutation tests to assess the statistical validity of our classifiers. In these tests, the labels for each tag were randomly shuffled, and the classifiers were implemented on these permuted datasets. The prediction quality was then evaluated, and this process was repeated for multiple permuted datasets. By comparing the performance of the classifiers on the permuted datasets with their performance on the original dataset, we established the statistical significance of our results.\n\nTo address the class imbalance in our dataset, we studied two data re-sampling techniques: random under-sampling and random over-sampling. Random under-sampling involved randomly eliminating majority class tags to achieve a balanced dataset, while random over-sampling involved randomly replicating minority class samples until a balanced class distribution was reached. We found that classifiers built on data derived from over-sampling methods provided better results in terms of overall classification accuracy, sensitivity, and specificity.\n\nWe also evaluated the performance of our classifiers using metrics that are independent of class prior probabilities, such as the true negative rate (specificity), true positive rate (sensitivity), and Receiver Operating Characteristic (ROC) graphs. These metrics provided a more accurate assessment of classifier performance in the presence of class imbalances.\n\nFurthermore, we varied the class distribution using the data over-sampling technique to investigate its effect on the classifier. We found that a balanced class sample distribution achieved the best results. The corresponding ROC curves and the area under the ROC curve (AUC) were also calculated to provide a reliable and robust measure of classification performance.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the quality of our classifiers. These metrics include precision, true negative rate (specificity), true positive rate (sensitivity), and Receiver Operating Characteristic (ROC) graphs. Precision measures the proportion of true positive predictions among all positive predictions made by the classifier. Sensitivity, also known as the true positive rate, indicates the proportion of actual positives that are correctly identified by the classifier. Specificity, or the true negative rate, represents the proportion of actual negatives that are correctly identified. ROC graphs provide a visual representation of the classifier's performance across various threshold settings, plotting the true positive rate against the false positive rate. The area under the ROC curve (AUC) serves as a reliable measure of the classifier's overall performance, with higher AUC values indicating better classification performance. These metrics are widely used in the literature and provide a comprehensive evaluation of classifier performance, especially in the context of imbalanced datasets.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparative assessment of three supervised classification models to evaluate their performance in predicting functional associations from Serial Analysis of Gene Expression (SAGE) data. The models compared were KStar, C4.5 decision tree, and multilayer perceptron (MLP) neural network. These models were implemented using the freely available Weka package.\n\nTo ensure a robust evaluation, we employed various metrics, including precision, true negative rate (specificity), true positive rate (sensitivity), and Receiver Operating Characteristic (ROC) graphs. The ROC graphs were particularly useful in characterizing the performance of classifiers across all possible predictive trade-offs between false negative and false positive rates.\n\nWe also investigated the effect of class distribution on the classifiers by varying the class distribution using data over-sampling and under-sampling techniques. The results indicated that the classifiers built on data derived from over-sampling methods generally provided better results in terms of overall classification accuracy, sensitivity, and specificity. This suggests that random under-sampling strategies may discard potentially useful data, thereby affecting the performance of the classifiers.\n\nInterestingly, the relatively simple KStar algorithm, which is an instance-based classifier using an entropy-based distance function, outperformed more complex models such as the MLP. This performance difference can be attributed to the fact that neural network-based prediction models typically require larger amounts of high-quality training data, which may not have been fully available in our dataset.\n\nAdditionally, we performed a 100-run permutation test to assess the statistical significance of our computational approaches. The results of this test strongly indicated that the relationship between the data and the labels could be reliably learned by the proposed classifiers, as the permuted datasets consistently yielded significantly worse performance metrics.\n\nIn summary, our evaluation methods provided a thorough comparison of different classification models, highlighting the strengths and limitations of each approach in the context of SAGE data analysis. The use of over-sampling techniques and the performance of simpler models like KStar offer valuable insights for future studies in this area.",
  "evaluation/confidence": "To evaluate the confidence in our classification results, we employed several statistical methods. We conducted 100-run permutation tests, where the labels for each tag were randomly shuffled, and classifiers were implemented on these permuted datasets. By comparing the performance of these permuted datasets with the original dataset, we established the statistical significance of our results. For instance, when implementing the permutation test for the KStar model on a balanced dataset and 10-fold cross-validation, the random classifiers never performed better than the original prediction model. This indicates that the relationship between the data and the labels can be reliably learned by our proposed classifiers.\n\nAdditionally, we calculated the area under the ROC curve (AUC) for each classifier, which provides a reliable and robust measure of classification performance. A higher AUC value is associated with a classifier that is both effective and robust, presenting a better average classification performance across different prediction thresholds.\n\nWe also assessed the statistical significance of our computational approaches by comparing the average values of accuracy (Ac), sensitivity (Se), and specificity (Sp) for the permuted datasets with those of the original dataset. The results showed that the average values of Ac, Se, and Sp for the permuted datasets were significantly lower than those of the original dataset (p < 0.01). This further supports the claim that our classifiers are superior to random class assignments.\n\nIn summary, our evaluation methods, including permutation tests and AUC calculations, provide strong evidence of the statistical significance and robustness of our classification results.",
  "evaluation/availability": "The raw evaluation files are not directly available in the main text. However, additional files are referenced throughout the text, which likely contain the detailed evaluation data. These additional files are mentioned as \"Additional file 1\" and \"Additional file 2\". Unfortunately, the specific contents and accessibility of these additional files are not detailed in the provided text. Therefore, it is not clear whether these files are publicly released or under what license they might be available. For precise information on the availability and access to these evaluation files, one would need to refer to the supplementary materials or contact the authors directly."
}