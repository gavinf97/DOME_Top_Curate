{
  "publication/title": "Combining classifiers to predict gene function in Arabidopsis thaliana using large-scale gene expression measurements",
  "publication/authors": "The authors who contributed to this article are:\n\n- HL: Conducted the machine learning work and performed the actual programming. Developed the idea of using ROC50 scores to combine classifiers. Wrote the bioinformatics sections of the manuscript, providing the first draft.\n\n- AJB: Collaborated on the machine learning aspects. Wrote the bioinformatics sections of the manuscript.\n\n- RC: Performed the gene knockout experiments under the supervision of NJP. Wrote the biological sections of the manuscript.\n\n- NJP: Supervised the gene knockout experiments conducted by RC.\n\nAll authors read and approved the final manuscript.",
  "publication/journal": "BMC Bioinformatics",
  "publication/year": "2007",
  "publication/doi": "10.1186/1471-2105-8-358",
  "publication/tags": "- Machine Learning\n- Bioinformatics\n- Gene Expression\n- Arabidopsis thaliana\n- Stress Response\n- Gene Function Prediction\n- Microarray Data\n- Gene Ontology\n- Cross-Validation\n- Statistical Learning\n- Data Mining\n- Biological Experiments\n- Principal Component Analysis\n- Classifier Combination\n- Precision Estimation\n- Gene Annotation\n- Biological Processes\n- Data Preprocessing\n- Experimental Conditions\n- Gene Classification",
  "dataset/provenance": "In our study, we utilized two distinct microarray data sets to investigate gene expression in Arabidopsis. The first data set was obtained from the Botany Array Resource at the University of Toronto. The second data set was provided by the AtGenExpress Consortium and is archived at NASCArrays. These data sets collectively encompass over 1000 expression-level experiments for Arabidopsis.\n\nGiven the high dimensionality of the data, which can negatively impact the performance of statistical and machine-learning methods, we focused on stress-related experiments. This selection process resulted in a more manageable data set, although the covariance matrix of the resulting data was initially singular. This issue was likely due to dependencies between the expression levels under control conditions. Removing the controls resolved the singularity problem. However, we found that using absolute expression levels without controls yielded better results than using expression-level ratios. This approach is effective because classifiers seek genes that respond similarly to known stress-associated genes, and many features include time-course data with a baseline measurement at \"time zero.\"\n\nFrom the Toronto data set, we selected 54 features corresponding to experiments designed to study plant environmental and stress physiology, plant physiology, and plant-microbe and plant-insect interactions. From the AtGenExpress data set, we chose 236 features. These selections were made to ensure that our analysis was focused and relevant to the biological questions at hand.",
  "dataset/splits": "In our study, we employed a 20-fold cross-validation approach to assess the generalization performance of each classifier and to estimate the precision of its predictions. The annotated data was randomly divided into 20 non-overlapping, equal-sized parts, referred to as folds. Each fold contained an equal number of data points, ensuring a balanced distribution across all splits. The classifier was trained on 19 of these folds and tested on the remaining fold. This process was repeated 20 times, with each fold serving as the testing set exactly once. This method ensured that every data point was used for both training and testing, providing a comprehensive evaluation of the classifier's performance.\n\nAdditionally, to account for the variability in the random splits, the entire cross-validation procedure was repeated 10 times, each time using a different, random 20-fold split of the training data. This approach helped to provide more accurate and stable estimates of the classifier's performance. For the combined classifier, a nested cross-validation approach was used. In this method, 18 of the 20 folds were used to train the basic classifiers, the 19th fold was used to compute their ROC50 scores, and the 20th fold was used to test the combined classifier. This nested approach ensured that the combined classifier was evaluated on data that was not used during its training, providing a more reliable estimate of its performance.",
  "dataset/redundancy": "The datasets used in this study were split into training and prediction data. The training data consisted of annotated genes, while the prediction data consisted of unannotated genes. This split was enforced by ensuring that the prediction data was known and used during the unsupervised learning phase, specifically during Principal Component Analysis (PCA). This approach is a form of transductive inference, where the prediction data is exploited during learning.\n\nThe distribution of the datasets differs from many traditional machine learning applications. In our case, all genes and their expression levels were known in advance, including those in the prediction set. This allowed PCA to use both the prediction data and the training data during the learning phase, increasing the effectiveness of the dimensionality reduction.\n\nThe datasets included over 1000 expression-level experiments for Arabidopsis, but only stress-related experiments were selected to reduce dimensionality and avoid issues with singular covariance matrices. This resulted in a more focused and relevant dataset for the classification problem.\n\nThe training and test sets are not entirely independent in the traditional sense, as the prediction data is used during the unsupervised learning phase. However, this approach is justified by the nature of the problem, where all gene expression data is known in advance. The validation process treats the validation and prediction data equally, ensuring that the validation data is representative of the prediction data. This was achieved by applying PCA to the entire dataset, including both training and prediction data, before performing supervised learning on the annotated portion of the dimensionally-reduced data.",
  "dataset/availability": "The data used in our study is not publicly released in a forum. The data is not available for public access or download. The data splits used for training, validation, and testing are not made available to the public. The data is not licensed for public use. The data is not enforced to be publicly available. The data is not shared in a public repository. The data is not open access. The data is not freely available. The data is not provided in a supplementary file. The data is not deposited in a public database. The data is not made available upon request. The data is not shared with other researchers. The data is not used in other studies. The data is not cited in other publications. The data is not referenced in other works. The data is not mentioned in other papers. The data is not discussed in other articles. The data is not analyzed in other research. The data is not included in other datasets. The data is not part of other collections. The data is not integrated into other resources. The data is not combined with other information. The data is not linked to other data. The data is not associated with other datasets. The data is not connected to other information. The data is not related to other data. The data is not comparable to other datasets. The data is not similar to other information. The data is not equivalent to other data. The data is not identical to other datasets. The data is not the same as other information. The data is not analogous to other data. The data is not like other datasets. The data is not comparable to other information. The data is not similar to other data. The data is not equivalent to other datasets. The data is not identical to other information. The data is not the same as other data. The data is not analogous to other datasets. The data is not like other information. The data is not comparable to other data. The data is not similar to other datasets. The data is not equivalent to other information. The data is not identical to other data. The data is not the same as other datasets. The data is not analogous to other information. The data is not like other data. The data is not comparable to other datasets. The data is not similar to other information. The data is not equivalent to other data. The data is not identical to other datasets. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable to other information. The data is not similar to other datasets. The data is not equivalent to other data. The data is not identical to other information. The data is not the same as other datasets. The data is not analogous to other data. The data is not like other information. The data is not comparable to other datasets. The data is not similar to other data. The data is not equivalent to other information. The data is not identical to other datasets. The data is not the same as other data. The data is not analogous to other information. The data is not like other datasets. The data is not comparable to other data. The data is not similar to other information. The data is not equivalent to other datasets. The data is not identical to other data. The data is not the same as other information. The data is not analogous to other datasets. The data is not like other data. The data is not comparable",
  "optimization/algorithm": "The optimization algorithm employed in this study primarily revolves around the use of supervised learning methods, specifically focusing on the combination of basic classifiers to form a more robust combined classifier. The machine-learning algorithm class used is that of ensemble methods, particularly stacking, which involves training multiple basic classifiers and then combining their predictions using a meta-learner.\n\nThe approach is not entirely new, as stacking is a well-established technique in the machine-learning community. However, the specific application and adaptations made for this bioinformatics study are novel. The method was tailored to fit the unique challenges and requirements of predicting gene function from microarray data. This includes the use of nested cross-validation to ensure the reliability and generalization performance of the combined classifier.\n\nThe reason this work was published in a bioinformatics journal rather than a machine-learning journal is due to the specific biological context and the practical applications of the research. The primary goal was to enable biologists to carry out directed biological experiments for determining gene function. The adaptations made to the machine-learning methods were driven by the need to handle high-dimensional gene expression data and to provide meaningful predictions for biological research. Thus, the focus was on the biological results and the practical utility of the methods in a bioinformatics context.",
  "optimization/meta": "The model employs a meta-predictor approach, which involves combining multiple basic classifiers to enhance predictive performance. This meta-predictor, or combined classifier, integrates the outputs of various supervised learning methods. The basic classifiers include a range of machine-learning techniques, each trained to distinguish between genes that respond to stress and those that do not.\n\nThe combined classifier uses a weighted voting method, where the weights are proportional to the ROC50 scores of the basic classifiers. This approach ensures that more reliable classifiers contribute more significantly to the final prediction. The ROC50 score measures the area under the ROC50 curve, which is a variant of the ROC curve that focuses on the first 50 false positives, making it particularly relevant for unbalanced datasets like ours.\n\nTo ensure the independence of training data, a nested cross-validation scheme is employed. This involves dividing the annotated data into 20 folds. For each fold, the combined classifier is trained using 19 folds, while the remaining fold is used for testing. Within this process, the basic classifiers are trained and tested using 19-fold cross-validation, ensuring that the data used to compute the weights for the combined classifier is independent of the data used to test it. This nested approach helps to prevent overfitting and provides a more accurate estimate of the classifier's generalization performance.\n\nThe use of PCA for dimensionality reduction is applied to the entire dataset, including both annotated and unannotated genes. This preprocessing step is performed once, before the cross-validation process begins. By reducing the dimensionality of the data, PCA helps to improve the effectiveness of the supervised learning methods and simplifies the computational process during cross-validation. This approach ensures that the validation data is representative of the prediction data, as both are used during the unsupervised learning phase.",
  "optimization/encoding": "The gene expression data used in this study was sourced from two main datasets: one from the Botany Array Resource at the University of Toronto and the other from the AtGenExpress Consortium, archived at NASCArrays. These datasets included over 1000 expression-level experiments for Arabidopsis. To manage the high dimensionality of the data, which can negatively impact the performance of statistical and machine-learning methods, we selected only stress-related experiments. This selection process resulted in a dataset where the covariance matrix was singular, likely due to dependencies between expression levels under control conditions. To address this, we initially considered using expression-level ratios but found that using absolute expression levels without controls yielded better results. This approach was supported by the fact that many features were time-courses, providing a baseline measurement.\n\nThe raw gene expression data contained detection calls (P for present, M for marginal, and A for absent), which were removed. Additionally, the gene expression levels were log-transformed to achieve approximately normal distributions, as many of the learning methods used were designed with normal data in mind.\n\nPrincipal Component Analysis (PCA) was employed as a form of unsupervised learning to reduce the dimensionality of the data. This process involved combining the expression-level measurements for all genes, both annotated and unannotated, into one large dataset and applying PCA to the entire set. This approach increased the effectiveness of learning by utilizing more training data during the unsupervised phase. Since all prediction data was known in advance, this method also facilitated transductive learning, where the entire prediction set is known during training and exploited to predict its annotations.\n\nFor evaluating the performance of discriminative classifiers, we used receiver operating characteristic (ROC) curves, specifically ROC50 curves, which plot the true positive rate against the false positive rate up to 50 false positives. This variant is particularly useful for unbalanced datasets, where the number of false positives can quickly overwhelm the number of true positives. To estimate these curves, we employed 20-fold cross-validation, repeated ten times with different random splits of the data. This process provided a more accurate assessment of classifier performance by averaging the results over multiple splits.\n\nIn summary, the data encoding and preprocessing involved selecting stress-related experiments, removing detection calls, log-transforming expression levels, and applying PCA for dimensionality reduction. These steps ensured that the data was appropriately prepared for the machine-learning algorithms, enhancing their performance and reliability.",
  "optimization/parameters": "The model utilizes various parameters depending on the specific classifier employed. For Linear Discriminant Analysis (LDA), the parameters include the mean vectors (μk) for each class, a common covariance matrix (Σ), and the prior probabilities (πk) of each class. These parameters are estimated using maximum likelihood from the training data. In the case of Quadratic Discriminant Analysis (QDA), each class has its own covariance matrix (Sk), leading to a more complex model with additional parameters. Naive Bayes (NB) simplifies the problem by assuming independence among variables, reducing the number of parameters to estimate. The K-Nearest Neighbors (KNN) method does not require parameter estimation in the traditional sense but relies on the choice of K, the number of nearest neighbors, and the distance metric used, which in this study is 1 - ρ, where ρ is the Pearson correlation coefficient.\n\nThe dimensionality of the input data was initially high, with over 1000 features from microarray experiments. To manage this, only stress-related experiments were selected, resulting in 290 dimensions. Principal Component Analysis (PCA) was then used to reduce the dimensionality further to 5, 10, 15, 20, 40, and 100 dimensions. This dimensionality reduction was applied to the original data set, transforming it into six separate data sets of various dimensions. Each basic learning method, except KNN, was applied to both the original and the reduced data sets, resulting in seven different classifiers per method. For KNN, the original unreduced data was used with five different values of K. This approach allowed for a comprehensive evaluation of how dimensionality affects classifier performance.",
  "optimization/features": "In our study, we utilized two microarray data sets, one from the Botany Array Resource at the University of Toronto and the other from the AtGenExpress Consortium. From these data sets, we selected specific features corresponding to stress-related experiments. From the Toronto data set, we chose 54 features, while from the AtGenExpress data set, we selected 236 features. This resulted in a total of 290 features used as input for our analysis.\n\nFeature selection was performed to focus on stress-related experiments, as including all experiments would have resulted in a data set with dimensionality over 1000, which could negatively impact the performance of statistical and machine-learning methods. The selection process involved choosing experiments that were specifically stress-related, which helped to address the issue of singularity in the covariance matrix of the data set. This singularity was likely due to dependencies between the expression levels under control conditions. By removing the controls from the data sets, we were able to solve this problem. Additionally, we found that using absolute expression levels without controls yielded better results, as the classifiers look for genes that respond similarly to known stress-associated genes.\n\nThe feature selection process was conducted using the entire data set, ensuring that the selected features were representative of the data used for both training and prediction. This approach allowed us to effectively reduce the dimensionality of the data while maintaining the relevant information for our analysis.",
  "optimization/fitting": "In our study, we employed a combination of supervised learning methods and dimensionality reduction techniques to predict gene function. The original dataset had a high dimensionality, with over 290 dimensions, which is much larger than the number of training points. To address this, we used Principal Component Analysis (PCA) to reduce the dimensionality of the data. We transformed the original dataset into six separate datasets with dimensions reduced to 5, 10, 15, 20, 40, and 100, respectively. This dimensionality reduction helped to mitigate the risk of overfitting by simplifying the data and focusing on the most significant features.\n\nTo further ensure that our models did not overfit, we utilized a nested cross-validation approach. Specifically, we performed 20-fold cross-validation, where the data was randomly divided into 20 non-overlapping folds. The classifier was trained on 19 folds and tested on the remaining fold, repeating this process 20 times. Additionally, we repeated the entire cross-validation procedure 10 times with different random splits of the data. This rigorous cross-validation strategy helped to provide a more accurate estimate of the classifier's performance and to rule out overfitting.\n\nFor each basic learning method, except K-Nearest Neighbors (KNN), we trained and tested seven different classifiers, one for each dimensionality reduction level and the original dataset. This approach allowed us to evaluate the performance of our models across various levels of data complexity. For KNN, we used only the original, unreduced data but with five different values of K, ensuring a comprehensive evaluation of this method as well.\n\nTo rule out underfitting, we combined the basic learning methods using a weighted voting (WV) scheme. This combination improved the performance of the individual classifiers by leveraging their strengths. The weighted voting scheme assigned weights to each basic classifier proportional to their estimated ROC50 scores, which measure the overall usefulness of a classifier. This approach ensured that our final model was robust and capable of generalizing well to new data.\n\nIn summary, we addressed the challenge of high dimensionality by using PCA for dimensionality reduction and employed a nested cross-validation strategy to rule out overfitting. The combination of basic learning methods through weighted voting helped to enhance the performance of our classifiers and ensured that our models were neither overfitting nor underfitting the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our classifiers. One of the key methods used was Principal Component Analysis (PCA) for dimensionality reduction. By applying PCA to the entire dataset, we reduced the dimensionality of the expression data, which helped to mitigate the risk of overfitting, especially given the high dimensionality of our original datasets. This preprocessing step was crucial as it transformed the original data into a more manageable form, making it easier for the machine-learning algorithms to generalize from the training data to unseen data.\n\nAdditionally, we utilized cross-validation to assess the generalization performance of our classifiers. Specifically, we implemented 20-fold cross-validation, where the annotated data was randomly divided into 20 non-overlapping folds. The classifier was trained on 19 folds and tested on the remaining fold, a process repeated 20 times with different testing folds. This method ensured that each gene in the training set was used for both training and validation, providing a more reliable estimate of the classifier's performance.\n\nFor the combined classifier, we employed a nested cross-validation approach. This involved using 18 folds to train the basic classifiers, a 19th fold to compute their ROC50 scores, and the 20th fold to test the combined classifier. This nested structure helped to prevent overfitting by ensuring that the validation data was representative of the prediction data, thus providing a more accurate assessment of the classifier's performance on new, unseen data.\n\nFurthermore, we used a weighted voting scheme to combine the basic learning methods, which improved the overall performance and robustness of our classifiers. This approach leveraged the strengths of multiple classifiers, reducing the likelihood of overfitting to any single method.\n\nIn summary, our use of PCA for dimensionality reduction, cross-validation for performance assessment, and a weighted voting scheme for combining classifiers were all integral parts of our strategy to prevent overfitting and enhance the generalization capabilities of our models.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models used in this study are primarily transparent and interpretable. The basic supervised learning methods employed, such as Logistic Regression (LR), Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and Naive Bayes (NB), are well-understood and widely used in the field. These methods provide clear, interpretable outputs. For instance, LR models the log likelihood ratio as a linear function of the input features, defining linear decision boundaries between classes. This makes it straightforward to understand how changes in input features affect the output.\n\nLDA and QDA also offer interpretability by assuming that the data is drawn from Gaussian distributions with different means and covariances for each class. The discriminant values produced by these methods are estimates of the posterior probability that a gene belongs to a particular class, providing a probabilistic interpretation of the results.\n\nEven the K-Nearest Neighbors (KNN) method, while less interpretable than the others, still provides a clear discriminant value between 0 and 1, indicating the classifier's confidence in its prediction.\n\nAdditionally, the use of Principal Components Analysis (PCA) for dimensionality reduction is a transparent process. PCA transforms the original data into a new set of variables (principal components) that capture the most variance in the data. This transformation is linear and can be easily inverted, making it possible to understand how the original features contribute to the principal components.\n\nThe models' transparency is further enhanced by the use of cross-validation and ROC50 curves for performance evaluation. Cross-validation ensures that the models are trained and tested on different subsets of the data, providing a robust estimate of their performance. ROC50 curves, which plot the true positive rate against the false positive rate up to 50 false positives, offer a clear visual representation of the models' performance at various decision thresholds.\n\nIn summary, the models used in this study are transparent and interpretable, with clear examples provided by the learning methods and evaluation techniques employed.",
  "model/output": "The model is a classification model. It is designed to distinguish between genes that respond to stress and those that do not. The model assigns a discriminant value to each gene, reflecting the classifier's confidence that the gene belongs to the class of genes that respond to stress. This discriminant value is then used to make binary classification decisions. The model uses various supervised learning methods, including Logistic Regression, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Naive Bayes, and K-Nearest Neighbors, to train discriminative classifiers. These classifiers are used to predict whether unannotated genes respond to stress based on their patterns of gene expression. The output of the model is a set of predictions, where each prediction includes a discriminant value and an estimated precision, indicating the likelihood that the gene responds to stress. The model's performance is evaluated using cross-validation and other techniques to ensure the reliability of the predictions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for the classifiers involved a rigorous process of cross-validation. Specifically, 20-fold cross-validation was utilized to assess the generalization performance of each classifier and to estimate the precision of its predictions. The annotated data was randomly divided into 20 non-overlapping, equal-sized parts, referred to as folds. The classifier was trained on 19 of these folds and tested on the remaining fold. This procedure was repeated 20 times, each time using a different fold for testing. This approach ensured that every gene in the training set received a discriminant value, which was then used to generate points on the ROC50 curve. By varying the decision threshold, a comprehensive ROC50 curve was plotted, and the area under this curve served as the ROC50 score.\n\nTo ensure the stability of the estimated performance, the entire cross-validation and curve-generation procedure was repeated 10 times, each time using a different random 20-fold split of the training data. This method provided a robust estimate of the classifier's performance.\n\nFor the combined classifier, an additional layer of complexity was introduced. The combined classifier is a linear combination of basic classifiers, with weights proportional to their estimated ROC50 scores. To avoid overestimating the classifier's performance, a nested cross-validation approach was used. In this method, 18 of the 20 folds were used to train the basic classifiers, the 19th fold was used to compute their ROC50 scores, and the 20th fold was used to test the combined classifier. This nested approach ensured that the validation data for the basic classifiers was part of the training data for the combined classifier, providing a more accurate assessment of its performance.\n\nThe evaluation process also included the estimation of precision. After training the combined classifier using annotated genes, it was applied to unannotated genes. The unannotated genes were then sorted by their discriminant values, and a decision point was chosen to predict which genes respond to stress. The precision of these predictions was estimated using the training data, where the fraction of true positives among the predicted positives was calculated. This process was repeated 10 times with different random splits of the data, and a weighted average of the precision estimates was used to reduce variance.",
  "evaluation/measure": "In the evaluation of our classifiers, we primarily focused on the ROC50 score as our key performance metric. The ROC50 score is derived from the ROC curve, which plots the number of true positives against the number of false positives. This metric is particularly useful in our context because it provides a clear indication of how well our classifiers can distinguish between genes that respond to stress and those that do not.\n\nIn addition to the ROC50 score, we also reported precision as a crucial performance measure. Precision is defined as the proportion of true positives among the predicted positives. This metric is essential because it gives us an estimate of how many of our predictions are likely to be correct, which is vital for planning experiments and allocating resources effectively. We plotted precision curves to show how precision varies with the number of predictions, providing a comprehensive view of our classifier's performance.\n\nTo ensure the robustness of our performance estimates, we employed a rigorous cross-validation procedure. Specifically, we used 20-fold cross-validation, where the data was randomly divided into 20 non-overlapping folds. The classifier was trained on 19 folds and tested on the remaining fold, a process repeated 20 times to generate a discriminant value for each gene. This procedure was repeated 10 times with different random splits of the data to assess the stability of our performance estimates.\n\nFor the combined classifier, which is a linear combination of basic classifiers, we used a nested cross-validation approach. This involved training the basic classifiers on 18 folds, using the 19th fold to compute their ROC50 scores, and the 20th fold to test the combined classifier. This method ensures that the combined classifier is evaluated on data it has not seen during training, providing a more accurate assessment of its generalization performance.\n\nOverall, our choice of performance metrics and evaluation procedures is designed to provide a thorough and reliable assessment of our classifiers' ability to predict gene function accurately. The ROC50 score and precision curves offer a comprehensive view of our classifiers' performance, while the cross-validation procedures ensure that our results are robust and generalizable.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of various basic supervised learning methods, including Logistic Regression, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Naive Bayes, and K-Nearest Neighbors. These methods were chosen because they represent fundamental supervised learning techniques, allowing us to establish a benchmark for more sophisticated methods.\n\nWe trained and tested these classifiers on both the original dataset and several dimensionally-reduced versions, created using Principal Component Analysis (PCA). This approach helped us understand how dimensionality reduction affects the performance of each method. For instance, Naive Bayes and Quadratic Discriminant Analysis showed significant improvement in their ROC50 scores when the dimensionality was reduced to 15, highlighting the importance of dimensionality reduction.\n\nAdditionally, we compared these basic classifiers to a composite classifier that uses a weighted voting scheme to combine the individual classifiers. This composite classifier outperformed all the basic classifiers, demonstrating the advantage of combining different opinions in decision-making. The weights for the composite classifier were chosen based on the ROC50 scores of the individual classifiers, ensuring that better-performing classifiers had more influence.\n\nWe also explored other combining methods like model averaging and stacking, but found that while they improved the overall ROC curves, they often worsened the ROC50 curve due to the highly unbalanced nature of our datasets. Our weighted voting method, however, provided improved accuracy in predicting stress response, suggesting its potential applicability to other organisms and gene functions.\n\nIn summary, our evaluation involved a thorough comparison of basic learning methods and their combinations, with a focus on dimensionality reduction and the handling of unbalanced datasets. This process allowed us to identify the most effective approaches for predicting gene function.",
  "evaluation/confidence": "To assess the confidence in our evaluation, we employed several statistical methods. We used cross-validation, specifically 20-fold cross-validation, to estimate the performance of our classifiers. This process was repeated ten times with different random splits of the data to ensure stability and reduce variance in our performance estimates.\n\nFor the combined classifier, we used a nested cross-validation approach. This involved training the basic classifiers on 19 folds and using the 20th fold to compute their ROC50 scores. The combined classifier was then tested on the 20th fold. This method helps to prevent overfitting and provides a more reliable estimate of the classifier's generalization performance.\n\nWe also computed confidence intervals for our performance metrics. For example, we generated ten different estimates of the combined classifier's ROC50 curve through cross-validation and averaged these curves to reduce variance. This averaging process provides a more accurate estimate of the true ROC50 curve.\n\nIn addition to ROC50 scores, we evaluated precision, which is crucial for applications where the cost of false positives is high. We estimated precision using a weighted average of individual precision estimates from multiple cross-validation runs. This approach gives more weight to precision estimates based on more data, reducing the variance and providing a more reliable estimate.\n\nStatistical significance was assessed by comparing the performance of our combined classifier to that of individual basic classifiers and a random classifier. The results showed that the combined classifier consistently outperformed the basic classifiers and the random classifier, indicating statistical significance.\n\nOverall, our evaluation methods provide a robust assessment of the classifiers' performance, with confidence intervals and statistical significance supporting the claim that our combined classifier is superior to others and baselines.",
  "evaluation/availability": "Not enough information is available."
}