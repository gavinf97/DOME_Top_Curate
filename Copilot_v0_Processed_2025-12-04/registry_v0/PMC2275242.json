{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "BMC Bioinformatics",
  "publication/year": "2008",
  "publication/doi": "10.1186/1471-2105-9-57",
  "publication/tags": "- Gene function prediction\n- Support Vector Machines (SVMs)\n- Negative sample generation\n- Cross-validation\n- Functional annotation\n- Bioinformatics\n- Machine learning\n- Gene expression profiles\n- Protein-protein interaction\n- Kernel integration\n- Functional linkage graph\n- S. cerevisiae genes\n- Data integration\n- Classification algorithms\n- Biological data analysis",
  "dataset/provenance": "The dataset used in this study integrates three types of data sources to predict the functions of S. cerevisiae genes. The first source is protein-protein interaction data, obtained from the BioGRID database, version 2.0.20. This dataset contains 82,633 interaction pairs among 5,299 yeast genes, with 4,049 of these genes annotated by 13 functional classes.\n\nThe second data source is gene expression profiles, downloaded from the Stanford Gene Expression Database (SMD). This dataset includes results from several studies and contains 6,012 common genes. After processing to handle missing values using the KNNimpute algorithm, the dataset used in this work includes 5,132 genes with 278 real-value features for gene expression data.\n\nThe third data source is protein complex data, obtained from the MIPS database in 2006. This data includes information from previous studies and is used under the assumption that genes occurring in the same complex are likely to have similar or related functions.\n\nThe functional annotation data for S. cerevisiae genes were obtained from the FunCat 2.0 functional classification scheme, available from the Comprehensive Yeast Genome Database (CYGD) of MIPS. The FunCat data is organized hierarchically with up to six levels of specificity, including 1,307 functional categories. For this work, 13 general functional classes were selected, resulting in the annotation of 4,049 genes in total.",
  "dataset/splits": "In our study, we employed a 10-fold cross-validation approach for various methods, including AGPS, PSoL, one-class SVMs, two-class SVMs, and kernel integration. This approach involved dividing the positive set into 10 groups. In each fold, 9 of these 10 subsets were used as the positive training set, while the remaining subset served as the validation set. Additionally, genes outside the target functional class and validation genes were considered unlabeled data.\n\nFor one-class SVMs, the negative samples consisted of genes outside the target functional class. The 10-fold cross-validation was used to determine the optimal parameters for kernel functions, with 9/10 of the positive set used for training and the remaining 1/10 as the positive validation set. A randomly selected negative subset, approximately the same size as the positive validation set, was used as the negative validation set.\n\nIn the case of two-class SVMs, the negative samples were also genes outside the target functional class. The 10-fold cross-validation was utilized to find the parameters that best separated the positive samples from the negative samples. A balanced training set was generated, where the negative samples were randomly selected from genes outside the functional class to match the size of the positive samples.\n\nFor the kernel integration method, the diffusion kernel was applied to binary networks generated by protein-protein interactions and complexes, while the RBF kernel was applied to gene expression profiles. The parameters of these kernels were determined through 10-fold cross-validation.\n\nAdditionally, for AGPS, the 10-fold cross-validation was used to find the optimal parameters for the kernel function. The negative samples occurring most frequently in the returned negative sets were taken as representative negative samples, with their size controlled to be nearly equal to that of the positive set. This approach aimed to reduce false negatives.\n\nFor PSoL, the 10-fold cross-validation was also employed to find the optimal parameters for the kernel function. The unlabeled data included genes outside the target functional class, unknown genes, and validation genes. The learning procedure for PSoL was similar to that of AGPS, but PSoL did not select a classifier and instead returned possible positive samples at the end of learning.\n\nIn summary, our dataset splits involved a 10-fold cross-validation strategy, with the positive set divided into 10 groups. Each fold used 9 groups for training and 1 group for validation, along with unlabeled data consisting of genes outside the target functional class and validation genes. This approach was applied consistently across different methods to ensure robust and comparable results.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets utilized in this work are derived from several publicly available sources. The protein interaction data were obtained from the BioGRID database, specifically version 2.0.20 for yeast. This dataset includes 82,633 interaction pairs among 5,299 yeast genes. The gene expression dataset was downloaded from the Stanford Gene Expression Database (SMD), which contains results from multiple studies. Missing values in the gene expression profiles were estimated using the KNNimpute algorithm with k set to 15. The dataset comprises 6,012 common genes, of which 5,132 are also present in the protein interaction dataset. Consequently, the final dataset used in this work includes 5,132 genes with 278 real-value features for gene expression data.\n\nThe protein complex data were sourced from the MIPS database in 2006, incorporating data from specific studies. These data were used under the assumption that genes occurring in the same complex share similar functions.\n\nThe annotation data in FunCat are organized hierarchically with up to six levels of increasing specificity, encompassing 1,307 functional categories. For this work, 13 general functional classes were selected, resulting in the annotation of 4,049 genes. The functional categories and the corresponding number of genes are detailed in the provided tables.\n\nThe datasets and their splits are not explicitly released in a public forum as part of this publication. However, the sources from which the data were obtained are well-documented and publicly accessible, ensuring reproducibility. The use of these datasets adheres to the licensing and usage policies of their respective databases. The enforcement of data usage compliance is managed through the terms and conditions set by the original data providers, such as BioGRID, SMD, and MIPS. Researchers interested in replicating the study can access the same datasets through these public repositories, following the specified guidelines for data usage and citation.",
  "optimization/algorithm": "The optimization algorithm discussed in this subsection is centered around the Annotating Genes with Positive Samples (AGPS) method. This approach falls under the class of machine-learning algorithms known as support vector machines (SVMs), specifically one-class SVMs and two-class SVMs.\n\nThe AGPS algorithm is indeed a novel method. It addresses the challenges in gene function prediction, particularly the lack of negative samples and the imbalanced data problem. The algorithm is designed to automatically define a negative set from unlabeled data, which helps in improving the performance of gene function prediction.\n\nThe reason this algorithm was not published in a machine-learning journal is that it is specifically tailored for bioinformatics applications, particularly gene function prediction. The focus of the study is on the biological significance and the practical application of the algorithm in the field of bioinformatics, rather than on the theoretical aspects of machine learning. The algorithm's effectiveness is demonstrated through its application to gene function prediction, showing how it outperforms other methods in this specific context. This makes it more relevant to bioinformatics journals, where the practical application and biological implications are of primary interest.",
  "optimization/meta": "The meta-predictor described in this work does not directly use data from other machine-learning algorithms as input. Instead, it integrates various methods to enhance gene function prediction. The methods constituting the whole include AGPS, PSoL, two-class SVMs, one-class SVMs, and kernel integration. Each of these methods contributes to the overall prediction process by leveraging different techniques and datasets.\n\nThe AGPS algorithm, for instance, employs a 10-fold cross-validation approach to determine optimal parameters and define representative negative samples. This process involves dividing the positive set into training and validation subsets, ensuring that the validation genes and those outside the target functional family are treated as unlabeled data. Similarly, PSoL uses a comparable cross-validation strategy but focuses on identifying possible positive samples from unlabeled data.\n\nTwo-class SVMs and kernel integration methods also utilize cross-validation to optimize parameters. For two-class SVMs, a balanced training set is generated by randomly selecting negative samples equal in size to the positive samples. Kernel integration combines diffusion kernels applied to protein-protein interaction networks and RBF kernels applied to gene expression profiles.\n\nThe independence of training data is maintained through the cross-validation process, where different subsets of the data are used for training and validation in each fold. This ensures that the models are evaluated on data they have not seen during training, providing a robust assessment of their performance.\n\nIn summary, the meta-predictor integrates multiple machine-learning methods, each with its own cross-validation strategy, to enhance gene function prediction. The training data independence is preserved through the cross-validation process, ensuring reliable and unbiased performance evaluation.",
  "optimization/encoding": "In our study, we integrated three types of data to form a functional linkage graph for predicting gene functions in S. cerevisiae. These data sources included protein-protein interaction networks, gene expression profiles, and protein complex data. To preprocess this data, we first normalized the individual matrices obtained from these sources and then combined them to create a new kernel. This integration allowed us to leverage multiple data types simultaneously, enhancing the robustness of our predictions.\n\nTo handle the high dimensionality and noise present in the data, we employed Singular Value Decomposition (SVD). SVD helped us reduce the dimensionality by extracting the dominant structure of the functional linkage graph, thereby removing noise and focusing on the most relevant features. This step was crucial for improving the performance of our machine-learning algorithm.\n\nFor the machine-learning algorithm itself, we utilized Support Vector Machines (SVMs) as the core learning method. Specifically, we developed the Annotating Genes with Positive Samples (AGPS) algorithm, which automatically generates negative samples from unlabeled data during the learning procedure. This approach differs from conventional single-class learning algorithms, such as one-class SVMs, which are trained only on positive samples. By defining negative samples from unlabeled data, AGPS aims to improve the effectiveness of gene function prediction.\n\nIn addition to AGPS, we also compared other methods, including two-class SVMs and kernel integration techniques. For two-class SVMs, we generated a balanced training set by randomly selecting negative samples from genes outside the target functional class. This balancing technique helped mitigate the imbalanced data problem, which can degrade the performance of classifiers. For kernel integration, we applied the diffusion kernel to binary networks generated from protein-protein interactions and complexes, while using the Radial Basis Function (RBF) kernel for gene expression profiles. The parameters for these kernels were determined through 10-fold cross-validation to ensure optimal performance.",
  "optimization/parameters": "In our study, the number of parameters used in the model varies depending on the method employed. For AGPS, PSoL, and one-class SVMs, the optimal parameters for the kernel function were determined using 10-fold cross-validation. This process involved dividing the positive set into 10 groups, using 9 groups for training and 1 for validation in each fold. The parameters that yielded the best performance across all folds were selected.\n\nFor two-class SVMs, the 10-fold cross-validation was utilized to find the parameters that best separate the positive samples from the negative samples. A balanced training set was generated by randomly selecting negative samples with the same size as the positive samples from the genes outside of the functional class.\n\nIn the kernel integration method, the diffusion kernel was applied to binary networks generated by protein-protein interaction and complexes, while the RBF kernel was applied to gene expression profiles. The parameters of these kernels were also determined by 10-fold cross-validation.\n\nThe number of features selected for different methods can be found in the provided table. This table lists the number of features used for each functional category across different methods, including AGPS, PSoL, one-class SVMs, two-class SVMs, and two-class SVMs with balanced data. The selection of these features was crucial for optimizing the performance of each method in gene function prediction.",
  "optimization/features": "The input features for the methods discussed are derived from a functional linkage graph, resulting in a total of 5132 features for each gene. The number of samples in each class ranges from 76 to 909.\n\nFeature selection was performed using Singular Value Decomposition (SVD) to uncover the dominant structure of the functional linkage graph. This technique was employed to extract informative features and reduce the impact of noise, which is crucial given the high dimensionality of the data. The SVD method decomposes the matrix into three matrices, revealing the underlying structure and aiding in the selection of relevant features.\n\nThe feature selection process was conducted without relying on negative samples, as their information was not available. This approach ensures that the feature selection is independent of the training set, focusing solely on the structure of the functional linkage graph.",
  "optimization/fitting": "In our study, we employed several methods to ensure that our models were neither overfitting nor underfitting the data. For methods like AGPS and PSoL, we used 10-fold cross-validation to find the optimal parameters for the kernel functions. This approach helps in ruling out overfitting by ensuring that the model generalizes well to unseen data. In each fold, 90% of the positive set was used for training, and the remaining 10% was used for validation. This process was repeated 10 times, and the parameters that performed best across all folds were selected.\n\nFor AGPS, the negative samples were carefully chosen to reduce false negatives. After the 10-fold cross-validation, the negative samples that occurred most frequently in the returned negative sets were selected as representative negative samples. This method helps in balancing the dataset and improving the model's performance.\n\nIn the case of one-class SVMs, the genes outside the target functional class were used as negative samples, and the classifier was trained only on the positive training set. The 10-fold cross-validation was utilized to find the optimal parameters for the kernel functions. A randomly selected negative subset, with nearly the same size as the positive validation set, was used as the negative validation set. This approach ensures that the model is not overfitting to the positive samples and can generalize well to negative samples.\n\nFor two-class SVMs, a balanced training set was generated by randomly selecting negative samples with the same size as the positive samples from the genes outside the functional class. This technique has been used in the literature to define negative samples and helps in preventing overfitting by ensuring that the model is trained on a balanced dataset.\n\nThe kernel integration method applied different kernels to various types of data, such as protein-protein interaction networks and gene expression profiles. The parameters of the kernels were determined by 10-fold cross-validation, ensuring that the model generalizes well to unseen data.\n\nTo evaluate the overall performance of the classifiers, the ROC score, i.e., the area under the ROC curve, was utilized. This metric provides a comprehensive evaluation of the model's performance across different threshold values.\n\nIn summary, we employed 10-fold cross-validation and careful selection of negative samples to rule out overfitting and underfitting. The use of balanced training sets and the evaluation of the ROC score further ensured that our models were robust and generalizable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was 10-fold cross-validation. This technique involves dividing the positive set into 10 groups, where 9 of these groups are used for training and the remaining group is used for validation. This process is repeated 10 times, with each group serving as the validation set once. This approach helps in finding the optimal parameters for the kernel functions and ensures that the model generalizes well to unseen data.\n\nFor the AGPS method, the 10-fold cross-validation was particularly crucial. In each trial, the best classifier and the corresponding negative set were identified. The negative samples that occurred most frequently across the 10 trials were selected as representative negative samples. This method helps in reducing false negatives and ensures that the final model is robust and not overfitted to the training data.\n\nSimilarly, for the PSoL method, 10-fold cross-validation was used to determine the optimal parameters for the kernel function. The unlabeled data included genes outside the target functional class, unknown genes, and validation genes. The learning procedure for PSoL was similar to AGPS but focused on identifying possible positive samples rather than selecting a classifier.\n\nFor one-class SVMs, the 10-fold cross-validation was utilized to find the optimal parameters for the kernel functions. The positive set was divided into training and validation sets, with a randomly selected negative subset used for validation. This ensured that the model was trained on a balanced dataset, reducing the risk of overfitting.\n\nIn the case of two-class SVMs, the 10-fold cross-validation was used to find the parameters that best separate the positive samples from the negative samples. A balanced training set was generated by randomly selecting negative samples of the same size as the positive samples from genes outside the functional class. This technique has been widely used in the literature to define negative samples and helps in preventing overfitting.\n\nFor the kernel integration method, the diffusion kernel was applied to binary networks generated by protein-protein interactions and complexes, while the RBF kernel was applied to gene expression profiles. The parameters of the kernels were determined through 10-fold cross-validation, ensuring that the integrated kernel was optimized for the given data.\n\nOverall, the use of 10-fold cross-validation across different methods ensured that our models were robust and generalizable, effectively preventing overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the text. Specifically, the 10-fold cross-validation method was employed to determine the optimal parameters for various kernel functions across different methods, including AGPS, PSoL, one-class SVMs, two-class SVMs, and the kernel integration method. The learning procedures and parameter selections for each method are described in the text, providing a clear understanding of how these configurations were derived.\n\nThe results of the 10-fold cross-validation, including the performance metrics and the number of features selected for each functional category, are presented in tables. These tables offer insights into the effectiveness of the defined negative samples and the overall performance of the classifiers.\n\nRegarding the availability of model files and optimization parameters, the specific details are not explicitly mentioned in the provided text. However, the methods and procedures described are comprehensive and can be replicated by following the outlined steps. The text does not specify the availability of model files or any associated licenses, so it is not clear if these are publicly accessible or under specific licensing terms.\n\nIn summary, while the hyper-parameter configurations and optimization parameters are well-documented within the text, the availability of model files and specific licensing information is not provided.",
  "model/interpretability": "The AGPS algorithm, while powerful in predicting gene functions, is not inherently transparent. It operates by automatically generating negative samples from unlabeled data, which allows it to define representative negative samples that can best recognize positive samples. This process involves integrating various data sources such as protein interaction networks, gene expression profiles, and protein complex data into a functional linkage graph. Singular Value Decomposition (SVD) is then used to reduce dimensionality and remove noise, making the data more manageable for the algorithm.\n\nThe core learning algorithm used by AGPS is Support Vector Machines (SVMs), which are known for their effectiveness in classification tasks. However, SVMs themselves are not transparent models; they work by finding a hyperplane that best separates the classes in the feature space, which can be complex and difficult to interpret directly.\n\nThe AGPS algorithm's strength lies in its ability to handle imbalanced data and improve recall rates, which is crucial for biologists who are primarily interested in identifying genes with specific functions. The algorithm's performance has been validated through comparisons with other methods, showing that it can recover most unknown genes for nearly each functional class. This indicates that while the internal workings of the AGPS algorithm may not be easily interpretable, its outputs are reliable and useful for practical applications in gene function prediction.",
  "model/output": "The model is primarily focused on classification tasks, specifically for gene function prediction. Various methods, including support vector machines (SVMs) and kernel integration, are employed to classify genes into different functional categories. The performance of these classifiers is evaluated using metrics such as precision, recall, F1 score, and the area under the ROC curve (ROC score). The results indicate that the AGPS algorithm outperforms other methods in terms of overall performance, particularly in ROC scores. The model's effectiveness is demonstrated through 10-fold cross-validation and testing on previously unknown genes, showcasing its ability to predict gene functions accurately. The use of balanced and imbalanced datasets further highlights the importance of selecting appropriate negative samples for improving classifier performance.",
  "model/duration": "The execution time for the models varied depending on the method used. For AGPS, the 10-fold cross-validation process was employed to find the optimal parameters for the kernel function. This involved dividing the positive set into 10 groups, using 9 subsets for training and 1 for validation in each trial. The learning procedure for AGPS in each trial was computationally intensive, as it involved selecting the best classifier and the corresponding negative set. The final results were obtained after completing all 10 trials, which took a significant amount of time.\n\nSimilarly, for PSoL, the 10-fold cross-validation was used to determine the optimal parameters. The learning process for PSoL was similar to that of AGPS but did not involve selecting a classifier. Instead, it focused on identifying possible positive samples from the unlabeled data. This process also required substantial computational resources and time.\n\nFor one-class SVMs, the execution time was influenced by the use of 10-fold cross-validation to find the optimal parameters for the kernel functions. The classifier was trained only on the positive training set, and a randomly-selected negative subset was used for validation. This method also required a considerable amount of time to complete the cross-validation process.\n\nTwo-class SVMs utilized 10-fold cross-validation to find the parameters that best separated the positive and negative samples. A balanced training set was generated, which involved randomly selecting negative samples of the same size as the positive samples. This process was time-consuming due to the need to balance the training set and perform cross-validation.\n\nThe kernel integration method applied different kernels to various data types, such as protein-protein interaction networks and gene expression profiles. The parameters of the kernels were determined through 10-fold cross-validation, which added to the overall execution time. The kernel matrices obtained were normalized and combined to form a new kernel, further contributing to the computational load.\n\nIn summary, the execution time for the models was significant due to the use of 10-fold cross-validation and the need to process large datasets. The specific execution times were not detailed, but it is clear that each method required substantial computational resources and time to complete the training and validation processes.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the methods involved a comprehensive approach using 10-fold cross-validation to determine optimal parameters for various kernel functions. For AGPS, the positive set was divided into 10 groups, with 9 subsets used for training and 1 for validation. The negative samples were selected based on their frequency in the returned negative sets, aiming to reduce false negatives. The final results were obtained using the defined negative set and positive set, mirroring the conventional two-class SVMs.\n\nPSoL also employed 10-fold cross-validation to find optimal parameters, defining unlabeled data to include genes outside the target functional class, unknown genes, and validation genes. Unlike AGPS, PSoL did not select a classifier but returned possible positive samples after the learning stage.\n\nFor one-class SVMs, the genes outside the target functional class were used as negative samples, and the classifier was trained solely on the positive training set. The 10-fold cross-validation helped determine the best parameters for kernel functions.\n\nTwo-class SVMs utilized genes outside the target functional class as negative samples and employed 10-fold cross-validation to find parameters that best separated positive from negative samples. A balanced training set was generated by randomly selecting negative samples equal in size to the positive samples.\n\nThe kernel integration method applied the diffusion kernel to binary networks from protein-protein interactions and complexes, and the RBF kernel to gene expression profiles. The parameters for these kernels were also determined through 10-fold cross-validation.\n\nAdditionally, the methods were evaluated on old data, specifically 386 previously unknown yeast genes annotated by 13 functional classes. These genes were used as a test set to validate the models trained earlier. The AGPS algorithm, in this context, functioned like a conventional two-class SVM with predefined parameters and negative sets. PSoL included the test data in its unlabeled genes and used the best parameters from the training procedure to identify putative positive samples. The other methods applied their trained classifiers to predict gene functions in the test data. The performance was assessed using the ROC score, which was not used previously due to the lack of negative samples for single-class methods. The results demonstrated the effectiveness of the AGPS algorithm in defining negative samples for gene function prediction.",
  "evaluation/measure": "In our study, we employed several key performance metrics to evaluate the effectiveness of our classifiers. These metrics include precision, recall, and the F1 score. Precision is calculated as the ratio of true positive predictions to the total number of positive predictions made by the classifier. Recall, on the other hand, measures the ratio of true positive predictions to the actual number of positive samples. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nAdditionally, we utilized the ROC score, which is the area under the Receiver Operating Characteristic curve. This metric evaluates the overall performance of the classifiers, particularly in scenarios where there is an imbalance in the data. The ROC score was not applicable in previous sections due to the absence of negative samples for single-class methods.\n\nThese metrics are widely recognized and used in the literature for evaluating classifier performance, especially in bioinformatics and machine learning contexts. They provide a comprehensive view of how well our methods can predict gene functions, considering both the accuracy of positive predictions and the coverage of actual positive samples.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our proposed AGPS algorithm against several other methods, including PSoL, two-class SVMs, one-class SVMs, and kernel integration. These comparisons were conducted to investigate the influence of different negative samples on gene function prediction and to demonstrate the effectiveness of the AGPS in defining negative samples.\n\nWe performed 10-fold cross-validation for each method to find the optimal parameters for kernel functions. For the AGPS algorithm, we employed a strategy where the positive set was divided into 10 groups, with 9 groups used for training and 1 for validation. The negative samples were selected based on their frequency in the returned negative sets, aiming to reduce false negatives. This approach allowed us to define a representative negative set that improved the overall performance of the classifier.\n\nFor the PSoL algorithm, we followed a similar cross-validation procedure but focused on identifying possible positive samples from unlabeled data. The two-class SVMs and kernel integration methods were evaluated both on imbalanced and balanced datasets. The balanced datasets were created by randomly selecting negative samples of the same size as the positive samples, which significantly improved the performance of these classifiers. This comparison highlighted the importance of selecting appropriate negative samples in gene function prediction.\n\nThe results of these evaluations are presented in Table 4, which shows that the AGPS algorithm performs comparably well with other methods due to its effective definition of negative samples. All methods utilizing negative samples outperformed the one-class SVMs, which were trained only on positive samples. The poor performance of one-class SVMs was attributed to the relatively small number of positive training samples, leading to underfitting.\n\nAdditionally, we validated our methods on a test set of 386 previously unknown yeast genes that were annotated by the selected 13 functional classes. The AGPS algorithm, working as a conventional two-class SVM with defined parameters and negative set, showed superior overall performance in terms of ROC scores. This further demonstrated the effectiveness of the AGPS in gene function prediction.\n\nIn summary, our comparisons to publicly available methods and simpler baselines on benchmark datasets showed that the AGPS algorithm outperforms other methods in defining negative samples and achieving higher recall, thereby recognizing more positive samples hidden in the unknown data.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files are available as supplementary materials. These files include the functional classes and corresponding genes used in different stages of the evaluation process. Specifically, there are three additional files provided:\n\n1. The first file contains the functional classes and corresponding genes used in the 10-fold cross-validation. The genes listed in this file have been annotated in MIPS until 2004.\n\n2. The second file lists the functional classes and corresponding genes used in the test stage. These genes were not annotated in 2004 but were annotated in MIPS in 2006.\n\n3. The third file includes the predicted functions of genes that were not annotated until 2006. These unknown genes are annotated with only the selected 13 functional classes by the AGPS algorithm.\n\nThese supplementary files can be accessed through the provided links, ensuring transparency and reproducibility of the evaluation process. The data is publicly released, and the files can be downloaded for further analysis or verification."
}