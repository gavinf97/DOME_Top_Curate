{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- **Y. Yang**: Designed the system and performed the computational tasks.\n- **W. Ma**: Designed the system and conducted wet-bench experiments.\n- **J. Zhao**: Conducted wet-bench experiments.\n- **R.L. Morgan**: Conducted wet-bench experiments.\n- **T. Jiang**: Supervised the project.",
  "publication/journal": "BMC Bioinformatics",
  "publication/year": "2010",
  "publication/doi": "10.1186/1471-2105-11-S1-S47",
  "publication/tags": "- Machine Learning\n- Bioinformatics\n- Type III Secretion System\n- Protein Prediction\n- SVM Classifier\n- Pseudomonas syringae\n- Rhizobia\n- Protein Features\n- Computational Biology\n- Effectors",
  "dataset/provenance": "The dataset used in this study is derived from the bacterium Pseudomonas syringae, which has been extensively studied as a model organism for type III secreted effectors (T3SEs). The positive dataset consists of 283 confirmed effectors from three different strains of P. syringae: P. syringae pv. tomato strain DC3000, P. syringae pv. syringae strain B728a, and P. syringae pv. phaseolicola strain 1448A. A non-redundant subset was also created by excluding homologous effectors with sequence similarity higher than 60%.\n\nThe negative dataset was extracted from the genome of P. syringae pv. tomato strain DC3000, with proteins related to the type III secretion system (T3SS) and hypothetical proteins removed. This resulted in a non-effector dataset. It is important to note that the negative dataset may contain unknown effectors, potentially leading to an overestimation of the negative data.\n\nThe dataset is imbalanced, with the positive data size being much smaller than the negative data size. This imbalance becomes even more pronounced after removing redundancy, as many known effectors were identified via homology search.\n\nIn addition to the P. syringae dataset, the method was also applied to a rhizobial dataset. This dataset includes protein sequences from four rhizobial strains known to possess the T3SS: Sinorhizobium sp. NGR234, Bradyrhizobium japonicum USDA 110, Mesorhizobium loti MAFF303099, and Sinorhizobium medicae WSM419. The rhizobial dataset consists of a total of 22,220 protein sequences.",
  "dataset/splits": "There are two main data splits in our study: a redundant data set and a non-redundant data set.\n\nThe redundant data set, referred to as Set I, consists of 283 confirmed effectors from various strains of Pseudomonas syringae. The negative data set for Set I was extracted from the genome of P. syringae pv. tomato strain DC3000, excluding proteins related to T3SS and hypothetical proteins. This results in a total of 3,779 non-effector proteins, making the total number of data points in Set I 4,062.\n\nThe non-redundant data set, referred to as Set II, was created by excluding homologous effectors with sequence similarity higher than 60%. This set contains 108 positive samples and 3,424 negative samples, totaling 3,532 data points.\n\nThe class distribution in both sets is imbalanced, with the positive data size being much smaller than the negative data size. This imbalance is more pronounced in the non-redundant set due to the removal of redundant effectors identified via homology search.",
  "dataset/redundancy": "The datasets used in this study were carefully constructed to ensure independence between training and test sets. The positive dataset consists of all 283 confirmed effectors from three strains of Pseudomonas syringae. A non-redundant subset was also created by excluding homologous effectors with sequence similarity higher than 60%. The negative dataset was derived from the genome of P. syringae pv. tomato strain DC3000, with proteins related to the type III secretion system (T3SS) and hypothetical proteins removed.\n\nThe class distribution in the datasets is notably imbalanced, with the positive data size being much smaller than the negative data size. This imbalance is further exacerbated after removing redundancy, as many known effectors were identified via homology search. This imbalance is a common challenge in machine learning datasets, particularly in biological data where the number of known effectors is limited compared to non-effectors.\n\nTo address this imbalance and ensure the robustness of our predictions, we employed a support vector machine (SVM) classifier with a 5-fold cross-validation test. This approach helps in evaluating the model's performance and generalizability by splitting the data into five subsets, training on four, and validating on the remaining one, repeating this process five times. The parameters for the SVM were optimized using grid search on the training data.\n\nThe training sets used in previous studies often had relatively balanced numbers of positive and negative samples. For instance, in the EffectiveT3 test, the negative set was twice as large as the positive set, while in the T3SS prediction test, the ratio was about 1:1. In contrast, our method maintains a ratio of effectors and non-effectors in the training data that is closer to their natural ratio in Pseudomonas syringae. This imbalanced training set helped achieve a high precision of 90.8% while keeping the recall at 64.8%.\n\nThe independence of the training and test sets was enforced by ensuring that the negative dataset did not include any proteins related to T3SS or hypothetical proteins, thereby reducing the likelihood of contamination with unknown effectors. This rigorous approach ensures that the model's performance is not artificially inflated by the inclusion of related proteins in the test set.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machine (SVM). This is a well-established supervised learning method widely used in bioinformatics and other fields.\n\nThe SVM algorithm is not new; it has been extensively studied and applied in various domains. The choice to use SVM in this context is due to its effectiveness in handling high-dimensional spaces and its ability to perform well with clear margin of separation.\n\nThe reason it was not published in a machine-learning journal is that the focus of this work is on applying machine learning to a specific biological problem—predicting novel type III secreted proteins. The innovation lies in the application of SVM to this particular biological dataset and the development of feature extraction methods tailored to protein sequences. The primary contribution is in the biological insights and the practical application of machine learning to advance understanding in microbiology, rather than in the development of a new machine-learning algorithm.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on a single machine-learning method, specifically the support vector machine (SVM), to classify feature vectors as effectors and non-effectors. The SVM is trained using a dataset of Pseudomonas syringae, which includes confirmed effectors and non-effectors. The features used for training and prediction are derived from amino acid sequences, focusing on amino acid composition, secondary structure, and solvent accessibility information. The model's performance is evaluated using metrics such as precision, recall, and total accuracy. The training data is carefully constructed to ensure that it is independent and representative of the natural ratio of effectors to non-effectors in Pseudomonas syringae. This approach aims to achieve high precision and recall in predicting novel type III secreted proteins.",
  "optimization/encoding": "For the machine-learning algorithm, the data encoding and preprocessing involved several key steps to effectively represent protein sequence features. Three primary feature extraction methods were considered: amino acid composition (AAC), k-mer composition, and a method that combines amino acid composition with secondary structure and solvent accessibility states, termed SSE-ACC.\n\nThe AAC method converts a protein sequence into a 20-dimensional feature vector, capturing the frequency of each of the 20 amino acids. This method is straightforward but results in significant information loss due to its simplicity.\n\nThe k-mer method retains the order and neighborhood information of amino acids up to a specified length (k). However, as k increases, the dimensionality of the feature space grows exponentially, making it computationally intensive. For the dataset used, the k-mer method did not show a clear advantage over AAC, and performance improvements were minimal with increasing k.\n\nThe SSE-ACC method generates 100-dimensional feature vectors. The first 60 dimensions describe the frequency of each amino acid within three possible secondary structure elements: strand (E), helix (H), and coil (C). The value for each dimension is calculated by dividing the frequency of an amino acid in a specific secondary structure by the length of the sequence. The last 40 dimensions represent the frequency of each amino acid in two solvent accessibility states: buried (B) and exposed (E). These two types of information are combined into a single feature vector.\n\nIn the experiments, the first 100 amino acids of the N-terminal sequences were used, as maximal secretion or translocation may require these residues. This approach ensures that the most relevant parts of the protein sequences are considered for feature extraction.\n\nThe SSE-ACC method was found to be the most effective, achieving higher recall and precision compared to AAC and k-mer methods. The best results were obtained using single amino acid composition in the first 100 residues, with a total accuracy of 98.3%. However, the SSE-ACC method outperformed this by over 5% in both recall and precision.",
  "optimization/parameters": "In the optimization process, two parameters were used in the model. These parameters were selected through a grid search on the training data during a 5-fold cross-validation test. The parameters were chosen to optimize the performance of the Support Vector Machine (SVM) classifier, which was implemented using LibSVM version 2.8. The specific values for these parameters were determined to be g = 0.25 and C = 4 for one dataset, and g = 0.5 and C = 4 for another. The radial basis function (RBF) kernel was found to provide the best classification accuracy among the considered kernels.",
  "optimization/features": "In our study, we employed three distinct feature extraction methods to represent protein sequence features: amino acid composition (AAC), k-mer composition, and the SSE-ACC method. The SSE-ACC method, which combines amino acid composition in terms of secondary structures and solvent accessibility states, was ultimately chosen for its superior performance and lower dimensionality.\n\nThe SSE-ACC method generates 100-dimensional feature vectors. The first 60 dimensions describe the frequency of each amino acid in the three possible secondary structure elements: strand (E), helix (H), and coil (C). The remaining 40 dimensions represent the frequency of each amino acid in the two possible solvent accessibility states: buried (B) and exposed (E). These features were calculated using the first 100 amino acids of each protein sequence, as maximal secretion or translocation may require these initial residues.\n\nFeature selection was not explicitly performed as a separate step. Instead, we evaluated the performance of different feature sets through cross-validation and selected the SSE-ACC method based on its superior results. The feature extraction process was conducted using the training data, ensuring that the evaluation and selection of features were done in a manner that prevents data leakage and maintains the integrity of the validation process.",
  "optimization/fitting": "The fitting method employed in our study utilized a Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel, which is known for its effectiveness in handling high-dimensional spaces and complex patterns. The number of parameters in our model is indeed large, given the dimensionality of our feature vectors, particularly when using the SSE-ACC method, which generates 100-dimensional vectors.\n\nTo address the potential issue of over-fitting, we implemented a 5-fold cross-validation strategy. This technique involves dividing the dataset into five subsets, training the model on four subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. By averaging the results, we ensure that the model's performance is robust and not merely a result of over-fitting to a specific subset of the data.\n\nAdditionally, we performed a grid search on the training data to find the optimum SVM parameters. This systematic approach helps in tuning the model's hyperparameters, further reducing the risk of over-fitting.\n\nTo mitigate under-fitting, we carefully selected relevant features and ensured that our model had sufficient complexity to capture the underlying patterns in the data. The use of the RBF kernel, which can model non-linear relationships, also helps in preventing under-fitting.\n\nMoreover, the imbalanced nature of our dataset, with a much smaller positive data size compared to the negative data size, was addressed by focusing on achieving a high precision. This approach ensures that the model is not overly simplistic and can accurately identify true positives, even in the presence of a large number of negative samples.",
  "optimization/regularization": "A regularization method was not explicitly mentioned in the context of optimization. However, the use of a support vector machine (SVM) with a radial basis function (RBF) kernel inherently includes regularization through the parameter C, which controls the trade-off between achieving a low training error and a low testing error. This helps in preventing overfitting by penalizing large coefficients in the decision function. Additionally, the use of a 5-fold cross-validation technique during the grid search for optimal SVM parameters further aids in preventing overfitting by ensuring that the model generalizes well to unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in the publication. Specifically, we used a Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel for our classifier. The parameters for the SVM, such as the regularization parameter (C) and the kernel parameter (γ), were optimized using a grid search and 5-fold cross-validation. The values used for these parameters are g = 0.25, C = 4 for the redundant data set, and g = 0.5, C = 4 for the non-redundant data set.\n\nThe model files and optimization parameters are not explicitly provided in the publication, as the focus was on reporting the methodology and results rather than distributing the specific model files. However, the implementation details and the software used, such as LibSVM version 2.8, are mentioned, allowing for reproducibility.\n\nRegarding the availability and licensing, the methods and tools used in our study are based on widely available and open-source software. LibSVM, for instance, is freely available under a permissive license, which allows for its use and modification in both academic and commercial settings. The feature extraction methods, such as PSIPRED and ACCpro, are also publicly accessible and commonly used in the bioinformatics community.\n\nFor those interested in replicating our results, the publication provides sufficient detail on the experimental settings, evaluation criteria, and feature extraction methods. This includes the use of amino acid composition (AAC), k-mer composition, and the SSE-ACC method, which considers secondary structure and solvent accessibility. The publication also discusses the computational environment used, which was a Pentium IV desktop PC with dual CPU (2.8 GHz) and 2 GB RAM.",
  "model/interpretability": "The model employed in this study is primarily based on a Support Vector Machine (SVM), which is a type of supervised learning algorithm. SVMs are generally considered to be black-box models, meaning that the decision-making process is not easily interpretable. The SVM operates by finding a hyperplane that best separates the data into different classes, but the specific weights and biases assigned to different features are not straightforward to interpret.\n\nHowever, the feature extraction process used in this model provides some level of transparency. The features considered include amino acid composition, secondary structure elements, and solvent accessibility states. These features are biologically meaningful and can be directly related to the properties of the proteins being analyzed. For example, the amino acid composition reflects the frequency of each amino acid in the protein sequence, while the secondary structure elements (strand, helix, and coil) and solvent accessibility states provide information about the protein's three-dimensional structure and its interaction with the solvent environment.\n\nThe use of these biologically relevant features allows for some interpretability. For instance, if a particular amino acid or secondary structure element is found to be important for classification, it can be inferred that this feature plays a significant role in the protein's secretion via the type III secretion system. This information can be valuable for further experimental validation and for gaining insights into the molecular mechanisms underlying protein secretion.\n\nIn summary, while the SVM itself is a black-box model, the use of biologically meaningful features provides a level of interpretability. This allows researchers to gain insights into the factors that contribute to protein secretion and to design experiments to validate these findings.",
  "model/output": "The model is a classification system designed to predict novel proteins secreted via the type III secretion system. It employs a supervised learning approach using a Support Vector Machine (SVM) as the classifier. The SVM is trained to distinguish between secreted and non-secreted proteins based on features extracted from N-terminal amino acid sequences. The output of the model is a probability indicating the likelihood of a protein being secreted through the type III secretion system. This probability is used to classify proteins as either secreted or non-secreted, with a specified cut-off value to determine the final classification. The model's performance is evaluated using metrics such as precision, recall, and total accuracy, which measure the quality of the predictions. The output includes a list of candidate secreted proteins, some of which have been experimentally verified as true positives.",
  "model/duration": "The computation process for our model took several tens of hours. The majority of this time was spent on extracting secondary structure and solvent accessibility information. These computations involved collecting multiple alignment profiles from public protein databases. The actual prediction procedure, once the necessary information was extracted, was relatively swift.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The method was evaluated using a 5-fold cross-validation test on both redundant and non-redundant datasets. This involved using a support vector machine (SVM) with a radial basis function (RBF) kernel. The parameters for the SVM were optimized through grid search on the training data. The performance of the method was assessed using multiple measures, including precision, recall, and total accuracy. Precision and recall were used to evaluate the prediction quality of effectors, while total accuracy measured the overall prediction quality. The experiments were conducted on a Pentium IV desktop PC with dual CPUs (2.8 GHz) and 2 GB of RAM. Additionally, the method was applied to predict type III secreted proteins in rhizobia, demonstrating its effectiveness in identifying novel secreted proteins. The prediction results were further validated by screening the data to remove proteins lacking the tts box in their promoters, resulting in 57 novel secreted proteins, of which 17 were confirmed as true positives.",
  "evaluation/measure": "In our evaluation, we employed multiple performance measures to comprehensively assess the effectiveness of our method. The primary metrics reported are precision, recall, and total accuracy. Precision is defined as the ratio of true positives to the sum of true positives and false positives. It indicates the accuracy of the positive predictions made by our model. Recall, on the other hand, is the ratio of true positives to the sum of true positives and false negatives, reflecting the model's ability to identify all relevant instances.\n\nTotal accuracy measures the overall correctness of the predictions by calculating the ratio of correctly classified samples to the total number of samples. These metrics are widely used in the literature and provide a robust evaluation framework. Precision and recall are particularly important for imbalanced datasets, such as ours, where the number of negative samples significantly outweighs the positive samples. By reporting these metrics, we ensure that our evaluation is representative and aligned with standard practices in the field.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our method with publicly available tools designed for predicting type III secreted proteins. Specifically, we compared our approach with EffectiveT3 and T3SS prediction tools. These comparisons were performed on benchmark datasets, including known effectors from Pseudomonas syringae and rhizobia.\n\nFor the EffectiveT3 tool, we noted that it uses a sliding-window technique and encodes each amino acid in a single window as a binary string of length 20. This tool can utilize either an artificial neural network (ANN) or a support vector machine (SVM) as the classifier. In our experiments, we adopted the ANN as recommended by the authors and used the default threshold of 0.4. The EffectiveT3 tool achieved a recall of 83.3% and a precision of 24%, indicating a high recall but relatively low precision.\n\nThe T3SS prediction tool also employs a sliding-window technique and can use either ANN or SVM. In our tests, this tool recognized 18 known effectors out of 21, achieving a recall of 85.7% and a precision of 24%. Similar to EffectiveT3, this tool demonstrated high recall but low precision.\n\nOur method, on the other hand, achieved a high precision of 90.8% while maintaining a recall of 64.8%. This improvement can be attributed to the imbalanced training set used in our method, which more closely reflects the natural ratio of effectors and non-effectors in Pseudomonas syringae. This imbalance helped in reducing the false positive rate, making our method more reliable for identifying novel effectors.\n\nAdditionally, we performed comparisons using different feature extraction methods, including amino acid composition (AAC), k-mer composition, and the SSE-ACC method. The SSE-ACC method, which considers amino acid composition in terms of secondary structures and solvent accessibility states, proved to be the most effective. It achieved a total accuracy of 98.3%, with a recall of 55.6% and a precision of 84.5% for effectors. This method outperformed both the AAC and k-mer methods, demonstrating its superiority in capturing relevant features for effector prediction.\n\nIn summary, our method was rigorously compared with existing tools and simpler baselines, showing significant improvements in precision while maintaining competitive recall. This comparison underscores the effectiveness of our approach in predicting novel type III secreted proteins.",
  "evaluation/confidence": "The evaluation of our method involved a 5-fold cross-validation test, which is a robust technique for assessing the performance and generalizability of a model. This process helps in understanding the variability and reliability of the results. However, specific confidence intervals for the performance metrics were not explicitly provided in the evaluation.\n\nThe statistical significance of our method's superiority over others and baselines can be inferred from the reported precision, recall, and total accuracy metrics. For instance, our method achieved a high precision of 90.8% and a recall of 64.8%, which are competitive compared to other tools like EffectiveT3 and T3SS prediction. The imbalanced training set, which more closely mirrors the natural ratio of effectors and non-effectors in Pseudomonas syringae, contributed to obtaining a high precision while maintaining a reasonable recall.\n\nAdditionally, the use of the SSE-ACC feature extraction method demonstrated better performance compared to AAC and k-mer methods, with a total accuracy of 98.3% when using single amino acid composition in the first 100 N-terminal residues. This indicates that the features extracted using the SSE-ACC method are more informative and effective for classifying effectors.\n\nThe prediction of novel secreted proteins in rhizobia further validated the effectiveness of our method. Out of 57 candidate effectors predicted, 17 were confirmed as true positives through wet-bench experiments. This high confirmation rate suggests that our method is reliable and statistically significant in identifying novel type III secreted effectors.\n\nIn summary, while explicit confidence intervals are not provided, the cross-validation results, comparative performance metrics, and experimental validations collectively indicate that our method is statistically significant and superior to other existing tools.",
  "evaluation/availability": "Not enough information is available."
}