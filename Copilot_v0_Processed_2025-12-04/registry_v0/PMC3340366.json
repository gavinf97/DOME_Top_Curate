{
  "publication/title": "Predicting CpG Island Methylation States",
  "publication/authors": "The authors who contributed to the article are:\n\n- Christian W. (Conceived and designed the experiments, Performed the experiments, Analyzed the data, Wrote the paper)\n- F. B. (Conceived and designed the experiments, Analyzed the data)\n- G. H. (Conceived and designed the experiments, Analyzed the data, Contributed reagents/materials/analysis tools)\n- J. E. (Conceived and designed the experiments)\n- F. M. (Conceived and designed the experiments, Contributed reagents/materials/analysis tools)\n- A. Z. (Conceived and designed the experiments, Head of department)",
  "publication/journal": "PLoS ONE",
  "publication/year": "2012",
  "publication/doi": "10.1371/journal.pone.0035327.t001",
  "publication/tags": "- DNA methylation\n- CpG islands\n- Machine learning\n- Support vector machines\n- Feature selection\n- Genomic attributes\n- Epigenomics\n- Bioinformatics\n- Predictive modeling\n- Cross-validation",
  "dataset/provenance": "The primary dataset used in this study is derived from the NAME21 Consortium, specifically a CpG island methylation dataset published by Zhang et al. This dataset is freely available and focuses on the promoter regions of all protein-coding genes on chromosome 21 in Homo sapiens. The dataset includes a window from 2000 base pairs upstream to 500 base pairs downstream of the transcription start site, identifying CpG-enriched regions using the Takai-Jones criteria.\n\nThe methylation status of each cytosine was determined using overlapping amplicons, ensuring that most CpGs are covered by multiple amplicons. This resulted in 297 amplicons for 190 genes. The experimental methods involved bisulfite conversion and subclone sequencing to detect methylated CpGs.\n\nThe dataset was analyzed in five different cell types: HEPG2 (a hepatocellular liver carcinoma cell line), trisomic fibroblasts (derived from an individual with Down syndrome), HEK293 (a human embryo kidney cell line), fibroblasts, and leukocytes. After processing, the dataset consists of varying numbers of methylated and unmethylated instances for each cell type. For example, leukocytes have 56 methylated and 112 unmethylated instances, while HEK293 has 73 methylated and 117 unmethylated instances. The trisomic fibroblast dataset was removed due to its high imbalance and insufficient training samples.\n\nAdditionally, two datasets from the ENCODE consortium were used for validation and evaluation. The \"ENCODE HudsonAlpha Methyl27 GM12878 replicate 1\" dataset was used for quantitative DNA methylation prediction, while the \"ENCODE HudsonAlpha MethylSeq HEPG2, Pcr2x, replicate 1\" dataset was used for method validation. These datasets provide binary and non-binary methylation information, respectively, and were mapped to CpG islands for analysis.\n\nThe HEP data, while popular, are not recommended for use because the amplicons do not fully meet the CpG island criteria defined by Gardiner et al. This issue has been confirmed by Bock et al. and should be considered when comparing different approaches.",
  "dataset/splits": "In our study, we employed multiple dataset splits to ensure robust validation of our method. We primarily used a ten-fold cross-validation approach, which involves dividing the dataset into ten parts, or folds. In each iteration of the cross-validation, nine folds are used for training, and the remaining fold is used for testing. This process is repeated ten times, with each fold serving as the test set once.\n\nAdditionally, we performed ten repetitions of this ten-fold cross-validation, each with a different random seed. This resulted in a total of 100 experiments, which were averaged to obtain the reported values. This extensive validation procedure helps to ensure the reliability and generalizability of our results.\n\nFor specific validation tasks, we also created additional dataset splits. For instance, we separated the dataset into training and test sets by randomly picking 10% of all CpG islands using a stratified sampling procedure. This means the training set maintained the same percentage of methylated CpG islands as the entire dataset. We also conducted a validation where all CpG islands from chromosome 21 were included in the training set, and CpG islands from other chromosomes were used as the test set.\n\nIn another validation approach, we used different percentages of the data for training: 10%, 25%, and 50%. For example, when using 10% of the data for training, 1,758 CpG islands were in the training set, and 15,830 were in the test set. Similarly, for 25% and 50% training sets, the respective numbers of CpG islands in the training and test sets were 4,397 and 13,191, and 8,794 and 8,794.\n\nThese various splits and their distributions ensured that our model was evaluated under different conditions, providing a comprehensive assessment of its performance.",
  "dataset/redundancy": "The datasets used in our study were split into training and test sets to ensure independent evaluation. For the HEPG2 dataset, we employed a stratified sampling procedure to randomly select 10% of all CpG islands for the test set, ensuring that the training set maintained the same percentage of methylated CpG islands as the entire dataset. This approach helps to preserve the class distribution and prevents data leakage.\n\nAdditionally, we performed another validation by using all CpG islands from chromosome 21 as the training set and declaring all CpG islands from other chromosomes as the test set. This method ensures that the training and test sets are completely independent, as no CpG islands from the test set were used in the training process. This strict separation is crucial for an accurate validation of our predictive models.\n\nThe distribution of our datasets is comparable to previously published machine learning datasets in the field of DNA methylation prediction. CpG islands tend to be predominantly unmethylated, which can lead to imbalanced datasets. To address this, we removed differentially methylated CpG islands that fell between 40% and 60% methylation, ensuring a clearer distinction between methylated and unmethylated states. This preprocessing step helps to mitigate the challenges posed by imbalanced data and improves the reliability of our predictions.",
  "dataset/availability": "The datasets used in this study are primarily from the NAME21 Consortium and the ENCODE consortium. The NAME21 dataset, published by Zhang et al., is freely available. This dataset includes promoter regions of all protein-coding genes on chromosome 21 in Homo sapiens, analyzed in five different cell types: HEPG2, trisomic fibroblasts, HEK293, fibroblasts, and leukocytes. The methylation status of each cytosine was determined using bisulfite conversion and subclone sequencing.\n\nAdditionally, two datasets from the ENCODE consortium were used. The \"ENCODE HudsonAlpha Methyl27 GM12878 replicate 1\" dataset was employed for evaluating a quantitative DNA methylation prediction approach. The \"ENCODE HudsonAlpha MethylSeq HEPG2, Pcr2x, replicate 1\" dataset was used for validating our method.\n\nThe data splits used in the study involved a ten-fold cross-validation with ten repetitions, resulting in 100 experiments that were averaged for each reported value. For validation, the dataset was split into training and test sets using stratified sampling to ensure the training set had the same percentage of methylated CpG islands as the whole dataset. In another validation approach, all CpG islands from chromosome 21 were used for training, and those from other chromosomes were used for testing.\n\nThe Java application developed for preprocessing the input datasets and generating features is available at http://www.cogsys.cs.uni-tuebingen.de/software/dna-methylation/. This application can read tab-separated files containing probe or CpG island locations and methylation intensities, map probes to CpG islands, lift coordinates between different releases of the human genome, and generate features for various feature classes. The generated feature file can be used with machine learning applications like LIBSVM to train models and evaluate classifiers or feature classes.\n\nThe data and the application are made available to ensure reproducibility and to allow other researchers to validate or build upon the findings. The application includes documentation, example datasets, and predicted methylation states for the NAME21 dataset, facilitating its use by the scientific community.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. These include support vector machines (SVMs) with both radial basis function (RBF) and linear kernels, random decision forests, k-nearest neighbor (kNN), decision trees (J48), K*, and naive Bayes. These algorithms are not new but have been chosen for their robustness and effectiveness in handling complex datasets.\n\nThe decision to use these specific algorithms was driven by their proven track record in similar biological and genomic studies. SVMs, in particular, have shown superior performance in many classification tasks, including those involving imbalanced datasets, which is common in genomic data. The use of multiple algorithms allowed for a comprehensive comparison and validation of the results, ensuring that the findings are reliable and not dependent on a single method.\n\nThe algorithms were implemented using established libraries such as LIBSVM and LIBLINEAR for SVMs, and the WEKA library for other classifiers. These libraries are widely used in the machine learning community and provide efficient and reliable implementations of the algorithms.\n\nThe focus of this study is on the application of these machine-learning algorithms to the specific problem of predicting DNA methylation of CpG islands, rather than the development of new algorithms. Therefore, the results and insights gained from this study are more relevant to the fields of genomics and bioinformatics than to machine learning per se. This is why the work was published in a genomics journal rather than a machine-learning journal.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine-learning algorithm, the data encoding and preprocessing involved several steps to ensure the quality and suitability of the dataset. Initially, the dataset consisted of CpG island methylation data from the NAME21 Consortium, which included promoter regions of protein-coding genes on chromosome 21 in Homo sapiens. The data was processed to include a window from 2000 base pairs upstream to 500 base pairs downstream of the transcription start site, identifying CpG-enriched regions using the Takai-Jones criteria.\n\nThe methylation status of each cytosine was determined using bisulfite conversion and subclone sequencing. The raw data was parsed into a cell type-specific structure, averaging methylation information from multiple amplicons for single CpGs. To determine the methylation status of a CpG island, the methylation status of all CpGs within that island was averaged, considering the island methylated if this value exceeded 60%.\n\nThe dataset was further refined by extending the sequence analysis for each CpG island to include the primer sequence length and 500 base pairs upstream and downstream. This extension aimed to cover nearby effects that might influence cytosine methylation, such as cis-acting transcription factors. The window size was chosen based on previous studies and validated as effective.\n\nTo ensure data accuracy, each CpG island sequence was retrieved from Ensembl and compared with the source data. Additionally, datasets from the ENCODE consortium were used for evaluation and validation. For the HEPG2 dataset, sequence regions were mapped to CpG islands, and regions not overlapping with CpG islands were discarded. Differentially methylated CpG islands were removed to avoid ambiguity in methylation status.\n\nThe final dataset consisted of various cell types, including HEPG2, HEK293, fibroblasts, and leukocytes, with specific counts of methylated and unmethylated instances for each. The trisomic fibroblast dataset was excluded due to its high imbalance and insufficient training samples for reliable support vector machine training with ten-fold cross-validation.\n\nThe preprocessing steps included normalizing and logarithmizing distance values to transcription start sites and calculating various features, such as distances to transcription start sites and CpG island-specific attributes. These features were used to train and evaluate machine-learning algorithms, ensuring a comprehensive and accurate prediction of DNA methylation states.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of features to train our models, resulting in a total of 948 features across 15 categories. These features were carefully selected to capture various aspects of DNA methylation, including distances to transcription start sites, CpG island-specific attributes, and more complex elements like transcription factor binding sites and histone modification data.\n\nThe selection of these features was driven by both biological relevance and empirical performance. For instance, we included features related to distances to transcription start sites because previous research has shown that methylation tends to decrease as one approaches these sites. Similarly, we incorporated histone modification data due to its established correlation with DNA methylation.\n\nTo ensure the robustness of our model, we employed a rigorous validation process. This included ten-fold cross-validation repeated ten times with different seeds, resulting in 100 experiments for each reported value. This approach helped us to identify the most effective features and to fine-tune our models.\n\nFor the support vector machines (SVMs) used in our predictions, we optimized two key parameters: C and Gamma for the RBF kernel. These parameters were selected through a systematic process of model and parameter selection, ensuring that our classifiers were well-calibrated and performed optimally across different datasets and cell types. The LIBSVM library was used for these SVM predictions, both for classification and regression tasks.",
  "optimization/features": "In our study, we utilized a comprehensive feature set consisting of 948 features, categorized into 15 distinct groups. These features were derived from various genomic and epigenomic data sources, ensuring a broad coverage of potential predictors for DNA methylation status.\n\nFeature selection was not explicitly performed in the traditional sense of reducing the number of features. Instead, we evaluated the suitability of all 15 feature classes for predicting DNA methylation of CpG islands. This was done by training and evaluating support vector machines with a radial basis function (RBF) kernel for each feature class and across four different cell types. This approach allowed us to assess the contribution of each feature class to the prediction accuracy without eliminating any features outright.\n\nThe evaluation process involved a rigorous validation procedure, including ten repetitions of ten-fold cross-validation. This ensured that the performance of each feature class was thoroughly tested and that the results were robust and generalizable. By using all available features and evaluating their collective performance, we aimed to capture the complex interplay between different genomic and epigenomic factors influencing DNA methylation.",
  "optimization/fitting": "In our study, we employed a robust cross-validation strategy to address potential issues of overfitting and underfitting. We utilized a ten-fold cross-validation approach, repeated ten times with different random seeds, resulting in 100 experiments for each reported value. This method ensures that our models are evaluated on diverse subsets of the data, reducing the risk of overfitting to any particular training set.\n\nTo further mitigate overfitting, we used support vector machines (SVMs) with both linear and radial basis function (RBF) kernels. SVMs are known for their effectiveness in high-dimensional spaces and their ability to handle overfitting through the regularization parameter. We carefully selected this parameter during model training to balance the trade-off between bias and variance.\n\nAdditionally, we evaluated the performance of our models using the Matthews correlation coefficient (MCC), which is particularly suitable for imbalanced datasets. This metric provides a more nuanced evaluation of model performance compared to accuracy alone, helping to ensure that our models are not merely memorizing the training data but are generalizing well to unseen data.\n\nFor the quantitative prediction approach, we employed support vector regression (SVR) models. The performance of these models was assessed using the average absolute error (AAE), which measures the average difference between the actual and predicted methylation values. This error metric helps to ensure that our regression models are not underfitting by providing a clear indication of prediction accuracy.\n\nIn summary, our use of cross-validation, appropriate model selection, and robust evaluation metrics helps to rule out both overfitting and underfitting, ensuring the reliability and generalizability of our predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was cross-validation. Specifically, we performed ten-fold cross-validation, where the data is divided into ten subsets, and the model is trained on nine subsets while being validated on the remaining one. This process is repeated ten times, with each subset serving as the validation set once. To further enhance the reliability of our results, we repeated this ten-fold cross-validation process ten times with different random seeds, resulting in a total of 100 experiments for each reported value. This extensive cross-validation approach helps to ensure that our models generalize well to unseen data and are not merely memorizing the training set.\n\nAdditionally, we used support vector machines (SVMs) with radial basis function (RBF) kernels, which inherently include regularization parameters. These parameters help to control the complexity of the model and prevent overfitting by penalizing large weights. The choice of the RBF kernel allows the model to capture non-linear relationships in the data while maintaining a balance between bias and variance.\n\nFurthermore, we carefully selected and engineered features to ensure that they were relevant and informative for the task of predicting DNA methylation. This involved removing features that were redundant or had low predictive power, thereby simplifying the model and reducing the risk of overfitting. We also employed stratified sampling to maintain the class distribution in both the training and test sets, which is crucial for handling imbalanced datasets like ours.\n\nIn summary, our approach to preventing overfitting included rigorous cross-validation, the use of regularized models, and careful feature selection. These techniques collectively contributed to the development of robust and generalizable models for predicting DNA methylation.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our experiments are fully reported within the publication. We utilized a ten-fold cross-validation approach, repeated ten times with different seeds, resulting in 100 experiments for each reported value. This ensures the robustness and reliability of our results.\n\nFor the support vector machine (SVM) predictions, both classification and regression tasks employed the LIBSVM and LIBLINEAR libraries. The WEKA library was used for all other classifiers. The specific parameters for these models, such as the choice of the radial basis function (RBF) kernel for SVMs, are detailed in the methods section.\n\nThe datasets used for validation, including the HEPG2 and GM12878 datasets from ENCODE, are publicly available. The coordinates of CpG islands and the methylation states for human blood lymphocytes, used in our comparisons, are also accessible. These datasets were lifted to the NCBI 36 release of the human genome for consistency.\n\nAll features were calculated based on this genome release, and the UCSC LiftOver tool was used to map the data accordingly. The feature dataset consists of 948 features from 15 categories, including distances to transcription start sites and CpG island-specific attributes.\n\nModel files and optimization parameters are not explicitly provided as downloadable assets, but the methods and configurations are thoroughly described, allowing for replication of the experiments. The publication includes detailed steps on data preprocessing, feature generation, and model training, ensuring transparency and reproducibility.\n\nThe license under which the data and methods are shared is not specified, but the datasets and tools used are from publicly available sources, adhering to standard academic practices for data sharing and reproducibility.",
  "model/interpretability": "The models employed in our study, particularly the support vector machines (SVMs) with both linear and radial basis function (RBF) kernels, are generally considered to be black-box models. This means that while they are highly effective in making predictions, the internal workings and the specific reasons behind their predictions are not easily interpretable.\n\nHowever, there are aspects of our approach that provide some level of transparency. For instance, the features used in our models are derived from genomic attributes and sequence-based information, which are biologically meaningful. This allows for some interpretability at the feature level. For example, certain sequence-based features, such as the presence of specific dinucleotides or transcription factor binding sites, can be correlated with the likelihood of cytosine methylation. This supports the assumption that there are DNA- and sequence-related features that increase the probability of methylation.\n\nAdditionally, the use of the Matthews correlation coefficient (MCC) as a performance metric provides a more nuanced understanding of model performance, especially in imbalanced datasets where CpG islands tend to be unmethylated. This metric helps in evaluating the model's ability to distinguish between methylated and unmethylated states, offering insights into the model's predictive accuracy beyond simple accuracy measures.\n\nFurthermore, the webservice we developed allows users to visualize the methylation status of CpG islands across different cell types and chromosomes. This tool provides a way to explore the predictions in a more interpretable manner, allowing users to compare experimental data with predicted data and understand the methylation landscape better.\n\nIn summary, while the core predictive models are black-box in nature, the use of biologically meaningful features and tools like the webservice and MCC metric add layers of interpretability to our approach.",
  "model/output": "The model encompasses both classification and regression approaches. For classification, support vector machines (SVMs) with radial basis function (RBF) and linear kernels were employed to predict the methylation status of CpG islands as either methylated or unmethylated. These models were evaluated using metrics such as accuracy and Matthews correlation coefficient (MCC). Additionally, a quantitative prediction approach was explored using support vector regression (SVR) models. These regression models were trained to predict the actual methylation percentage of CpG islands, rather than a binary distinction. The performance of these quantitative models was assessed using error rates, specifically the average absolute error (AAE), which measures the average difference between the actual and predicted methylation values. The models were validated using datasets from the ENCODE consortium, with training and testing splits to ensure robust evaluation. The results indicated that the models could accurately predict methylation states and percentages, with performance improving as more data was available for training.",
  "model/duration": "Not enough information is available.",
  "model/availability": "A Java application has been developed to preprocess input datasets and generate features for this study. This application is publicly available at http://www.cogsys.cs.uni-tuebingen.de/software/dna-methylation/. The page includes documentation for the application, example datasets, and the predicted methylation states for the NAME21 dataset. The application can read tab-separated files containing probe or CpG island locations and methylation intensities. It can map probes to CpG islands, lift coordinates between different releases of the human genome, and generate features for all 15 mentioned feature classes. The generated feature file can then be used with various machine learning applications, such as LIBSVM, to train a model and evaluate classifiers or feature classes. The application is designed to be user-friendly and accessible, allowing researchers to replicate and build upon the methods described in this study.",
  "evaluation/method": "The evaluation of our method involved a rigorous process to ensure its accuracy and reliability. We employed a ten-fold cross-validation technique, which was repeated ten times with different random seeds, resulting in 100 experiments for each reported value. This approach helped to mitigate the variability and ensure that the results were robust.\n\nFor the support vector machine (SVM) predictions, we utilized LIBSVM and LIBLINEAR. Other classifiers were implemented using the WEKA library. The evaluation focused on both classification and regression tasks.\n\nIn the validation phase, we used the HEPG2 dataset from ENCODE, which is a binary dataset containing sequence regions scored as either unmethylated (0) or methylated (1000). These sequence regions were mapped to CpG islands, and each CpG island was assigned a methylation value based on the average methylation of overlapping sequence regions. Regions that did not overlap with CpG islands were discarded. We also removed differentially methylated CpG islands to avoid ambiguity in the methylation status.\n\nThe dataset was then split into training and test sets using stratified sampling to maintain the same percentage of methylated CpG islands in the training set as in the entire dataset. Additionally, we performed another validation by using all CpG islands from chromosome 21 as the training set and the remaining chromosomes as the test set. This ensured that no CpG islands used in training were included in the evaluation, providing an unbiased assessment of the method's performance.\n\nFor the quantitative prediction approach, we used the GM12878 dataset from ENCODE, which is non-binary. Similar mapping and averaging processes were applied to this dataset. We picked 10% of the CpG islands for training and evaluated the regression model by comparing the predicted methylation values with the experimental data.\n\nThe performance of our method was assessed using various metrics, including accuracy, Matthews correlation coefficient (MCC), and the area under the receiver operating characteristics curve (AUC) for classification tasks. For regression tasks, we used the average absolute error (AAE) to measure the difference between the actual and predicted methylation values. These metrics provided a comprehensive evaluation of the method's predictive performance.",
  "evaluation/measure": "In our evaluation, we employed several performance metrics to comprehensively assess the predictive power of our models. The primary metrics reported include accuracy, Matthews correlation coefficient (MCC), and the area under the receiver operating characteristics curve (AUC). Accuracy is defined as the percentage of correct predictions out of all predictions made. However, due to the imbalanced nature of our datasets, where CpG islands tend to be unmethylated, accuracy alone can be misleading. Therefore, we also calculated the MCC, which is particularly suited for imbalanced binary datasets. MCC provides a correlation coefficient between -1 (perfect inverse prediction) and 1 (perfect prediction), with 0 indicating random prediction. This metric is crucial for DNA methylation predictions because it accounts for the underlying class distribution, making it a more reliable measure than accuracy alone.\n\nAdditionally, we used the AUC to evaluate the performance of our models. AUC measures the ability of the model to distinguish between the classes (methylated and unmethylated CpG islands) and provides a single scalar value that summarizes the performance across all classification thresholds. This metric is useful for understanding the overall effectiveness of our predictive models.\n\nFor support vector regression models, we employed the average absolute error (AAE) to measure performance. AAE calculates the average difference between the actual and predicted methylation values, providing a clear indication of the model's predictive accuracy.\n\nThese metrics are representative of those commonly used in the literature for evaluating DNA methylation prediction models. They provide a robust and comprehensive assessment of our models' performance, ensuring that our results are both reliable and comparable to other studies in the field.",
  "evaluation/comparison": "A comparison to publicly available methods was indeed performed on benchmark datasets. Specifically, the approach was compared to the method developed by Bock et al., which is one of the latest and most impactful approaches in the field. The CpG island coordinates and binary methylation states from the human blood lymphocytes dataset used by Bock et al. were lifted to the NCBI 36 release of the human genome. Features were generated, and support vector machines (SVMs) were trained using the same procedures applied to the NAME21 data. The prediction results were then compared, with our approach achieving a maximal prediction accuracy of 95.76% compared to 91.5% by Bock et al., and a maximum correlation coefficient of 0.87 compared to 0.74.\n\nAdditionally, a comparison was made using the HEP pilot phase data, further validating the performance of our method. The results of these comparisons are detailed in Table 4, which includes other approaches that have also been compared to Bock et al.\n\nRegarding simpler baselines, the performance of various machine learning algorithms was evaluated, including support vector machines with different kernels, decision trees, naive Bayesian networks, k-nearest neighbor, random decision forest, and the K* classifier. Support vector machines, particularly with a linear kernel, outperformed other methods, achieving the highest Matthews correlation coefficient. This indicates that our feature set and model selection are robust and effective for predicting DNA methylation states.",
  "evaluation/confidence": "To ensure the reliability of our results, we employed a rigorous evaluation process. We measured the performance of our algorithms using Matthews correlation coefficient (MCC), accuracy, and the area under the receiver operating characteristics curve (AUC). These metrics were calculated for each prediction, and all values are averages of ten repetitions using ten-fold cross-validation. This approach provides a robust estimate of our model's performance and accounts for variability in the data.\n\nThe use of ten-fold cross-validation with ten repetitions helps to mitigate the risk of overfitting and provides a more reliable estimate of the model's performance. This method ensures that each data point is used for both training and validation, leading to a more comprehensive evaluation.\n\nWe also compared our method against other published approaches. For instance, when using the human peripheral blood lymphocytes dataset, our method achieved a maximal prediction accuracy of 95.76% and an MCC of 0.87, outperforming previous methods such as Bock et al., who reported an accuracy of 91.5% and an MCC of 0.74. This comparison was conducted using the same input data and evaluation techniques, ensuring a fair assessment.\n\nAdditionally, we validated our method using datasets from the ENCODE consortium. For the quantitative DNA methylation prediction approach, we used the ENCODE HudsonAlpha Methyl27 GM12878 replicate 1 dataset, and for validation, we used the ENCODE HudsonAlpha MethylSeq HEPG2, Pcr2x, replicate 1 dataset. These external validations further support the generalizability and robustness of our approach.\n\nIn summary, our evaluation process includes multiple layers of validation, ensuring that our performance metrics are reliable and statistically significant. The use of cross-validation, comparison with other methods, and external dataset validation collectively demonstrate the superiority and confidence in our method's performance.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. The study primarily focuses on the datasets used for training and validation, such as the NAME21 Consortium dataset and datasets from the ENCODE consortium. While the Java application developed for preprocessing input datasets and generating features is available at a specified URL, there is no direct mention of the raw evaluation files being released alongside it. Therefore, it is not clear whether these files are publicly accessible or under what license they might be distributed."
}