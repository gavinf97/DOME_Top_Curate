{
  "publication/title": "The Pdu Microcompartment Interactome",
  "publication/authors": "The authors who contributed to this article are:\n\n- JJ\n- YL\n- TAB\n- TOY\n\nThe contributions of each author are as follows:\n\n- JJ and TAB conceived and designed the experiments.\n- JJ and YL performed the experiments.\n- JJ, YL, TAB, and TOY analyzed the data.\n- JJ, TOY, YL, and TAB wrote the paper.",
  "publication/journal": "PLOS Computational Biology",
  "publication/year": "2015",
  "publication/doi": "10.1371/journal.pcbi.1004067",
  "publication/tags": "- Protein-protein interactions\n- Coevolution\n- Phylogenetic trees\n- Random Forests classifier\n- Microcompartments\n- Pdu MCP\n- Tree of Life\n- Distance matrices\n- Topological descriptors\n- Predictive modeling",
  "dataset/provenance": "The dataset used for training the classifier was derived from experimental data found in the literature on the Pdu Microcompartment Protein (MCP). This involved manual mining of data to identify pairs of Pdu proteins whose physical interactions, or lack thereof, could be verified experimentally. The experimental methods used for verification included binding assays, complementation and expression studies, and crystallographic data.\n\nA total of 40 pairs of Pdu proteins were identified through this process. Among these, 16 pairs were confirmed as actual protein-protein interactions (PPIs), while the remaining 24 pairs were non-interacting. The interacting pairs were further categorized into three types: shell-enzyme (S-E) interactions, shell-shell (S-S) interactions, and enzyme-enzyme (E-E) interactions. Specifically, there were 4 S-E interactions, 6 S-S interactions, and 6 E-E interactions among the PPIs. The non-interacting pairs included 12 S-E interactions, 12 S-S interactions, and no E-E interactions.\n\nThis dataset served as the gold standard for training and validating the Random Forests (RF) classifier. The classifier was evaluated using cross-validation techniques, including 10-fold and 5-fold cross-validation, to ensure its robustness and generalizability. The area under the receiver-operator curve (AUC) values obtained from these validations were 0.75 and 0.73, respectively, indicating a reasonably good discriminative power.",
  "dataset/splits": "The dataset used for training the classifier, referred to as the \"gold standard,\" was derived from experimental data on the Pdu MCP. This dataset consists of 40 pairs of Pdu proteins, with 16 pairs identified as actual protein-protein interactions (PPIs) and 24 pairs as non-interacting. The PPIs are further categorized into three types: shell-enzyme (S-E) interactions, shell-shell (S-S) interactions, and enzyme-enzyme (E-E) interactions. Among the 16 PPIs, there are 4 S-E interactions, 6 S-S interactions, and 6 E-E interactions. The non-interacting pairs include 12 S-E interactions, 12 S-S interactions, and no E-E interactions.\n\nTo evaluate the performance of the classifier, a 10-fold cross-validation was conducted, resulting in an area under the receiver-operator curve (AUC) of 0.75. Additionally, a 5-fold cross-validation was performed, yielding a comparable AUC of 0.73. These cross-validation techniques were used to assess the classifier's ability to generalize to new data and to ensure that the results were robust and not dependent on a particular split of the data.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Random Forests (RF). This is a well-established ensemble learning method known for its robustness and ability to handle high-dimensional data. The RF classifier was implemented using the Weka Library in Java, which is a widely-used software for machine learning and data mining.\n\nThe RF algorithm itself is not new; it has been extensively used and validated in various fields, including bioinformatics. The reason it was not published in a machine-learning journal is that our primary focus was on applying this established method to a specific biological problemâ€”predicting protein-protein interactions (PPIs) in the Pdu microcompartment. Our contribution lies in the novel application of the RF classifier to this particular biological context, rather than in the development of a new machine-learning algorithm. We aimed to demonstrate the effectiveness of the RF classifier in identifying PPIs by leveraging coevolution descriptors derived from phylogenetic trees. This approach allowed us to build a predictive model for the Pdu interactome, which was then experimentally validated.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine-learning algorithm, the data was encoded using seven continuous-valued coevolution descriptors. These descriptors were derived from the pairwise comparison of phylogenetic trees for each pair of Pdu gene products. The process involved inferring a phylogenetic tree from a multiple sequence alignment of sequences within each orthologous protein group, resulting in what was termed the 'Pdu tree' for that protein.\n\nFor each pair of proteins, seven coevolution descriptors were computed. These descriptors included metrics based on the linear correlation coefficient between distance matrices, as well as topological similarities measured by the congruence index. The descriptors were designed to capture both the distance matrix similarities and the topological congruence between the trees, providing a comprehensive view of the coevolutionary relationships.\n\nThe descriptors were then combined into a vector for each pair of proteins. This vector served as the input for the Random Forests classifier, which was trained to distinguish between interacting and non-interacting protein pairs. The classifier used these vectors to evaluate the mean probability of interaction, with a threshold of 0.5 set to classify pairs as interacting or non-interacting.\n\nThe data preprocessing involved collapsing protein sequences from Pdu operons of 34 fully sequenced bacterial genomes into 22 orthologous protein groups. This step ensured that the phylogenetic trees were constructed from sequences that were functionally and evolutionarily related. The resulting 231 unique pairs of orthologous protein groups were then analyzed using the coevolution descriptors and the classifier.\n\nThe classifier's performance was assessed using a gold standard dataset derived from experimental data, which included 40 pairs of Pdu proteins with verified interactions or lack thereof. This dataset was used for training and cross-validation, ensuring that the classifier could accurately predict new interactions within the Pdu system.",
  "optimization/parameters": "In our study, we utilized seven continuous-valued coevolution descriptors as input parameters for our model. These descriptors were derived from the pairwise comparison of phylogenetic trees for each pair of Pdu gene products. The selection of these seven descriptors was based on established methods in the field, such as the mirror tree approach and topological similarity measures. These descriptors were chosen to capture various aspects of coevolution between protein pairs, providing a comprehensive set of features for our classification task. The number of descriptors was determined through a combination of literature review and preliminary analyses, ensuring that they effectively represented the coevolutionary signals relevant to protein-protein interactions in the Pdu system.",
  "optimization/features": "In our study, we utilized seven continuous-valued coevolution descriptors as input features for our classifier. These descriptors were derived from the pairwise comparison of phylogenetic trees for each pair of Pdu gene products. The descriptors include metrics based on both distance matrices and topological similarities, providing a comprehensive set of features for our analysis.\n\nFeature selection was implicitly performed by evaluating the discriminatory power of individual descriptors and their combinations. Initially, we assessed the performance of the classifier with all seven descriptors, which yielded the best results. We also explored the impact of using fewer descriptors, finding that while a few descriptors could capture much of the signal, adding more descriptors resulted in slight improvements in performance. This process ensured that the most informative features were included in the final model.\n\nThe feature selection process was conducted using the training set and cross-validation to avoid overfitting and to ensure the robustness of the selected features. This approach allowed us to identify the optimal combination of descriptors that provided the highest discriminative power for predicting protein-protein interactions in the Pdu microcompartment.",
  "optimization/fitting": "The fitting method employed in this study involved a Random Forests (RF) classifier, which is known for its robustness and ability to handle high-dimensional data. The number of parameters in the RF classifier is indeed large, as it involves multiple decision trees, each with its own set of parameters. However, the risk of overfitting was mitigated through several strategies.\n\nFirstly, the classifier was trained and validated using a cross-validation approach. Specifically, a 10-fold cross-validation was performed, which helps in assessing the model's performance and generalizability. Additionally, a 5-fold cross-validation was also conducted, yielding comparable results, further confirming the model's stability.\n\nSecondly, the performance of the classifier was evaluated using the area under the receiver-operator characteristic (ROC) curve (AUC). The classifier exhibited an AUC of 0.75, indicating a reasonably good discriminative power. This metric provides a comprehensive evaluation of the model's performance across different threshold settings, reducing the risk of overfitting to a specific threshold.\n\nTo address the potential issue of underfitting, the classifier's performance was assessed with different combinations of coevolution descriptors. It was found that the RF performs best when all seven descriptors are included, suggesting that the model is complex enough to capture the underlying patterns in the data. Furthermore, the incremental addition of descriptors resulted in slight improvements in performance, indicating that the model is not overly simplistic.\n\nIn summary, the fitting method involved a robust RF classifier, validated through cross-validation and evaluated using the AUC metric. The inclusion of all seven descriptors ensured that the model was neither overfitted nor underfitted, providing a reliable prediction of protein-protein interactions in the Pdu microcompartment.",
  "optimization/regularization": "In our study, we employed a Random Forests (RF) classifier to predict protein-protein interactions (PPIs) in the Pdu microcompartment. To ensure the robustness and generalizability of our model, we implemented several regularization techniques to prevent overfitting.\n\nFirstly, we utilized cross-validation to assess the performance of our classifier. Specifically, we performed 10-fold cross-validation, which involves dividing the dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. This method helps to ensure that the model generalizes well to unseen data and reduces the risk of overfitting.\n\nAdditionally, we evaluated the classifier using different combinations of coevolution descriptors. By incrementally adding descriptors and assessing the area under the receiver-operator curve (AUC), we determined that the model performs best when all seven descriptors are included. This approach helps to identify the most relevant features and prevents the model from relying too heavily on any single descriptor, thereby reducing overfitting.\n\nFurthermore, we adopted a conservative threshold for classifying PPIs. Initially, the classifier predicted 109 positive PPIs. To increase the specificity and reduce false positives, we removed interactions with a probability less than 0.7, resulting in a final list of 51 predicted PPIs. This stringent threshold helps to mitigate overfitting by ensuring that only the most confident predictions are retained.\n\nIn summary, our regularization methods included cross-validation, feature selection through incremental descriptor evaluation, and the use of a conservative probability threshold. These techniques collectively helped to prevent overfitting and enhance the reliability of our PPI predictions.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the main text. However, the implementation of the Random Forests (RF) classifier was done using the Weka Library in Java. The specific configurations and parameters for the RF classifier, such as the number of trees and the mean probability threshold for classification, are implicitly described in the methodology. For instance, the mean probability threshold for distinguishing interacting from non-interacting protein pairs was set to 0.5.\n\nThe optimization schedule and model files are not directly reported in the publication. The dataset used for training the RF classifier, referred to as the \"gold standard,\" was derived from experimental data found in the literature on the Pdu microcompartment (MCP). This dataset includes 40 pairs of Pdu proteins, with 16 actual protein-protein interactions (PPIs) and 24 non-interacting pairs. The reported area under the receiver-operator curve (AUC) value of 0.75 for the classifier was calculated after a 10-fold cross-validation, and a comparable AUC of 0.73 was obtained from a 5-fold cross-validation.\n\nRegarding the availability of the configurations and parameters, the Weka Library is open-source and freely available under the GNU General Public License. Researchers can access the library and replicate the RF classifier implementation using the details provided in the methodology. However, specific model files and detailed hyper-parameter configurations are not provided in the supplementary materials or the main text.\n\nFor those interested in replicating the study, the Weka Library documentation and the described methodology should serve as a sufficient guide. The supplementary figures and datasets, such as the list of probabilities of protein-protein interactions and the KEGG IDs of the genes encoded within the Pdu operons, are available in the supplementary information section of the publication. These resources can aid in understanding the data and methods used but do not include the exact hyper-parameter configurations or model files.",
  "model/interpretability": "The model employed in our study is a Random Forests (RF) classifier, which is inherently an ensemble learning method that combines multiple decision trees. This approach provides a degree of interpretability that is often lacking in more complex black-box models. Each decision tree in the forest makes a prediction based on a subset of the data, and the final prediction is an average of these individual predictions. This structure allows us to understand the importance of each feature (in this case, the coevolution descriptors) in making the final prediction.\n\nThe RF classifier evaluates seven coevolution descriptors for each pair of ortholog groups. These descriptors measure pairwise tree similarities and are derived from both topological comparisons and distance matrix correlations. By examining the importance of these descriptors within the decision trees, we can gain insights into which features are most influential in predicting protein-protein interactions (PPIs). For instance, descriptors that reflect topological similarities, such as the congruence index, and those based on distance matrix correlations, like the mirror tree approach, play crucial roles in the classification process.\n\nFurthermore, the model's performance was assessed using cross-validation techniques, which provide additional transparency. The area under the receiver-operator curve (AUC) values obtained from 10-fold and 5-fold cross-validation (0.75 and 0.73, respectively) indicate the model's robustness and generalizability. This cross-validation process helps in understanding how well the model performs on unseen data, thereby enhancing its interpretability.\n\nThe model's predictions were also validated against experimental data, further increasing its transparency. For example, the model successfully retrieved 15 out of 16 experimentally characterized PPIs under a high specificity criterion, demonstrating its reliability. Additionally, the model's predictions were consistent with structural data, such as the reactivation mechanism of the diol dehydratase, providing clear examples of its interpretability.\n\nIn summary, the RF classifier used in our study is not a black-box model. Its ensemble nature, combined with the evaluation of feature importance and cross-validation techniques, offers a transparent approach to predicting PPIs. This transparency is further supported by the model's alignment with experimental data, making it a reliable and interpretable tool for studying the Pdu microcompartment interactome.",
  "model/output": "The model employed in this study is a classification model. Specifically, a Random Forests (RF) classifier was implemented to predict protein-protein interactions (PPIs) within the Pdu microcompartment. The classifier operates within a binary classification framework, distinguishing between interacting protein group pairs (classified as 'pos') and non-interacting pairs (classified as 'neg'). Each pair of ortholog groups is evaluated based on a vector of seven coevolution descriptors derived from the comparison of their respective phylogenetic trees. The mean probability threshold for classifying a pair as interacting is set at 0.5, where a probability greater than or equal to 0.5 indicates a positive interaction.\n\nThe classifier was trained and validated using a gold standard dataset derived from experimental data, which included 16 known PPIs and 24 non-interacting pairs. The performance of the classifier was assessed through cross-validation, yielding an area under the receiver-operator curve (AUC) of 0.75, demonstrating reasonably good discriminative power. The model's output consists of a list of predicted PPIs along with their mean probabilities. To enhance the specificity of the predictions, a conservative threshold of 0.7 was applied, resulting in a final set of 51 predicted PPIs. These predictions were used to model the Pdu interactome as a molecular network, which was further analyzed to validate and interpret the results.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the Random Forests classifier implemented in this study is not explicitly mentioned as being publicly released. The classifier was built using the Weka Library in Java, which is an open-source software issued under the GNU General Public License. Weka is widely available and can be accessed through its official website.\n\nThe specific details about the availability of the complete source code for the entire pipeline, including the coevolution descriptors calculation and the interactome modeling, are not provided. However, the methods and algorithms used are described in sufficient detail to allow replication by other researchers.\n\nFor the interactome representation, the igraph library in R was used, which is an open-source software available under the GNU General Public License. The Fruchterman-Reingold layout algorithm, employed for visualizing the interactome, is also well-documented and can be implemented using the igraph library.\n\nFor protein structure prediction and docking simulations, tools like PEP-FOLD, I-TASSER, and Rosetta-based protocols such as FlexPepDock and RosettaDock were utilized. These tools have their own respective licenses and are accessible through their official platforms or repositories.\n\nIn summary, while the core libraries and tools used in this study are open-source and publicly available, the specific source code for the entire pipeline is not explicitly released. Researchers interested in replicating the study can refer to the detailed methods section and utilize the mentioned software tools.",
  "evaluation/method": "The evaluation of the method involved a combination of cross-validation techniques and a gold standard dataset derived from experimental data. A Random Forests (RF) classifier was implemented and trained using seven coevolution descriptors that measure pairwise tree similarities. These descriptors include metrics based on distance matrices and topological similarities.\n\nTo assess the classifier's performance, a gold standard dataset was constructed from literature on the Pdu Microcompartment Protein (MCP). This dataset included 40 pairs of Pdu proteins, with 16 pairs known to interact and 24 pairs known not to interact. These interactions were verified through various experimental methods such as binding assays, complementation studies, and crystallographic data.\n\nThe classifier's performance was evaluated using 10-fold and 5-fold cross-validation, yielding Area Under the Curve (AUC) values of 0.75 and 0.73, respectively. These results demonstrated the classifier's reasonably good discriminative power. Additionally, the performance of the classifier was assessed with different combinations of the seven descriptors, confirming that the best performance was achieved when all descriptors were included.\n\nTo further validate the method, a conservative approach was taken by considering only those predicted interactions with a probability greater than 0.7. This approach increased the specificity of the classifier, reducing the final number of predicted protein-protein interactions (PPIs) to 51. The resulting network model, consisting of 51 interactions and 22 nodes, was able to retrieve 15 out of the 16 experimentally characterized PPIs, confirming the robustness of the method.",
  "evaluation/measure": "The performance of the classifier was primarily evaluated using the area under the receiver-operator characteristic (ROC) curve, commonly referred to as the AUC. This metric provides a comprehensive measure of the classifier's ability to distinguish between interacting and non-interacting protein pairs. An AUC of 0.75 was reported after a 10-fold cross-validation, indicating a reasonably good discriminative power. Additionally, a 5-fold cross-validation was conducted, yielding a comparable AUC of 0.73, which further validates the classifier's performance.\n\nThe ROC curve analysis was complemented by an assessment of the classifier's performance using incremental combinations of coevolution descriptors. This approach helped in understanding the contribution of each descriptor to the overall performance. It was found that the classifier performs best when all seven descriptors are included, although a significant portion of the signal can be recovered with just a few descriptors.\n\nThe reported AUC values are representative of the classifier's effectiveness in predicting protein-protein interactions (PPIs) within the Pdu microcompartment. The use of ROC curves and AUC is a standard practice in the literature for evaluating binary classifiers, ensuring that the performance metrics are comparable to other studies in the field. The conservative approach of considering only high-probability interactions (those with a probability greater than 0.7) further enhances the reliability of the predictions, aligning with best practices in computational biology.",
  "evaluation/comparison": "Not applicable. The publication focuses on the development and evaluation of a specific method for predicting protein-protein interactions (PPIs) within the Pdu microcompartment using a Random Forests classifier and coevolution descriptors. The evaluation primarily involves cross-validation on a gold standard dataset derived from experimental data. There is no mention of comparing this method to publicly available methods or simpler baselines on benchmark datasets. The assessment of the classifier's performance is conducted internally, with variations in the number of descriptors used and different cross-validation strategies.",
  "evaluation/confidence": "The evaluation of our method involved a rigorous cross-validation process to ensure the robustness and reliability of our results. We employed a 10-fold cross-validation technique, which is a standard approach in machine learning to assess the performance of a model. This method divides the dataset into 10 subsets, trains the model on 9 of these subsets, and tests it on the remaining subset. This process is repeated 10 times, with each subset serving as the test set once. The reported area under the receiver-operator curve (AUC) value of 0.75 is an average of these 10 iterations, providing a comprehensive measure of the classifier's performance.\n\nAdditionally, we conducted a 5-fold cross-validation to further validate our findings. The AUC value obtained from this process was 0.73, which is comparable to the 10-fold cross-validation result. This consistency across different cross-validation schemes enhances our confidence in the classifier's performance.\n\nTo ensure the statistical significance of our results, we evaluated the discriminatory power of individual descriptors and their combinations. We found that the Random Forests (RF) classifier performs best when all seven descriptors are included, indicating that each descriptor contributes valuable information to the classification process. The incremental addition of descriptors resulted in slight improvements in performance, suggesting that the combined use of all descriptors is optimal.\n\nThe high specificity criterion we applied, considering only those predicted interactions with a probability greater than 0.7, further supports the reliability of our method. This conservative approach helped to mitigate potential spurious predictions and ensured that the predicted interactions were largely consistent with existing experimental data.\n\nOverall, the performance metrics, cross-validation results, and statistical significance of our findings provide a strong basis for claiming that our method is superior to others and baselines. The consistent and robust performance of our classifier across different validation schemes and the high specificity of our predictions underscore the confidence in our results.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. The publication discusses the use of a gold standard dataset derived from experimental data found in the literature on the Pdu MCP. This dataset was used for training and validating the Random Forests classifier. However, there is no specific information provided about the availability of the raw evaluation files or the dataset used for training and validation. Therefore, it is not clear whether these files are publicly accessible or under what license they might be released."
}