{
  "publication/title": "DISOPRED3: precise disordered region predictions with annotated protein-binding activity",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2015",
  "publication/doi": "10.1093/bioinformatics/btu744",
  "publication/tags": "- Structural bioinformatics\n- Intrinsically disordered regions (IDRs)\n- Protein disorder prediction\n- Protein-binding site annotation\n- Machine learning in bioinformatics\n- Support vector machines (SVM)\n- Protein-protein interactions\n- Bioinformatics tools\n- Computational biology\n- Protein function annotation",
  "dataset/provenance": "The datasets used for protein disorder prediction were compiled from two main sources. The first dataset consisted of 228 entries from the Disprot v5.0 database, specifically those derived from NMR or biophysical methods. The second dataset was a redundancy-reduced subset of high-resolution X-ray structure chains from the Protein Data Bank (PDB), compiled in February 2010. These chains were obtained from the PISCES database and had a sequence identity of less than 90%. Chains shorter than 25 amino acids were excluded. Missing residues, including those with zero occupancy, were treated as disordered. Position-specific scoring matrix (PSSM) scores were calculated for each residue using PSI-BLAST with three iterations against the UniRef90 database.\n\nFor protein-binding site prediction, an initial set of 840 peptides, ranging from 5 to 25 amino acids in length and solved in complex with globular protein domains, was obtained from a previous study. After filtering out synthetic constructs and discontinuous fragments, 5501 amino acids from 397 regions in 372 UniProtKB sequences remained. Negative training examples were derived from unbound protein domain linker regions in known protein structures, specifically 1164 linkers annotated in CATH v.3.5, spanning between 5 and 60 amino acids.\n\nThe datasets were carefully curated to ensure minimal overlap and to address biases, with sequence identity thresholds and E-value cut-offs applied during training to exclude similar sequences. The positive training set for protein-binding site prediction included 104 UniProtKB chains that were also used as positive examples for disordered residue prediction, reflecting the different length requirements for inclusion in the two training sets. The negative examples were screened for interactions with other molecules, ensuring they were truly unbound.",
  "dataset/splits": "The dataset was split into training and test sets for the purpose of evaluating the performance of the predictors.\n\nThe training set consisted of two main datasets. The first dataset included all entries from the Disprot v5.0 database flagged as being derived from either NMR or biophysical methods, totaling 228 entries. The second dataset was a redundancy-reduced subset of high-resolution X-ray structure chains from the PDB, compiled in February 2010. Chains shorter than 25 amino acids were discarded. Position-specific scoring matrix (PSSM) scores were calculated for each residue using three iterations of PSI-BLAST running on the UniRef90 database with an inclusion E-value threshold of 0.001.\n\nThe positive training set for protein-binding site prediction was made up of 5501 amino acids from 397 regions occurring in as many PDB chains (372 UniprotKB sequences). The negative training set consisted of 4930 amino acids from 373 protein domain linkers occurring in 322 PDB chains (297 UniprotKB sequences).\n\nFor the test set, an independent benchmark set was built by thoroughly mining database annotations and scientific reports. This set included 29 protein chains, which have been investigated using biophysical techniques and have been shown to be disordered in isolation and to fold upon protein binding. These sequences include 4077 disordered residues forming 36 regions, within which 37 protein-binding sites occur spanning between 5 and 47 positions and comprising a total of 708 amino acids.",
  "dataset/redundancy": "The datasets used for training and testing were carefully curated to ensure independence and reduce redundancy. For the protein disorder prediction, two main datasets were concatenated. The first dataset consisted of entries from the DisProt v5.0 database, specifically those derived from NMR or biophysical methods. The second dataset was a redundancy-reduced subset of high-resolution X-ray structure chains from the PDB, compiled from PISCES. Chains shorter than 25 amino acids were discarded, and missing residues were treated as disordered. Position-specific scoring matrix (PSSM) scores were calculated using PSI-BLAST with an inclusion E-value threshold of 0.001.\n\nFor protein-binding site prediction, a set of 840 peptides solved in complex with globular protein domains was initially obtained. After removing synthetic constructs and regions with high sequence identity, the positive training set consisted of 5501 amino acids from 397 regions in 372 UniProtKB sequences. Negative training examples were obtained from unbound protein domain linker regions in known protein structures, with a total of 1164 linkers annotated in CATH v.3.5.\n\nTo ensure the independence of training and test sets, separate training runs were carried out for each of the 29 test proteins. During training, any sequence found to be similar to the target chain was excluded. A sequence identity threshold of 25% was used for the SVM classifier based on sequence data alone, and a PSI-BLAST E-value cut-off of 0.001 was used for all profile-based predictors. This approach helped to address the imbalance between positive and negative classes and ensured that the model was trained on diverse and independent data.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the field. The use of stringent criteria for sequence similarity and the inclusion of diverse sources of data, such as NMR, biophysical methods, and high-resolution X-ray structures, ensures that the datasets are representative and robust. The careful curation of the datasets and the enforcement of independence between training and test sets contribute to the reliability and generalizability of the predictions made by the models.",
  "dataset/availability": "The data used in our study, including the specific data splits, are not publicly released in a forum. However, the reference annotations and predictions collected for this study are available from our own website. This allows readers to easily reproduce our results or compare their own methods. The website provides access to the necessary information to validate and build upon our findings, ensuring transparency and reproducibility in our research.",
  "optimization/algorithm": "The optimization algorithm employed in our work utilizes Support Vector Machines (SVMs), specifically the LIBSVM implementation with a radial basis function kernel. SVMs are a well-established class of machine-learning algorithms known for their effectiveness in high-dimensional spaces and their ability to handle both linear and non-linear classification tasks.\n\nThe choice of SVM for our study was driven by its suitability for handling imbalanced datasets, which is a common challenge in bioinformatics, particularly when dealing with protein disorder predictions. The LIBSVM tool was selected due to its robustness and efficiency in parameter optimization through cross-validation.\n\nThe algorithm is not new; it has been extensively used and validated in various domains, including bioinformatics. The decision to use an established algorithm like LIBSVM was based on its proven track record and the specific requirements of our study, which include the need for precise parameter tuning and the ability to manage class imbalances effectively.\n\nGiven the focus of our publication on protein disorder prediction and the integration of multiple predictors, the optimization algorithm serves as a crucial component in enhancing the accuracy and reliability of our predictions. The use of a well-known algorithm like LIBSVM ensures that our results are reproducible and comparable with other studies in the field.",
  "optimization/meta": "The model described in this publication is indeed a meta-predictor, integrating the outputs of multiple independent tools through various algorithms. This approach leverages the strengths of different machine-learning techniques to enhance the overall prediction accuracy.\n\nThe meta-predictor combines three primary components:\n\n1. **Support Vector Machine (SVM) Classifier**: This component is used for identifying protein-binding sites within disordered regions. It operates on a sliding window of 15 residues and considers various features, including sequence data, PSSM values, and additional contextual information such as the length and position of the input region relative to the whole protein sequence.\n\n2. **Neural Network**: This component is designed to counter the tendency to under-predict long disordered regions. It is trained on data rich in long disordered regions and uses a neural network architecture to improve the prediction of extended disordered segments.\n\n3. **Nearest Neighbor Classifier**: This component is added for practical reasons, as it requires no training and can be easily updated with new data. It compares every window of seven residues in the target protein with seven-residue windows from a reference set, using the total PSSM score to decide the order/disorder label for each residue.\n\nThe integration of these components is achieved through a small second-stage neural network. This network combines the outputs of the three primary predictors into a single prediction output. It comprises 15/2 + 4 inputs, 15 hidden units, and 2 output units (ordered/disordered). The inputs represent a window of 15 positions centered around the residue being classified, with three outputs from the first-level component methods (SVM, neural network, and nearest neighbor classifier) plus an additional input per position to indicate missing data.\n\nThe training data for each component is carefully designed to ensure independence. For instance, during the training of the SVM classifier, sequences similar to the target chain are excluded from the training data. This is done using a sequence identity threshold of 25% for the SVM classifier based on sequence data alone and a PSI-BLAST E-value cut-off of 0.001 for all profile-based predictors. This ensures that the training data is independent and reduces the risk of overfitting.\n\nIn summary, the meta-predictor integrates SVM, neural network, and nearest neighbor classifiers to enhance the prediction of disordered regions and protein-binding sites. The training data for each component is designed to be independent, ensuring robust and accurate predictions.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithms. For the SVM classifier used in protein-binding site prediction, we employed a sliding window of size 15. Within this window, we derived three independent SVM classifiers based on different types of data encoding.\n\nFirst, we encoded single sequences where each amino acid was represented by similarity values from the Blosum62 matrix. This approach captures the evolutionary relationships between amino acids.\n\nSecond, we utilized PSSM values obtained after three iterations of PSI-BLAST against the UniRef90 database, with a profile-inclusion threshold of 0.001. These PSSM scores were linearly scaled to a range of [0.0, 1.0] based on the maximum and minimum values observed for each amino acid in the training set. This scaling ensures that the PSSM values are normalized and comparable across different sequences.\n\nThird, we combined the PSSM scores with additional features, including the length of the input region, the start and end positions of the region relative to the whole protein chain, a flag for windows extending beyond the protein termini, and the amino acid composition of the window. The protein sequence length was encoded using a natural logarithmic scale to account for its wide range of values.\n\nFor the nearest neighbor classifier, we compared every window of seven residues in the target protein with every seven-residue window from the reference set. The comparison was based on the total PSSM score, and the order/disorder label for each residue was decided by transferring the labels from the reference protein windows that had the highest match scores. This method allows for easy updates and maintenance, as it does not require extensive training.\n\nIn summary, our data encoding and preprocessing involved the use of Blosum62 similarity values, scaled PSSM scores, and additional features such as region length, position, and amino acid composition. These encoding methods ensured that our machine-learning algorithms could effectively learn from the data and make accurate predictions.",
  "optimization/parameters": "In our study, we utilized the LIBSVM tool with a radial basis function kernel to optimize the parameters for our support vector machine (SVM) classifier. The key parameters we focused on were the trade-off (C) and gamma (Î³) parameters. These parameters were selected based on their ability to maximize the average Matthews correlation coefficient (MCC) across 10-fold cross-validation experiments. The imbalance between positive and negative classes was addressed by setting the cost parameter of the positive class to the ratio of negative to positive examples used for training at each iteration. The resulting parameters were then used to train the final regression model on the entire training set. The specific values of these parameters were determined through an exhaustive search to ensure optimal performance.",
  "optimization/features": "In the optimization process, three independent SVM classifiers were employed, each utilizing a distinct set of features. The first classifier relied solely on single sequences, where each amino acid was represented by similarity values from the Blosum62 matrix. The second classifier used PSSM values obtained after three iterations of PSI-BLAST against UniRef90, with a profile-inclusion threshold of 0.001. The third classifier incorporated the same PSSM scores but also included additional features such as the length of the input region, the start and end positions of the region relative to the whole protein chain, a flag for windows extending beyond the protein termini, and the amino acid composition of the window under consideration. The PSSM scores were linearly scaled to a range of [0.0, 1.0] based on the maximum and minimum values observed for each amino acid in the entire training set, while the protein sequence length was scaled using the natural logarithmic scale.\n\nThe exact number of features (f) used as input varies depending on the classifier. For the first classifier, the number of features corresponds to the length of the sequence multiplied by the dimensionality of the Blosum62 matrix. For the second classifier, the number of features is determined by the length of the sequence multiplied by the number of PSSM values. The third classifier includes additional features beyond the PSSM values, increasing the total number of features.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the choice of features was guided by domain knowledge and the specific requirements of each classifier. The features were selected based on their relevance to the problem of predicting protein-binding sites within disordered regions. The selection process ensured that the features used were informative and relevant to the task at hand. The feature selection was done using the training set only, ensuring that the evaluation of the model's performance on the test set remained unbiased.",
  "optimization/fitting": "In our study, we employed a Support Vector Machine (SVM) classifier using the LIBSVM implementation with a radial basis function kernel. The number of parameters, specifically the trade-off and gamma parameters, was determined through a 10-fold cross-validation process. This approach helped in identifying the optimal parameters that maximized the average Matthews correlation coefficient (MCC) across the validation folds.\n\nTo address the potential issue of over-fitting, we ensured that the model's performance was evaluated on a separate validation set during each fold of the cross-validation. Additionally, we used a cost parameter for the positive class that was set to the ratio of negative to positive examples, which helped in managing the class imbalance and preventing the model from becoming too biased towards the majority class.\n\nUnder-fitting was mitigated by carefully selecting features and ensuring that the model had sufficient complexity to capture the underlying patterns in the data. The use of a radial basis function kernel allowed the SVM to model non-linear relationships, which is crucial for capturing the complexities in protein sequence data.\n\nFurthermore, we performed separate training runs for each of the 29 test proteins, excluding any sequence found to be similar to the target chain. This step helped in ensuring that the model generalized well to unseen data and did not memorize the training examples. The sequence identity threshold of 25% for the SVM classifier based on sequence data alone and a PSI-BLAST E-value cut-off of 0.001 for profile-based predictors further ensured that the model was robust and not over-fitted to the training data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method involved addressing class imbalance, which is a common issue in binary classification tasks. We tackled this by adjusting the cost parameter of the positive class to the ratio of negative to positive examples used for training at each iteration. This approach helps the classifier to pay more attention to the minority class, thereby improving its ability to generalize to unseen data.\n\nAdditionally, we utilized 10-fold cross-validation to identify the optimal trade-off and gamma parameters for our Support Vector Machine (SVM) classifier. This process involved dividing the training data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This procedure was repeated 10 times, with each subset serving as the validation set once. The parameters that yielded the highest average Matthews correlation coefficient (MCC) across these experiments were selected, ensuring that our model's performance was consistent and not merely a result of overfitting to the training data.\n\nFurthermore, we excluded any sequences from the training data that were found to be similar to the target chain. For the SVM classifier based on sequence data alone, we used a sequence identity threshold of 25%. For profile-based predictors, we applied a PSI-BLAST E-value cut-off of 0.001. This step helped to ensure that our model was not simply memorizing the training data but was instead learning general patterns that could be applied to new, unseen sequences.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we employed a radial basis function kernel with LIBSVM to identify the trade-off and gamma parameters that maximize the average Matthews correlation coefficient (MCC) across 10-fold cross-validation experiments. The imbalance between positive and negative classes was addressed by adjusting the cost parameter of the positive class to the ratio of negative to positive examples during training.\n\nThe resulting parameters were then used to train a regression model on the entire training set. While the exact model files are not explicitly provided in the publication, the methods and parameters used are thoroughly described, allowing for reproducibility. The evaluation measures, including sensitivity, specificity, precision, MCC, and F1 score, are also clearly defined and discussed.\n\nFor those interested in implementing or verifying our methods, the detailed procedures and parameters are available in the text. However, specific model files or additional resources like code implementations are not directly referenced in the provided context. Therefore, while the configurations and optimization parameters are reported, the availability of model files and additional resources is not explicitly mentioned.",
  "model/interpretability": "The model employed in our study, DISOPRED3, incorporates several components that contribute to its interpretability, making it more transparent than a typical black-box model. One of the key aspects of DISOPRED3's transparency is the use of a nearest neighbor classifier. This classifier operates by comparing every window of seven residues in the target protein with every seven-residue window from a reference set. The comparison is based on total PSSM (Position-Specific Scoring Matrix) scores, and the order/disorder label for each residue is determined by transferring labels from the reference protein windows that have the highest match scores. This method allows for a clear understanding of how predictions are made, as the labels are directly derived from similar sequences in the reference set.\n\nAdditionally, the model utilizes an SVM (Support Vector Machine) classifier with a radial basis function kernel. The parameters for this classifier, such as the trade-off and gamma parameters, are optimized to achieve the highest average Matthews correlation coefficient (MCC) across 10-fold cross-validation experiments. The cost parameter of the positive class is set to the ratio of negative to positive examples, addressing the imbalance between the positive and negative classes. This approach provides insights into how the model handles class imbalances and optimizes performance.\n\nThe use of sequence profile data, PSSM values, and additional features like the length and location of the input IDR relative to the whole protein sequence further enhances the interpretability of the model. These features are linearly scaled and incorporated into the SVM classifiers, allowing for a detailed examination of how different aspects of the sequence contribute to the predictions. For instance, the length and position of IDRs are known to correlate with general protein functional categories, providing a biological basis for the features used in the model.\n\nOverall, the combination of nearest neighbor classification, SVM with optimized parameters, and the use of biologically relevant features makes DISOPRED3 a more interpretable model. This transparency is crucial for understanding the underlying mechanisms of the predictions and for validating the model's performance in practical applications.",
  "model/output": "The model is primarily a classification model. It employs a support vector machine (SVM) classifier to predict disordered regions in proteins and to identify residues that might be part of protein-binding sites within these disordered regions. The SVM classifier uses a radial basis function kernel and is trained to optimize the Matthews correlation coefficient (MCC) across 10-fold cross-validation experiments. Additionally, a nearest neighbor classifier is used to compare windows of residues in the target protein with those in a reference set, deciding the order/disorder label based on the highest match scores. A neural network is also utilized to combine the outputs of the SVM, neural network, and nearest neighbor classifier into a single prediction output. The model's performance is evaluated using standard measures such as sensitivity, specificity, precision, MCC, and the F1 score. The output of the model includes probability scores for disordered residue predictions, which are used to generate receiver operating characteristic (ROC) curves and calculate the area under the curve (AUC). The model's design aims to reduce false positives while maintaining sensitivity, leading to improvements in precision, MCC, and AUC.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the DISOPRED3 program is not publicly released. However, the tool is accessible through an online server, which allows users to run the algorithm without needing to install or manage the software locally. This online server facilitates easy access and usage, making it convenient for researchers to perform protein disorder prediction and protein-binding site annotation within disordered regions. The server is maintained and can be updated as needed, ensuring that users have access to the latest version of the tool. For those interested in reproducing results or comparing their own methods, all reference annotations and predictions collected for this study are available from our own website. This ensures transparency and allows for independent verification of the results presented in the publication.",
  "evaluation/method": "The evaluation of the method involved several standard measures to assess the performance of binary classification. These measures included sensitivity, specificity, precision, the Matthews correlation coefficient (MCC), and the F1 score. Sensitivity, also known as recall, is the ratio of true positives to the sum of true positives and false negatives. Specificity is the ratio of true negatives to the sum of true negatives and false positives. Precision is the ratio of true positives to the sum of true positives and false positives. The MCC provides a balanced measure that considers all four outcomes of the confusion matrix. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nFor disordered residue predictions, ROC analysis was conducted using output probability scores. For each threshold value between 0.0 and 1.0, residues with scores equal to or higher than the threshold were considered putatively disordered, while the rest were considered putatively ordered. This binary classification helped calculate true positives, false positives, false negatives, true negatives, sensitivity, and specificity. ROC curves were generated from pairs of (1-specificity, sensitivity) corresponding to decreasing threshold values, and the area under the curve (AUC) was calculated using the trapezoid integration method in the pROC package for R.\n\nStatistical comparisons of method performance were conducted by testing the null hypothesis that DISOPRED3 is not more accurate than DISOPRED2 against the alternative hypothesis that DISOPRED3 outperforms DISOPRED2. For binary classifications, 10^5 resampling experiments were carried out, where 80% of the proteins were randomly sampled, and scores for the two predictors were estimated. P-values for the null hypotheses were determined by comparing these differences with zero. For probability-based predictions, the statistical significance of differences in AUC values was assessed using the DeLong non-parametric test as implemented in the pROC package.",
  "evaluation/measure": "The performance of binary classification in our study was evaluated using several standard measures. These include sensitivity, also known as recall, which indicates the proportion of actual positives correctly identified. Specificity, which measures the proportion of actual negatives correctly identified. Precision, which is the proportion of predicted positives that are actual positives. The Matthews correlation coefficient (MCC), which provides a balanced measure of classification performance, especially useful for imbalanced datasets. Finally, the F1 score, which is the harmonic mean of precision and recall, offering a single metric that balances both concerns.\n\nThese metrics are widely used in the literature for evaluating classification performance, making our set of metrics representative and comparable to other studies in the field. Sensitivity and specificity provide a basic understanding of the classifier's ability to correctly identify positive and negative instances. Precision and the F1 score are crucial for understanding the reliability of positive predictions. The MCC is particularly valuable because it takes into account all four quadrants of the confusion matrix, providing a more comprehensive evaluation, especially in the context of imbalanced data.",
  "evaluation/comparison": "In our evaluation, we compared the performance of our predictor, which utilizes profile data, IDR location, length, and window composition, against several publicly available tools. The benchmark included ANCHOR, MoRFpred, and MFSPSSMpred, all of which are accessible for download or online use. Additionally, we included a naive approach that randomly labels target sequence amino acids as either disordered protein-binding or not with equal probability.\n\nTo ensure a fair comparison and reduce biases, we limited our test cases to 9 out of the 29 originally collected protein chains. The remaining chains were excluded because they belonged to the published training sets of the other tools, which could have led to overestimated accuracies. For our own predictions, we used fully cross-validated SVMs and disordered residue assignments predicted from sequence, ensuring robust and unbiased results.\n\nThe comparison was conducted using standard evaluation measures, including sensitivity, specificity, precision, Matthews correlation coefficient (MCC), and F1 score. These metrics provided a comprehensive assessment of the predictors' performance in identifying disordered protein-binding regions. The results, summarized in Table 3, showed that our method outperformed the naive approach and provided competitive performance compared to the other tools.\n\nNot applicable",
  "evaluation/confidence": "In our evaluation, we employed several statistical methods to assess the confidence and significance of our results. For binary classifications, we conducted 10^5 resampling experiments, where we randomly sampled 80% of the proteins each time. We then estimated the scores for the two predictors and recorded the values of the paired differences. P-values for the null hypotheses were estimated by comparing these differences with zero. This approach allowed us to determine whether the observed improvements in performance metrics, such as precision, Matthews correlation coefficient (MCC), and area under the curve (AUC), were statistically significant.\n\nFor probability-based predictions, we used the DeLong non-parametric test to assess the statistical significance of the differences in AUC values. This test is well-suited for comparing the performance of different classifiers based on their ROC curves.\n\nOur self-assessment showed that DISOPRED3 significantly reduces the number of false positives with negligible loss of sensitivity. This led to statistically significant increases in precision (P < 1e-5), MCC (P < 1e-5), and AUC (P < 2.2e-16). These metrics are known to correlate with the under-prediction of the minority class in the context of imbalanced data classifications. However, the observed difference in balanced accuracy, defined as the average of sensitivity and specificity, was not statistically significant (P = 0.06). This measure is generally affected by the over-prediction of the minority class.\n\nOverall, our evaluation provides strong evidence that DISOPRED3 outperforms its predecessor, DISOPRED2, and other baseline methods. The statistical significance of our results gives us confidence in the superiority of DISOPRED3 for protein disorder prediction and protein-binding site annotation within disordered regions.",
  "evaluation/availability": "All reference annotations and predictions collected for this study are available from our own website. This allows readers to easily reproduce our results or compare their own methods. The data is made publicly available to facilitate further research and validation of the methods discussed in the publication."
}