{
  "publication/title": "Machine Learning Assisted Design of Highly Active Peptides for Drug Discovery",
  "publication/authors": "The authors who contributed to the article are:\n\n- Sébastien Giguère\n- François Laviolette\n- Mario Marchand\n- Denise Tremblay\n- Sylvain Moineau\n- Éric Biron\n- Xinxia Liang\n- Jacques Corbeil\n\nAll authors contributed to conceiving and designing the experiments, performing the experiments, analyzing the data, contributing reagents/materials/analysis tools, and writing the paper.",
  "publication/journal": "PLoS Computational Biology",
  "publication/year": "2015",
  "publication/doi": "10.1371/journal.pcbi.1004074",
  "publication/tags": "- Machine Learning\n- Drug Discovery\n- Peptide Design\n- Bioinformatics\n- Computational Biology\n- Kernel Methods\n- Predictive Modeling\n- Antimicrobial Peptides\n- Graph Theory\n- Iterative Combinatorial Chemistry",
  "dataset/provenance": "Not enough information is available.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "All relevant data are included within the paper and its supplementary files. The article is distributed under the terms of the Creative Commons Attribution License. This license permits unrestricted use, distribution, and reproduction in any medium, provided that the original author and source are credited. This ensures that the data is publicly accessible and can be used by others for further research or verification of the findings presented in the paper.",
  "optimization/algorithm": "The optimization algorithm presented in our work leverages recent advances in kernel methods and machine learning to learn a predictive model. Specifically, we utilize string kernels, which are symmetric positive semi-definite similarity functions between strings, in this case, sequences of amino acids. These kernels have been widely applied in machine learning for biological data, particularly for tasks involving protein homology detection and peptide similarity characterization.\n\nThe algorithm we propose is not entirely new but builds upon existing methodologies in kernel-based machine learning. It is designed to address the specific challenges of peptide design, where the goal is to identify peptides with maximal predicted bioactivity. The core innovation lies in the application of graph theory to efficiently solve the combinatorial problem of peptide optimization. This approach ensures that the algorithm can find the peptides with the highest predicted bioactivity in a computationally tractable manner.\n\nThe reason this algorithm was published in a computational biology journal rather than a machine-learning journal is due to its specific application in the field of drug discovery. While the underlying machine-learning techniques are well-established, the novel contribution is the adaptation and optimization of these techniques for the unique challenges of peptide design. This work demonstrates how machine learning can be used to accelerate the discovery and validation of peptide leads, making it highly relevant to the computational biology community. The focus is on the practical application and validation of the method in a biological context, which is why it was published in a journal that specializes in computational biology.",
  "optimization/meta": "The optimization process described in the publication does not involve a meta-predictor. Instead, it focuses on learning a predictor from training data to identify peptides with maximal bioactivity. The predictor is a function that estimates the bioactivity of a peptide with a specific target, typically a protein. This predictor can be either target-specific, focusing on a single protein, or multi-target, capable of predicting bioactivity for various proteins within a family.\n\nThe learning process involves using kernel functions to compare peptides and proteins. These kernel functions are integral to the predictor's ability to generalize from the training data. The predictor's output is a real number that estimates the bioactivity between a peptide and a target. This approach leverages machine learning algorithms such as Support Vector Machines, Support Vector Regression, Ridge Regression, and Gaussian Processes, which all produce prediction functions similar to the one described.\n\nThe training data consists of examples where each example includes a peptide, a target protein, and a real number representing the bioactivity of the peptide with the target. These examples are obtained from in vitro or in vivo experiments. The learning task is to infer the bioactivity value for new, untested peptide-target pairs.\n\nThe predictor's design allows it to be compatible with both target-specific and multi-target scenarios. The weights on the training examples are adjusted based on the specific target, ensuring that the predictor can accurately estimate bioactivity for new peptide-target combinations. This flexibility makes the proposed method robust and applicable to a wide range of drug discovery tasks.",
  "optimization/encoding": "In our study, we employed a sophisticated encoding scheme to capture the physicochemical properties of amino acids and their combinations in peptides. This encoding was crucial for our machine-learning approach, as it allowed us to compare and weight the contributions of different k-mers (subsequences of length k) based on their properties.\n\nWe used an encoding function to map each amino acid to a vector, where each component of the vector represents a specific physicochemical property of the amino acid. This function, denoted as ψ, transforms an amino acid a into a vector ψ(a) = (ψ1(a), ψ2(a), ..., ψd(a)), where d is the number of properties considered. For our work, we utilized the BLOSUM62 matrix, where ψ(a) corresponds to the row associated with the amino acid a in the matrix.\n\nFor k-mers, we defined an encoding function ck that concatenates the property vectors of the individual amino acids in the k-mer. Specifically, for a k-mer consisting of amino acids a1, a2, ..., ak, the encoding is given by ck(a1, a2, ..., ak) = (c(a1), c(a2), ..., c(ak)). This results in a vector with dk components, where each component encodes a physicochemical property of one of the amino acids in the k-mer.\n\nThis encoding scheme enabled us to compute the similarity between k-mers based on their physicochemical properties. We used a weighting function that compares the Euclidean distance between the encoded vectors of two k-mers. This distance is then used to compute a similarity score, which is incorporated into our machine-learning model.\n\nThe Generic String (GS) kernel, which we employed in our study, builds upon this encoding scheme. The GS kernel compares biological sequences by considering their 1-mers, 2-mers, up to k-mers, and incorporates both a position-penalizing term and a physicochemical contribution term. The hyper-parameters k, σp, and σc, which control the kernel's behavior, were chosen through cross-validation.\n\nThis encoding and preprocessing approach allowed our machine-learning algorithm to effectively learn from the data and make accurate predictions about the bioactivity of peptides. The use of physicochemical properties in the encoding scheme ensured that the model could generalize well to new, unseen peptides.",
  "optimization/parameters": "In our approach, the number of parameters used in the model can vary depending on the specific configuration of the predictor. The predictor's output is influenced by several factors, including the weights assigned to training examples, which are determined by the function βq(y). This function can be arbitrary, allowing for a wide range of possible configurations.\n\nThe selection of parameters is guided by the need to achieve optimal performance with a modest-sized database. For instance, when using random peptides for training, near-optimal accuracy is reached with approximately 300 peptides. This suggests that the method can achieve excellent performance without requiring an excessively large dataset.\n\nThe flexibility in the choice of parameters allows the model to be more general and sophisticated compared to simpler methods like position-specific weight matrices (PSWM). PSWM assume statistical independence between positions in the pattern and do not account for quantified bioactivity or similarities between amino acids. In contrast, our method can learn more complex predictors that do not have these limitations.\n\nThe specific values of parameters such as k, σp, and σc can be adjusted to fit the requirements of the prediction task. The weight vector α, which depends on the learning algorithm used, is also a crucial component. Many popular learning algorithms, including Support Vector Machines, Support Vector Regression, Ridge Regression, and Gaussian Processes, produce prediction functions that fit the form of our model. This compatibility ensures that the approach can be integrated with well-established bioinformatics learning algorithms.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The fitting method employed in this study leverages machine learning algorithms to predict peptide bioactivity, focusing on avoiding both overfitting and underfitting.\n\nThe number of parameters in the model is indeed larger than the number of training points, especially when dealing with high-dimensional peptide sequences. To mitigate overfitting, several strategies were implemented. Firstly, the model incorporates regularization techniques that penalize complex models, ensuring that the predictor generalizes well to unseen data. Secondly, cross-validation was used to assess the model's performance on different subsets of the data, providing a robust estimate of its predictive accuracy. Additionally, the model's performance was evaluated on independent datasets, demonstrating its ability to generalize beyond the training data.\n\nTo avoid underfitting, the model's complexity was carefully tuned. This involved selecting an appropriate set of hyperparameters that balance the model's capacity to capture the underlying patterns in the data without becoming too simplistic. The use of advanced machine learning algorithms, such as those based on kernel methods, allows the model to capture intricate relationships between peptide sequences and their bioactivities. Furthermore, the model's performance was validated through in vitro experiments, confirming its practical applicability and ensuring that it does not underfit the data.\n\nIn summary, the fitting method effectively addresses the challenges of overfitting and underfitting by employing regularization, cross-validation, and careful hyperparameter tuning, supported by rigorous experimental validation.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, ensuring that our model generalizes well to unseen data. One key method involved sacrificing some accuracy on the training data. This approach is common in machine learning to avoid overfitting, where the model might perform exceptionally well on training data but poorly on new, unseen data. By allowing slight discrepancies in the training data predictions, we aimed to create a more robust model that can better handle real-world variations.\n\nAdditionally, our model incorporates a sophisticated predictor that considers the dependencies between amino acids in a peptide sequence, rather than assuming independence as in simpler models like Position-Specific Weight Matrices (PSWMs). This allows the model to capture more complex patterns and interactions within the data, reducing the risk of overfitting to noise or specific idiosyncrasies in the training set.\n\nWe also utilized a combination of kernel methods and machine learning algorithms that are designed to handle high-dimensional data and complex relationships. These methods, including Support Vector Machines and Gaussian Processes, inherently include regularization techniques that help in preventing overfitting by controlling the model's complexity.\n\nFurthermore, we validated our approach through extensive in vitro experiments, demonstrating that the predicted peptides exhibit high biological activity in real-world tests. This practical validation step is crucial as it ensures that the model's predictions are not just artifacts of the training process but have genuine biological relevance.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters are not explicitly detailed in the publication. However, the methodology and algorithms used for the learning and prediction of peptide bioactivity are thoroughly described. The data used for training and validation is available within the paper and its Supporting Information files. The work is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction, provided the original author and source are credited. This license allows for the sharing and adaptation of the material, including the methods and algorithms described, under the condition that appropriate credit is given.",
  "model/interpretability": "The model presented in this work is not a black-box model. It is designed to be interpretable and transparent, allowing users to understand how predictions are made. The predictor function is based on a combination of kernel functions and weighted contributions from training examples. This structure provides insights into the factors influencing the predicted bioactivity of a peptide.\n\nFor instance, the predictor function for a target-specific predictor is given by a weighted sum of similarities between the input peptide and the training peptides, where the weights depend on the similarity between the target protein and the training proteins. This means that the model's output can be traced back to specific training examples and their contributions, making it possible to interpret the predictions in terms of known data.\n\nMoreover, the use of kernel functions, such as the GS kernel, allows for the incorporation of domain knowledge about the similarities between amino acids and proteins. This further enhances the interpretability of the model, as the similarities used in the predictions are based on established biological principles.\n\nAdditionally, the model's compatibility with various learning algorithms, such as Support Vector Machines and Ridge Regression, ensures that the interpretability is maintained across different implementations. These algorithms produce prediction functions that are explicit and can be analyzed to understand the underlying patterns in the data.\n\nIn summary, the model is designed to be transparent and interpretable, providing clear examples of how predictions are made and allowing users to understand the factors influencing the predicted bioactivity of peptides.",
  "model/output": "The model is designed for regression, focusing on predicting real-valued bioactivity scores. This approach is more general than binary classification, as it aims to estimate the true bioactivity between a peptide and a target protein. The output of the predictor is a real number, which represents the estimated bioactivity. This real-valued prediction allows for a more nuanced understanding of the peptide-target interactions, rather than simply classifying them as active or inactive. The model can be either target-specific, predicting bioactivity for a particular protein, or multi-target, predicting bioactivity for a family of proteins. In both cases, the output is a continuous value that quantifies the bioactivity, enabling a more detailed analysis and comparison of different peptides.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed methodology involved a combination of in silico simulations and in vitro experiments. Initially, the approach was validated through simulations where laboratory experiments were replaced by an oracle, which represented the best understanding of the studied phenomena. This oracle was used to quantify the bioactivity level of randomly generated peptides and those proposed by our methodology.\n\nThe simulation process involved several steps:\n\n1. Randomly generating a set of peptides on a computer.\n2. Using the oracle to measure the bioactivities of these peptides.\n3. Training a second predictor using these random peptides of low bioactivity.\n4. Using this predictor to initiate a graph-based approach to obtain the top K potentially best peptides.\n5. Validating the bioactivities of these new peptides using the oracle.\n6. Comparing the bioactivities of the initial set of randomly generated peptides with those proposed by our approach.\n\nThis simulation was conducted twice on both the CAMPs and the BPPs datasets, once with R = 100 peptides and K = 100 best predicted peptides, and then with R = 1,000 and K = 1,000. The results showed that the number of peptides drawn (R) had no impact on the average activity of randomly drawn peptides, supporting the hypothesis that random peptides will consistently be of low activity. However, the proposed machine learning approach was able to significantly improve the bioactivity of the peptides, outperforming the random approach on both datasets.\n\nIn addition to the simulations, in vitro experiments were conducted to further validate the approach. Antimicrobial peptides identified during the in silico validation were synthesized, and their antimicrobial activity against Escherichia coli and Staphylococcus aureus was measured in a growth inhibitory assay. The results demonstrated that the proposed methodology could improve the putative candidates, with some peptides showing better activity than the original candidates from the CAMPs dataset.",
  "evaluation/measure": "In the evaluation of our approach, several performance metrics were reported to assess the effectiveness of our machine learning-assisted design of highly active peptides. One of the primary metrics used was the Pearson correlation coefficient (PCC), also known as Pearson’s r. This metric was employed to measure the correlation between the predicted bioactivity values of our model and the actual values in the datasets. For instance, when our predictor was initiated with a larger set of random peptides (R = 1,000), it achieved a correlation coefficient of 0.90 on the CAMPs dataset and 0.93 on the BPPs dataset. These values are comparable to those achieved by the oracle, which had correlation coefficients of 0.91 and 0.97, respectively, on the same peptides. This indicates that our model can predict bioactivity with high accuracy, even when trained on a modest number of low-bioactivity peptides.\n\nAdditionally, we reported the average and maximum bioactivity values of the peptides generated by our approach and compared them to those of randomly picked peptides. For the CAMPs dataset, our approach achieved an average bioactivity of 1.07 and a maximum bioactivity of 1.09 when initiated with R = 1,000 random peptides. This represents a significant improvement over the average and maximum bioactivity of the randomly picked peptides, which were -0.59 and 0.18, respectively. Similarly, for the BPPs dataset, our approach achieved an average bioactivity of 1.66 and a maximum bioactivity of 2.20, compared to 0.26 and 1.36 for the randomly picked peptides.\n\nThese metrics are representative of the state-of-the-art in the field, as they provide a comprehensive evaluation of both the predictive accuracy and the bioactivity enhancement capabilities of our approach. The use of the Pearson correlation coefficient is a standard practice in evaluating the performance of predictive models in bioinformatics and computational biology. The comparison of average and maximum bioactivity values further ensures that our approach not only predicts bioactivity accurately but also identifies peptides with superior biological activity.",
  "evaluation/comparison": "A comparison to simpler baselines was performed. Specifically, the proposed methodology was compared to position-specific weight matrices (PSWMs). PSWMs are a straightforward approach that assumes statistical independence between positions in a peptide sequence. They consist of a position frequency matrix where each entry denotes the frequency of an amino acid at a specific position. While PSWMs are simple and have been widely used, they have several limitations. They do not account for the quantified bioactivity of peptides, the similarities between amino acids, or the need for peptides to be aligned or of the same length. The proposed method addresses these limitations by allowing more sophisticated predictors to be learned, which can capture complex dependencies and interactions within peptide sequences.\n\nAdditionally, the testing methodology was conducted on two datasets: CAMPs and BPPs. The approach was validated by generating a set of random peptides and comparing the bioactivity of the best predicted peptides to those randomly selected. The results showed that the proposed method significantly outperformed the random approach in terms of both the best peptide found and the average bioactivity. This demonstrates the effectiveness of the machine learning approach in identifying highly bioactive peptides.",
  "evaluation/confidence": "The evaluation of our method includes statistical measures that provide confidence in the results. For instance, we report correlation coefficients, which inherently provide a sense of the strength and direction of the relationship between predicted and actual bioactivities. However, specific confidence intervals for these metrics are not explicitly stated.\n\nStatistical significance is demonstrated through comparisons with random baselines and other methods. For example, the method's ability to outperform random peptide selection is evident in the results, where the average and maximum bioactivities of predicted peptides are significantly higher than those of randomly selected peptides. This is supported by the correlation coefficients, which show that our predictor achieves high accuracy comparable to an oracle, even when trained on low-bioactivity peptides.\n\nThe use of Pearson correlation coefficients (PCC) further supports the statistical significance of our results. The high PCC values indicate a strong linear relationship between the predicted and actual bioactivities, suggesting that our method is reliable and accurate. Additionally, the consistent improvement in bioactivity measures when increasing the number of initial peptides (R) from 100 to 1,000 provides further evidence of the method's robustness and superiority over random selection.",
  "evaluation/availability": "All relevant data used for evaluation are included within the paper and its Supporting Information files. This ensures that the information is readily accessible to readers and researchers interested in replicating or building upon the study. The paper is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. This licensing approach facilitates open access and encourages further research and collaboration."
}