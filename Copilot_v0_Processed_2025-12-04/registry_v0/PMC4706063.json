{
  "publication/title": "Machine learning models identify molecules active against the Ebola virus in vitro",
  "publication/authors": "The authors who contributed to the article are Sean Ekins, Jason S. Freundlich, and Antony M. Clark. Sean Ekins is the corresponding author and works for Collaborations in Chemistry and Collaborations Pharmaceuticals, Inc. He also consults for Collaborative Drug Discovery Inc. Jason S. Freundlich and Antony M. Clark are co-authors, with Antony M. Clark also consulting for Collaborative Drug Discovery Inc.",
  "publication/journal": "F1000Research",
  "publication/year": "2017",
  "publication/doi": "10.12688/f1000research.7217.3",
  "publication/tags": "- Ebola\n- Machine learning\n- Drug discovery\n- In vitro studies\n- Viral infection\n- Computational biology\n- Molecular descriptors\n- Antiviral compounds\n- HeLa cells\n- Bayesian models",
  "dataset/provenance": "The dataset utilized in this study is derived from a comprehensive set of compounds screened for activity against the Ebola virus. Specifically, the MicroSource Spectrum set, which comprises 2,320 compounds, was employed. This set includes a diverse range of chemical structures, enabling a broad exploration of potential therapeutic agents.\n\nThe compounds in the dataset were initially screened using machine learning techniques, which involved training models on known active and inactive compounds. The training set for the replication assay included features such as piperazine, phenothiazine, tertiary amines, and alkoxyethylamino, which were identified as common active features. In contrast, the training set for inactives frequently included carboxylic acids, N,N'-disubstituted ureas, secondary and tertiary amides, pyrazoles, aromatic sulfonamides, tertiary cyclopentanols, 1,2-mercaptoethanol, and penams.\n\nThe dataset has been used in previous research and by the community to develop and validate machine learning models for drug discovery. The models were cross-validated using various techniques, including 5-fold cross-validation and a more exhaustive 'leave out 50% repeated randomly 100 times' approach. These validation methods ensured the stability and reliability of the models, with Receiver Operator Curve (ROC) values consistently above 0.8, indicating strong predictive performance.\n\nThe dataset is part of an open-access initiative, making it available for further research and validation by the scientific community. This openness is crucial for collaborative efforts in drug discovery, especially in the context of emerging infectious diseases like Ebola. The availability of this dataset facilitates the development of new therapeutic strategies and the refinement of existing models, contributing to the global effort to combat viral infections.",
  "dataset/splits": "The dataset was split using a 5-fold cross-validation approach. This means that the data was divided into five subsets, or \"folds\". In each iteration of the cross-validation process, one fold was used as the test set, and the remaining four folds were used as the training set. This process was repeated five times, with each fold serving as the test set once.\n\nAdditionally, a more exhaustive cross-validation method was employed, known as 'leave out 50% repeated randomly 100 times'. This involved randomly selecting 50% of the data for testing and the remaining 50% for training, repeating this process 100 times to ensure the stability and robustness of the models.\n\nThe distribution of data points in each split was balanced, with each fold containing an approximately equal number of data points. This ensures that the models were trained and tested on representative samples of the entire dataset. The specific number of data points in each fold was not explicitly stated, but the total number of compounds in the training set was 868.",
  "dataset/redundancy": "The datasets used in this study were derived from viral pseudotype entry assays and Ebola virus replication assays. A total of 868 molecules were made available for analysis. To ensure the robustness of the models, salts were stripped and duplicate compounds were removed using Discovery Studio. This preprocessing step was crucial to avoid redundancy and ensure that the models were trained on unique chemical entities.\n\nThe compounds were classified based on their IC50 values. Those with IC50 values less than 50 μM were designated as actives, while the remaining compounds were classified as inactives. This binary classification was essential for training the machine learning models effectively.\n\nTo validate the models, a standard protocol involving five-fold cross-validation was employed. This method involved splitting the dataset into five subsets, where four subsets were used for training and one subset was used for testing. This process was repeated five times, with each subset serving as the test set once. Additionally, a more exhaustive cross-validation method, known as 'leave out 50% repeated randomly 100 times,' was used to further validate the stability and performance of the models.\n\nThe training and test sets were designed to be independent to prevent data leakage and ensure that the models could generalize well to unseen data. This independence was enforced through the cross-validation process, where the data was randomly split into training and test sets multiple times.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the field. The use of interpretable molecular descriptors, such as molecular function class fingerprints (FCFP_6), AlogP, molecular weight, number of rotatable bonds, and others, ensured that the models could discern active molecule features from inactive ones. This approach has been successfully applied in predicting whole-cell activity for various pathogens, including mycobacterium tuberculosis and Trypanosoma cruzi, demonstrating its versatility and reliability.",
  "dataset/availability": "The data used in this study, including the data splits, have been made publicly available. The dataset consists of 868 molecules from viral pseudotype entry assays and Ebola virus (EBOV) replication assays. This dataset was provided as an SDF file, with salts stripped and duplicates removed using Discovery Studio 4.1. For each assay, compounds with IC50 values less than 50 μM were selected as actives, while all other compounds were classified as inactives.\n\nTo ensure accessibility and reproducibility, open Bayesian models for the Ebola datasets were developed using open-source software. These models are openly accessible and can be uploaded into the Mobile Molecular Data Sheet (MMDS) to score molecules of interest. The models and associated data can be found at http://molsync.com/ebola/. This approach allows other researchers to use the same training sets for anti-EBOV activity using replication and pseudotype screening data, facilitating further research and validation.\n\nThe open-source nature of these models and data ensures that they can be freely used and shared within the scientific community, promoting transparency and collaboration. By making these resources available, we aim to support ongoing efforts to develop effective therapies against Ebola and other viruses.",
  "optimization/algorithm": "The machine-learning algorithms employed in our study include Random Forest, Support Vector Machines (SVM), and Bayesian models. These are well-established classes of algorithms in the field of machine learning, known for their robustness and wide applicability in various predictive tasks.\n\nThe algorithms used are not new; they have been extensively studied and applied in numerous scientific and industrial contexts. The choice of these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to discern active molecule features from inactive ones.\n\nThe decision to use these established algorithms in a biological context, rather than a machine-learning journal, is rooted in the specific application and the interdisciplinary nature of our research. Our primary focus is on identifying molecules active against the Ebola virus, leveraging machine learning as a tool to achieve this goal. The biological significance and potential impact on public health are the driving forces behind our work, making it more appropriate for publication in a life sciences journal.",
  "optimization/meta": "The models employed in this study do not function as meta-predictors. Instead, they utilize a variety of machine learning techniques independently to discern active molecule features from inactive ones. The methods used include Recursive Partitioning (RP) Forest, RP Single Tree, Support Vector Machine (SVM), Bayesian, and Open Bayesian models. Each of these models was built using the same set of molecular descriptors, which include FCFP_6 fingerprints and several interpretable descriptors such as AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area.\n\nThe training data for these models consists of 868 molecules from viral pseudotype entry assays and Ebola virus (EBOV) replication assays. Compounds with IC50 values less than 50 μM were selected as actives, while all other compounds were classified as inactives. The models were validated using five-fold cross-validation or leave-out 50% × 100 fold cross-validation to calculate the Receiver Operator Curve (ROC).\n\nThe independence of the training data is ensured by the use of cross-validation techniques, which help to prevent overfitting and ensure that the models generalize well to new, unseen data. This approach allows the models to identify new molecules that are structurally distinct from those in the current training set, thereby enhancing the predictive power and reliability of the models.",
  "optimization/encoding": "The data encoding process involved using FCFP_6 fingerprints, which are circular topological fingerprints that capture structural features of molecules. Additionally, eight interpretable descriptors were employed to further characterize the molecular properties. These descriptors and fingerprints were used to discern active molecule features from inactive ones, enabling the identification of new molecules. The approach did not rely on molecular weight or rotatable bond number, focusing instead on features that are useful for predicting whole-cell activity. This method has been successfully applied to various pathogens, including mycobacterium tuberculosis and Trypanosoma cruzi, demonstrating its versatility and effectiveness. The use of these specific fingerprints and descriptors allowed for a comprehensive and interpretable encoding of the molecular data, facilitating the machine learning models' ability to identify active compounds against the Ebola virus.",
  "optimization/parameters": "In our study, we utilized several molecular descriptors to build our models. Specifically, the descriptors included molecular function class fingerprints of maximum diameter 6 (FCFP_6), AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area.\n\nThe selection of these descriptors was based on a standard protocol aimed at capturing a wide range of chemical properties that could influence the activity of the compounds against Ebola virus. This set of descriptors was chosen to ensure a comprehensive representation of the molecular features relevant to the biological activity being studied. The number of parameters, p, corresponds to the number of these descriptors used in the model.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The fitting method employed in this study utilized machine learning models to analyze a dataset of 868 compounds from viral pseudotype entry assays and Ebola virus (EBOV) replication assays. The models were built using a standard protocol with several molecular descriptors, including molecular function class fingerprints of maximum diameter 6 (FCFP_6), AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area.\n\nTo address the potential issue of overfitting, given the number of parameters relative to the number of training points, several validation techniques were employed. Five-fold cross-validation was used, where the dataset was divided into five parts, and the model was trained on four parts while validated on the remaining part. This process was repeated five times, ensuring that each part was used as the validation set once. Additionally, a more exhaustive cross-validation method, 'leave out 50% repeated randomly 100 times,' was used. This method involved randomly leaving out 50% of the data 100 times and calculating the Receiver Operator Curve (ROC) values. The consistency of the ROC values across these different validation methods indicated that the models were stable and not overfitting.\n\nTo rule out underfitting, the models were compared using different machine learning algorithms, including Bayesian, Support Vector Machine (SVM), and Recursive Partitioning Forest (RP Forest) models. The Bayesian approach performed the best for the EBOV replication data and was equivalent to the RP Forest approach, indicating that the models were complex enough to capture the underlying patterns in the data. The use of interpretable descriptors and the comparison of multiple models ensured that the chosen models were not too simplistic, thus avoiding underfitting.\n\nIn summary, the fitting method involved rigorous cross-validation techniques to prevent overfitting and the use of multiple machine learning algorithms to ensure that the models were not underfitting. This approach provided a robust framework for analyzing the dataset and identifying active and inactive compounds.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was cross-validation. Specifically, we utilized 5-fold cross-validation, where the data is divided into five parts, and the model is trained on four parts while being tested on the remaining part. This process is repeated five times, with each part serving as the test set once. This approach helps to ensure that the model generalizes well to unseen data and is not merely memorizing the training set.\n\nAdditionally, we implemented a more exhaustive cross-validation technique known as 'leave out 50% repeated randomly 100 times.' This method involves randomly selecting 50% of the data for training and the remaining 50% for testing, repeating this process 100 times. This rigorous validation strategy further enhances the stability and reliability of our models.\n\nFor the Recursive Partitioning (RP) Forest models, we employed bagging, which stands for \"Bootstrap Aggregating.\" In this technique, multiple subsets of the data are created by sampling with replacement, and a decision tree is built for each subset. The final prediction is made by aggregating the results from all the trees. This method helps to reduce the variance and improve the model's performance on unseen data.\n\nFurthermore, we compared different machine learning algorithms, including Bayesian, Support Vector Machine (SVM), and Recursive Partitioning Forest and single tree models. By evaluating the performance of these diverse models, we could select the most robust and generalizable approach for our datasets. The Bayesian models, in particular, showed strong performance with ROC values greater than 0.8, indicating their effectiveness in distinguishing between active and inactive compounds.\n\nIn summary, our study incorporated multiple overfitting prevention techniques, including cross-validation, bagging, and the comparison of different machine learning algorithms. These methods collectively ensured that our models were reliable and capable of generalizing well to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available and have been reported. Specifically, we utilized molecular descriptors such as molecular function class fingerprints of maximum diameter 6 (FCFP_6), AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area. These descriptors were employed in the construction of our models.\n\nFor the machine learning models, we compared Bayesian, Support Vector Machine (SVM), and Recursive Partitioning Forest (RP Forest) approaches. The Bayesian models, in particular, demonstrated robust performance with Receiver Operator Curve (ROC) values consistently above 0.80. We also conducted a more exhaustive cross-validation method, 'leave out 50% repeated randomly 100 times,' which produced comparable ROC values, indicating the stability of our models.\n\nThe open Bayesian models developed using open-source software are accessible and can be loaded into the Mobile Molecular Data Sheet (MMDS). These models are openly available at http://molsync.com/ebola/ and can be used to score molecules of interest. This accessibility ensures that other researchers can replicate and build upon our findings.\n\nAdditionally, the specific configurations and parameters for each model type, such as the number of trees in the RP Forest models and the cross-validation methods used, are detailed in the publication. This information allows for reproducibility and further exploration by the scientific community.",
  "model/interpretability": "The models developed in this study are not entirely black-box. We employed several interpretable descriptors alongside molecular function class fingerprints (FCFP_6) to ensure that the models could provide insights into the features contributing to activity or inactivity. These descriptors include AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area.\n\nFor instance, the Bayesian models and Support Vector Machine (SVM) models utilized these interpretable descriptors, allowing us to discern active molecule features from those that are inactive. The Recursive Partitioning (RP) Forest and single tree models also benefited from these descriptors, enabling the identification of new molecules with desirable properties.\n\nAdditionally, the models were validated using cross-validation techniques, which helped in assessing their performance and reliability. The use of these descriptors and validation methods ensures that the models are not merely predictive but also provide a level of interpretability, making them useful for understanding the underlying mechanisms of molecular activity.\n\nFigures 1 and 2 in the publication illustrate the active and inactive features identified by the models, providing visual examples of how the models differentiate between active and inactive compounds. These figures serve as clear examples of the model's transparency and its ability to highlight key molecular features.",
  "model/output": "The model developed in this study is a classification model. It was designed to distinguish between active and inactive compounds in the context of Ebola virus assays. Specifically, compounds with IC50 values less than 50 μM were classified as actives, while all other compounds were classified as inactives. The model utilized various molecular descriptors and was validated using cross-validation techniques to assess its performance in classifying these compounds.\n\nSeveral machine learning algorithms were employed, including Random Forest, Single Tree, Support Vector Machine (SVM), and Bayesian models. Each of these models was evaluated using Receiver Operator Curve (ROC) statistics to measure their classification performance. The ROC curves provided insights into the models' ability to discriminate between active and inactive compounds effectively.\n\nThe models were built using a standard protocol with molecular descriptors such as molecular function class fingerprints, AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors and donors, and molecular fractional polar surface area. These descriptors were crucial in training the models to accurately classify the compounds.\n\nIn summary, the output of the models is a classification of compounds into active or inactive categories based on their predicted activity against the Ebola virus. The performance of these models was rigorously validated to ensure their reliability in identifying potential therapeutic compounds.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the models used in this study is not released. However, the models themselves are openly accessible. The Bayesian models developed for the Ebola datasets can be found at http://molsync.com/ebola/. These models can be uploaded into the Mobile Molecular Data Sheet (MMDS), which is available at http://molmatinf.com/, to score molecules of interest. Additionally, open source Bayesian algorithms and fingerprint descriptors, such as \"function class fingerprints of maximum diameter 6\" (FCFP6) and \"extended connectivity (ECFP6) fingerprints,\" have been made available and can be implemented with the Chemistry Development Kit (CDK) components. These tools enable the creation of models that can be used within mobile apps, such as TB Mobile, MMDS, Approved Drugs, and MolPrime. These apps allow scientists to select a molecule and score it with the models, making the models more accessible for use in research.",
  "evaluation/method": "The evaluation of our method involved several rigorous steps to ensure the robustness and reliability of our models. We employed machine learning techniques to analyze a dataset of 868 compounds from viral pseudotype entry assays and Ebola virus (EBOV) replication assays. These compounds were classified as active or inactive based on their IC50 values, with actives having values less than 50 μM.\n\nTo validate our models, we used a standard protocol that included various molecular descriptors such as molecular function class fingerprints, AlogP, molecular weight, number of rotatable bonds, and others. We compared different machine learning approaches, including Bayesian, Support Vector Machine (SVM), and Recursive Partitioning (RP) Forest and single tree models. For the RP Forest models, we utilized bagging, a technique where multiple trees are created from bootstrap samples of the original data.\n\nCross-validation was a crucial part of our evaluation process. We performed 5-fold cross-validation, where the dataset was divided into five parts, and the model was trained on four parts while tested on the remaining one. This process was repeated five times, with each part serving as the test set once. Additionally, we conducted a more exhaustive cross-validation method known as 'leave out 50% repeated randomly 100 times,' which involved leaving out 50% of the data and repeating this process 100 times to ensure the stability and generalizability of our models.\n\nThe performance of our models was assessed using the Receiver Operator Curve (ROC) statistics. The Bayesian approach performed the best for the EBOV replication data and was equivalent to the RP Forest approach. It also outperformed the SVM for the pseudotype data. The Open Bayesian models, developed using open-source software, had slightly lower ROC scores compared to the Bayesian models built with Discovery Studio.\n\nIn summary, our evaluation method involved a comprehensive cross-validation strategy and the comparison of multiple machine learning models to ensure the reliability and effectiveness of our approach in identifying potential therapies against Ebola.",
  "evaluation/measure": "In the evaluation of our machine learning models, we primarily reported the Receiver Operator Curve (ROC) statistics. This metric was chosen for its ability to provide a comprehensive view of the model's performance across all classification thresholds. Specifically, we used the area under the ROC curve (AUC-ROC) to quantify the models' ability to distinguish between active and inactive compounds.\n\nThe ROC statistics were calculated using different cross-validation techniques to ensure the robustness of our results. For most models, we employed five-fold cross-validation, which involves dividing the dataset into five parts, training the model on four parts, and testing it on the remaining part. This process is repeated five times, with each part serving as the test set once. Additionally, we used a more exhaustive cross-validation method for the Bayesian models, known as 'leave out 50% repeated randomly 100 times.' This technique involves randomly leaving out 50% of the data, training the model on the remaining data, and testing it on the left-out data. This process is repeated 100 times to provide a more stable estimate of the model's performance.\n\nThe models evaluated include Random Forest, Single Tree, Support Vector Machine (SVM), Bayesian, and Open Bayesian models. The ROC statistics for these models were reported in a table, allowing for easy comparison of their performance. The Bayesian approach performed the best for the Ebola virus (EBOV) replication data and was equivalent to the Random Forest approach for the pseudotype data. The Open Bayesian models had slightly lower ROC scores than the Bayesian models built with Discovery Studio, but they were still comparable.\n\nIn summary, the ROC statistics reported in our study provide a representative and comprehensive evaluation of our models' performance. This metric is widely used in the literature for evaluating classification models, particularly in the context of drug discovery and virtual screening. The use of multiple cross-validation techniques further ensures the reliability and robustness of our results.",
  "evaluation/comparison": "In our study, we employed various machine learning methods to build models for predicting anti-Ebola activity. We compared different algorithms, including Random Forest, Support Vector Machine (SVM), and Bayesian models, using the same set of molecular descriptors. The descriptors used included FCFP_6 fingerprints and several interpretable descriptors such as AlogP, molecular weight, number of rotatable bonds, and others.\n\nThe performance of these models was evaluated using five-fold cross-validation, and the results were presented as Receiver Operator Curve (ROC) statistics. Bayesian models consistently showed ROC values above 0.80, indicating robust performance. We also developed open Bayesian models using open-source software, which were made accessible to the community. These models were validated and used to score compounds from the MicroSource library, demonstrating their effectiveness in identifying potential anti-Ebola compounds.\n\nAdditionally, we ensured that our models were not dependent on simplistic descriptors like molecular weight and the number of rotatable bonds. Instead, we used a combination of FCFP_6 fingerprints and eight interpretable descriptors, which has proven useful for predicting whole-cell activity in various contexts, including Ebola, tuberculosis, and Chagas disease.\n\nWe also addressed the concern about the complexity of computational models by making our models accessible through mobile devices. This approach allows scientists to select and score molecules using cheminformatics mobile apps, making the models more practical and user-friendly.\n\nIn summary, our comparison of different machine learning methods and the development of open-source models highlight the robustness and accessibility of our approach. The consistent performance of Bayesian models and the practical implementation through mobile apps underscore the effectiveness of our methodology in identifying potential anti-Ebola compounds.",
  "evaluation/confidence": "The evaluation of our models involved rigorous cross-validation techniques to ensure robustness and reliability. We employed 5-fold cross-validation, where the data is split into five parts, and the model is trained on four parts while tested on the remaining one. This process is repeated five times, with each part serving as the test set once. Additionally, we used a more exhaustive cross-validation method called 'leave out 50% repeated randomly 100 times,' which further validated the stability of our models.\n\nThe performance metrics, specifically the Receiver Operator Curve (ROC) scores, were calculated for each model. For the Ebola replication data, the Bayesian approach performed the best, with ROC values consistently above 0.8, indicating strong predictive power. The Open Bayesian models had slightly lower ROC scores but were still comparable. For the pseudotype data, the Bayesian models were better than Support Vector Machine (SVM) models, demonstrating their superiority in this context.\n\nConfidence intervals were provided for the EC50 values of the compounds tested in vitro, which indicate the concentration of a drug that gives half-maximal response. For instance, the EC50 for chloroquine was reported as 4.0 μM with a 95% confidence interval of 1.0–15 μM. This provides a range within which the true EC50 value is likely to fall, giving a measure of the uncertainty in the estimate.\n\nStatistical significance was assessed to claim the superiority of our methods. The Bayesian models consistently outperformed other models like SVM and Recursive Partitioning (RP) Forest, with ROC values that were statistically significant. This was evident from the cross-validation results, where the Bayesian models showed superior performance metrics.\n\nIn summary, the performance metrics were robustly evaluated using cross-validation techniques, and the results were statistically significant. The provision of confidence intervals for key metrics further enhances the reliability of our findings.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. However, we have made significant efforts to ensure that our models and methodologies are accessible to the broader scientific community. We developed open Bayesian models for the Ebola datasets using open source software, which are openly accessible. These models can be loaded into the Mobile Molecular Data Sheet (MMDS) and used to score molecules of interest. The models are available at http://molsync.com/ebola/. Additionally, we have described the implementation of \"function class fingerprints of maximum diameter 6\" (FCFP6) and \"extended connectivity (ECFP6) fingerprints\" with the Chemistry Development Kit (CDK) components, making them open source. This allows other researchers to use these descriptors in their own studies. We have also developed cheminformatics mobile apps that combine Bayesian models and open source fingerprint descriptors, enabling models that can be used within a mobile app. These apps include TB Mobile, MMDS, Approved Drugs, and MolPrime, which facilitate the selection and scoring of molecules."
}