{
  "publication/title": "Machine Learning for Characterization of Insect Vector Feeding",
  "publication/authors": "The authors who contributed to the article are:\n\n- Denis S. Willett, who is affiliated with the USDA-ARS, Chemistry Unit, Center for Medical, Agricultural, and Veterinary Entomology in Gainesville, FL, USA. Denis Willett is the corresponding author and can be reached at denis.willett@ars.usda.gov.\n- Justin George, affiliated with the USDA-ARS, Subtropical Insects and Horticultural Research Unit, United States Horticultural Research Laboratory in Fort Pierce, Florida, USA.\n- Nora S. Willett, affiliated with the Department of Computer Science at Princeton University in Princeton, NJ, USA.\n- Lukasz L. Stelinski, affiliated with the University of Florida, Entomology and Nematology Department, Citrus Research and Education Center in Lake Alfred, FL, USA.\n- Stephen L. Lapointe, affiliated with the USDA-ARS, Subtropical Insects and Horticultural Research Unit, United States Horticultural Research Laboratory in Fort Pierce, Florida, USA.\n\nDenis S. Willett, Justin George, and Nora S. Willett contributed equally to this work. The specific contributions of the authors to the paper are not detailed.",
  "publication/journal": "PLOS Computational Biology",
  "publication/year": "2016",
  "publication/doi": "10.1371/journal.pcbi.1005158",
  "publication/tags": "- Machine Learning\n- Insect Vector Feeding\n- Electrical Penetration Graph\n- Random Forests\n- Hidden Markov Models\n- Hierarchical Cluster Analysis\n- Citrus Greening Disease\n- Pathogen Transmission\n- Data Analysis\n- Automated Classification",
  "dataset/provenance": "The dataset used in this study consists of Electrical Penetration Graph (EPG) recordings. These recordings were performed using a Giga-8 DC-EPG system to capture the feeding activities of adult Asian citrus psyllids on nine different trifoliate and citrus varieties. The psyllids were tethered to the recording equipment and settled on the adaxial midrib of a leaf. The recordings were conducted within a Faraday cage in a climate-controlled laboratory under lighted conditions for durations ranging from 8 to 21 hours.\n\nA total of 27 EPG recordings were collected, amounting to 470 hours of data. These recordings were classified by visual inspection by a trained expert into six distinct feeding states: salivary sheath secretion and stylet passage (C), first contact with phloem (D), salivation at phloem (E1), phloem ingestion (E2), xylem ingestion (G), and no probing (NP). The data were initially recorded using WinDaq Data acquisition and Playback software, then classified and annotated using the WinDaq data browser before being exported to comma-separated value files for further analysis.\n\nThe dataset has not been used in previous papers by the community, but it builds upon established methods for EPG recordings and classification. The focus was on removing the data analysis bottleneck through the application of machine learning algorithms, which allowed for high-throughput analysis and reduced the need for extensive human input. This approach is novel in the context of EPG data analysis and aims to facilitate the development of effective intervention strategies for managing insect-vectored plant diseases.",
  "dataset/splits": "The dataset was split into training and test sets for each recording. A random five percent subset of each recording was used for training, while the remaining ninety-five percent was used for testing. This split was chosen to reduce human labor while maintaining high accuracies. Additionally, 50:50 and 95:5 training to test set schemes were considered but did not produce differences in overall accuracy. A leave-one-out classification scheme was also pursued, where a random five percent subsample of each feeding state from each of 26 human-annotated recordings was used to train the model. The model was then used to classify the 27th recording, and this process was repeated for each recording, leaving one out each time.",
  "dataset/redundancy": "The datasets used in this study were split into training and test sets for each recording. A random five percent subset of each recording was used to train a supervised random forests model with 3 repeated 10-fold cross-validation. The remaining ninety-five percent of the recording was then used as the test set. This procedure was employed to classify all six human-recognized feeding states and to differentiate between phloem and non-phloem feeding states.\n\nThe training and test sets were independent, as the test set was not used in any way during the training process. This independence was enforced by using a random five percent subset for training and the remaining data for testing. Additionally, a leave-one-out classification scheme was pursued to determine the possibility of classification without additional human input. In this scheme, a random five percent subsample of each feeding state from each of 26 human-annotated recordings was used to train the model. The model was then used to classify the 27th recording, and this process was repeated for each recording, ensuring that each recording was left out once.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in terms of maintaining high accuracy while reducing human labor. Using randomly sampled training sets less than five percent of the overall dataset increased the likelihood of missing certain feeding states and lowered classification accuracy. Therefore, a five percent training to ninety-five percent test set was considered most advantageous. Additionally, 50:50 and 95:5 training to test set schemes were considered but did not produce differences in overall accuracy.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. Specifically, random forests and hidden Markov models were employed. Random forests are an ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes of the individual trees. This algorithm is not new and has been successfully applied in various classification tasks, including land cover classification and 3D facial recognition.\n\nHidden Markov models, on the other hand, are statistical models that represent systems assumed to be Markov processes with hidden states. These models are commonly used in natural language processing and protein topology prediction. The application of these models in our study was to uncover hidden states affecting given observations from electrical penetration graph (EPG) recordings.\n\nThe choice of these algorithms was driven by their proven effectiveness in handling complex data and their ability to provide high accuracy in classification tasks. The focus of this publication is on the application of these machine-learning techniques to the specific problem of classifying insect feeding states, rather than the development of new algorithms. Therefore, the algorithms were not published in a machine-learning journal but rather in a computational biology journal, as the primary contribution lies in the novel application of these techniques to biological data.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding process involved transforming raw voltage data from psyllid feeding recordings into a format suitable for machine learning algorithms. Initially, the raw data was recorded using WinDaq Data acquisition and Playback software and then classified by visual inspection and annotated using the WinDaq data browser. This annotated data was exported to comma-separated value files.\n\nSubsequently, the raw data from these comma-separated values was loaded into the R computing environment, version 3.2.2. The data was then converted from the time domain to the frequency domain using the fast Fourier transform. This transformation allowed for the extraction of the six frequencies with the highest magnitudes, which were often harmonics. These dominant frequencies were then used as features in the machine learning algorithms.\n\nThe preprocessing steps ensured that the data was in a suitable format for training and testing the machine learning models, specifically the random forests and hidden Markov models. This approach facilitated the automated classification of insect feeding states, reducing the need for manual annotation and speeding up the analysis process.",
  "optimization/parameters": "In our study, we utilized Fourier-transformed data from electrical penetration graph (EPG) recordings to train our machine learning models. The specific number of parameters (p) used in the model is not explicitly stated, but it is implied that a twelve-dimensional feature set was derived from the Fourier-transformed data. This feature set was then used for various analyses, including principle coordinates analysis and hierarchical cluster analysis.\n\nThe selection of these parameters was likely driven by the need to capture the essential characteristics of the EPG recordings that correspond to different insect feeding states. The Fourier transform is a mathematical technique used to express a time signal in terms of the frequencies it contains. By transforming the raw EPG data into the frequency domain, we could identify dominant frequencies that are indicative of specific feeding behaviors. These dominant frequencies were then used as features in our machine learning models.\n\nThe use of a twelve-dimensional feature set suggests that twelve dominant frequencies were deemed sufficient to represent the complexity of the insect feeding behaviors being studied. This dimensionality was likely chosen to balance the need for comprehensive data representation with the computational efficiency required for high-throughput analysis.\n\nAdditionally, the use of random forests models, which are an ensemble learning method, allowed us to aggregate the results of multiple decision trees. This approach helps to improve the robustness and accuracy of the classification by reducing the risk of overfitting to the training data. The models were trained using a random five percent subset of each recording, with three repeated 10-fold cross-validation to ensure the generalizability of the results.\n\nIn summary, the model parameters were selected based on the dominant frequencies extracted from the Fourier-transformed EPG data, resulting in a twelve-dimensional feature set. This feature set was used to train random forests models, which demonstrated high accuracy in classifying insect feeding states.",
  "optimization/features": "The input features used in our analysis were derived from the frequency domain representation of the raw electrical penetration graph (EPG) data. Specifically, we employed the fast Fourier transform to convert the time-domain data into the frequency domain. From this transformation, we extracted the six frequencies with the highest magnitudes, which often included harmonics. These six dominant frequencies served as the input features for our machine learning algorithms.\n\nFeature selection was inherently performed by focusing on the dominant frequencies, as these were deemed most relevant for distinguishing between different feeding states. This approach ensured that the most informative features were used, thereby enhancing the model's performance. The selection of these features was based on the entire dataset, but the training process itself was conducted using a random 5% subsample of each recording. This subsampling strategy was crucial for maintaining high accuracy while minimizing the need for extensive human annotation. The use of these dominant frequencies as input features allowed our models to achieve high classification accuracy, particularly in distinguishing between phloem and non-phloem feeding states.",
  "optimization/fitting": "The fitting method employed in this study involved the use of random forests and hidden Markov models, both of which are robust to overfitting due to their inherent design.\n\nRandom forests, an ensemble learning method, utilize multiple decision trees to make predictions. Each tree is trained on a different bootstrap sample of the data, and the final prediction is an average (for regression) or majority vote (for classification) of the individual trees. This approach reduces the risk of overfitting by averaging out the noise and bias that individual trees might capture. Additionally, the use of a 5% training set and 95% test set scheme, along with 3 repeated 10-fold cross-validation, ensured that the model's performance was evaluated on unseen data, further mitigating overfitting concerns.\n\nThe hidden Markov models (HMMs) used in this study were fitted using the expectation-maximization (EM) algorithm, which iteratively improves the model parameters to maximize the likelihood of the observed data. The Bayesian information criterion (BIC) was employed to penalize additional feeding states, preventing the model from becoming too complex and overfitting the data. The BIC balances the goodness of fit with the complexity of the model, ensuring that the chosen model is not overly tailored to the training data.\n\nTo address underfitting, the study utilized a comprehensive feature set derived from Fourier-transformed electrical penetration graph (EPG) data. This transformation captures the dominant frequencies of the insect feeding states, providing a rich set of features for the models to learn from. Furthermore, the use of a leave-one-out classification scheme demonstrated that the models could generalize well to new, unseen recordings, indicating that they were not underfitting the data.\n\nIn summary, the fitting methods employed in this study were designed to balance model complexity and performance, effectively ruling out both overfitting and underfitting. The use of ensemble learning, cross-validation, and regularization techniques ensured that the models were robust and generalizable to new data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. For the random forests classification, we used repeated 10-fold cross-validation. This method involves splitting the data into training and test sets multiple times, which helps to ensure that the model generalizes well to unseen data. Additionally, we used a 5% training to 95% test set scheme, which was found to be advantageous in terms of reducing human labor while maintaining high accuracies. This approach helps to mitigate overfitting by ensuring that the model is evaluated on a large and diverse test set.\n\nFor the hidden Markov models, we utilized the Bayesian information criterion to penalize additional feeding states. This criterion helps to balance the complexity of the model with its fit to the data, preventing overfitting by avoiding overly complex models that may fit the noise in the training data rather than the underlying patterns.\n\nThese regularization methods were crucial in ensuring that our models were not only accurate but also generalizable to new data, thereby enhancing the reliability of our findings.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the provided information. However, the methods and tools employed for the analysis are well-documented. The study utilized various R packages for data management, machine learning, and statistical analysis. These packages include data.table, dplyr, tidyr, and pryr for data management; caret and randomForest for machine learning implementation; foreach, doParallel, and doMC for parallel processing; pvclust and ggdendro for hierarchical cluster analysis; and depmixS4 for hidden Markov models. Additionally, ggplot2 was used for developing graphics.\n\nThe specific configurations and parameters for these tools and models are not provided, but the use of these packages suggests a structured approach to data handling and analysis. The study also mentions the use of a leave-one-out classification scheme and hidden Markov models, which indicate a rigorous methodology for model training and validation.\n\nFor those interested in replicating or building upon this work, the R packages mentioned are freely available and can be accessed through the Comprehensive R Archive Network (CRAN). The study does not provide direct links to model files or specific optimization schedules, but the methodologies and tools used are standard and well-documented in the field. This should allow other researchers to implement similar analyses with the appropriate data and computational resources.",
  "model/interpretability": "The models employed in this study, including random forests, hidden Markov models, and hierarchical cluster analysis, offer varying degrees of interpretability.\n\nRandom forests, an ensemble learning method, are considered relatively transparent. They consist of multiple decision trees, each providing a simple, rule-based structure that is easy to interpret. The importance of each feature in the model can be quantified, allowing for an understanding of which aspects of the data are most influential in the classification process. For instance, specific frequency components derived from the Fourier-transformed EPG data can be identified as critical for distinguishing between different feeding states. This transparency is beneficial for validating the model's decisions and gaining insights into the underlying patterns in the data.\n\nHidden Markov models, on the other hand, are more complex and less transparent. These models use Markov processes to uncover hidden states affecting observed data, making them powerful for identifying unrecognized feeding states. However, the internal workings of these models are not as straightforward to interpret. The states and transitions identified by the model can be visualized, but the specific reasons for these classifications are less clear. For example, the model might identify additional feeding states within a known state, such as the C feeding state, but the exact biological significance of these sub-states may require further investigation.\n\nHierarchical cluster analysis provides a visual representation of the relationships between different data points, making it somewhat interpretable. The dendrograms generated by this analysis show how data points group together based on similarity, which can be useful for understanding the variation in feeding behaviors across different citrus varieties. However, the specific criteria used by the algorithm to form these clusters are not always immediately apparent, requiring additional context to fully interpret the results.\n\nIn summary, while random forests offer a high degree of interpretability, hidden Markov models and hierarchical cluster analysis provide more abstract insights that may require further analysis to fully understand. The combination of these methods allows for both high-throughput data analysis and deeper exploration of the underlying patterns in insect feeding behaviors.",
  "model/output": "The model employed in this study is a classification model. Specifically, it utilizes supervised random forests to classify insect feeding states based on electrical penetration graph (EPG) recordings. The model was trained to recognize six distinct feeding states, including phloem salivation and ingestion, which are critical for understanding pathogen transmission. The classification accuracy of the model is notably high, reaching up to 97.4% when compared to human expert annotations. This high accuracy demonstrates the model's effectiveness in distinguishing between different feeding states, making it a reliable tool for automated analysis of EPG data. Additionally, the model's ability to achieve high accuracy with a minimal training set (5% of the data) highlights its efficiency in reducing the need for extensive human annotation, thereby facilitating high-throughput analysis.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the algorithms and methods used in this study is not publicly released. However, the analysis was conducted using several R packages, which are publicly available and can be accessed through the Comprehensive R Archive Network (CRAN). These packages include data.table, dplyr, tidyr, pryr, caret, randomForest, foreach, doParallel, doMC, pvclust, ggdendro, and depmixS4. Additionally, the ggplot2 package was used for developing graphics. All of these packages are open-source and can be installed and used under the terms of their respective licenses, which are typically permissive and allow for both academic and commercial use. While the specific implementations and scripts used in this study are not provided, the use of these publicly available packages allows for reproducibility of the analysis with the appropriate data and configurations.",
  "evaluation/method": "The evaluation of the method involved several rigorous procedures to ensure the accuracy and reliability of the classification models. For the supervised random forests classification, the data underwent a random split into training and test sets for each recording. A random five percent subset of each recording was used to train the model, which employed 3 repeated 10-fold cross-validation. The model was then tested on the remaining ninety-five percent of the recording. This procedure was repeated for all six human-recognized feeding states and was used to differentiate between phloem and non-phloem feeding states. The out-of-sample accuracy was compared to human expert classification of the test set, and ninety-five percent confidence intervals were averaged for all feeding states.\n\nAdditionally, different training-to-test set schemes, such as 50:50 and 95:5, were considered but did not produce differences in overall accuracy. The 5% training to 95% test set scheme was found to be the most advantageous in terms of reducing human labor while maintaining high accuracies. Using training sets smaller than 5% increased the likelihood of missing certain feeding states and lowered classification accuracy.\n\nA leave-one-out classification scheme was also pursued to determine the possibility of classification without additional human input. In this scheme, a random five percent subsample of each feeding state from each of 26 human-annotated recordings was used to train the random forests model with 3 repeated 10-fold cross-validation. The model was then used to classify the 27th recording, and the results were compared with human expert annotation to determine out-of-sample accuracy. This procedure was repeated for each of the 27 recordings, leaving out one recording each time.\n\nFor the unsupervised hidden Markov model classification, the models were applied to the dominant frequencies extracted from Fourier-transformed data to separate the electrical penetration graph time series into up to 12 feeding states. Parameter estimation was accomplished through the expectation-maximization algorithm, and the posterior state sequence was recovered by the Viterbi algorithm. The Bayesian information criterion was used to penalize additional feeding states.\n\nCluster analysis was performed to explore similarities between varieties and insect feeding states. Hierarchical cluster analysis was applied to density distributions of dominant frequencies extracted from Fourier-transformed electrical penetration graph recordings. Variety similarity was determined through bootstrapping 1000 times the difference in Euclidean distance among and between frequency density distributions of trifoliate varieties. The comparison of unsupervised classification using hierarchical clustering to human-annotated states was accomplished through the construction of a heatmap presenting the percent median feeding bout time scaled within each feeding state.",
  "evaluation/measure": "The performance of the models was evaluated using out-of-sample accuracy, which was compared to human expert classification of the test set. This metric was chosen to assess how well the models generalize to unseen data. Additionally, 95% confidence intervals for the accuracy were averaged across all feeding states to provide a measure of the reliability of the accuracy estimates.\n\nThe models were trained using a random 5% subset of each recording, and the remaining 95% was used for testing. This approach was found to be advantageous in terms of reducing human labor while maintaining high accuracies. The use of a 5% training set was also considered most advantageous in terms of reducing human labor while maintaining high accuracies.\n\nThe accuracy of the models was reported for different training-to-test set schemes, including 50:50 and 95:5, but these did not produce differences in overall accuracy. The 5% training to 95% test set scheme was ultimately chosen as it provided a good balance between reducing human labor and maintaining high accuracies.\n\nThe models were also evaluated using a leave-one-out classification scheme, where a random 5% subsample of each feeding state from each of 26 human-annotated recordings was used to train the model. The model was then used to classify the 27th recording, and this process was repeated for each recording. This approach allowed for the evaluation of the models' ability to classify recordings without additional human input.\n\nThe accuracy of the models was also evaluated for different feeding states, including phloem (E1 and E2) and non-phloem (C, D, NP, and G) feeding states. The models were able to achieve high accuracy in classifying phloem feeding states, which was of primary interest as this is when pathogen acquisition and inoculation are presumed to occur.\n\nIn summary, the performance of the models was evaluated using out-of-sample accuracy and 95% confidence intervals, and the models were found to achieve high accuracies across different feeding states and training-to-test set schemes. The use of a 5% training set was found to be advantageous in terms of reducing human labor while maintaining high accuracies. The models were also evaluated using a leave-one-out classification scheme, which allowed for the evaluation of the models' ability to classify recordings without additional human input.",
  "evaluation/comparison": "Not applicable. The publication focuses on the application of machine learning algorithms, specifically random forests, hidden Markov models, and hierarchical cluster analysis, to classify insect feeding states from electrical penetration graph (EPG) recordings. The methods used are compared internally, such as evaluating different training-to-test set ratios and leave-one-out classification schemes, but there is no mention of comparing these methods to publicly available methods or simpler baselines on benchmark datasets. The evaluation is primarily based on the accuracy of the models compared to human expert annotations and the identification of additional feeding states.",
  "evaluation/confidence": "The evaluation of the machine learning models used in this study includes confidence intervals for the performance metrics. Specifically, the out-of-sample accuracy of the random forests models is reported with 95% confidence intervals. This provides a measure of the reliability of the accuracy estimates. The models achieved high accuracy, with the overall classification accuracy reaching 97.4Â±0.1% (95% CI) when compared to human expert annotation. This indicates that the results are statistically significant and that the method is robust.\n\nThe use of a leave-one-out classification scheme further supports the reliability of the models. In this scheme, the models were trained on a random 5% subsample of 26 recordings and then used to classify the remaining recording. This process was repeated for each recording, and the results showed greater than 95% accuracy in some cases. This approach helps to ensure that the models generalize well to new, unseen data.\n\nAdditionally, the study employed hierarchical cluster analysis and hidden Markov models to explore similarities between varieties and insect feeding states. The Bayesian information criterion was used to penalize additional feeding states, ensuring that the models did not overfit the data. The use of bootstrapping techniques, such as bootstrapping 1000 times the difference in Euclidean distance among and between frequency density distributions, further supports the statistical significance of the results.\n\nOverall, the evaluation metrics and statistical methods used in this study provide strong evidence that the machine learning models are superior to manual annotation methods and other baselines. The inclusion of confidence intervals and the use of robust statistical techniques ensure that the results are reliable and statistically significant.",
  "evaluation/availability": "Not enough information is available."
}