{
  "publication/title": "Deep Learning-Based Prediction of Drug Sensitivity in Cancer Cell Lines",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Mol Cancer Res.",
  "publication/year": "2019",
  "publication/doi": "10.1093/bioinformatics/btv315",
  "publication/tags": "- Drug Sensitivity\n- Machine Learning\n- Deep Learning\n- Genomics\n- Cancer Cell Lines\n- Predictive Modeling\n- Elastic Net Regression\n- Support Vector Machines\n- Omics Data\n- Pharmacogenomics\n- Clustering\n- Tissue Type\n- Drug Response\n- Feature Selection\n- Autoencoders\n- Cross-Validation\n- External Validation\n- Drug Sensitivity Prediction\n- Consensus Clustering\n- Regularization",
  "dataset/provenance": "The datasets utilized in this study were sourced from two prominent pharmacogenomics studies: the Genomics of Drug Sensitivity in Cancer Project (GDSC) and the Cancer Cell Line Encyclopedia (CCLE).\n\nThe GDSC dataset contains results from drug sensitivity experiments involving 140 drugs across 624 cell lines. Each cell line is characterized by genomic features, including somatic copy number alteration (SCNA) status of 426 genes, mutation status of 71 genes, and gene expression values of 22,215 gene probes. The dataset includes drug sensitivity measurements, copy number variation data, mutation data, and cell line annotations, all of which were downloaded from the GDSC website.\n\nThe CCLE dataset comprises gene expression data, copy number variation data, mutation data, and cell line annotations, all of which were downloaded from the CCLE website. Additionally, drug sensitivity measurements were obtained from the associated publication. The CCLE dataset consists of 3577 features measured in 1067 cell lines. The CCLE mutation data were collected using two methods: Oncomap 3.0 and hybrid capture analysis. These data were extracted from specific files available on the CCLE website and were classified as mutated or not based on The Cancer Genome Atlas specification for the Mutation Annotation Format.\n\nThe datasets have been used in previous studies and by the community. For instance, the GDSC dataset has been analyzed to systematically evaluate the utility of genome-status markers as therapeutic indicators for molecularly targeted drugs. The CCLE dataset has been used for external validation of predictive models, where the autoencoder trained on GDSC data was applied to derive features for the CCLE cell lines, and the best elastic net models trained using GDSC were used to predict drug sensitivity for CCLE cell lines. This cross-validation approach helps in assessing the robustness and generalizability of the models.",
  "dataset/splits": "The dataset was split into two main parts: a training set and a testing set. The training set consisted of 520 samples, while the testing set had 104 samples. These splits were used to train and evaluate a deep autoencoder model. During the training process, the model's performance was periodically assessed on the testing dataset to apply an early stopping rule, which helps prevent overfitting. This split ensures that the model is trained on a substantial amount of data while also having a separate set to validate its performance.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study were retrieved from two large pharmacogenomics studies: the Genomics of Drug Sensitivity in Cancer Project (GDSC) and the Cancer Cell Line Encyclopedia (CCLE). The GDSC gene expression data were downloaded from ArrayExpress in the form of raw Affymetrix CEL files. Additionally, drug sensitivity measurements, copy number variation data, mutation data, and cell line annotations were obtained from the GDSC website. Similarly, CCLE gene expression data, copy number variation data, mutation data, and cell line annotations were downloaded from the CCLE website. Drug sensitivity measurements for CCLE were obtained from the associated publication.\n\nThe data from these sources were processed and combined to create a comprehensive dataset. For instance, GDSC gene expression data were normalized using Robust Multi-Array Averaging, and replicate experiments were averaged. The normalized data were then filtered using various variance metrics to select the most variant gene probes. This resulted in a dataset containing discretized gene expression data of 3080 genes in 727 cell lines. Copy number variation data and mutation data were also extracted and processed to ensure compatibility with the GDSC dataset.\n\nThe processed data, including the feature-selected dataset, were used to train various models, such as deep autoencoders and elastic net regression models. The splits used for training and testing these models were randomly assigned, with 520 samples used for training and 104 samples used for testing. The performance of the models was periodically evaluated on the testing dataset to apply the early stopping rule and prevent overfitting.\n\nThe data and the models trained on them are not explicitly mentioned to be released in a public forum. However, the sources from which the data were obtained are publicly accessible. The GDSC data can be accessed from ArrayExpress and the GDSC website, while the CCLE data can be accessed from the CCLE website. The specific files and methods used for data retrieval and processing are detailed in the materials and methods section, ensuring reproducibility. The use of public datasets and detailed methodologies ensures that the data splits and processing steps can be replicated by other researchers.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is deep learning, specifically autoencoders. Autoencoders are a type of unsupervised deep neural network designed to learn efficient codings of input data. They aim to learn new representations of a vector of observed variables using multiple hidden layers of hierarchically organized latent variables. This approach allows for the capture of complex statistical structures within the data, which can be particularly useful for high-dimensional datasets like those involving genomic information.\n\nThe autoencoder used in our work is not entirely new; it is based on the deep autoencoder described by Hinton and Salakhutdinov. However, we modified the existing code to utilize our feature-selected dataset for unsupervised representation learning. This adaptation was necessary to tailor the model to our specific dataset and research objectives.\n\nRegarding the publication venue, our focus was on applying machine learning techniques to improve drug sensitivity predictions in cancer research. The primary contribution of our study lies in the application of these methods to a biological problem rather than the development of a novel machine-learning algorithm. Therefore, publishing in a cancer research journal was more aligned with our goals and the impact we aimed to achieve within the field of oncology. The modifications made to the autoencoder were technical adjustments to fit our data and were not substantial enough to warrant publication in a machine-learning journal.",
  "optimization/meta": "The models discussed in this publication do not constitute a meta-predictor. Instead, they primarily rely on elastic net regression and deep learning techniques, specifically autoencoders, to predict drug sensitivity.\n\nElastic net regression is used to generate logistic models for drug sensitivity prediction. This method combines lasso and ridge regularization to handle high-dimensional data effectively. The elastic net models are trained using omics data, which include gene expression, copy number variation, and mutation data.\n\nDeep learning, particularly autoencoders, is employed to learn cellular state features from the omics data. The autoencoder is trained in an unsupervised manner to derive a novel representation of the input data. This representation is then used as input for the elastic net models to predict drug sensitivity.\n\nThe training data for the elastic net models and the autoencoder are derived from the Genomics of Drug Sensitivity in Cancer (GDSC) dataset. The models are evaluated using data from the Cancer Cell Line Encyclopedia (CCLE) to assess their external validity. The use of independent datasets for training and evaluation ensures that the models are robust and generalizable.\n\nIn summary, the predictive models discussed here do not use data from other machine-learning algorithms as input. They rely on elastic net regression and deep learning techniques, with training data that is independent and derived from different sources for validation purposes.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for training and prediction. Initially, gene expression data from the Genomics of Drug Sensitivity in Cancer Project (GDSC) were normalized using Robust Multi-Array Averaging. For replicate experiments, expression values were averaged. Spike control probes were removed, resulting in an array of 22,215 probe expression measurements across 727 cell lines.\n\nTo select the most informative genes, three variance metrics were applied: Hartigans’ dip test for unimodality, the outlier sum method, and median absolute deviation. These methods helped identify genes with multimodal distributions, significant outlier populations, and high variance across samples. Approximately 14% of the genes, totaling 3080, were retained based on these criteria. A mixture of two normal distributions was fitted to each gene’s expression profile, and a t-test was used to determine statistical significance between the two groups. This process discretized the expression levels of each gene into low and high values.\n\nCopy number variation data, ranging from 0 to 10, were normalized to real values between 0 and 1, with values above this range set to 1. Mutation data, already in binary form, required no further processing. These datasets were combined with gene expression data using cell line annotations, resulting in a single array containing information on 3577 features across 624 cell lines. Cell lines lacking all three data types were excluded from the analysis.\n\nDrug sensitivity measurements were extracted from the GDSC and discretized into sensitive and resistant categories using the waterfall method. This method involved sorting drug sensitivity measurements, fitting a linear regression, and determining a cutoff value based on the Pearson correlation coefficient. This cutoff separated sensitive and resistant cell lines for each drug.\n\nFor the deep learning component, an autoencoder was trained using the feature-selected GDSC dataset. The dataset was split into training and testing sets, with 520 and 104 samples, respectively. The autoencoder, with hidden layers of sizes 1300, 552, 235, and 100, was trained using 50 epochs of pretraining a stacked restricted Boltzmann machine and 400 epochs of backpropagation. A batch size of 26 was used, and early stopping was applied to prevent overfitting.\n\nThe encoded data, including the original genomic features, feature-selected dataset, and latent variables from the autoencoder, were used as input vectors for training machine learning models. Elastic net regression and support vector machines (SVM) with a Gaussian kernel were employed to predict drug sensitivity. The target vector for each model consisted of the discretized sensitivity data for a particular drug. For elastic net regression, six models were built with varying input vector sizes, while for SVM, two models were built using the original and feature-selected datasets.",
  "optimization/parameters": "In our study, the number of input parameters (p) varied depending on the specific model and the feature set used. For the elastic net regression models, we built six models for each drug, each with input vectors of varying sizes. These included the original unprocessed genomic features, the feature-selected dataset, and each of the four layers of latent variables from the deep learning autoencoder. The sizes of these layers were 1300, 552, 235, and 100, respectively.\n\nFor the support vector machine (SVM) models, we built two models for each drug. One used the original unprocessed genomic features as input, while the other used the feature-selected dataset.\n\nThe selection of the number of parameters was influenced by the goal of balancing model complexity and predictive performance. The feature-selected dataset was chosen to reduce dimensionality while retaining important predictive variables. The layers of the autoencoder were designed to progressively reduce dimensionality, capturing increasingly abstract representations of the data. The specific sizes of these layers were determined through a combination of empirical testing and theoretical considerations, aiming to optimize the trade-off between computational efficiency and model performance.",
  "optimization/features": "In our study, we utilized a comprehensive set of features derived from omics data to predict drug sensitivity. Specifically, we combined three types of data: gene expression, copy number variation, and mutation data. These were integrated into a single array containing information on 3577 features across 624 cell lines. It is important to note that cell lines for which all three data types were not available were excluded from the analysis.\n\nFeature selection was indeed performed to refine the input features. This process involved creating a feature-selected dataset, which was then used for unsupervised representation learning via a deep autoencoder. The autoencoder was trained using the feature-selected dataset, and the learned representations were subsequently used as inputs for predictive modeling.\n\nTo ensure the robustness of our feature selection process, it was conducted using only the training set. This approach helps to prevent data leakage and maintains the integrity of the validation process. By doing so, we aimed to create a more reliable and generalizable model for predicting drug sensitivity.",
  "optimization/fitting": "In our study, we indeed dealt with a high-dimensional dataset, where the number of features (3577) was significantly larger than the number of training samples (520). This scenario posed a risk of overfitting, where the model might learn the noise in the data rather than the underlying patterns.\n\nTo mitigate overfitting, we employed several strategies. Firstly, we used regularization techniques. For the elastic net regression, we incorporated both lasso (L1) and ridge (L2) penalties, which helped to shrink some coefficients to zero and reduce the complexity of the model. The hyperparameter alpha controlled the balance between these two penalties, and lambda determined the overall strength of the regularization. We optimized lambda using cross-validation to find the best trade-off between bias and variance.\n\nSecondly, we implemented early stopping during the training of our deep autoencoder. We monitored the model's performance on a separate testing dataset and stopped training when the performance on this dataset started to degrade, indicating that the model was beginning to overfit the training data.\n\nAdditionally, we performed 25-fold cross-validation for both the elastic net regression and support vector machine (SVM) models. This technique ensured that each sample was used for both training and validation, providing a more robust estimate of the model's performance and helping to prevent overfitting.\n\nTo address the risk of underfitting, we used a sufficiently complex model architecture for our deep autoencoder, with hidden layers of size 1300, 552, 235, and 100. We also trained the model for a substantial number of epochs (50 epochs of pretraining and 400 epochs of backpropagation), allowing it to learn the underlying patterns in the data. Furthermore, we evaluated the performance of our models using multiple metrics, including sensitivity, specificity, positive predictive value (PPV), and the area under the receiver operating characteristic curve (AUROC). This comprehensive evaluation helped us to ensure that our models were not only complex enough to capture the underlying patterns but also generalizable to new, unseen data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, a common challenge in machine learning, especially when dealing with high-dimensional data.\n\nFor the deep learning component, we utilized early stopping during the training of the autoencoder. This involved periodically evaluating the model's performance on a separate testing dataset. If the model's performance on this dataset began to decline, training was halted to prevent overfitting to the training data.\n\nIn the context of elastic net regression, we used a hybrid regularization term that combines lasso and ridge regularization. This approach helps to shrink some coefficients to zero (lasso) and others to small values (ridge), effectively selecting a simpler model that generalizes better to unseen data.\n\nAdditionally, we performed 25-fold cross-validation during the elastic net regression process. Cross-validation helps to ensure that the model is not overfitting to a particular subset of the data by evaluating its performance on multiple splits of the data.\n\nThese techniques collectively helped to mitigate the risk of overfitting and improve the generalizability of our models.",
  "optimization/config": "The configuration details for the deep learning model, specifically the autoencoder, are available. The code for training the autoencoder was obtained from a publicly accessible source and modified for the specific dataset used in this study. The autoencoder was trained using a batch size of 26, with hidden layers of size 1300, 552, 235, and 100. The training process involved 50 epochs of pretraining a stacked restricted Boltzmann machine and 400 epochs of backpropagation. The dataset was split into training and testing sets with 520 and 104 samples, respectively. Early stopping was applied using the testing dataset to prevent overfitting.\n\nFor the elastic net regression, the hyperparameters alpha and lambda were used, with alpha fixed at 0.5 and lambda optimized for predictive performance. The regression was performed with 25-fold cross-validation using the glmnet R package.\n\nThe specific model files and optimization parameters are not explicitly detailed in the provided information, but the general approach and configurations are described. The methods and configurations are reported in the publication, and the code modifications are based on publicly available resources. However, the exact license terms for the modified code are not specified.",
  "model/interpretability": "The models employed in this study, particularly the autoencoder and the elastic net, can be considered somewhat interpretable, although they are not entirely transparent. The autoencoder, a type of unsupervised deep neural network, learns new representations of observed variables through multiple hidden layers. Each hidden layer transforms the input data using a set of weights, encoding the statistical distributions underlying the omics data into latent variables. These latent variables can be seen as features that reflect the cellular state, making the model somewhat interpretable. For instance, the states of latent variables within specific layers can be used to represent each cell line, providing insights into the signaling pathways in these cells.\n\nThe elastic net models, which are used for drug sensitivity prediction, incorporate these latent variables as additional features. While the elastic net itself is a regularized logistic regression model, which is generally more interpretable than black-box models like deep neural networks, the inclusion of latent variables from the autoencoder adds a layer of complexity. The elastic net's coefficients can indicate the importance of different features, including the latent variables, in predicting drug sensitivity. However, the exact meaning of these latent variables is not straightforward to interpret, as they are learned representations of complex biological data.\n\nIn summary, while the models used in this study provide some level of interpretability through the use of latent variables and regularized logistic regression, they are not entirely transparent. The latent variables offer insights into the cellular state, but their specific biological significance is not immediately clear. The elastic net models can indicate the importance of different features, but the inclusion of latent variables adds complexity to the interpretation.",
  "model/output": "The model employed in this study is primarily a classification model, specifically designed for drug sensitivity prediction. We utilized elastic net regression to generate logistic models, which are inherently classification models. These models predict whether a cell line is sensitive or resistant to a particular drug, based on the discretized drug sensitivity data.\n\nAdditionally, we used support vector machines (SVMs) with a Gaussian kernel for drug sensitivity prediction. SVMs are typically used for classification tasks, and in this case, they classify cell lines as either sensitive or resistant to drugs.\n\nThe target vectors for both the elastic net and SVM models consist of discretized sensitivity data, indicating a classification task rather than regression. The models were built for each drug, with input vectors of varying sizes, including original genomic features, feature-selected datasets, and latent variables from deep learning autoencoders.\n\nThe performance of these models was evaluated using metrics such as sensitivity, specificity, and positive predictive value, which are common in classification tasks. The models demonstrated varying levels of performance, with some drugs being better predicted by certain types of input features.\n\nIn summary, the models developed in this study are classification models aimed at predicting drug sensitivity in cell lines.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for training a deep autoencoder, as described by Hinton and Salakhutdinov, was obtained from Hinton’s website. This code was modified to utilize the feature-selected dataset for unsupervised representation learning. However, it is not explicitly stated whether this modified source code or any other software related to the models and methods described in the publication has been publicly released.\n\nNo information is provided about the availability of an executable, web server, virtual machine, or container instance to run the algorithms described in the publication. Therefore, it is not possible to confirm whether such resources are available for public use.\n\nNot sure about the licensing terms, as no details were provided regarding the license under which the software, if released, would be distributed.",
  "evaluation/method": "The evaluation of our predictive models involved several rigorous methods to ensure their validity and robustness. We employed 25-fold cross-validation for both elastic net regression and support vector machine (SVM) training, which helped in assessing the models' performance and generalizability. This cross-validation approach was crucial for tuning hyperparameters and preventing overfitting.\n\nIn addition to cross-validation, we conducted external validation using data from the Cancer Cell Line Encyclopedia (CCLE). This involved applying our autoencoder, trained on Genomics of Drug Sensitivity in Cancer (GDSC) data, to derive features for CCLE cell lines. We then used the best elastic net models trained on GDSC data to predict drug sensitivity for CCLE cell lines and evaluated these predictions against actual sensitivity calls from the CCLE experiment. The models achieved an average Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.67, which was significantly higher than results obtained using randomly permuted input data. This demonstrated that the relationships modeled by deep learning persist even under different experimental conditions.\n\nFurthermore, we investigated the external validity of our models by evaluating them using randomly permuted data. The significant difference in performance between the models evaluated on actual data and those evaluated on permuted data (p < 10e-5) indicated that our models capture genuine biological relationships rather than spurious correlations.\n\nWe also explored the possibility of tissue type confounding by comparing the performance of our models to a simple tissue-type-based prediction method. The elastic net models achieved a significantly higher average accuracy (0.62) compared to the tissue-type-based method (0.47), suggesting that our models encode additional information regarding the cellular state beyond just tissue type.\n\nOverall, these evaluation methods provided comprehensive evidence of the models' predictive power and their ability to generalize to independent datasets.",
  "evaluation/measure": "In the evaluation of our predictive models, several performance metrics were reported to provide a comprehensive assessment of their effectiveness. The primary metrics used include the Area Under the Receiver Operating Characteristic Curve (AUROC), sensitivity, specificity, and positive predictive value.\n\nThe AUROC is a widely used metric in the literature for evaluating the performance of binary classifiers. It provides a single scalar value that represents the ability of the model to distinguish between the positive and negative classes across all possible classification thresholds. An AUROC of 1 indicates perfect classification, while an AUROC of 0.5 indicates performance no better than random guessing.\n\nSensitivity, also known as recall or true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. These metrics are crucial for understanding the model's performance in identifying true positives and true negatives, respectively.\n\nThe positive predictive value, or precision, measures the proportion of predicted positives that are actual positives. This metric is particularly important in scenarios where the cost of false positives is high.\n\nThe reported metrics are representative of those commonly used in the literature for evaluating predictive models in similar contexts. The use of AUROC, sensitivity, specificity, and positive predictive value ensures that the performance of the models is assessed from multiple angles, providing a robust evaluation of their predictive capabilities. Additionally, the comparison of these metrics against other models, such as genomic marker rule-based models and FDA genomic guideline clinical indications, further contextualizes the performance of our models within the existing landscape of predictive modeling in cancer research.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our methods with both publicly available methods and simpler baselines to ensure the robustness and effectiveness of our approach. We benchmarked our models against genomic marker rule-based models and FDA genomic guideline clinical indications. Specifically, we compared the sensitivity and specificity of our best elastic net models with these established methods. Our models demonstrated superior performance, particularly in reducing false negatives for molecularly targeted drugs and false positives for nonspecific medications.\n\nAdditionally, we evaluated the performance of our models against simpler baselines, such as models based solely on tissue type. These baselines achieved an average accuracy of 0.47 for drugs in enriched tissue, whereas our best elastic net models achieved a significantly higher average accuracy of 0.62. This comparison underscores that our deep learning representations capture more than just tissue type information, encoding additional details about the cellular state to predict drug sensitivity accurately.\n\nFurthermore, we validated our models using data from an external study, the Cancer Cell Line Encyclopedia (CCLE). We applied our autoencoder, trained on GDSC data, to derive features for CCLE cell lines and then used our best elastic net models to predict drug sensitivity. The models achieved an average AUROC of 0.67, significantly higher than results obtained using randomly permuted input data. This external validation confirms that the relationships modeled by our deep learning approach persist under different experimental conditions, reinforcing the reliability and generalizability of our methods.",
  "evaluation/confidence": "The evaluation of our predictive models includes several performance metrics, and we have taken steps to ensure the statistical significance of our results. For instance, the sensitivity and specificity of our best elastic net models were compared to genomic marker rule-based models and FDA genomic guideline clinical indications, with statistical significance indicated by *** p < 10e-3. Similarly, the positive predictive value and sensitivity of these models were also evaluated with the same level of statistical significance.\n\nIn our study, we applied agglomerative hierarchical clustering to cell lines based on the autoencoder’s first hidden layer features, recovering a stable partitioning into 12 groups. We found that sensitivity to 74 drugs was significantly enriched (p < 0.05) in at least one group, supporting the idea that deep learning produces a novel and useful representation for predicting drug sensitivity.\n\nWe also investigated the external validity of our predictive models by evaluating them using data from the Cancer Cell Line Encyclopedia (CCLE). The fifteen models achieved an average AUROC of 0.67, which is significantly higher than results obtained using randomly permuted input data (p < 10e-5). This indicates that the relationships modeled by deep learning persist even under different experimental conditions.\n\nAdditionally, we compared the performance of our models to tissue-type-based predictions. The best elastic net models achieved a significantly higher average accuracy of 0.62 compared to the 0.47 accuracy of tissue-type-based models (p < 10e-7), demonstrating that our deep learning representations encode additional information regarding the cellular state beyond just tissue type.\n\nOverall, the statistical significance of our results provides confidence in the superiority of our method over other approaches and baselines.",
  "evaluation/availability": "Not enough information is available."
}