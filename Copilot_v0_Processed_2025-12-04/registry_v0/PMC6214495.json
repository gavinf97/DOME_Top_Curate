{
  "publication/title": "LogLoss-BERAF: An ensemble-based machine learning model for constructing highly accurate diagnostic sets of methylation sites accounting for heterogeneity in prostate cancer",
  "publication/authors": "The authors who contributed to the article are:\n\n- K. Babalyan: Conceptualization, formal analysis, investigation, visualization, writing – original draft.\n- R. Sultanov: Data curation, methodology, project administration.\n- E. Generozov: Conceptualization, data curation, writing – original draft, writing – review & editing.\n- E. Sharova: Conceptualization, data curation, supervision, writing – review & editing.\n- E. Kostryukova: Data curation, supervision.\n- A. Larin: Data curation, resources.\n- A. Kanygina: Investigation, writing – original draft.\n- V. Govorun: Project administration.\n- G. Arapidi: Supervision, writing – review & editing.",
  "publication/journal": "PLOS ONE",
  "publication/year": "2018",
  "publication/doi": "https://doi.org/10.1371/journal.pone.0204371",
  "publication/tags": "- DNA methylation\n- Prostate cancer\n- Diagnostic model\n- Machine learning\n- Ensemble methods\n- Heterogeneity\n- Classification efficacy\n- Stability\n- Cross-entropy loss\n- Biomarkers\n- Logistic regression\n- Random forest\n- Feature selection\n- Diagnostic panels\n- Tumor samples\n- Non-tumor samples\n- Methylation sites\n- Algorithm stability\n- Kuncheva index\n- Noise tolerance",
  "dataset/provenance": "The datasets used in this study were acquired using Illumina Infinium Human-Methylation 450k BeadChip technology. The primary dataset for developing the model and estimating its parameters was obtained from the TCGA PRAD project, which includes DNA methylation data from tumor and corresponding non-tumor prostate tissue samples. Additionally, our own dataset for 48 samples is available at the Gene Expression Omnibus (GEO) under the accession number GSE74013.\n\nTo demonstrate the efficiency of the framework, it was applied to other types of oncological diseases. For non-invasive prostate cancer diagnostics, methylation data for urothelial bladder carcinoma (BLCA), kidney renal clear cell carcinoma (KIRC), and kidney renal papillary cell carcinoma (KIRP) were analyzed. Since prostate cancer is often co-localized with colon adenocarcinoma, the framework was also applied to TCGA COAD data.\n\nThe samples used for the framework development and validation include:\n\n* Prostate adenocarcinoma: 331 samples from the TCGA PRAD dataset, along with additional datasets from GEO (GSE55479 with 143 samples, GSE38240 with 12 samples, and GSE73549 with 92 samples).\n* Urothelial bladder carcinoma: 351 samples from the TCGA BLCA dataset.\n* Kidney cancer: 420 samples from the TCGA KIRC dataset for renal clear cell carcinoma and 419 samples from the TCGA-KIRP dataset for kidney renal papillary cell carcinoma.\n\nThese datasets were selected based on age and clinical criteria to ensure a comprehensive and representative sample set for the study.",
  "dataset/splits": "The dataset splits for the study involved multiple datasets for different types of cancers. For prostate cancer, the training set consisted of 117 tumor samples and 15 non-tumor samples from the TCGA PRAD dataset, along with 8 tumor samples and 11 non-tumor samples from the FRCC PCM FMBA dataset. The test set included 176 tumor samples and 23 non-tumor samples from the TCGA PRAD dataset, as well as additional samples from GSE55479, GSE38240, and GSE73549.\n\nFor bladder cancer, the training set comprised 134 tumor samples and 9 non-tumor samples from the TCGA BLCA dataset. The test set included 201 tumor samples and 14 non-tumor samples from the same dataset.\n\nIn the case of colorectal cancer, the training set consisted of 133 tumor samples and 15 non-tumor samples from the TCGA COAD dataset, along with 6 tumor samples and 9 non-tumor samples from the FRCC PCM FMBA dataset. The test set included 200 tumor samples and 22 non-tumor samples from the TCGA COAD dataset.\n\nFor kidney cancer, specifically kidney renal clear cell carcinoma (KIRC), the training set included 116 tumor samples and 52 non-tumor samples from the TCGA KIRC dataset. The test set consisted of 174 tumor samples and 78 non-tumor samples from the same dataset.\n\nFor kidney renal papillary cell carcinoma (KIRP), the training set comprised 101 tumor samples and 63 non-tumor samples from the TCGA KIRP dataset. The test set included 151 tumor samples and 104 non-tumor samples from the same dataset.\n\nAdditionally, for urothelial bladder carcinoma, 167 non-tumor samples from the kidney cancer dataset were added to the dataset before splitting into train and test subsets due to the small number of non-tumor samples in the urothelial bladder carcinoma dataset. This was acceptable because tumors of this type represent a transitional epithelium carcinoma that affects the renal pelvis, renal ducts, bladder, and urethra.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is publicly available from two main sources. The first source is the Gene Expression Omnibus (GEO), accessible via the National Center for Biotechnology Information (NCBI) website. The specific accession numbers for the datasets are GSE74013, GSE55479, GSE38240, GSE73549, GSE42752, and GSE87571. The second source is The Cancer Genome Atlas (TCGA), which can be accessed through its portal.\n\nThe data is distributed under the terms of the Creative Commons Attribution License. This license permits unrestricted use, distribution, and reproduction in any medium, provided that the original author and source are credited. This ensures that the data can be freely accessed and utilized by the scientific community for further research and validation.\n\nThe availability of these datasets in public forums enhances the reproducibility and transparency of the study. Researchers can independently verify the findings and potentially build upon the work by using the same datasets. The use of public repositories like GEO and TCGA also standardizes the data sharing process, making it easier for other scientists to access and utilize the data.",
  "optimization/algorithm": "The machine-learning algorithm class used is ensemble-based methods. Specifically, the algorithm employs a combination of randomized logistic regression (RLR) and random forest (RF) algorithms. The RLR method, also known as the stability method, is used for feature selection by splitting the original set randomly and selecting sites with non-zero coefficients after regularization. This method is particularly useful for handling high-dimensional data and identifying highly correlated sites. The random forest algorithm is then used for classification, which is efficient for handling unbalanced data by adjusting sample weights inversely proportional to class frequencies.\n\nThe algorithm is not entirely new, as it builds upon established methods like randomized logistic regression and random forest. However, the specific combination and application of these methods to construct diagnostic sets of methylation sites for prostate cancer is novel. The focus of the publication is on the application of these methods to a specific biological problem rather than the development of a new machine-learning algorithm per se. Therefore, it is published in a biomedical journal rather than a machine-learning journal. The emphasis is on the biological insights and clinical applicability of the method, demonstrating its effectiveness in identifying methylation sites that can be used for diagnostic purposes.",
  "optimization/meta": "The model described in this publication is indeed a meta-predictor, as it leverages multiple machine learning methods to construct a highly accurate diagnostic set of methylation sites. The ensemble-based approach integrates several techniques to enhance the robustness and accuracy of the diagnostic model.\n\nThe process begins with the selection of factors based on a user-defined minimum difference between average methylation levels. This initial step ensures that only relevant factors are considered for further analysis.\n\nFollowing this, two feature selection methods are employed: randomized logistic regression (RLR) and a random forest (RF) algorithm. RLR, also known as the stability method, is used to identify significant sites for classification. It involves random splitting of the dataset and selecting sites with non-zero coefficients after regularization. This method is particularly useful for handling high-dimensional data and accounting for heterogeneity among samples.\n\nThe random forest algorithm is then used to handle unbalanced data by adjusting sample weights inversely proportional to class frequencies. The RF algorithm provides an estimate of feature importance, which is crucial for further feature selection.\n\nThe model also incorporates a pairwise correlational analysis to avoid data loss, ensuring that highly correlated features are not discarded prematurely. This step is essential for maintaining the integrity of the data and improving the model's performance.\n\nThe final step involves varying the feature importance threshold to construct a random forest for each factor subset and performing 10-fold cross-validation. This approach provides an unbiased estimate of model accuracy and helps in identifying less noisy sites.\n\nThe ensemble nature of the model ensures that it can reveal various connections between factors and predicted classes, leading to more stable and reproducible results. The use of multiple machine learning methods allows the model to handle the complexity and heterogeneity of DNA methylation profiles in oncological diseases effectively.\n\nRegarding the independence of training data, the model employs bootstrapping iterations with random selection of samples at each iteration. This process helps in ensuring that the training data is independent and reduces the risk of overfitting. The high Kuncheva index obtained from the experiments further supports the stability and reliability of the model.",
  "optimization/encoding": "The data encoding process involved representing the methylation level of each CpG site as a beta-value. This beta-value is calculated using the formula β = M / (M + U + 100), where M is the methylated intensity and U is the unmethylated intensity of each probe. This vector of beta values, denoted as β ∈ (0, 1)^N, where N is the number of samples, serves as a feature for further analysis.\n\nPreprocessing of raw IDAT files was conducted using the RnBeads package. Systematic batch effect correction was performed with the ComBat algorithm from the sva package. Normalization and background correction were achieved using the NOOB and BMIQ algorithms, which together demonstrated the best results in correcting technical errors.\n\nThe feature selection method was designed to handle unbalanced datasets, where the number of samples from one class (e.g., pathology) is significantly greater than another, or where the number of factors exceeds the total number of samples. The selected feature set, referred to as a signature, can include heterogeneously methylated CpG sites and must not exceed a predefined number of CpG sites. The methylation values of the selected CpG sites must differ between analyzed classes by more than a predefined value and may vary within the experimental level of accuracy.",
  "optimization/parameters": "The model construction algorithm incorporates several input parameters that are crucial for its operation. One of the key parameters is the upper limit for the number of features, denoted as P, in the diagnostic panel. This parameter is essential for ensuring that the model remains practical and interpretable, especially when dealing with high-dimensional data. The selection of P is guided by the need to balance model complexity and performance, aiming to include only the most diagnostically informative features.\n\nAnother important parameter is the number of analyzed classes, denoted as C. This parameter defines the number of distinct groups or categories that the model aims to differentiate. The value of C is determined by the specific diagnostic task at hand, such as distinguishing between different stages of a disease or different types of pathological conditions.\n\nThe model also utilizes a user-defined value, Δβ, which represents the minimum difference between average methylation levels. This threshold is used in the initial step of factor selection, where features are chosen based on their differential methylation between at least one pair of groups. The value of Δβ is set to ensure that only meaningful differences in methylation levels are considered, thereby enhancing the model's ability to identify relevant biomarkers.\n\nAdditionally, the model employs a combination of feature selection methods, including randomized logistic regression (RLR) and a random forest (RF) algorithm. These methods are chosen for their ability to handle high-dimensional data and unbalanced sets, where the number of samples from one class may be much greater than that of another. The RLR method, in particular, is selected for its capability to identify highly correlated sites and include them in the resulting set, which is crucial for capturing the complexity of methylation data.\n\nThe random forest algorithm is used for its efficiency in classification problems and its design to avoid overfitting. Sample weights are adjusted inversely proportional to class frequencies to handle unbalanced data, ensuring that the model performs well across all classes.\n\nIn summary, the model's input parameters include the upper limit for the number of features (P), the number of analyzed classes (C), and the minimum difference between average methylation levels (Δβ). These parameters are carefully selected to optimize the model's performance and ensure its practical applicability in diagnostic settings.",
  "optimization/features": "The input features for the diagnostic model are derived from DNA methylation data, specifically obtained using the Illumina Infinium Human-Methylation 450k BeadChip technology. This technology provides a comprehensive dataset of methylation sites across the genome.\n\nFeature selection is a critical step in the model construction process. The method employed is designed to handle unbalanced datasets, where the number of samples from one class (e.g., pathology) is significantly greater than that of another. The feature selection process involves several steps. Initially, factors are selected based on the average methylation differences between groups, ensuring that the differences exceed a user-defined threshold. This step helps in identifying potentially informative methylation sites.\n\nFollowing this, a combination of feature selection methods is used. The first method is randomized logistic regression (RLR), which involves splitting the original dataset randomly and selecting sites with non-zero coefficients after regularization. This method is effective in identifying highly correlated sites and can account for heterogeneity among samples. However, due to its stochastic nature, some valuable features might be discarded. To mitigate this, a pairwise correlational analysis is performed to avoid data loss.\n\nAdditionally, a random forest (RF) algorithm is utilized. This algorithm is popular for classification problems and helps in handling unbalanced data by adjusting sample weights inversely proportional to class frequencies. The RF algorithm provides an estimate of feature importance, which is used for further feature selection. The feature importance threshold is varied to construct random forests for different factor subsets, and 10-fold cross-validation is performed to estimate classification efficiency based on metrics such as precision, recall, and LogLoss.\n\nThe final set of features is selected based on the LogLoss function, ensuring that the resulting set is of minimum size while maintaining diagnostic efficiency. This approach allows for the detection of outliers and ensures that the model is robust and reliable.",
  "optimization/fitting": "The fitting method employed in our study addresses the challenge of high dimensionality, where the number of features (methylation sites) is significantly larger than the number of samples. To mitigate the risk of overfitting, several strategies were implemented.\n\nFirstly, randomized logistic regression (RLR) was used as part of the feature selection process. This method involves random splitting of the dataset and selecting features that have non-zero coefficients after regularization. The use of L1 regularization in RLR helps in selecting a limited number of the most significant features, thereby reducing the risk of overfitting. Additionally, RLR can identify and include highly correlated features due to its random splitting at each iteration, which accounts for heterogeneity among samples.\n\nSecondly, a random forest (RF) algorithm was utilized. RF is designed to avoid overfitting through the use of ensembles of decision trees and bootstrap aggregating. To handle unbalanced data, sample weights were adjusted inversely proportional to class frequencies. The RF algorithm provides an estimate of feature importance, which was used for further feature selection.\n\nTo ensure the model's robustness, 10-fold cross-validation was performed. This approach provides an unbiased estimate of model accuracy and helps in identifying the optimal number of features. The classification efficiency was evaluated using metrics such as precision, recall, and LogLoss. LogLoss, in particular, imposes penalties for both false predictions and low confidence in true predictions, helping to identify less noisy sites and detect outliers.\n\nThe stability of the algorithm was assessed using the Kuncheva index, which measures the variability of factor selection resulting from minor changes in the training set. The method demonstrated a relatively high Kuncheva index, indicating stability even with few samples and high dimensionality.\n\nFurthermore, the model's tolerance to input data errors was evaluated. The use of LogLoss as a metric allows the model to impose penalties for incorrect classifications and low confidence predictions, making it robust to noise in the input data.\n\nIn summary, the fitting method employed in our study effectively addresses the challenges of high dimensionality and unbalanced data. Through the use of randomized logistic regression, random forest algorithm, cross-validation, and stability assessment, the risk of overfitting was mitigated, and the model's robustness and accuracy were ensured.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, ensuring the robustness and generalizability of our diagnostic model. One of the key methods used was regularization, specifically L1 regularization within the randomized logistic regression (RLR) framework. This approach helps in selecting a limited number of the most significant sites for classification by penalizing the absolute size of the regression coefficients. By doing so, it encourages sparsity in the model, effectively reducing the risk of overfitting.\n\nAdditionally, we utilized a random forest (RF) algorithm, which is inherently designed to mitigate overfitting through the use of ensembles of decision trees and bootstrap aggregating. This method involves creating multiple decision trees during the training phase and combining their results to improve the model's predictive accuracy and stability. To handle unbalanced data, we adjusted sample weights inversely proportional to class frequencies, ensuring that the model does not become biased towards the majority class.\n\nFurthermore, we performed 10-fold cross-validation to provide an unbiased estimate of model accuracy. This technique involves dividing the data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once, thereby ensuring that the model's performance is evaluated across different data partitions.\n\nTo further enhance the model's stability and prevent overfitting, we conducted a pairwise correlational analysis. This step helps in identifying and including highly correlated sites, which might be discarded during the initial model construction due to the stochastic nature of the RLR process. By incorporating these correlated features, we aim to retain valuable information that could otherwise be lost, thereby improving the model's overall performance and robustness.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black-box but rather a transparent and interpretable framework. The interpretability stems from several key aspects of the methodology employed.\n\nFirstly, the model allows for the inclusion of methylation sites that exhibit high heterogeneity between groups, which provides insights into the differential variability of the sites used. This is in contrast to supervised approaches that strictly select candidate markers based on differential methylation levels. The model's capability to handle intra-group methylation level variability of individual sites enables a more nuanced understanding of the data.\n\nFor instance, the methylation patterns of the resulting model CpG sites in cancer samples can be clustered using algorithms like k-means. This clustering reveals distinct methylation patterns that can be biologically interpreted, offering insights into the metagenetic manifestations of disease heterogeneity. Different methylation patterns of samples, combined with the predictive values of the sites, can be used to interpret the biological significance of the results.\n\nMoreover, the model's stability and robustness are well-documented. The use of bootstrapping iterations and the Kuncheva index to measure stability ensures that the model's performance is reliable and reproducible. The high Kuncheva index of 0.72 indicates that the model maintains its factor selection consistency even with minor changes in the training set.\n\nThe model's tolerance to input data errors is another testament to its interpretability. By gradually introducing noise into the methylation levels and observing the model's performance, it was demonstrated that the model remains robust at noise levels of approximately 0.16 of the methylation β-value. This robustness suggests that the model can handle real-world data imperfections, making it more interpretable and applicable in clinical settings.\n\nAdditionally, the model's ability to classify samples with highly non-uniform methylation levels as tumors, while correctly identifying non-tumor samples, further enhances its interpretability. This capability is crucial for understanding the model's decision-making process and its potential clinical applicability.\n\nIn summary, the model's transparency is evident through its ability to handle heterogeneous data, its stability and robustness, and its interpretability in biological and clinical contexts. These features make the model a valuable tool for understanding the underlying mechanisms of prostate cancer and for developing practical diagnostic applications.",
  "model/output": "The model is designed for classification tasks, specifically for diagnosing different types of cancer based on methylation patterns. It utilizes a combination of feature selection methods, including randomized logistic regression and random forest algorithms, to identify the most significant methylation sites for classification. The model's performance is evaluated using metrics such as precision, recall, F1-score, and the area under the curve (AUC), which are commonly used in classification problems. Additionally, the model's output includes the classification of samples into different clusters based on their methylation patterns, further supporting its use in diagnostic classification. The model has been applied to various cancer types, demonstrating high classification efficacy with AUC values close to or equal to 1 for several cancer types, indicating its strong performance in distinguishing between different classes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the algorithm described in the publication is publicly available. It is implemented as standalone Python code and can be accessed from a GitHub repository. The repository contains the models discussed in the article, allowing users to replicate the results and apply the method to their own datasets. The software is open-source and distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction, provided that the original authors and source are credited. This ensures that the method is accessible to the broader scientific community for further research and practical applications.",
  "evaluation/method": "The method was evaluated using several approaches to ensure its robustness and diagnostic efficacy. Initially, the model's stability was assessed through bootstrapping iterations, where 90% of samples were randomly selected at each iteration. This process resulted in a high Kuncheva index of 0.72, indicating the model's stability. In contrast, LASSO alone achieved a score of 0.55, highlighting the superior stability of our method.\n\nTo evaluate the model's tolerance to input data errors, noise was gradually introduced into the methylation levels of the input data. The model demonstrated robustness at noise levels of approximately 0.16 of the methylation β-value, suggesting its potential for practical clinical diagnostics. Additionally, the model was tested on sufficiently noisy data (±0.5 β-value) and produced high AUC values, further confirming its robustness.\n\nThe diagnostic performance of the developed model was compared with several other published multigene models. The model was applied to datasets from various studies, including those by Stewart et al., Chung et al., and Tang et al. The comparisons showed that our model outperformed or matched the performance of these existing models in terms of AUC, precision, recall, and F1-score.\n\nFurthermore, the model's ability to handle highly heterogeneous data was assessed by applying it to leukocyte blood fraction methylation data from nominally healthy people. The model correctly classified all samples as non-tumors, demonstrating its effectiveness in distinguishing between tumor and non-tumor samples despite the high intragroup heterogeneity of tumor samples.\n\nThe model's diagnostic significance was also evaluated by assessing its ability to predict negative histopathological results in repeat prostate biopsies. The model's performance was compared with a 3-gene model based on the methylation levels of GSTP1, RASSF1, and APC, and it showed superior performance.\n\nOverall, the evaluation methods included stability assessments, noise tolerance tests, comparisons with existing models, and application to diverse datasets, all of which demonstrated the model's robustness, diagnostic efficacy, and potential for clinical application.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the diagnostic models developed for prostate cancer. These metrics include the Area Under the Curve (AUC), precision, recall, and the F1-score. The AUC provides a comprehensive measure of the model's ability to distinguish between tumor and non-tumor samples, with values ranging from 0 to 1, where 1 indicates perfect discrimination. Precision measures the accuracy of the positive predictions made by the model, while recall assesses the model's ability to identify all relevant instances in the dataset. The F1-score is the harmonic mean of precision and recall, offering a single metric that balances both concerns.\n\nThese metrics are widely used in the literature for evaluating diagnostic models, particularly in the context of cancer diagnosis. For instance, the 3-gene model based on GSTP1, RASSF1, and APC demonstrated an AUC of 0.92, precision of 0.91, recall of 0.89, and an F1-score of 0.89. Similarly, the model proposed by Chung et al., which focused on SPOCK2 and NSE1 gene methylation, reported a precision of 0.95 and a recall of 0.80. Our models, which utilized ensemble methods and considered multiple methylation sites, showed competitive performance with an AUC of 0.97, precision of 0.95, recall of 0.95, and an F1-score of 0.95. This set of metrics is representative of the standards in the field, ensuring that our results can be compared and validated against other studies. Additionally, we used LogLoss, also known as cross-entropy loss, to impose penalties for false predictions and low confidence in true ones, helping to identify less noisy sites and improve model robustness.",
  "evaluation/comparison": "To evaluate the diagnostic performance of our developed model, we compared it with several other published multigene models and simpler baselines. We reproduced the calculations of these models and applied them to the datasets being analyzed in this study.\n\nOne of the models we compared against was a 3-gene model based on the combined analysis of average methylation levels for GSTP1, RASSF1, and APC. This model demonstrated good results when applied to our data, achieving an AUC of 0.92, 0.91 precision, 0.89 recall, and 0.89 F1-score. However, our model outperformed this 3-gene model in all metrics.\n\nWe also compared our model with the diagnostic significance of SPOCK2 and NSE1 gene methylation, which had a recall of 0.80 and precision of 0.95. Our model achieved a precision of 0.90, recall of 0.87, and an F1-score of 0.88 with an AUC of 0.91, showing superior performance.\n\nAdditionally, we applied a method that selects 3 methylation sites (cg00054525, cg16794576, and cg24581650) using a linear mixed model and then used logistic regression to construct a diagnostic model. This model had a recall of 0.845 and specificity of 0.917, with an AUC of 0.92 for the test set. When trained and tested on our datasets, it demonstrated an AUC of 0.93, 0.92 precision, 0.92 recall, and a 0.91 F1-score. Our model again showed better performance in all metrics.\n\nFurthermore, we considered an 8-site model that used logistic regression and achieved an AUC of 0.94 when a combination of sites was used. When reproduced on our datasets, this 8-site model demonstrated an AUC of 0.95, 0.93 recall, 0.92 precision, and a 0.93 F1-score. While this model performed well, our model still showed slightly better performance in terms of precision and F1-score.\n\nIn summary, our model was compared against several publicly available methods and simpler baselines on benchmark datasets, consistently demonstrating superior diagnostic performance.",
  "evaluation/confidence": "The evaluation of our model includes several performance metrics with associated confidence intervals, ensuring a robust assessment of its efficacy. For instance, the area under the curve (AUC) for the classification efficacy is reported with a 95% confidence interval (CI), such as 0.93 (95% CI: 0.90–0.97) for the permutation test and 0.97 (95% CI: 0.94–0.99) for the test set. These intervals provide a range within which the true AUC value is expected to lie, giving a measure of the precision of our estimates.\n\nStatistical significance is also a key aspect of our evaluation. For example, the survival analysis of disease recurrence demonstrated a statistically significant difference between clusters 2 and 3, with a hazard ratio for recurrence of 0.48 (95% CI: 0.05–0.92) and a p-value of less than 0.03. This indicates that the differences observed are unlikely to be due to chance, reinforcing the clinical applicability of our model.\n\nAdditionally, the model's stability was assessed using the Kuncheva index, which resulted in a score of 0.72, compared to 0.55 for LASSO alone. This higher stability score suggests that our method is more reliable and less sensitive to minor changes in the training set, which is crucial for tasks involving few samples and high dimensionality.\n\nThe model's robustness to noise was also evaluated by gradually introducing noise into the methylation levels and observing the change in AUC. The model demonstrated good performance at noise levels of approximately 0.16 of the methylation β-value, indicating its tolerance to input data errors.\n\nIn summary, the performance metrics are accompanied by confidence intervals, and the results are statistically significant, providing strong evidence of the model's superiority over other methods and baselines.",
  "evaluation/availability": "All files used in the evaluation are available from the Gene Expression Omnibus (GEO) and The Cancer Genome Atlas. The specific accession numbers for the GEO datasets are GSE74013, GSE55479, GSE38240, GSE73549, GSE42752, and GSE87571. These datasets can be accessed via the GEO website. Additionally, data from The Cancer Genome Atlas is accessible through their portal. The data is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction, provided that the original author and source are credited. This ensures that the evaluation data is publicly available and can be used by other researchers for further studies or validations."
}