{
  "publication/title": "Artificial Intelligence Understands Peptide Observability and Assists With Absolute Protein Quantification",
  "publication/authors": "The authors who contributed to the article are:\n\nDavid Zimmer, who collected and processed the data, designed and implemented the deep learning algorithm, and wrote the article.\n\nKevin Schneider, who implemented the web interface.\n\nFrederik Sommer, who designed the QconCAT protein and performed the LC-MS/MS analyses.\n\nMichael Schroda, who conceived and supervised the work.\n\nTimo Mühlhaus, who conceived and supervised the work, and wrote the article with contributions from all other authors.",
  "publication/journal": "Frontiers in Plant Science",
  "publication/year": "2018",
  "publication/doi": "10.3389/fpls.2018.01559",
  "publication/tags": "- Peptide observability\n- Protein quantification\n- Deep learning\n- Proteomics\n- Machine learning\n- Peptide ranking\n- Plant proteomics\n- Yeast proteomics\n- Physicochemical properties\n- Targeted proteomics assays",
  "dataset/provenance": "The datasets used in our study were assembled from large shotgun proteomic data for two model organisms: baker’s yeast (Saccharomyces cerevisiae) and Chlamydomonas reinhardtii. To achieve extensive coverage of observable and quantifiable peptides, we blended proteomics data from several studies into two distinct assemblies, one for each model organism. For the yeast data, we downloaded datasets from the PRIDE repository with the following IDs: PXD000409, PXD002694, PXD004028, PXD005041, and PXD005795. For Chlamydomonas reinhardtii, we combined data from previous proteome-wide studies. Both datasets were filtered to include only unique proteins, ensuring that each protein was measured in only one study to maximize the information in the datasets. We then randomly removed 20% of the proteins in each assembly to use as validation datasets, resulting in training datasets consisting of 2,652 yeast proteins and 2,732 Chlamydomonas reinhardtii proteins, and validation datasets consisting of 664 yeast proteins and 685 Chlamydomonas reinhardtii proteins. Additionally, we constructed a test dataset for the plant model using Arabidopsis thaliana data downloaded from the PRIDE repository with the ID PXD006257, containing 1,074 proteins.",
  "dataset/splits": "There are three data splits: training, validation, and test datasets. For the yeast model organism, the training dataset consists of 2,652 proteins, while the validation dataset contains 664 proteins. For the Chlamydomonas reinhardtii model organism, the training dataset comprises 2,732 proteins, and the validation dataset includes 685 proteins. Additionally, there is a test dataset specifically for the plant model, constructed using Arabidopsis thaliana data, which contains 1,074 proteins. The datasets were created by randomly removing 20% of the proteins from each assembly to serve as validation datasets, ensuring sufficient generalization of the trained deep neural networks. The remaining proteins were used for training. The test dataset for the plant model was constructed separately using Arabidopsis thaliana data.",
  "dataset/redundancy": "The datasets used in this study were assembled from large shotgun proteomic data for two model organisms: baker's yeast (Saccharomyces cerevisiae) and Chlamydomonas reinhardtii. To ensure extensive coverage of observable and quantifiable peptides, proteomics data from several studies were blended into two distinct assemblies, one for each organism. The resulting lists were filtered for peptide spectrum matches (PSMs) of fully tryptically digested peptides with a MaxQuant posterior error probability of at most 0.01.\n\nTo create the training and validation datasets, 20% of the proteins in each assembly were randomly removed and used as validation datasets. This process controlled for sufficient generalization of the trained deep neural networks (DNNs). As a result, two training datasets consisting of 2,652 yeast and 2,732 C. reinhardtii proteins, and two validation datasets consisting of 664 yeast and 685 C. reinhardtii proteins were obtained. Additionally, an independent test dataset for the plant model was constructed using Arabidopsis thaliana data, containing 1,074 proteins.\n\nThe training and test sets are independent. This independence was enforced by ensuring that proteins measured in more than one study were represented by the dataset with the most identified peptides, maximizing the information in the datasets. This approach aimed to achieve minimal redundancy while retaining maximum relevance, ensuring that the models do not suffer from overfitting.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in proteomics. By including peptides that had not been quantified (i.e., which had an XIC value of zero), the datasets were expanded to provide a more comprehensive representation of peptide observability. This approach aligns with the goal of selecting candidate signature peptides for targeted protein quantification, especially in scenarios where MS-based experimental data is fragmentary or missing.",
  "dataset/availability": "The datasets used in this study are publicly available. For the yeast data, the proteomics data were downloaded from the PRIDE repository with the following identifiers: PXD000409, PXD002694, PXD004028, PXD005041, and PXD005795. The data for Chlamydomonas reinhardtii were combined from several previous proteome-wide studies. Additionally, a test dataset for the plant model was constructed using Arabidopsis thaliana data from the PRIDE repository with the identifier PXD006257.\n\nThe data were processed to ensure extensive coverage of observable and quantifiable peptides. Peptide spectrum matches (PSMs) of fully tryptically digested peptides with a MaxQuant posterior error probability of at most 0.01 were considered. The resulting lists were filtered for PTPs, and peptides were ranked according to the areas of the extracted ion chromatograms (XIC). The datasets were further filtered to include only single occurrences of all proteins, retaining the protein with the most identified peptides if measured in more than one study. This approach maximized the information in the datasets.\n\nTo control for sufficient generalization of the trained deep neural networks (DNNs), 20% of the proteins in each assembly were randomly removed to serve as validation datasets. This resulted in two training datasets consisting of 2,652 yeast and 2,732 C. reinhardtii proteins, and two validation datasets consisting of 664 yeast and 685 C. reinhardtii proteins. An additional test dataset for the plant model was constructed accordingly, containing 1,074 proteins.\n\nThe data is available under the terms of the PRIDE repository, which typically allows for open access and reuse of the data for research purposes, subject to proper citation and acknowledgment. The specific licensing details can be found on the PRIDE repository website. The enforcement of data availability and usage is managed through the repository's policies and terms of service, ensuring that the data is accessible and properly cited in any subsequent research.",
  "optimization/algorithm": "The machine-learning algorithm class used is deep learning, specifically a deep neural network (DNN). This approach is not entirely new, as deep learning has been widely used in various fields. However, the specific application to peptide observability prediction and the formulation of the problem as a \"learning to rank\" task is novel. The deep learning network structure is designed to handle the unique properties of the peptide ranking problem, making it distinct from traditional ranking algorithms used in information retrieval and web searches.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of this work is on its application in proteomics, rather than the development of a new machine-learning technique. The deep learning approach is adapted and optimized for the specific problem of predicting peptide observability, which is a critical aspect of targeted proteomics. The innovation lies in how the deep learning framework is applied to this biological problem, rather than the creation of a new machine-learning algorithm from scratch. The emphasis is on the biological relevance and the improvement in prediction accuracy for peptide observability, which is crucial for protein quantification in proteomics studies.",
  "optimization/meta": "The model presented, d::pPop, is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it is a deep learning algorithm designed specifically for peptide detectability prediction. d::pPop circumvents the binary classification problem by reformulating it into a \"learning to rank\" problem. This approach allows it to capture the continuous nature of peptide observability, which depends on various factors such as ionization efficiency, signal acquisition variability, digestion efficiency, and post-translational modifications.\n\nThe model is trained on a large dataset of peptide sequences from both plant and non-plant organisms, allowing it to optimize the capture of differences in peptide observability. The training process involves creating feature vectors that serve as numerical physicochemical footprints of peptides. These feature vectors are then fed into a deep neural network (DNN) with five hidden layers and 128 neurons each. The DNN assigns a predicted observability to each peptide based on its feature vectors, which is then normalized to provide a ranked result list.\n\nTo account for organism-specific differences, two distinct training sets were used, leading to the development of separate models for plant and non-plant organisms. This ensures that the training data is independent for each model, allowing d::pPop to perform better in rank-based comparisons and recommend peptides for targeted proteomics.",
  "optimization/encoding": "The data encoding process involved converting peptide sequences into feature vectors using the BioFSharp framework. Each peptide sequence was transformed into a numerical footprint consisting of 45 entries, representing various physicochemical properties. These properties included molecular weight, isoelectric point, peptide length, net charge, and the relative frequencies of different types of amino acids (polar, hydrophobic, positively charged, negatively charged). Additionally, features from the AAindex1 database were incorporated, such as activation Gibbs energy of unfolding, amino acid composition, hydrophobicity index, and helix formation parameters. The feature set was optimized to minimize redundancy while retaining maximum relevance, using techniques like pairwise feature correlation, hierarchical clustering, and importance ranking. This comprehensive feature vector served as the input for the deep neural network, enabling the prediction of peptide observability based on these physicochemical properties.",
  "optimization/parameters": "The model utilizes a set of 45 features as input parameters. These features represent a numerical footprint of physicochemical peptide properties. The selection of these features was based on an initial library of 574 features from the AAindex1. From this library, amino acid frequencies and ten general properties were chosen, including molecular weight, isoelectric point, peptide length, net charge, positively charged residues, negatively charged residues, relative frequency of polar amino acids, relative frequency of hydrophobic amino acids, and relative frequency of negatively charged amino acids. This set was further optimized to contain minimal redundancy while retaining maximum relevance. The optimization process included pairwise feature correlation followed by hierarchical clustering, minimum spanning tree analysis, and subsequent cluster-wise importance ranking. This resulted in the inclusion of additional features such as the activation Gibbs energy of unfolding at pH 9.0, amino acid composition of membrane proteins, hydrophobicity index, Chou-Fasman parameter of coil conformation, average number of surrounding residues, interior composition of amino acids in intracellular proteins, weights for coil at specific window positions, helix formation parameters, free energy in alpha-helical regions, average relative fractional occurrence in extended loops, composition of amino acids in extracellular proteins, hydrophobicity index 2, frequency of occurrence of missed tryptic cleavage sites, and C- and N-terminal digestion probabilities.",
  "optimization/features": "The input features used in our model consist of a set of 45 entries that represent a numerical footprint of physicochemical peptide properties. These features were selected from an initial library of 574 features from the AAindex1. The selection process involved choosing amino acid frequencies and ten general properties, such as molecular weight, isoelectric point, peptide length, net charge, and the relative frequency of various types of amino acids. This initial set was further optimized to minimize redundancy while retaining maximum relevance. The optimization process included pairwise feature correlation, hierarchical clustering, minimum spanning tree analysis, and cluster-wise importance ranking. This ensured that the selected features were both relevant and non-redundant. The feature selection was performed using the training set only, ensuring that the model's performance on unseen data was not compromised.",
  "optimization/fitting": "The deep learning approach employed in our study utilizes a deep neural network (DNN) with a substantial number of parameters, which indeed exceeds the number of training points. This architecture consists of five hidden layers, each containing 128 neurons, resulting in a total of 6,400 neurons. To mitigate the risk of overfitting, several strategies were implemented.\n\nFirstly, dropout regularization was employed during the training phase. This technique randomly sets the output of a rectified linear unit (ReLU) to zero with a probability of 0.2, effectively eliminating its influence on the backpropagation of the gradient. This helps in preventing the model from becoming too reliant on specific neurons and promotes generalization.\n\nAdditionally, the model was trained using a minibatch size of 3 for 10 epochs, which helps in introducing variability in the training process and reduces the likelihood of overfitting. The training sets consisted of 76,117 yeast peptides and 76,962 C. reinhardtii peptides, providing a robust dataset for learning.\n\nTo further ensure that the model does not underfit, the cumulative distributions of the normalized discounted cumulative gain (nDCG@4) were examined. The small difference between the training and test datasets indicates that the model generalizes well and does not suffer from extensive overfitting. Moreover, the median nDCG@4 scores achieved by our model were superior to those of other peptide-to-protein (PTP) predictors, suggesting that the model performs well in rank-based comparisons.\n\nThe use of a squared error loss function and stochastic gradient descent with a learning rate of 0.001 also contributed to the model's ability to learn effectively from the data. The evaluation metrics and comparative analysis with other predictors further validate the model's performance and generalization capabilities.",
  "optimization/regularization": "To prevent overfitting, we employed the dropout technique. This method randomly sets the output of a Rectified Linear Unit (ReLU) to zero during the training phase, with a probability of 0.2. This process helps to eliminate the influence of certain neurons on the backpropagation of the gradient, thereby reducing the risk of overfitting. By incorporating dropout, we ensured that the model generalizes better to unseen data, maintaining robust performance across different datasets.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are available through the Microsoft Cognitive Toolkit (CNTK) repository. The specific architecture used for the deep neural network in our study consists of five dense layers, each with 128 nodes. The neurons are modeled as rectified linear units (ReLUs), which facilitate faster training and mitigate issues with vanishing gradients. The dropout technique, with a probability of 0.2, is employed to reduce overfitting during the training phase.\n\nThe networks were trained using a minibatch size of 3 for 10 epochs. The training sets included 76,117 yeast peptides and 76,962 C. reinhardtii peptides. The loss function used was the squared error between the predicted observability and the normalized peptide intensity. Optimization of network weights was performed using stochastic gradient descent with a learning rate of 0.001.\n\nThe BioFSharp framework, available on GitHub, was used to process each peptide sequence into a feature vector with 45 entries, representing physicochemical peptide properties. This feature set was derived from an initial library of 574 features from the AAindex1, optimized for minimal redundancy and maximum relevance.\n\nThe d::pPop algorithm, including its training parameters and network architecture, is implemented in F# using the Microsoft Cognitive Toolkit. The code and models are accessible through the respective repositories, adhering to open-source licensing to ensure reproducibility and further development by the scientific community.",
  "model/interpretability": "The model employed in our study is based on deep neural networks, which are often considered black-box models due to their complex, multi-layered architecture. However, we have taken steps to enhance the interpretability of our model. To understand the contribution of individual features to the model's predictions, we analyzed the activation potentials of the ReLU units in the first hidden layer. This approach allowed us to estimate the importance of various physicochemical properties in determining peptide observability.\n\nBy examining the neuronal weights assigned during the learning process, we could calculate the relevance of each physicochemical property. This analysis revealed that peptide observability is not dictated by a small subset of dominant features but rather by the intricate interplay of multiple, more homogeneous features. Notably, structural features exhibited a uniform impact, suggesting that microdomain formation, akin to protein folding, plays a significant role.\n\nThis method provides insights into how the model makes predictions, moving beyond the typical black-box nature of deep learning models. By understanding which physicochemical properties are most influential, researchers can gain a deeper understanding of the factors that govern peptide observability in proteomics experiments.",
  "model/output": "The model, d::pPop, is designed as a regression model rather than a classification model. It addresses the problem of peptide detectability prediction by ranking peptides within the same protein according to their measured abundance. This approach circumvents the binary classification of peptides into observable and non-observable categories, which is a limitation in many existing methods. Instead, d::pPop leverages deep learning to capture the continuous relationship between peptide observability and their physicochemical properties. The model uses a deep neural network with five hidden layers and 128 neurons each, trained on extensive datasets of peptide sequences from both plant and non-plant organisms. This design allows d::pPop to predict the relative observability of peptides, providing a more nuanced and accurate output compared to traditional classification-based approaches. The output is a ranked list of peptides based on their predicted observability, normalized by the highest scoring peptide, which is crucial for targeted proteomics where selecting representative peptides is essential.",
  "model/duration": "The execution time for our model, d::pPop, is influenced by several factors, including the size of the datasets and the computational resources used. The model was trained using a minibatch size of 3 for 10 epochs. This training process involved approximately 76,117 yeast peptides and 76,962 C. reinhardtii peptides. The optimization of network weights was carried out using stochastic gradient descent with a learning rate of 0.001.\n\nTo mitigate the risk of overfitting, we employed the dropout technique, which randomly sets the output of a ReLU to zero during the training phase. This technique, along with the use of deep neural networks, ensures that the model generalizes well to unseen data.\n\nThe specific execution time can vary depending on the hardware used, but the model is designed to be efficient. The use of deep neural networks and the dropout technique helps in reducing the risk of problems with vanishing gradients, making the training process more stable and faster.\n\nOverall, the model's execution time is optimized for performance and accuracy, ensuring that it can handle large datasets efficiently.",
  "model/availability": "The source code for the d::pPop algorithm is publicly available. The deep learning network architecture is implemented in F# using the Microsoft Cognitive Toolkit (CNTK). The CNTK source code can be accessed via its GitHub repository. Additionally, the BioFSharp framework, which is used for feature extraction, is also available on GitHub. Both tools are open-source, allowing researchers to access, modify, and utilize the code for their own purposes. The specific details regarding the license under which these tools are released can be found on their respective GitHub pages.",
  "evaluation/method": "The evaluation method employed for our study involved a thorough empirical assessment of the deep learning approach, d::pPop, designed to predict peptide observability. We compared d::pPop with several existing peptide-to-protein (PTP) predictors, including both rule-based and machine learning-based approaches. The evaluation utilized datasets containing quantitative information about each peptide, allowing us to calculate the relative rank of each peptide within a given protein.\n\nA key metric used for performance evaluation was the normalized discounted cumulative gain (nDCG), which is particularly suited for ranking accuracy. The nDCG metric credits high prediction accuracy according to its relevance for ranking and ranges from zero to one, indicating random to correctly ranked top peptides according to observed abundance. This metric is well-suited for targeted proteomics, where a small number of representative peptides are selected to quantify a given target protein.\n\nThe evaluation involved training d::pPop on datasets from model organisms, specifically baker’s yeast (Saccharomyces cerevisiae) and Chlamydomonas reinhardtii. The performance was assessed on both training and test datasets to ensure that the models did not suffer from overfitting. The cumulative distributions of the nDCG@4 scores showed only a small difference between predictions on training and test datasets, indicating robust generalization.\n\nAdditionally, we analyzed the organism-specific effects on predictive power by comparing the performance of d::pPop's non-plant and plant models on the C. reinhardtii proteome data set. The results revealed a substantial difference in prediction accuracy between the two models, highlighting the organism-specific nature of peptide observability prediction. This organism bias was further corroborated by comparing d::pPop with other PTP predictors on plant data sets, where d::pPop consistently achieved higher median nDCG@4 scores.\n\nIn summary, the evaluation method involved a comprehensive comparison of d::pPop with existing predictors using quantitative datasets and the nDCG metric. The results demonstrated d::pPop's superior performance in rank-based comparisons and its ability to generalize well across different datasets, while also highlighting the organism-specific nature of peptide observability prediction.",
  "evaluation/measure": "In our evaluation of the deep peptide observability predictor (d::pPop), we employed the normalized discounted cumulative gain (nDCG) as our primary performance metric. This metric is particularly well-suited for our purposes because it credits high prediction accuracy on the top results, which is crucial for targeted proteomics where only a small number of representative peptides are selected to quantify a given target protein. The nDCG metric ranges from zero to one, indicating random to correctly ranked top peptides according to observed abundance.\n\nThe use of nDCG is representative of current practices in the field, as it has gained high popularity among the information retrieval community. This metric allows us to evaluate the ranking quality up to a specified position (k), making it robust to permutations of lower-ranking peptides. By focusing on the top results, nDCG ensures that our predictions are practical and relevant for experimental design in proteomics.\n\nIn addition to nDCG, we also considered the cumulative distributions of the nDCG@4 scores. This approach allowed us to compare the performance of d::pPop with other peptide-to-protein (PTP) predictors, both on training and test datasets. The small difference in performance between these datasets indicates that our models do not suffer from extensive overfitting, which is a common concern in machine learning.\n\nFurthermore, we analyzed the median nDCG@4 scores achieved by d::pPop and other PTP predictors. This comparison showed that d::pPop consistently outperforms other predictors in rank-based comparisons, both for yeast and plant datasets. This demonstrates the robustness and generalizability of our approach across different organisms.\n\nOverall, the set of metrics we reported is comprehensive and representative of the literature. The use of nDCG, along with cumulative distribution analysis and median score comparisons, provides a thorough evaluation of d::pPop's performance and its advantages over existing PTP predictors.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of d::pPop with several existing peptide-to-protein (PTP) predictors, including both rule-based and machine learning-based approaches. These predictors included ChemScore, PeptideSieve, PeptideRank, CONSequence, and ESPPredictor. The comparison was performed on benchmark datasets containing quantitative information about each peptide, allowing us to calculate the relative rank of each peptide within a given protein. We used the normalized Discounted Cumulative Gain at rank 4 (nDCG@4) as the metric for performance evaluation, which is well-suited for targeted proteomics where a small number of representative peptides are selected to quantify a given target protein.\n\nThe datasets used for comparison included yeast and plant proteomes. For yeast, we used a dataset consisting of 664 proteins, while for plants, we used datasets from Chlamydomonas reinhardtii and Arabidopsis thaliana. The results demonstrated that d::pPop achieved higher median nDCG@4 scores compared to the other predictors, indicating better ranking accuracy. This was evident in both the yeast and plant datasets, suggesting that d::pPop performs best in rank-based comparisons.\n\nAdditionally, we evaluated the performance of d::pPop on training and test datasets to assess overfitting. The small difference in performance between these datasets indicated that d::pPop does not suffer from extensive overfitting. Furthermore, we observed organism-specific effects on prediction accuracy, with d::pPop's plant model outperforming its non-plant model on plant datasets. This highlights the importance of organism-specific training for accurate peptide observability prediction.\n\nIn summary, our comparison with publicly available methods on benchmark datasets showed that d::pPop outperforms existing PTP predictors in ranking accuracy. The use of nDCG@4 as a performance metric provided a robust evaluation of d::pPop's capabilities in targeted proteomics.",
  "evaluation/confidence": "The evaluation of our method, d::pPop, includes a thorough comparison with existing PTP predictors, using the normalized discounted cumulative gain (nDCG) as a key performance metric. This metric is particularly suited for ranking problems, as it credits high prediction accuracy at the top positions, which is crucial for targeted proteomics.\n\nThe cumulative distributions of the nDCG@4 show only a small difference between predictions on training and test datasets. This indicates that our models do not suffer from extensive overfitting, as the performance does not differ substantially between these datasets. The small difference in performance between training and test data for the same model evidences that both d::pPop models do not suffer from overfitting.\n\nStatistical significance is implied through the consistent performance of d::pPop across different datasets and comparisons. For instance, d::pPop achieved a higher median nDCG@4 score than other predictors in both yeast and plant datasets. The corresponding cumulative distribution reflects a more accurate prediction by being closer to a constant nDCG@4 value of 1, which corresponds to an ideal ranking.\n\nFurthermore, the comparison of d::pPop with other PTP predictors shows that most predictors produced a higher median nDCG@4 score on the plant data than on the yeast data. This corroborates the organism bias on the predictive power, highlighting the specificity of d::pPop's performance.\n\nWhile specific confidence intervals for the performance metrics are not explicitly stated, the consistent superiority of d::pPop in rank-based comparisons across different datasets and organisms suggests a high level of confidence in its performance. The use of nDCG@4 as a metric also provides a robust measure of ranking accuracy, further supporting the statistical significance of our results.",
  "evaluation/availability": "Not enough information is available."
}