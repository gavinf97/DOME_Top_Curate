{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Andersen, who is the first author and likely played a significant role in the research and writing of the paper.\n- Bhattacharya, who contributed to the study as part of the MURDOCK Study Community Registry and Biorepository.\n- Dunham, who contributed to the study as part of the MURDOCK Study Community Registry and Biorepository.\n- Cornish, who contributed to the study as part of the MURDOCK Study Community Registry and Biorepository.\n- Chong, who contributed to the development of MetaboAnalyst 4.0, a tool used in the analysis.\n- Soufan, who contributed to the development of MetaboAnalyst 4.0.\n- Li, who contributed to the development of MetaboAnalyst 4.0.\n- Johnson, who contributed to the development of the empirical Bayes methods used for adjusting batch effects.\n- Rabinovic, who contributed to the development of the empirical Bayes methods used for adjusting batch effects.\n- Goldstein, who contributed to the development of the random forests method used for genetic association studies.\n- Polley, who contributed to the development of the random forests method used for genetic association studies.\n- Briggs, who contributed to the development of the random forests method used for genetic association studies.\n- Chen, who contributed to the analytical sciences laboratory work.\n- Siecinski, who contributed to the molecular physiology institute work.\n- Burns, who contributed to the molecular physiology institute work.\n- Arvai, who contributed to the molecular physiology institute work.\n- Zhang, who contributed to the development of the MetPP software.\n- Wei, who contributed to the development of the MetPP software.\n\nThe specific contributions of each author to the paper are not detailed, but their involvement in related research and tools is noted.",
  "publication/journal": "Mult Scler Relat Disord.",
  "publication/year": "2020",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Multiple Sclerosis\n- Metabolomics\n- Gene Expression\n- Genetic Association\n- Random Forests\n- Machine Learning\n- Biomarkers\n- Metabolite Profiling\n- Genetic Data Analysis\n- Statistical Genetics",
  "dataset/provenance": "The dataset used in this study was sourced from the Measurement to Understand Reclassification of Disease of Cabarrus/Kannapolis (MURDOCK) Study Community Registry and Biorepository. This study collected samples from participants, which included serum, RNA, and DNA, following standard collection criteria.\n\nThe sample collection involved 25 study participants for whom metabolomic data, gene expression data, and genotypic data were generated. For metabolomic data, serum aliquots were processed and analyzed using GCxGC-TOFMS and the Biocrates AbsoluteIDQ p150 kit. Gene expression data were obtained from whole-genome expression arrays, specifically Illumina HumanHT-12 v4.0 Gene Expression BeadChips, for 24 of the 25 participants. Genotypic data were generated using the Sequenom platform Iplex Gold Reagent Kit for 186 of 200 putative non-MHC MS risk variants.\n\nThe dataset has been used in this specific study to identify metabolites associated with multiple sclerosis (MS) and to explore the relationships between gene expression and these metabolites. The study also conducted pathway enrichment analyses to understand the biological significance of the findings. The data has not been previously published or used by the community in other studies, as this is the first report detailing these specific analyses and findings.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in this study is a random forests algorithm. This is a well-established supervised machine learning technique, known for its robustness and ability to handle data where the number of predictors exceeds the sample size. It is particularly useful for prediction and variable importance assessment.\n\nThe random forests algorithm used is not new; it has been extensively used and validated in various fields, including genetic association studies. The choice to use this algorithm in this context is driven by its suitability for the specific challenges posed by the data, such as the need to identify important metabolites for classification and its ability to manage high-dimensional data.\n\nThe decision to use a proven algorithm like random forests, rather than developing a new one, is likely due to the focus of the study on metabolomics and genetics related to multiple sclerosis, rather than on machine learning innovation. The study aims to leverage the strengths of existing methods to gain insights into the disease, and publishing in a specialized journal aligns with the study's objectives and the target audience.",
  "optimization/meta": "The study employed a random forest algorithm, a supervised machine learning method, to identify metabolites important for multiple sclerosis (MS) classification. This approach is well-suited for prediction and variable importance, and it is robust to the setting of tuning parameters. The random forest consisted of 5,000 trees, and 100 randomly selected metabolites were used to determine classification at each node in a tree.\n\nThe random forest algorithm was used to rank the importance of metabolites for MS classification. A scree plot of the ranked variable importance scores was utilized to identify the top-ranking metabolites. This method does not explicitly use data from other machine-learning algorithms as input but rather focuses on the intrinsic importance of metabolites within the random forest framework.\n\nThe random forest method is non-parametric and capable of analyzing data where predictors outnumber the sample size, making it suitable for the metabolomic data analyzed in this study. The out-of-bag error for classifying the samples by MS status was reported, indicating the performance of the random forest model.\n\nThe study also employed logistic regression models to assess the relationship between each important metabolite and MS status. These models included a random effect to account for any residual batch effects. The area under the curve (AUC) and 95% confidence intervals were determined by non-parametric receiver operating characteristic (ROC) analyses for each metabolite. Metabolites with an AUC greater than 80% were considered top metabolites.\n\nThe integration of random forests and logistic regression provides a comprehensive approach to identifying and validating metabolites associated with MS. The random forest algorithm serves as the primary method for feature selection, while logistic regression models are used to assess the predictive power of the selected metabolites. This multi-step approach ensures that the identified metabolites are both important and predictive of MS status.",
  "optimization/encoding": "For the machine-learning algorithm, specifically the random forests, the data underwent several preprocessing steps. Initially, 325 metabolites with less than 30% missing observations were retained for analysis. Missing values were imputed using the default setting in MetaboAnalyst, which replaces them with half of the minimum positive values detected in the data. Batch effects were adjusted using ComBat, a method designed to remove technical variability between batches. The data were then quantile normalized and Pareto scaled to ensure a consistent distribution and to reduce the influence of outliers. This preprocessing was crucial for the random forests algorithm, which consisted of 5,000 trees and used 100 randomly selected metabolites to determine classification at each node. The preprocessing steps ensured that the data were in an optimal state for the algorithm to identify important metabolites for multiple sclerosis classification.",
  "optimization/parameters": "In the optimization process, the number of parameters used in the model was determined by the random forests algorithm. Specifically, 100 randomly selected metabolites were used to determine classification at each node in a tree. The forest consisted of 5,000 trees, which helped in identifying metabolites important for multiple sclerosis (MS) classification. The selection of these parameters was guided by the need for a robust and non-parametric approach that could handle data where predictors outnumber the sample size. This method ensured that the model was fairly robust to the setting of tuning parameters and well-adapted for prediction and variable importance.",
  "optimization/features": "In our study, we initially captured 400 metabolite variables using GCxGC-TOFMS and Biocrates p150 approaches. To ensure data quality, we retained 325 metabolites with less than 30% missing observations for further analysis. This subset of metabolites served as the input features for our machine learning models.\n\nFeature selection was performed using a random forests algorithm, which is well-suited for identifying important variables in datasets where predictors outnumber the sample size. The random forests model consisted of 5,000 trees, and 100 randomly selected metabolites were used to determine classification at each node in a tree. A scree plot of the ranked variable importance scores was used to identify the top-ranking metabolites for multiple sclerosis (MS) classification. This process helped in narrowing down the most informative metabolites, ensuring that our models focused on the most relevant features.\n\nThe feature selection process was conducted using the entire dataset, including both training and testing sets, to ensure that the selected features were robust and generalizable. This approach helped in mitigating the risk of overfitting and ensured that the identified metabolites were truly informative for MS classification.",
  "optimization/fitting": "In our study, we employed random forests, a supervised machine learning algorithm, to identify metabolites important for multiple sclerosis (MS) classification. The number of metabolite predictors (400) indeed outnumbered the sample size (25), which could potentially lead to overfitting. To mitigate this risk, we utilized several strategies.\n\nFirstly, random forests are inherently robust to overfitting due to their ensemble nature and the randomness introduced in the tree-building process. We further ensured robustness by setting a high number of trees (5,000) in the forest, which helps to reduce variance and overfitting. Additionally, at each node in a tree, we used a random subset of 100 metabolites to determine the best split, which helps to decorrelate the trees and further reduces overfitting.\n\nTo rule out underfitting, we assessed the model's performance using out-of-bag (OOB) error estimation, which is an internal validation method specific to random forests. The OOB error for classifying the samples by MS status was 0.32, indicating a reasonable level of model performance given the complexity of the data and the relatively small sample size. Moreover, we validated the importance of the top metabolites using logistic regression models, which showed that eight of the twelve metabolites identified by random forests were significantly associated with MS (p<0.05), with six of them having an area under the curve (AUC) greater than 80%.\n\nIn summary, while the number of parameters was larger than the number of training points, we employed strategies specific to random forests to prevent overfitting and validated our findings using additional statistical methods to ensure the robustness of our results.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our findings. One key method used was random forests, a supervised machine learning algorithm known for its ability to handle high-dimensional data and reduce overfitting. Random forests operate by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees. This ensemble approach helps to mitigate overfitting by averaging the results, thereby reducing the variance of the predictions.\n\nAdditionally, we utilized ComBat to adjust for batch effects, which is crucial in metabolomics and gene expression studies to account for technical variations between different experimental runs. By applying ComBat, we ensured that our results were not biased by these technical artifacts, thereby enhancing the reliability of our findings.\n\nIn the context of logistic regression models, we included random effects to account for any residual batch effects. This approach helps to control for unobserved heterogeneity and reduces the risk of overfitting by incorporating the variability due to batch effects into the model.\n\nFurthermore, we conducted thorough quality control (QC) procedures for our genetic data, removing samples and SNPs with excessive missing genotypes and those that deviated from Hardy-Weinberg equilibrium. This rigorous QC process helped to ensure the integrity of our genetic data and reduced the likelihood of spurious associations.\n\nOverall, these methods collectively contributed to the robustness of our analyses and helped to prevent overfitting, ensuring that our findings were reliable and generalizable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is not a blackbox. It utilizes random forests, a supervised machine learning algorithm known for its interpretability. Random forests provide insights into variable importance, allowing us to identify which metabolites are most significant for multiple sclerosis (MS) classification. This is evident in the ranking of metabolites, where the top metabolites were determined based on their importance scores derived from the random forest analysis. For instance, pyroglutamate, laurate, and phosphatidylcholine PC ae C42:5 were among the top-ranked metabolites, indicating their strong association with MS status.\n\nAdditionally, the use of logistic regression models further enhances the interpretability of the results. These models assess the relationship between each important metabolite and MS status, providing p-values and area under the curve (AUC) values. Metabolites with an AUC greater than 80% were considered top metabolites, offering clear evidence of their predictive power. For example, pyroglutamate had an AUC of 0.85, and laurate had an AUC of 0.86, both indicating strong predictive performance.\n\nThe study also conducted pathway enrichment analyses, which linked the top metabolites to specific biological processes. This approach not only identifies important metabolites but also provides context on how these metabolites might be involved in MS pathology. For instance, pyroglutamate was associated with glutathione metabolism and iron homeostasis signaling, while acylcarnitine C14:1 was linked to antigen presentation. These associations help in understanding the underlying biological mechanisms.\n\nIn summary, the model's transparency is demonstrated through the use of random forests for variable importance, logistic regression for statistical significance, and pathway enrichment analyses for biological context. These methods collectively provide a clear and interpretable framework for understanding the relationship between metabolites and MS.",
  "model/output": "The model employed in this study is primarily a classification model, specifically utilizing random forests for identifying metabolites important for multiple sclerosis (MS) classification. Random forests is a supervised machine learning algorithm well-suited for prediction and variable importance, making it robust for data where predictors outnumber the sample size. The model consisted of 5,000 trees, with 100 randomly selected metabolites used to determine classification at each node in a tree. This approach helped in identifying 12 metabolites as informative for MS classification.\n\nAdditionally, logistic regression models were used to assess the relationship between each important metabolite and MS status. These models included a random effect to account for any residual batch effects. The area under the curve (AUC) and 95% confidence intervals were determined by non-parametric receiver operating characteristic (ROC) analyses for each metabolite. Metabolites with an AUC greater than 80% were considered top metabolites.\n\nThe study also involved multivariable linear mixed-effects regression models to explore the relationships between gene expression values and top metabolites, adjusting for MS status and residual chip effects. Furthermore, multivariable regression models were conducted with top metabolites as outcomes and single nucleotide polymorphisms (SNPs) as predictors, adjusting for MS status and possible plate effects.\n\nIn summary, the model is primarily a classification model using random forests, supplemented by logistic regression and multivariable regression analyses to understand the relationships between metabolites, gene expression, and genetic data in the context of MS.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure the robustness and validity of the findings. Initially, random forests, a supervised machine learning algorithm, were employed to identify metabolites important for multiple sclerosis (MS) classification. The forest consisted of 5,000 trees, with 100 randomly selected metabolites used to determine classification at each node. This approach is well-suited for prediction and variable importance, and it is robust to the setting of tuning parameters.\n\nTo assess the performance of the random forests model, a scree plot of the ranked variable importance scores was used to identify top-ranking metabolites for MS classification. This visual tool helped in determining which metabolites were most significant in distinguishing between cases and controls.\n\nFollowing the identification of important metabolites, logistic regression models were used to assess the relationship between each important metabolite and MS status. These models included a random effect to account for any residual batch effects. The area under the curve (AUC) and 95% confidence intervals were determined by non-parametric receiver operating characteristic (ROC) analyses for each metabolite. Metabolites with an AUC greater than 80% were considered top metabolites.\n\nAdditionally, gene expression data were background subtracted and quantile normalized. ComBat was applied to remove any chip effects, and data were further quantile normalized and pareto scaled. Multivariable linear mixed-effects regression models were conducted to explore the relationships between gene expression values and the top metabolites, adjusting for MS status and residual chip effects.\n\nFor genetic data, multivariable regression models were performed with the top metabolites as the outcome and each single nucleotide polymorphism (SNP) as a predictor, adjusting for MS status and possible plate effects. Two HLA alleles were genotyped in all samples, and similar regression models were conducted as described.\n\nThe evaluation also included quality control measures for the genetic data, such as removing samples and SNPs with excessive missing genotypes and those not in Hardy-Weinberg equilibrium. After quality control, the final genotype dataset included 19 subjects and 175 putative non-HLA MS risk SNPs.\n\nOverall, the method was evaluated through a combination of machine learning techniques, statistical modeling, and quality control measures to ensure the reliability and significance of the findings related to MS classification and associated metabolites.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models in identifying metabolites associated with multiple sclerosis (MS).\n\nWe utilized random forests, a supervised machine learning algorithm, to identify important metabolites for MS classification. The performance of this model was assessed using the out-of-bag error, which measures the classification error rate on the samples left out of the bootstrap samples. For our dataset of 25 samples, the out-of-bag error was 0.32, indicating a moderate level of classification accuracy. Specifically, the error rates were 0.42 for MS cases and 0.23 for controls, suggesting better classification performance for controls.\n\nAdditionally, we conducted logistic regression analyses to assess the relationship between each important metabolite and MS status. The area under the curve (AUC) from receiver operating characteristic (ROC) analyses was used to evaluate the discriminative ability of each metabolite. Metabolites with an AUC greater than 80% were considered top metabolites. This metric is widely used in the literature for evaluating the performance of biomarkers and is representative of standard practices in the field.\n\nThe set of metrics we reported is representative of those commonly used in metabolomics and genetic association studies. The out-of-bag error provides a measure of the model's generalizability, while the AUC offers a clear indication of each metabolite's ability to discriminate between MS cases and controls. These metrics together provide a comprehensive evaluation of our model's performance and the significance of the identified metabolites.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The evaluation of our study's performance metrics included confidence intervals to provide a range within which the true effect size is likely to lie. Specifically, we determined the area under the curve (AUC) and 95% Bamber and Hanley confidence intervals using non-parametric receiver operating characteristic (ROC) analyses for each metabolite. This approach ensures that our results are robust and not due to random chance.\n\nStatistical significance was a key consideration in our analysis. We used a two-sided alpha level of less than 0.05 for all statistical comparisons, which is a standard threshold in scientific research. This stringent criterion helps to ensure that our findings are reliable and not merely due to random variation.\n\nIn our logistic regression models, metabolites with an AUC greater than 80% were considered our top metabolites, indicating a strong predictive performance. Additionally, we identified 12 metabolites as informative for MS classification using random forests, with an out-of-bag error rate of 0.32, demonstrating the model's ability to classify samples by MS status.\n\nThe use of random forests, a supervised machine learning algorithm, allowed us to identify metabolites important for MS classification without relying solely on p-values. This method is robust to the setting of tuning parameters and capable of analyzing data where predictors outnumber the sample size, further enhancing the confidence in our results.\n\nOverall, the combination of confidence intervals, statistical significance, and robust analytical methods provides a strong foundation for claiming that our approach is superior to others and baselines in identifying key metabolites associated with MS.",
  "evaluation/availability": "Not enough information is available."
}