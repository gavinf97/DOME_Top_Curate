{
  "publication/title": "Machine learning identifies unaffected first-degree relatives with functional network patterns and cognitive impairment similar to those of schizophrenia patients",
  "publication/authors": "The authors who contributed to this article are:\n\nRixing Jing, Peng Li, Zengbo Ding, Xiao Lin, Rongjiang Zhao, Le Shi, Hao Yan, Jinmin Liao, Chuanjun Zhuo, Lin Lu, and Yong Fan.\n\nRixing Jing and Peng Li contributed equally to this study. Lin Lu and Yong Fan share senior authorship.\n\nYong Fan is the corresponding author. He is affiliated with the Center for Biomedical Image Computing and Analytics, Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA 19104. His email addresses are yong.fan@uphs.upenn.edu and yong.fan@ieee.org.",
  "publication/journal": "Human Brain Mapping",
  "publication/year": "2019",
  "publication/doi": "10.1002/hbm.24678",
  "publication/tags": "- Cognitive impairment\n- Functional networks\n- Machine learning\n- Pattern classification\n- Resting-state functional magnetic resonance imaging\n- Unaffected first-degree relatives\n- Schizophrenia\n- Biomarkers\n- Brain alterations\n- Support vector machine classifiers",
  "dataset/provenance": "The dataset used in this study was collected from participants who underwent resting-state functional magnetic resonance imaging (rsfMRI) scans. The study included three groups: schizophrenia (SCZ) patients, first-degree relatives (FDRs) of SCZ patients, and healthy controls (HCs). Specifically, the dataset comprised 60 SCZ patients, 43 unaffected FDRs, and 50 HCs. An independent dataset of 40 patients and 40 controls was also used as a validation cohort.\n\nThe participants were recruited and scanned at Peking University Third Hospital using a Siemens Magnetom Trio 3.0 Tesla imaging system. The rsfMRI scans were obtained using a gradient-recalled echo-planar imaging sequence, with each scan consisting of 240 volumes of 33 axial slices. The data acquisition process ensured that participants were instructed to close their eyes, relax, and remain awake during the scans.\n\nThe preprocessing steps involved calculating frame-wise displacement to measure head movements, and excluding participants with large head movements. This resulted in a final sample of 40 controls, 34 FDRs, and 42 SCZ patients. The dataset was further analyzed using independent component analysis (ICA) to extract subject-specific functional networks (FNs) from the rsfMRI data. The number of independent components was estimated to be 15, based on a subset of randomly selected controls and SCZ patients. These FNs were then used to identify informative networks and build support vector machine (SVM) classifiers to distinguish SCZ patients from HCs. The classifiers were also applied to the FNs of FDRs to determine their similarity to SCZ patients.",
  "dataset/splits": "The dataset was split into multiple parts for different stages of analysis. Initially, a subset of subjects was used to compute group-level independent components (ICs), which were then used to guide the extraction of subject-specific functional networks (FNs) for the remaining participants. This resulted in a dataset of 106 subjects, comprising 40 controls, 34 first-degree relatives (FDRs), and 42 schizophrenia patients (SCZs).\n\nFor the pattern classification, a leave-one-out (LOO) cross-validation approach was employed. This method involved creating 62 support vector machine (SVM) classifiers, each trained on the data of 61 subjects and tested on the left-out subject. This process was repeated such that each subject was used as the test subject once, resulting in 62 classification scores.\n\nAdditionally, an independent dataset was used to validate the classification performance of the informative FNs. The details of this independent dataset are provided in the Supporting Information.\n\nIn the post hoc analyses, subjects with lower classification certainty (<0.9) were excluded, resulting in a final sample of 88 subjects: 27 controls, 33 FDRs, and 28 SCZs. This final sample was used for further statistical comparisons and correlation analyses.",
  "dataset/redundancy": "The study utilized a dataset comprising 60 schizophrenia (SCZ) patients, 43 unaffected first-degree relatives (FDRs) of patients, and 50 healthy controls (HCs). An independent dataset of 40 patients and 40 controls was also used as a validation cohort to evaluate the performance of the classifiers developed in the study. This independent dataset ensured that the training and test sets were distinct, reducing the risk of data leakage and overfitting.\n\nThe main dataset was split into training and test sets through a leave-one-out cross-validation (LOO) approach. This method involved creating 62 support vector machine (SVM) classifiers, each trained on data from 61 subjects and tested on the remaining subject. This process was repeated for each subject, ensuring that every subject served as a test case exactly once. The LOO cross-validation model yielded classification scores that were median values of the classification scores from nested LOO classifiers, providing a robust measure of each subject's affinity to schizophrenia.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field of neuropsychiatry. The use of an independent validation cohort is a strength, as it mimics real-world scenarios where models are applied to new, unseen data. This approach enhances the generalizability of the findings and ensures that the results are not merely an artifact of overfitting to the training data. The demographic and clinical characteristics of the participants were carefully matched to control for potential confounding variables, such as age, sex, and educational level, further strengthening the robustness of the dataset.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is Support Vector Machines (SVM). This is a well-established class of algorithms in the field of machine learning, known for its effectiveness in classification tasks.\n\nThe specific SVM algorithm employed here is not new; it has been previously used and validated in similar contexts. The choice of SVM is justified by its robustness and ability to handle high-dimensional data, which is crucial for analyzing functional networks derived from resting-state functional magnetic resonance imaging (rsfMRI) data.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of this study is on its application in neuroscience, specifically in identifying unaffected first-degree relatives with functional network patterns and cognitive impairment similar to those of schizophrenia patients. The innovation lies in the application of the SVM algorithm to this particular problem in neuroscience, rather than in the development of a new machine-learning algorithm. The study aims to demonstrate the practical utility of SVM in a clinical context, contributing to the field of biomedical research rather than to the development of new machine-learning techniques.",
  "optimization/meta": "The model employs a leave-one-out (LOO) cross-validation approach to build multiple support vector machine (SVM) classifiers. Each SVM classifier generates a classification score, which is the median value of the classification scores from its nested LOO classifiers. These scores indicate whether the subject is more likely to have schizophrenia (SCZ) or be normal.\n\nThe process involves using informative functional networks (FNs) identified from the data. These FNs are selected based on their high frequency of occurrence (frequency >0.8) across subjects. The LOO cross-validation model yields 62 SVM classifiers, one for each subject in the training set. Each classifier is trained on the data of all other subjects, ensuring that the training data is independent for each subject's classifier.\n\nThe classification performance is evaluated using metrics such as accuracy, sensitivity, specificity, the receiver operating characteristic curve (ROC), and the area under the ROC (AUC). Nonparametric permutation tests are used to estimate the statistical significance of the classification performance. This approach ensures that the model's predictions are robust and reliable.\n\nThe final classification scores for each subject are used to determine the affinity of each first-degree relative (FDR) to SCZ, with a positive score indicating a SCZ pattern. This method allows for the identification of FDRs with functional network patterns and cognitive impairment similar to those of SCZ patients.",
  "optimization/encoding": "The data encoding and preprocessing steps were meticulously designed to ensure the quality and reliability of the machine-learning algorithm. Resting-state functional MRI (rsfMRI) data were collected from participants using a Siemens Magnetom Trio 3.0 Tesla imaging system. During the acquisition, participants were instructed to close their eyes, relax, and remain awake. The rsfMRI scans consisted of 240 volumes, each with a resolution of 3.4 mm × 3.4 mm × 4.0 mm.\n\nAll images were visually inspected by neuroradiologists to check for artifacts, structural abnormalities, and pathologies. Frame-wise displacement (FD) was calculated to measure volume-to-volume changes in head position, and participants with large head movements (mean FD > 0.5 mm) were excluded from the study. This resulted in a final sample comprising 40 controls, 34 first-degree relatives (FDRs), and 42 schizophrenia (SCZ) patients.\n\nThe preprocessing steps involved several key procedures. Independent component analysis (ICA) guided by group information (GIG-ICA) was used to extract subject-specific functional networks (FNs) from the rsfMRI data. The number of independent components (ICs) was automatically estimated to be 15, based on a subset of randomly selected controls and SCZ patients. A gray matter mask was applied during ICA to minimize partial volume effects of cerebrospinal fluid and spurious effects on connectivity measures, thereby increasing the sensitivity to blood-oxygen-level-dependent (BOLD) signal changes.\n\nFor the machine-learning algorithm, a pattern classification method was employed to identify informative FNs and build support vector machine (SVM) classifiers. The SVM classification was based on similarity measures between subjects computed from their FNs. A forward component selection technique was used to identify the most discriminative set of FNs. Classifiers were initially built on individual FNs, and then evaluated using leave-one-out (LOO) cross-validation. The FN with the best classification performance was selected, and this process was repeated to include more FNs until a single classifier was built upon all available FNs.\n\nThe informative FNs were defined as those with a high frequency (frequency >0.8). Based on these FNs, 62 SVM classifiers were generated using LOO cross-validation. Each classifier produced a classification score, with positive values indicating schizophrenia and negative values indicating normalcy. The classification performance was evaluated using metrics such as accuracy, sensitivity, specificity, receiver operating characteristic (ROC) curve, and area under the ROC (AUC). Nonparametric permutation tests were used to estimate the statistical significance of the classification performance.",
  "optimization/parameters": "The model utilized a support vector machine (SVM) classifier with a sigmoid kernel. The selection of parameters for the SVM classifier was optimized using a nested leave-one-out (LOO) cross-validation procedure. This involved tuning the parameters and choosing an optimal combination of functional networks (FNs) with a forward component selection algorithm. The forward component selection technique was used to identify the most discriminative set of FNs by iteratively building classifiers on individual FNs and combinations of FNs, evaluating them with LOO cross-validation, and selecting the FNs with the best classification performance. This process was repeated until a single classifier was built upon all available FNs, ensuring that the combination of FNs with the overall best classification performance was identified. The specific number of parameters used in the final model is not explicitly stated, but the process ensured that the parameters were optimized for the best classification performance.",
  "optimization/features": "The input features used in the study are functional networks (FNs) derived from resting-state functional MRI (rsfMRI) data. The number of independent components, and thus the number of FNs, was estimated to be 15. This estimation was based on a subset of randomly selected controls and schizophrenia (SCZ) patients.\n\nFeature selection was performed using a forward component selection technique. This process involved building classifiers on individual FNs and then evaluating them using leave-one-out (LOO) cross-validation. The FN with the best classification performance was selected and combined with other FNs to build classifiers with increasing numbers of FNs. This procedure was repeated until a classifier was built using all available FNs. The combination of FNs that yielded the best classification performance was identified for the final classification.\n\nThe feature selection and classifier construction were carried out using the training data only. To avoid bias, a nested LOO procedure was applied to optimize the parameters of the support vector machine (SVM) classifier and to choose an optimal combination of FNs. This ensured that the feature selection process was conducted in a manner that prevented data leakage and maintained the integrity of the validation process.",
  "optimization/fitting": "The fitting method employed in this study utilized a leave-one-out (LOO) cross-validation approach to build SVM classifiers, which inherently helps to mitigate overfitting. By training the model on all but one subject and testing on the left-out subject, this method ensures that each subject is used as a test case exactly once. This process is repeated for each subject, resulting in 62 SVM classifiers, one for each subject in the study.\n\nTo further address overfitting, a nested LOO procedure was applied. This involved optimizing the parameters of the SVM classifier by tuning them and selecting an optimal combination of functional networks (FNs) using a forward component selection algorithm. This nested approach ensures that the model's performance is evaluated on data that was not used in the parameter tuning process, providing a more robust estimate of the model's generalization capability.\n\nThe use of nonparametric permutation tests also played a crucial role in estimating the statistical significance of the classification performance. By performing 10,000 random permutation tests with subject class labels randomly permuted, the null distribution of the classification rate was estimated. This method helps to rule out the possibility of overfitting by comparing the observed classification performance against a distribution of performances that would be expected by chance.\n\nAdditionally, the study included a certainty measure to evaluate the classification reliability for each individual subject. This measure, calculated as np/(n − 0.5), where np is the number of positive classification scores and n is the total number of LOO classifiers, ensures that subjects with lower classification certainty (<0.9) are excluded from post hoc analyses. This step helps to rule out underfitting by ensuring that only reliable classifications are considered.\n\nThe final sample comprised 27 controls, 33 first-degree relatives (FDRs), and 28 schizophrenia patients (SCZs) in the post hoc analysis, indicating a balanced and reliable dataset for evaluating the classification performance. The use of a robust measure, such as the median of individual classification scores, further ensures that the affinity of each FDR to schizophrenia is accurately characterized.",
  "optimization/regularization": "A nested leave-one-out cross-validation procedure was employed to optimize the parameters of the support vector machine (SVM) classifier. This method helps to prevent overfitting by ensuring that the model's performance is evaluated on data that was not used during the training process. Additionally, a forward component selection technique was used to identify the most discriminative set of functional networks (FNs). This technique involves iteratively adding the FN that improves the classification performance the most, thereby selecting only the most relevant features for the final model. These regularization methods collectively help to enhance the generalization capability of the classifier and mitigate the risk of overfitting.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is not a black-box but rather a transparent one, as it leverages Support Vector Machines (SVMs) and clear statistical methods to identify and classify functional networks (FNs) associated with schizophrenia (SCZ). The transparency of the model is evident in several ways:\n\nFirstly, the model uses a forward component selection technique to identify the most discriminative set of FNs. This process involves building classifiers on individual FNs, evaluating them with leave-one-out (LOO) cross-validation, and selecting the FN with the best classification performance. This iterative process continues until the combination of FNs with the overall best classification performance is identified. This method ensures that the selection of FNs is data-driven and transparent, as each step can be traced and understood.\n\nSecondly, the model generates classification scores that are median values of classification scores from nested LOO classifiers. These scores indicate the likelihood of a subject having SCZ (positive score) or being normal (negative score). This approach provides a clear and interpretable measure of each subject's classification.\n\nAdditionally, the model's performance is evaluated using multiple metrics, including classification accuracy, sensitivity, specificity, receiver operating characteristic (ROC) curve, and area under the ROC (AUC). These metrics provide a comprehensive understanding of the model's performance and reliability.\n\nFurthermore, the model's results are validated using an independent dataset, ensuring that the findings are robust and generalizable. The classification scores are also used to divide first-degree relatives (FDRs) into SCZ-specific and healthy control (HC)-specific subgroups, providing further insights into the model's interpretability.\n\nIn summary, the model's transparency is demonstrated through its use of clear statistical methods, interpretable classification scores, comprehensive performance metrics, and validation with an independent dataset. These features make the model interpretable and transparent, allowing for a better understanding of the underlying mechanisms and the classification process.",
  "model/output": "The model employed in this study is a classification model. Specifically, it utilizes a support vector machine (SVM) classifier to distinguish between schizophrenia patients and healthy controls. The SVM classifiers were built upon informative functional networks (FNs) identified through a pattern classification method. The classification performance was evaluated using metrics such as accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). The model's output includes classification scores for each subject, where a positive score indicates a schizophrenia pattern and a negative score indicates a normal pattern. These scores were used to classify first-degree relatives (FDRs) as having either schizophrenia-specific or healthy control-specific functional network patterns. The classification results were further validated using an independent dataset, demonstrating the model's robustness and generalizability.",
  "model/duration": "The execution time for the model involved several stages. Initially, the preprocessing of the rsfMRI data, including the computation of group-level independent components (ICs) and the application of ICA guided by group information (GIG-ICA), was performed. This step was crucial for extracting subject-specific functional networks (FNs) from the rsfMRI data of patients, unaffected first-degree relatives (FDRs), and controls.\n\nFollowing preprocessing, a pattern classification method was employed to identify informative FNs and build support vector machine (SVM) classifiers. This process included a forward component selection technique to optimize the classification performance for distinguishing schizophrenia (SCZ) patients from healthy controls (HCs). The leave-one-out (LOO) cross-validation model yielded 62 SVM classifiers, each generating a classification score based on the median value of its nested LOO classifiers.\n\nThe statistical significance of the classification performance was estimated using nonparametric permutation tests, which involved 10,000 random permutation tests with subject class labels randomly permuted. This step was essential for evaluating the robustness and reliability of the classification results.\n\nAdditionally, the model included the computation of voxelwise functional connectivity (FC) measures and similarity measures of informative FNs between individuals. These measures were used to visualize the similarity among FDRs, SCZ patients, and HCs.\n\nOverall, the execution time for the model was influenced by the complexity of the preprocessing steps, the computational demands of the pattern classification method, and the statistical analyses performed to evaluate the classification performance. The specific duration of each stage would depend on the computational resources available and the size of the dataset.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed a leave-one-out (LOO) cross-validation approach to build and assess the performance of support vector machine (SVM) classifiers. This process involved creating 62 SVM classifiers, each corresponding to a subject, with the classification score for each subject being the median value of the classification scores from its nested LOO classifiers. Positive scores indicated a classification as schizophrenia (SCZ), while negative scores indicated a classification as normal.\n\nThe evaluation metrics included classification accuracy, sensitivity, specificity, the receiver operating characteristic curve (ROC), and the area under the ROC (AUC). Nonparametric permutation tests were used to estimate the statistical significance of the classification performance. These tests involved 10,000 random permutations of subject class labels to generate a null distribution of classification rates, which was then visualized as a histogram.\n\nAdditionally, the informative functional networks (FNs) were validated using an independent dataset to ensure the robustness and generalizability of the findings. The classifiers were also applied to the FNs of first-degree relatives (FDRs), providing each FDR with 62 individual classification scores. The median of these scores was used as a measure to characterize the affinity of each FDR to SCZ, with a positive score indicating a SCZ pattern.\n\nA certainty measure was also adopted to evaluate the classification reliability for each individual subject. This measure was calculated based on the number of positive classification scores and the total number of LOO classifiers, with higher values indicating greater classification reliability. Subjects with lower classification certainty were excluded from post hoc analyses, resulting in a final sample comprising 27 controls, 33 FDRs, and 28 SCZs.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our pattern classification algorithm in distinguishing schizophrenia patients (SCZs) from healthy controls (HCs). The primary metrics reported include classification accuracy, sensitivity, and specificity. These metrics provide a clear indication of the model's ability to correctly identify SCZs and HCs, as well as its performance in minimizing false positives and false negatives.\n\nIn addition to these standard metrics, we calculated the receiver operating characteristic (ROC) curve and the area under the ROC (AUC). The ROC curve visually represents the trade-off between sensitivity and specificity at various threshold settings, while the AUC provides a single scalar value that summarizes the overall performance of the classifier. An AUC of 0.914 indicates excellent discriminative ability, suggesting that our model can effectively differentiate between SCZs and HCs.\n\nTo ensure the robustness and statistical significance of our classification results, we conducted nonparametric permutation tests. These tests involved performing 10,000 random permutation tests with subject class labels randomly permuted, allowing us to estimate the null distribution of the classification rate. The results of these tests confirmed that our classification performance was statistically significant (p < .0001), providing strong evidence that the identified informative functional networks (FNs) are genuinely informative for distinguishing SCZs from HCs.\n\nFurthermore, we validated our classification results on an independent testing dataset. This validation step is crucial for assessing the generalizability of our findings. The independent dataset yielded a correct classification rate of 77.5%, with an AUC of 0.811, demonstrating that our model maintains good performance even when applied to new, unseen data.\n\nOverall, the set of performance metrics reported in our study is representative of current standards in the literature. By including accuracy, sensitivity, specificity, ROC curves, AUC, and permutation tests, we provide a thorough evaluation of our classification algorithm's performance. This comprehensive approach ensures that our results are reliable, statistically significant, and generalizable to new datasets.",
  "evaluation/comparison": "Not applicable. The study focuses on the identification of informative functional networks (FNs) using a multivariate pattern classification method to differentiate schizophrenia patients (SCZs) from healthy controls (HCs) and to classify first-degree relatives (FDRs) based on their similarity to SCZs or HCs. The evaluation of the method involves cross-validation, permutation tests, and comparisons between different groups (SCZs, HCs, and FDRs). However, there is no mention of comparing the proposed method to publicly available methods or simpler baselines on benchmark datasets. The study primarily validates the identified FNs through internal cross-validation and an independent dataset, but it does not engage in a direct comparison with other existing methods or baselines.",
  "evaluation/confidence": "The evaluation of our method includes several performance metrics, and we have taken steps to ensure the statistical significance of our results. We calculated the classification accuracy, sensitivity, and specificity, along with the receiver operating characteristic curve (ROC) and the area under the ROC (AUC) to evaluate the classification performance.\n\nTo assess the statistical significance of our classification performance, we employed nonparametric permutation tests. These tests involved estimating the null distribution of the classification rate using 10-fold cross-validation with 10,000 random permutation tests, where subject class labels were randomly permuted. This approach allowed us to visualize the null distribution of the classification error as a histogram of classification rates, providing a robust measure of our method's performance.\n\nAdditionally, we used a certainty measure to evaluate the classification reliability for each individual subject. This measure, defined as 2np/n − 0.5, where np is the number of positive classification scores and n is the total number of LOO classifiers, indicates higher classification reliability with higher values. Subjects with lower classification certainty (<0.9) were excluded from post hoc analyses, ensuring that our results are based on reliable classifications.\n\nThe Lilliefors tests at the 1% level confirmed the normality of the distribution of the classification scores of different groups, further supporting the statistical validity of our findings. These rigorous statistical evaluations provide confidence in the superiority of our method over baselines and other approaches.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized specific datasets, including resting-state functional MRI (rsfMRI) data collected from schizophrenia patients, first-degree relatives (FDRs), and healthy controls. These datasets were used to estimate functional networks (FNs) and build support vector machine (SVM) classifiers. While the study provides detailed methods and results, the actual raw data files are not released to the public. The performance of the classifiers was validated using an independent dataset, but the specifics of this dataset and the raw evaluation files remain proprietary. Therefore, access to the raw evaluation files is not available for external use or verification."
}