{
  "publication/title": "GIPAE: A Computational Model for Predicting Drug-Disease Associations",
  "publication/authors": "The authors who contributed to the article are Han-Jing Jiang, Yu-An Huang, and Zhu-Hong You. Han-Jing Jiang and Zhu-Hong You are affiliated with the Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, and the University of Chinese Academy of Sciences. Yu-An Huang is associated with the Department of Computing at the Hong Kong Polytechnic University. The article was primarily focused on predicting drug-disease associations using a novel feature learning method based on the Gaussian interaction profile kernel and autoencoder (GIPAE). The contributions of the authors include the development of the computational model, the implementation of the 10-fold cross-validation method, and the evaluation of the model's performance on different datasets. Additionally, they conducted case studies on complex human diseases to validate the model's predictions.",
  "publication/journal": "BioMed Research International",
  "publication/year": "2019",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Machine Learning\n- Drug-Disease Associations\n- Computational Methods\n- Cross-Validation\n- Gaussian Interaction Profile Kernel\n- Random Forest Classifier\n- Support Vector Machine\n- Precision\n- Recall\n- F1-Score\n- AUC\n- Drug Repositioning\n- Deep Learning\n- Predictive Modeling\n- Bioinformatics",
  "dataset/provenance": "The datasets used in this study are derived from two sources, each providing a comprehensive collection of drug-disease associations. The first dataset, referred to as the Fdataset, was compiled by Gottlieb et al. and includes 593 drugs, 313 diseases, and 1933 validated drug-disease associations. The second dataset, known as the Cdataset, was collected by Luo et al. and encompasses 663 drugs, 409 diseases, and 2532 associations between them.\n\nThe information for the drugs in these datasets is extracted from DrugBank, a well-known database that contains extensive details about drugs. Additionally, drug fingerprints defined in the PubChem database are used to represent the chemical substructures of the drugs. Disease information is sourced from the Online Mendelian Inheritance in Man (OMIM) database, which focuses on human genes and diseases.\n\nThese datasets have been utilized in previous studies and by the community for drug repositioning and related research. The Fdataset and Cdataset provide a robust foundation for evaluating the performance of predictive models, such as the one proposed in this study, which aims to identify new drug-disease associations.",
  "dataset/splits": "The dataset was divided into ten roughly equal parts for cross-validation. Specifically, one group was used as the test set, while the remaining nine groups served as the training set. This process was repeated ten times, with each subset being used as the test set once and the remaining nine subsets used as training sets to form ten models. The final result was obtained by averaging the performance of these ten models. This approach ensures that each data point is used for both training and testing, providing a robust evaluation of the model's performance.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is an ensemble method, specifically the random forest classifier. This classifier is not new; it is a well-established method known for its robustness and ability to handle high-dimensional data.\n\nThe random forest classifier was chosen due to its ensemble model and random tree splitting strategy, which helps to achieve better performance compared to other classifiers like Support Vector Machines (SVM). The random forest classifier's ability to correct overfitting and provide stable prediction performance makes it suitable for our model, GIPAE.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of our study is on drug-disease association prediction, not on the development of new machine-learning algorithms. The random forest classifier is used as a tool to evaluate the performance of our proposed feature extraction method and its application in predicting drug-disease interactions. The innovation lies in the integration of this classifier with our feature representation process, which includes the Gaussian interaction profile kernel, disease semantic similarity, and drug fingerprint. This combination allows for more significant prediction results in the context of drug repositioning.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on a combination of Gaussian interaction profile kernels, disease semantic similarity, and drug fingerprint to create similarity descriptors for drugs and diseases. These descriptors are then processed through a fully connected layer to extract features, which are subsequently used by a random forest classifier to yield predicted scores.\n\nThe random forest classifier is an ensemble model that combines multiple decision trees. Each tree is trained on a different subset of the training data, which helps to increase the diversity of the trees and improve the overall stability and performance of the model. This approach does not involve using the outputs of other machine-learning algorithms as input; rather, it focuses on leveraging the strengths of the random forest classifier's ensemble and random tree splitting strategy.\n\nThe training data for the model is divided into ten roughly equal parts for cross-validation. In each fold, one part is used as the test set, and the remaining nine parts are used as the training set. This process is repeated ten times, with a different subset used as the test set each time. The final result is the average of the ten models, ensuring that the training data is independent for each fold. This cross-validation method helps to evaluate the model's performance and generalization ability.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithm. We utilized two primary datasets, Fdataset and Cdataset, which contain drug-disease associations. These datasets were compiled from multiple sources, including DrugBank for drug information and the Online Mendelian Inheritance in Man (OMIM) database for disease information.\n\nDrug fingerprints from the PubChem database were used to represent the chemical substructures of drugs. These fingerprints provide a binary vector indicating the presence or absence of specific substructures within each drug. Disease information was encoded using semantic similarity measures derived from the OMIM database, which focuses on human genes and diseases.\n\nTo enhance the feature representation, we employed the Gaussian interaction profile kernel. This kernel allows for the consideration of nonlinear relationships in known drug-disease associations. The Gaussian interaction profile for a disease is calculated based on the assumption that similar diseases often bind to the same drug molecules. This method has been successfully used in various disease prediction studies.\n\nAdditionally, we integrated an autoencoder module to extract meaningful features from the drug fingerprints. The autoencoder, a type of neural network, consists of an encoder and a decoder. The encoder compresses the input data into a lower-dimensional representation, while the decoder reconstructs the data from this compressed form. This process helps in learning a compact and informative feature representation of the drug fingerprints.\n\nFor diseases, we combined the Gaussian interaction profile similarity and semantic similarity to create a comprehensive feature descriptor. This descriptor captures both the structural and semantic aspects of diseases, providing a richer representation for the machine-learning algorithm.\n\nNegative samples were randomly generated from unlabeled drug-disease pairs, ensuring an equal number of positive and negative samples for training. This balanced dataset helps in reducing bias and improving the model's performance.\n\nOverall, the encoding and preprocessing steps involved extracting and integrating multiple types of data, including drug fingerprints, disease semantic similarity, and Gaussian interaction profiles. These encoded features were then used as inputs for our machine-learning classifier, enabling effective prediction of drug-disease associations.",
  "optimization/parameters": "In our study, the model utilized several input parameters, which were carefully selected to optimize performance. The primary parameters include those related to the Gaussian interaction profile kernel, disease semantic similarity, and drug fingerprint. These parameters were integrated to form the drug and disease similarity descriptors.\n\nThe selection of these parameters was guided by their known influence on drug-disease associations. Specifically, the Gaussian interaction profile kernel was chosen for its effectiveness in capturing the interaction profiles between drugs and diseases. The disease semantic similarity and drug fingerprint were included to enhance the model's ability to predict associations accurately.\n\nThe random forest classifier, which forms a crucial part of our model, also has its own set of parameters. These include the number of trees in the forest, the maximum depth of the trees, and the minimum number of samples required to split an internal node. These parameters were tuned using cross-validation to ensure optimal performance.\n\nThe feature representation process involves combining the drug Gaussian interaction profile kernel with the drug fingerprint and the disease Gaussian interaction profile kernel with the disease semantic similarity. This combination is then processed through a full-connected layer to extract relevant features. The outputs of this layer are fed into the random forest classifier to yield the predicted scores.\n\nIn summary, the model's parameters were selected based on their relevance to drug-disease associations and were optimized through cross-validation to achieve the best possible performance. The integration of these parameters allows the model to effectively predict potential associations between drugs and diseases.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "In our study, we employed a random forest classifier, which is known for its robustness against overfitting due to its ensemble nature and random tree splitting strategy. This approach helps to mitigate the risk of overfitting, even when the number of parameters is large relative to the number of training points.\n\nTo further ensure the model's performance, we utilized 10-fold cross-validation. This method involves dividing the dataset into ten roughly equal parts, using nine parts for training and one part for testing, and repeating this process ten times with different subsets. This technique helps to provide a more accurate estimate of the model's performance and generalizability, reducing the likelihood of overfitting.\n\nAdditionally, the feature representation process, which includes combining drug Gaussian interaction profile kernels with drug fingerprints and disease Gaussian interaction profile kernels with disease semantic similarity, helps to create meaningful and informative features. This step is crucial in preventing underfitting by ensuring that the model has access to relevant and sufficient information to make accurate predictions.\n\nThe use of a full-connected layer to extract features based on the combined drug and disease similarity further enhances the model's ability to learn complex patterns, reducing the risk of underfitting. The random forest classifier then uses these extracted features to yield predicted scores, leveraging the ensemble model's strength to improve prediction performance.\n\nIn summary, the combination of the random forest classifier's inherent resistance to overfitting, the thorough cross-validation process, and the comprehensive feature representation strategy ensures that our model effectively balances between overfitting and underfitting, leading to robust and reliable predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was the random forest classifier, which inherently helps to mitigate overfitting due to its ensemble nature and random tree splitting strategy. This approach increases tree diversity by growing trees from different subsets of training data, thereby reducing the risk of overfitting to any single subset.\n\nAdditionally, we utilized 10-fold cross-validation, a robust technique that involves dividing the dataset into ten roughly equal parts. In each fold, one part is used as the test set while the remaining nine parts are used as the training set. This process is repeated ten times, with each subset serving as the test set once. The final results are averaged across all ten folds, providing a more reliable estimate of the model's performance and helping to prevent overfitting.\n\nFurthermore, we evaluated our model using various performance metrics such as accuracy, precision, recall, and F1-score, along with the area under the receiver operating characteristic curve (AUC). These metrics provided a comprehensive assessment of the model's predictive performance and helped to ensure that the model generalized well to unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The GIPAE model, while leveraging advanced machine learning techniques, is not entirely a black-box model. The interpretability of the model can be attributed to several key components and processes that provide insights into its decision-making.\n\nFirstly, the feature representation process in GIPAE involves combining drug Gaussian interaction profile kernels with drug fingerprints and disease Gaussian interaction profile kernels with disease semantic similarity. This step creates drug and disease similarity descriptors, which are more interpretable than raw data. By understanding these descriptors, one can gain insights into how the model perceives the relationships between drugs and diseases.\n\nSecondly, the use of a random forest classifier enhances the interpretability of the model. Random forests consist of multiple decision trees, each of which can be individually interpreted. The majority vote mechanism used by the random forest allows for the identification of the most important features contributing to the predictions. This transparency is crucial for understanding which drug and disease characteristics are most influential in the model's predictions.\n\nAdditionally, the model's performance metrics, such as precision, recall, F1-score, and accuracy, provide clear evaluations of its effectiveness. These metrics help in understanding the model's strengths and weaknesses, making it easier to interpret its predictions in practical scenarios.\n\nThe case studies on diseases like Obesity and Alzheimer's further illustrate the model's interpretability. By comparing the top predicted drugs with known associations in databases like CTD, it is possible to validate the model's predictions and understand the underlying associations it identifies. For instance, in the case of Obesity, 14 out of the top 20 predicted drugs were confirmed, demonstrating the model's ability to identify meaningful drug-disease associations.\n\nIn summary, while the GIPAE model utilizes complex machine learning techniques, its interpretability is supported by the transparent feature representation process, the use of a random forest classifier, and the validation through case studies. These elements collectively make the model more interpretable and trustworthy for practical applications in drug repositioning.",
  "model/output": "The model is a classification model. It is designed to predict whether certain drugs are related to certain diseases. The performance of the model was evaluated using metrics such as precision, F1-score, recall, and accuracy, which are commonly used for classification tasks. The model employs a random forest classifier, which is a type of ensemble learning method used for classification. Additionally, the model's output includes predicted scores for positive and negative samples, further indicating its classification nature. The evaluation criteria and the comparison with other models also focus on classification performance metrics.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, we employed a rigorous evaluation method to assess the performance of our proposed model. We utilized 10-fold cross-validation, a widely accepted technique in machine learning, to ensure the robustness and generalizability of our results. This method involves randomly dividing the datasets into ten roughly equal parts. In each iteration, one part is used as the test set, while the remaining nine parts serve as the training set. This process is repeated ten times, with each subset being used as the test set exactly once. The final performance metrics are averaged across all ten iterations.\n\nFor our evaluation, we focused on several key performance metrics: precision, recall, F1-score, and accuracy. These metrics provide a comprehensive view of the model's ability to correctly identify positive and negative samples. Precision measures the accuracy of the positive predictions, recall assesses the model's ability to find all relevant instances, the F1-score is the harmonic mean of precision and recall, and accuracy reflects the overall correctness of the predictions.\n\nAdditionally, we computed the receiver operating characteristic (ROC) curve and the area under the ROC curve (AUC) to further evaluate the model's performance. The ROC curve plots the true positive rate against the false positive rate at various threshold settings, providing a visual representation of the model's diagnostic ability. The AUC summarizes the ROC curve into a single value, with higher values indicating better performance.\n\nOur model was evaluated on two datasets, Fdataset and Cdataset. On Fdataset, our proposed model achieved an average accuracy of 87.30%, precision of 86.06%, recall of 89.08%, and F1-score of 87.53%. On Cdataset, the model yielded an average accuracy of 90.52%, precision of 89.77%, recall of 91.47%, and F1-score of 90.60%. These results demonstrate the strong predictive performance of our model.\n\nTo further validate our approach, we compared it with five other previously proposed methods using the same 10-fold cross-validation framework and datasets. Our model consistently outperformed these methods, achieving the highest AUC values on both datasets. This comparison underscores the effectiveness of our model's feature extraction method and the use of a random forest classifier, which leverages an ensemble model and random tree splitting strategy to enhance prediction accuracy.",
  "evaluation/measure": "In our evaluation, we employed several key performance metrics to assess the effectiveness of our proposed model. These metrics include precision, recall, F1-score, and accuracy. Precision is defined as the ratio of true positive predictions to the sum of true positives and false positives. Recall, also known as sensitivity, is the ratio of true positive predictions to the sum of true positives and false negatives. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. Accuracy is the ratio of the sum of true positives and true negatives to the total number of predictions.\n\nAdditionally, we computed the receiver operating characteristic (ROC) curve and the area under the ROC curve (AUC) to further evaluate the model's performance. The ROC curve plots the true positive rate against the false positive rate at various threshold settings, and the AUC provides a single scalar value that summarizes the performance across all thresholds.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in the context of drug-disease association prediction. They provide a comprehensive view of the model's ability to correctly identify positive and negative samples, as well as its overall accuracy. The use of these metrics allows for a fair comparison with other models in the field.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our proposed model, GIPAE, against several other methods using the same 10-fold cross-validation framework and datasets. The methods compared include MBiRW, DrugNet, HGBI, KBMF, and DRRs. On the Fdataset, GIPAE achieved the highest AUC, which was significantly better than the other methods. Specifically, GIPAE's AUC was 0.155 higher than DrugNet, 0.104 higher than HGBI, and 0.018 higher than KBMF. MBiRW and DRRs yielded poorer AUCs of 0.917 and 0.930, respectively. On the Cdataset, GIPAE also performed exceptionally well with an AUC of 0.960, outperforming DrugNet, MBiRW, HGBI, KBMF, and DRRs, which had AUCs of 0.804, 0.858, 0.928, 0.933, and 0.947, respectively.\n\nAdditionally, we compared the effectiveness of our proposed feature extraction method combined with a random forest classifier against a support vector machine (SVM) classifier. The random forest classifier demonstrated better performance due to its ensemble model and random tree splitting strategy. On the Fdataset, the random forest classifier achieved an average accuracy of 87.30%, precision of 86.06%, recall of 89.08%, and F1-score of 87.53%. In contrast, SVM achieved an accuracy of 79.31%, precision of 79.28%, recall of 79.36%, and F1-score of 79.30%. On the Cdataset, the random forest classifier achieved an average accuracy of 90.52%, precision of 89.77%, recall of 91.47%, and F1-score of 90.60%, while SVM achieved an accuracy of 83.83%, precision of 83.93%, recall of 83.69%, and F1-score of 83.80%. These comparisons highlight the superior performance of the random forest classifier in conjunction with our proposed feature extraction method.",
  "evaluation/confidence": "In our evaluation, we employed 10-fold cross-validation to ensure robust and reliable performance metrics. This method involves dividing the datasets into ten roughly equal parts, using nine parts for training and one part for testing, and repeating this process ten times with different subsets. This approach helps in obtaining a more accurate estimate of the model's performance.\n\nThe performance metrics we reported, including accuracy, precision, recall, and F1-score, are accompanied by standard deviations. For instance, on the Fdataset, our proposed model yielded an average accuracy of 87.30% with a standard deviation of 1.84%, indicating a consistent performance across different folds. Similarly, on the Cdataset, the average accuracy was 90.52% with a standard deviation of 1.57%. These standard deviations provide a measure of the confidence intervals around our performance metrics, showing that the results are stable and not overly sensitive to the specific data splits used in cross-validation.\n\nTo further evaluate the statistical significance of our results, we compared our method with five other previously proposed models using the same 10-fold cross-validation framework. The comparison included methods like MBiRW, DrugNet, HGBI, KBMF, and DRRs. The results demonstrated that our model, GIPAE, achieved the highest Area Under the Curve (AUC) on both the Fdataset and Cdataset, indicating superior performance. For example, on the Fdataset, GIPAE's AUC was 0.933, which is significantly higher than the AUCs of the other methods. This statistical comparison provides strong evidence that our method is not only effective but also superior to existing baselines.\n\nAdditionally, we conducted a detailed analysis of the predicted scores for positive and negative samples. For more than 85% of negative samples and 90% of positive samples, the predicted scores were distinctly separated, with negative samples scoring lower than 0.2 and positive samples scoring higher than 0.8. This clear separation further supports the reliability and confidence in our model's predictions.\n\nIn summary, the performance metrics reported in our study are accompanied by standard deviations, providing confidence intervals. The results are statistically significant, as demonstrated by the superior performance of our model compared to other methods in the same evaluation framework. This comprehensive evaluation underscores the robustness and effectiveness of our proposed approach.",
  "evaluation/availability": "Not enough information is available."
}