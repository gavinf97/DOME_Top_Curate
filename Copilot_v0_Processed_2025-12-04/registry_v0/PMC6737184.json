{
  "publication/title": "MLLASSO improves genomic prediction",
  "publication/authors": "The authors who contributed to the article are:\n\n- Xuehai Hu\n- Weibo Xie\n- SX\n\nUnfortunately, the specific contributions of each author to the paper are not detailed.",
  "publication/journal": "Plant Biotechnology Journal",
  "publication/year": "2019",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Genomic Prediction\n- Transcriptomic Prediction\n- Metabolomic Prediction\n- LASSO Method\n- Predictability\n- Heritability\n- Gene Expression\n- Genetic Markers\n- Cross-Validation\n- Agronomic Traits\n- Multi-Layer Genetic Features\n- Predicted Transcriptome\n- Instrumental Variables\n- Regularization Techniques\n- Phenotype Prediction",
  "dataset/provenance": "The dataset used in this study consists of 210 recombinant inbred lines (RILs) of rice, derived from nine rounds of selfing from the cross between Zhenshan 97 and Minghui 63, two elite indica rice varieties. These RILs were sequenced using next-generation sequencing technology, and the sequencing results were confirmed with traditional RFLP/SSR markers. This process identified a total of 270,820 high-quality single nucleotide polymorphisms (SNPs) as the genotypes of each individual. These SNPs were subsequently combined into 1619 bins, where within a bin, all markers segregate with the same pattern. The genomic data are represented by a 210 x 1619 feature matrix, where each element is a numerically coded genotype for an individual at a specific bin.\n\nGene expressions of transcriptomic data were measured by extracting RNA collected from flag leaves using a microarray sequencing platform. A total of 24,994 genes were recorded from all the 210 RILs, forming a 210 x 24,994 feature matrix. The metabolomic data consist of 683 metabolites measured from flag leaves and 317 metabolites measured from germinated seeds, totaling 1000 metabolites. These metabolites form a 210 x 1000 matrix for metabolomic traits. For these intermediate phenotypes, the heritability of each gene expression or metabolite was calculated as the broad-sense heritability.\n\nThe dataset includes four important agronomic traits collected from the same population: yield per plant, tiller number per plant, grain number per panicle, and 1000 grain weight. These traits were obtained from a field experiment conducted at the Farm of Huazhong Agricultural University in Wuhan, China. The dataset has been used in previous studies, such as those by Wang et al. (2014) and Gonget al. (2013), and is part of a broader community effort to understand and improve rice genetics and breeding.",
  "dataset/splits": "The dataset was divided into ten groups for a 10-fold cross-validation (CV) test. This means there were ten data splits. Each split contained approximately one-tenth of the total samples, as the whole samples were divided into ten groups. The remaining one group of samples never appeared in the training process until they were tested with the trained multilayer model. This cross-layer CV approach ensured that each group was used once as the test set while the other nine groups were used for training. The distribution of data points in each split was roughly equal, with each split containing about one-tenth of the total data points.",
  "dataset/redundancy": "The datasets used in this study consist of 210 recombinant inbred lines (RILs) of rice, derived from crosses between two elite indica rice varieties. These RILs were sequenced using next-generation sequencing technology, and the results were confirmed with traditional RFLP/SSR markers, yielding a total of 270,820 high-quality SNPs. These SNPs were subsequently combined into 1619 bins, where each bin contains markers that segregate with the same pattern.\n\nThe genomic data are represented by a 210 x 1619 feature matrix, where each element is a numerically coded genotype for an individual at a specific bin. Gene expressions of transcriptomic data were measured from RNA extracted from flag leaves using a microarray sequencing platform, resulting in a 210 x 24,994 feature matrix. The metabolomic data consist of 1000 metabolites measured from flag leaves and germinated seeds, forming a 210 x 1000 matrix.\n\nTo evaluate the predictability of the trained models, a 10-fold cross-validation (CV) test was adopted. This CV test was performed in a cross-layer manner, rather than within-layer. The entire sample set was divided into ten groups, with nine groups used for training the models layer by layer. The remaining group, which had not appeared in the training process, was used for testing the trained multilayer model. This process was repeated ten times to ensure that each group of samples was tested exactly once.\n\nThe distribution of the datasets compares favorably with previously published machine learning datasets in the field of genomic prediction. The use of multiple omics layers, including genomic, transcriptomic, and metabolomic data, provides a comprehensive and integrated approach to phenotype prediction. This methodology addresses common problems such as heterogeneity between different data sources, imputation of missing values, and sparse selection of significant variables, making it a robust and practical strategy for integrative analysis studies.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the Least Absolute Shrinkage and Selection Operator (LASSO). This is a type of regression analysis method that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model it produces.\n\nThe algorithm employed is not a standard LASSO but a novel extension called Multilayered LASSO (MLLASSO). This new method integrates multiple layers of omic data into a single model, enabling the iterative learning of three layers of genetic features supervised by observed transcriptome and metabolome data.\n\nThe reason MLLASSO was not published in a machine-learning journal is that its development and application are primarily driven by the need to improve genomic prediction in plant breeding. The focus is on leveraging intermediate omic data to enhance the predictability of complex traits, such as yield in rice. This directed learning strategy, supervised by intermediate omic data, aims to achieve more reliable and robust predictions compared to conventional genomic prediction models. The integration of multiple omic layers allows for the learning of higher-order information of gene interactions, which is crucial for understanding and predicting polygenic traits in plants.",
  "optimization/meta": "The model described in this publication is a meta-predictor that integrates multiple layers of genetic features to improve genomic prediction (GP). It uses data from other machine-learning algorithms as input, specifically the least absolute shrinkage and selection operator (LASSO) method.\n\nThe whole system is constituted by a multilayered least absolute shrinkage and selection operator (MLLASSO). This approach implements a directed learning strategy that allows learning three layers of genetic features. These layers are denoted as GFs.1L, GFs.2L, and GFs.3L. The first layer (GFs.1L) is learned using genetic markers as instrumental variables (IV) and is supervised by transcriptomic data. The second layer (GFs.2L) combines the first layer with additional genetic features, and the third layer (GFs.3L) is learned based on the second layer and is supervised by metabolomic data.\n\nThe training data for each layer is independent in the sense that a cross-layer 10-fold cross-validation (CV) test is adopted. This means that the whole samples are first divided into ten groups. Nine of these groups are used to train models layer by layer, while the remaining one group of samples is never used in the training process until it is tested with the trained multilayer model. This ensures that the training data for each layer is independent of the test data.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, a cut-off criterion of 'CV > 0.2 and PD > 1' was applied to screen the entire transcriptome, resulting in 5467 genes that met these criteria and were selected for further analysis. These genes constituted the representative transcriptome.\n\nNext, all genomic markers, consisting of 1619 bins, were used to predict each transcript of the representative transcriptome using the LASSO method. This process yielded the first layer of genetic features, denoted as GFs.1L or predicted transcriptome (PT.1L).\n\nThe LASSO method was employed to predict the transcriptome from the genomic markers, incorporating a regularization methodology with L1-penalty. This approach ensured that the model selected an optimal set of sparse representatives of the regression coefficients.\n\nAdditionally, a 10-fold cross-validation (CV) test was adopted to evaluate the predictability of the trained model. This CV test was performed in a cross-layer manner, where the entire sample set was divided into ten groups. Nine of these groups were used to train the models layer by layer, while the remaining group was used for testing, ensuring that it did not appear in the training process until the testing phase.\n\nThe integration of genomic, transcriptomic, and metabolomic data into a single model allowed for the iterative learning of three layers of genetic features using genetic variants as instrumental variables. This multi-layered approach enabled the model to capture complex relationships between the genome, transcriptome, and metabolome, ultimately improving the prediction of polygenic traits such as yield.",
  "optimization/parameters": "In our study, we utilized a multi-layer LASSO (MLLASSO) approach to predict various traits in rice. The model incorporates multiple layers of genetic features, each with its own set of parameters.\n\nThe first layer of our model uses genomic markers as input features. We employed 1619 bins of genomic markers to predict the transcriptome. The LASSO method was used to select relevant features, resulting in a sparse model that includes only the most predictive genomic markers.\n\nIn the second layer, we predicted gene expressions using the genomic markers and the first layer of predicted transcriptome. This layer involves two discrimination thresholds, alpha (a) and beta (b), which determine the predictability of genetically predictable genes (GPGs) in the first and second layers, respectively. Through a grid search and cross-validation, we found that the optimal values for alpha and beta were 0.55 and 0.25, respectively.\n\nThe third layer of our model predicts metabolomic traits using the combined genetic features from the first and second layers. This layer introduces an additional tuning parameter, gamma (c), which defines the predictability threshold for genetically predictable metabolites. We performed a grid search to determine the optimal combination of alpha, beta, and gamma, ultimately achieving a maximal predictability of 0.2313 with the values a = 0.2, b = 0.35, and c = 0.70.\n\nThroughout the model, the number of features (p) varies depending on the layer and the selected thresholds. For instance, in the first layer, the number of GPGs (k) is approximately 1883 when alpha is set to 0.55. In the second layer, the number of GPGs (l) is around 1767 when beta is set to 0.25. The combination of these layers results in a comprehensive model that effectively predicts yield and other agronomic traits in rice.",
  "optimization/features": "In our study, we utilized various input features to predict agronomic traits. The number of features (f) used as input varied depending on the specific model and layer.\n\nFor the LASSO method using genomic data, we employed 1619 bins as features. When using the transcriptome data, the input dimension was 24,994 genes. The metabolomic data consisted of 1000 metabolites. Additionally, we used a representative transcriptome consisting of 5467 gene expressions.\n\nFeature selection was performed using the LASSO method, which employs regularization techniques to perform variable selection and prediction. This method often yields a sparse model, involving only a small subset of variables or features, making it more interpretable. The tuning parameter in the LASSO method was determined via a 10-fold cross-validation (CV) method to minimize the predicted residual sum of squares (PRESS).\n\nThe 10-fold CV test was conducted in a cross-layer form, ensuring that the feature selection and model training were performed using different subsets of the data. This approach helps to prevent overfitting and ensures that the model's predictability is evaluated on unseen data.\n\nIn summary, feature selection was performed using the training set only, and the number of input features varied depending on the specific omic data used. The LASSO method was employed to select a sparse subset of features, enhancing the model's interpretability and predictability.",
  "optimization/fitting": "In our study, we employed a multi-layer LASSO (MLLASSO) approach to predict phenotypes using genetic, transcriptomic, and metabolomic data. The number of parameters in our models is indeed much larger than the number of training points. Specifically, we have 210 samples and a total of approximately 5467 transcriptomic features, 1619 genomic features, and 1000 metabolomic features.\n\nTo address the risk of over-fitting, we utilized a 10-fold cross-validation (CV) strategy. This method involves dividing the dataset into ten groups, training the model on nine groups, and testing it on the remaining group. This process is repeated ten times, ensuring that each group is used as the test set once. Importantly, we performed cross-layer CV, where the training and testing sets are not from the same layer, further mitigating the risk of over-fitting.\n\nAdditionally, the LASSO method itself incorporates L1 regularization, which promotes sparsity in the model by driving some coefficients to zero. This regularization helps to select a sparse subset of features, reducing the complexity of the model and preventing over-fitting.\n\nTo rule out under-fitting, we carefully tuned the regularization parameters (alpha, beta, and gamma) through a grid search. This process involved systematically evaluating different combinations of these parameters to find the optimal values that maximize the predictability of the model. By doing so, we ensured that the model is complex enough to capture the underlying patterns in the data without being too simplistic.\n\nFurthermore, we compared the performance of our MLLASSO model with traditional methods using only genomic, transcriptomic, or metabolomic data. The improved predictability achieved by our model indicates that it is not under-fitting the data. For instance, the predictability of yield improved from 0.1588 to 0.1900 when using the predicted values of genetically predictable genes (GPGs) with an optimal alpha value of 0.55.\n\nIn summary, our use of cross-layer 10-fold CV, L1 regularization, and parameter tuning helped to balance the model complexity, effectively addressing both over-fitting and under-fitting concerns.",
  "optimization/regularization": "In our study, we employed a regularization method with L1-penalty, also known as the LASSO (Least Absolute Shrinkage and Selection Operator) method, to prevent overfitting. This technique is particularly useful for feature selection and regularization in regression models. By applying L1-penalty, we encourage sparsity in the model, which means that some of the regression coefficients are exactly zero, effectively selecting a subset of the most relevant features.\n\nThe LASSO method was implemented across all three layers of our model. In the first layer, it was used to predict the transcriptome based on genomic markers. In the second layer, it predicted the expressions of genetically unpredictable genes using a combination of genomic markers and the predicted expressions from the first layer. In the third layer, it predicted the metabolome based on the predicted expressions from the first and second layers.\n\nThis regularization approach helps to avoid overfitting by simplifying the model and reducing the complexity, making it more interpretable and generalizable to new data. The tuning parameter in the LASSO method was determined via a 10-fold cross-validation process to minimize the predicted residual sum of squares, ensuring that the model's performance is robust and not overly fitted to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule are reported in the publication. The optimal values for the tuning parameters alpha, beta, and gamma were determined through a grid search and cross-validation process. Specifically, the optimal combination for metabolite prediction was found to be alpha = 0.2, beta = 0.35, and gamma = 0.70, achieving a maximal predictability of 0.2313.\n\nThe 10-fold cross-validation (CV) test was used extensively to evaluate the predictability of the trained models. This CV test was performed in a cross-layer manner, ensuring that each group of samples was tested only once after being trained on different layers.\n\nThe results of these optimizations, including the predictabilities for various traits and the selection processes of optimal alpha and beta, are presented in tables and figures within the publication. For instance, Table 1 provides the predictabilities of ten different inputs using the 10-fold cross-validation test, and Figure 3 illustrates the variation tendencies of predictabilities for different traits as alpha and beta increase.\n\nRegarding the availability of model files and optimization parameters, the publication does not explicitly mention the provision of these files. However, the methods and results are thoroughly documented, allowing for replication of the experiments by other researchers. The publication is available under the license of the Plant Biotechnology Journal, published by the Society for Experimental Biology and The Association of Applied Biologists and John Wiley & Sons Ltd.",
  "model/interpretability": "The MLLASSO model is not a black-box model. It integrates multiple layers of biological data, making it interpretable and transparent. The model uses a hierarchical structure that includes genomic, transcriptomic, and metabolomic layers. This structure allows for the identification of genetically predictable genes (GPGs) and metabolites, which are key drivers of the predictions.\n\nThe first layer of the model uses genomic markers to predict transcript expressions, and a threshold (alpha) is applied to identify GPGs. These GPGs are then used to predict phenotypes, providing a clear link between genetic variants and the predicted outcomes. The second layer further refines these predictions by incorporating the GPGs from the first layer, and the third layer adds metabolomic data to enhance the model's predictive power.\n\nThe use of LASSO regression with L1-penalty in each layer ensures that the model selects an optimal set of sparse representatives of the regression coefficients. This sparsity makes the model interpretable, as it highlights the most relevant genetic and molecular features contributing to the predictions.\n\nAdditionally, the model's performance is evaluated using a 10-fold cross-validation test, which provides insights into its robustness and generalizability. The predictability of different inputs, such as genomic markers, transcriptome, and metabolome, is compared, offering a transparent view of how each type of data contributes to the model's predictions.\n\nIn summary, the MLLASSO model's hierarchical structure and the use of LASSO regression make it transparent and interpretable. The model's ability to identify key genetic and molecular features provides clear examples of how it operates and what drives its predictions.",
  "model/output": "The model presented in this publication is a regression model. It is designed to predict continuous outcomes, specifically phenotypes related to plant biology, such as yield, tiller number, grain number, and thousand kernel weight (KGW). The model employs a multi-layer LASSO (Least Absolute Shrinkage and Selection Operator) approach to integrate genomic, transcriptomic, and metabolomic data for predictive purposes. The output of the model is the predicted values of these phenotypic traits, which are continuous variables. The model's performance is evaluated using predictability metrics, such as the coefficient of determination (R²), which measures the proportion of variance in the dependent variable that is predictable from the independent variables. The goal is to achieve high predictability for the phenotypic traits of interest, indicating that the model can accurately predict these outcomes based on the input data.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The method was evaluated using a 10-fold cross-validation (CV) test, specifically in a cross-layer format. This approach involved dividing the entire dataset into ten groups. Nine of these groups were used to train the models layer by layer, while the remaining group was reserved for testing. This process was repeated ten times, ensuring that each group was used for testing exactly once. The cross-layer CV method was chosen to assess the predictability of the trained models effectively. The predictability was defined as R², which is calculated using the formula R² = 1 - (PRESS / SS), where PRESS is the predicted residual sum of squares and SS is the total sum of squares. This evaluation method helped in determining the performance and reliability of the models developed using the MLLASSO framework.",
  "evaluation/measure": "In our evaluation, we primarily focused on predictability as our key performance metric. This metric was assessed using a 10-fold cross-validation (CV) test, which was conducted in a cross-layer manner rather than within-layer. This approach involved dividing the entire dataset into ten groups, using nine of them for training and the remaining one for testing, ensuring that each group was tested only once.\n\nWe reported the predictability for various inputs, including genomic markers, transcriptome, metabolome, and different layers of genetic features. Specifically, we evaluated the predictability for four traits: yield, tiller, grain, and kernel grain weight (KGW). The predictability values for these traits were presented in a table, allowing for a clear comparison across different inputs and methods.\n\nThe predictability metric is widely used in the literature for evaluating the performance of predictive models in genomics and related fields. It provides a straightforward measure of how well the model's predictions align with the actual observed values. By reporting predictability for multiple traits and inputs, we aimed to provide a comprehensive assessment of our model's performance and its potential applications in different contexts.\n\nIn addition to predictability, we also discussed the relationship between predictability and heritability, highlighting that the accuracy of gene expression prediction by genetic variants is largely dependent on the gene's heritability. This finding is consistent with previous studies and adds depth to our evaluation by connecting predictability to underlying genetic principles.\n\nOverall, the set of metrics we reported is representative of the literature and provides a clear and informative evaluation of our model's performance. The focus on predictability, along with the consideration of heritability, ensures that our evaluation is both rigorous and relevant to the broader field of genomic prediction.",
  "evaluation/comparison": "In our study, we compared our MLLASSO method to several publicly available methods and simpler baselines to evaluate its performance. We used a 10-fold cross-validation (CV) test to assess the predictability of different models. The CV test was conducted in a cross-layer manner, where the samples were divided into ten groups, and nine groups were used for training while the remaining group was used for testing. This process was repeated ten times to ensure that each group was tested once.\n\nWe compared our MLLASSO method to traditional models of genomic prediction (GP), transcriptomic prediction (TP), and metabolomic prediction (MP). The traditional methods use LASSO with different types of data: genomic markers, transcriptome, and metabolome. We found that the observed transcriptome achieved much greater predictability than genomic markers alone. However, the predicted transcriptome did not initially achieve the expected predictability, likely due to the noise from poorly predicted transcripts.\n\nTo address this, we introduced the concept of genetically predictable genes (GPGs) and genetically unpredictable genes (GUGs). By focusing on GPGs with high predictability, we improved the predictability of yield. For instance, using PT.1L.GPGs with a discrimination threshold of 0.55, we achieved a 19.65% increase in predictability compared to using genomic markers alone.\n\nWe also compared our method to simpler baselines, such as using the whole predicted transcriptome (GFs.1L) without filtering for GPGs. This approach did not improve predictability and even slightly decreased it. This comparison highlighted the importance of selecting genetically predictable features for accurate phenotype predictions.\n\nAdditionally, we performed a grid search to determine the optimal combination of discrimination thresholds (alpha, beta, and gamma) for metabolite prediction. We found that selecting genetically predictable metabolites improved the predictability of metabolites compared to using genomic markers alone. This comparison showed that our MLLASSO method, which integrates multiple layers of data, outperforms simpler baselines and traditional methods.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the models was conducted using a 10-fold cross-validation (CV) test, which is a robust method for assessing the predictability of the trained models. This CV test was performed in a cross-layer manner, ensuring that each group of samples was tested only once after being trained on the remaining nine groups. This approach helps in providing a more reliable estimate of the model's performance by reducing the risk of overfitting.\n\nThe predictability of the models was quantified using the R-squared (R²) metric, which measures the proportion of the variance in the dependent variable that is predictable from the independent variables. The R² values for different inputs and models were reported, allowing for a direct comparison of their performance.\n\nStatistical significance was addressed by determining optimal tuning parameters through grid search and cross-validation. For instance, the optimal value of alpha for genetically predictable genes (GPGs) was found to be 0.55, which improved the predictability of yield by 19.65%. Similarly, the optimal combination of tuning parameters for metabolite prediction was determined to be alpha = 0.2, beta = 0.35, and gamma = 0.70, achieving a maximal predictability of 0.2313.\n\nThe results indicated that the predicted transcriptome did not achieve the expected predictability initially, but by focusing on genetically predictable genes, the predictability was significantly improved. This suggests that the method is effective in identifying and utilizing the most informative genetic features for phenotype prediction.\n\nAdditionally, the performance metrics for different metabolite classes were compared, showing that certain classes, such as flavonoids, polyphenols, and amino acids, had distinctive predictabilities. This indicates that the method can capture complex interactions and provide insights into the underlying biological processes.\n\nOverall, the evaluation provides strong evidence that the proposed method, MLLASSO, is superior to traditional genomic prediction methods and baselines, as it effectively integrates genomic, transcriptomic, and metabolomic information to improve phenotype prediction.",
  "evaluation/availability": "Not enough information is available."
}