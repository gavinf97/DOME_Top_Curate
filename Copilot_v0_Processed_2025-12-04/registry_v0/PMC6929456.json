{
  "publication/title": "scReClassify: a post hoc classification tool for fine-tuning cell type annotations in single-cell RNA-seq datasets",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "BMC Genomics",
  "publication/year": "2019",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- scRNA-seq\n- Cell type classification\n- Mislabelled cells\n- scReClassify\n- Single-cell RNA sequencing\n- Data analysis\n- Bioinformatics\n- Computational biology\n- Machine learning\n- Data correction",
  "dataset/provenance": "The datasets used in this study were sourced from the GEO, EBI, and Broad repositories. These datasets were generated and/or analyzed during the current study. The details of these datasets are listed in a table within the publication.\n\nThe experimental scRNA-seq datasets included in the study are summarized in a table. This table provides information about the publication from which each dataset originates, a brief description of the dataset, the organism from which the data was obtained, the number of cells, the number of classes, and the protocol used.\n\nFor instance, one dataset is from a study on early human development, involving 1059 cells across 3 classes, using the SMART-Seq2 protocol. Another dataset focuses on fetal liver development in mice, comprising 367 cells across 6 classes, also using the SMART-Seq2 protocol. Additionally, there are datasets on the cortex and hippocampus of mice, with 3005 cells across 7 classes, and the striatum of mice, with 705 cells across 10 classes, both using the SMARTer protocol.\n\nThese datasets were used to evaluate the proposed method, with cell type annotation information from their original studies treated as the gold standard for method evaluation. The datasets were preprocessed by removing genes with more than 80% missing values across cells, as many genes in scRNA-seq datasets are not expressed and removing non-expressed genes is a common preprocessing approach. After filtering, these datasets were used to assess the method's ability to correctly recover mislabeled cells.",
  "dataset/splits": "In our study, we utilized both simulated and experimental single-cell RNA sequencing (scRNA-seq) datasets to evaluate our proposed method. For the simulated datasets, we created datasets with varying numbers of cell types: 3, 5, 7, and 9. Each cell type within these datasets contained 100 cells, and each transcriptome consisted of 10,000 genes. To simulate mislabeling, we flipped the cell type labels of a certain percentage of randomly selected cells in each cell type group to the next cell type group. This process was repeated for all cell types in each dataset, resulting in overall mislabeling rates of 10%, 20%, 30%, 40%, and 50%.\n\nFor the experimental scRNA-seq datasets, we treated the cell type annotation information from their original studies as the gold standard for method evaluation. We applied the same mislabeling procedure to these datasets, flipping the labels of 10%, 20%, 30%, 40%, and 50% of the cells randomly selected in each cell type group to the next cell type group.\n\nBoth simulated and experimental datasets were preprocessed by converting them into log2(FPKM+1) and removing genes with more than 80% missing values across cells. This preprocessing step is common in scRNA-seq data analysis to focus on expressed genes. After filtering, these datasets were used to assess the ability of our method to correctly recover the mislabeled cells.\n\nIn summary, we had multiple data splits corresponding to different levels of mislabeling (10%, 20%, 30%, 40%, and 50%) for both simulated and experimental datasets. Each split contained datasets with varying numbers of cell types, and the distribution of data points (cells) in each split was consistent within each cell type, with 100 cells per type.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The datasets generated and analyzed during the current study are available from the GEO, EBI, and Broad repositories. Details of these datasets are listed in Table 1. This ensures that the data is publicly accessible, allowing other researchers to verify and build upon the findings. The availability of these datasets in reputable repositories like GEO, EBI, and Broad ensures that the data is stored in a reliable and standardized format, making it easier for other researchers to access and use. The use of these repositories also ensures that the data is preserved for long-term access, which is crucial for reproducibility and future research.",
  "optimization/algorithm": "The optimization algorithm employed in our work leverages semi-supervised learning techniques, specifically through the AdaSampling procedure. This approach is not entirely new but has been adapted and implemented within the context of single-cell RNA sequencing (scRNA-seq) data analysis. The choice of using AdaSampling is driven by its effectiveness in handling mislabelled data, which is a common issue in scRNA-seq datasets.\n\nAdaSampling is a wrapper procedure that iteratively improves the accuracy of the classification model by adjusting the weights of the training samples. It relies on base classification models to estimate the mislabelling probability of each cell. In our implementation, we utilized support vector machines (SVM) and random forests (RF) as the base classifiers. These are well-established machine-learning algorithms known for their robustness and ability to provide probabilistic estimates.\n\nThe reason for not publishing this specific adaptation in a machine-learning journal is that the focus of our work is on the application of these techniques to the biological domain of scRNA-seq data analysis. The primary contribution lies in demonstrating the utility of AdaSampling and ensemble learning for improving cell type annotations in scRNA-seq datasets, rather than the development of a novel machine-learning algorithm. Our goal is to provide a practical tool for researchers in the field of single-cell genomics, and thus, the publication is targeted towards a bioinformatics audience.\n\nThe use of SVM and RF as base classifiers is justified by their proven performance in various classification tasks. SVM is particularly effective in high-dimensional spaces, which is characteristic of scRNA-seq data. RF, on the other hand, is robust to overfitting and can handle a large number of input variables, making it suitable for the complex and noisy nature of single-cell data. By combining these classifiers in an ensemble, we aim to enhance the overall performance and reliability of the cell type classification process.",
  "optimization/meta": "The model described in this publication employs a meta-predictor approach, specifically utilizing an ensemble of base classification models to improve the accuracy of cell type classification in single-cell RNA sequencing (scRNA-seq) data. The AdaSampling framework, which is essentially a wrapper procedure, relies on base classification models to estimate the mislabelling probability of each cell in a scRNA-seq dataset.\n\nThe base classifiers used in this framework can be either support vector machines (SVM) or random forests (RF). These classifiers provide probabilistic estimates of cell type labels. For SVM, the prediction probability is estimated using Platt’s method, which converts the SVM output into a probability. For RF, the prediction probability is estimated by counting the fraction of trees that vote for a certain class.\n\nThe ensemble classification is obtained by combining the classification probabilities of each cell from each of the base models. This ensemble approach helps to improve the robustness and accuracy of the final classification. The number of base classifiers used to form the ensemble can be varied, and it has been found that an ensemble size of 10 is sufficient for achieving desirable performance.\n\nThe training data for the base classifiers is generated through a weighted sampling process based on the estimated mislabelling probabilities. This iterative process improves the quality of the cell labels included in the training, thereby enhancing the accuracy of the classification model. The final training dataset is used to train the base classifiers, which are then combined to form the ensemble classifier.\n\nThe independence of the training data is ensured by the iterative process of improving the quality of cell labels. Cells that are likely to be mislabelled have a lower chance of being included in the next iteration of model training, thus improving the overall accuracy of the classification model. The use of an ensemble of classifiers further enhances the robustness of the model by reducing the risk of overfitting and improving the generalization performance.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved several key steps to prepare the single-cell RNA sequencing (scRNA-seq) data for the machine-learning algorithm. Initially, the gene expression matrix, which represents the expression levels of genes across different cells, was used. To reduce the dimensionality of this matrix, Principal Component Analysis (PCA) was employed. The number of principal components (PCs) to retain was determined by capturing at least 70% of the overall variability in the dataset. If the number of PCs required fell outside the range of 10 to 20, it was adjusted to either 10 or 20. This dimensionality reduction helped in managing the high-dimensional nature of the scRNA-seq data, making it more suitable for subsequent analysis.\n\nAfter dimensionality reduction, the data was further processed using AdaSampling, a wrapper approach that combines weighted sampling with a probabilistic classification model. This method was tailored for multi-class classification problems, which are common in scRNA-seq datasets. AdaSampling estimates the probability of each cell being mislabelled by using a probabilistic classification model. Cells with a higher probability of being mislabelled were given less weight in the training process, thereby improving the accuracy of the classification model iteratively.\n\nThe base classifiers used in this framework were support vector machines (SVMs) and random forests (RFs). For SVMs, Platt's method was utilized to estimate the prediction probability of each cell. This method converts the SVM output into a probability using a sigmoid function. For RFs, the prediction probability was estimated by aggregating the votes from multiple decision trees, each trained on a bootstrap sample of the data.\n\nThe final step involved generating the training dataset through weighted sampling based on the estimated mislabelling probabilities. This dataset was then used to train the classification model, which was subsequently applied to reclassify all cells in the original dataset. The ensemble learning approach, where multiple base classifiers were combined, further enhanced the robustness and accuracy of the classification.",
  "optimization/parameters": "In our study, several key parameters were used to optimize the performance of our model. One of the primary parameters is the number of iterations (L) for the AdaSampling procedure. This parameter determines how many times the weighted sampling and model training process is repeated. Our previous evaluations suggested that only a few iterations are needed to achieve good performance, with a default of 3 iterations used in our study.\n\nAnother crucial parameter is the ensemble size, which refers to the number of base classifiers used to form the ensemble. We varied the ensemble size from 10 to 50 and found that an ensemble size of 10 was sufficient for achieving desirable performance. This parameter is particularly important when dealing with datasets that have a low level of mislabelled cells.\n\nAdditionally, the number of principal components (M') used in the dimensionality reduction step is an important parameter. We determined M' by first calculating the number of principal components (d) required to capture at least 70% of the overall variability in the dataset. If d falls outside the range of 10 to 20, we set M' to either 10 or 20. This ensures that the dimensionality of the original expression matrix is reduced appropriately for further analysis.\n\nThe selection of base classifiers is also a critical parameter. In our work, we used either support vector machines (SVM) or random forests (RF) as base classifiers. These classifiers provide probabilistic estimates of the mislabelling probability for each cell in the scRNA-seq dataset. The choice of base classifier can significantly impact the performance of the model, with SVM generally showing better performance than RF, especially when the level of mislabelled cells is low.\n\nOverall, the parameters used in our model were carefully selected and optimized to ensure robust performance in correcting mislabelled cells in scRNA-seq datasets. The combination of these parameters allows our model to effectively handle label noise and improve the accuracy of cell type annotations.",
  "optimization/features": "The input features for our method are derived from the gene expression matrix of single-cell RNA sequencing (scRNA-seq) data. This matrix has dimensions N × M, where N represents the number of cells and M represents the number of genes. Due to the high dimensionality of this data, with a large number of genes measured in each cell, it is crucial to apply dimension reduction techniques.\n\nWe use Principal Component Analysis (PCA) to reduce the dimensionality of the expression matrix. The number of principal components (PCs) to retain, denoted as M′, is determined by first calculating the number of PCs, d, required to capture at least 70% of the overall variability in the dataset. If d falls outside the range of 10 to 20, we set M′ to either 10 or 20. This ensures that the dimensionality is reduced to a manageable size while retaining most of the relevant information.\n\nFeature selection is implicitly performed through the PCA process, as it identifies the most informative principal components that capture the majority of the variance in the data. This dimensionality reduction step is applied to the entire dataset, ensuring that the selected features are based on the overall structure of the data rather than just the training set. This approach helps in mitigating overfitting and improves the robustness of the classification model.",
  "optimization/fitting": "The fitting method employed in our study involves a careful balance to avoid both overfitting and underfitting. The number of parameters in our models, particularly when using support vector machines (SVM) and random forests (RF), can indeed be large compared to the number of training points, especially in high-dimensional single-cell RNA sequencing (scRNA-seq) data.\n\nTo mitigate overfitting, we utilized ensemble learning techniques. Ensemble models, which combine multiple base classifiers, generally perform better than single models by reducing the variance and improving generalization. Specifically, we found that an ensemble size of 10 was sufficient to achieve desirable performance. Additionally, we employed AdaSampling, a wrapper procedure that iteratively improves the accuracy of the classification model by refining the quality of the cell labels included in training. This iterative process helps in identifying and correcting mislabelled cells, thereby enhancing the model's robustness.\n\nTo address underfitting, we ensured that our models had enough capacity to capture the underlying patterns in the data. We varied the range of the mislabelling ratio (ρ) from 0.1 to 0.5 and assessed the performance using mean classification accuracy and Adjusted Rand Index (ARI). The results indicated that our models, particularly SVM, showed notably better performance when ρ was set to less than or equal to 0.4. This suggests that the models were adequately complex to learn from the data without being too simplistic.\n\nFurthermore, we used principal component analysis (PCA) to reduce the dimensionality of the expression matrix, retaining only the most informative principal components. This dimensionality reduction step helps in focusing on the relevant features, thereby preventing the model from being overwhelmed by noise and irrelevant information.\n\nIn summary, our approach combines ensemble learning, iterative refinement through AdaSampling, and dimensionality reduction via PCA to effectively balance the trade-off between overfitting and underfitting. This ensures that our models generalize well to new data while capturing the essential patterns in the scRNA-seq datasets.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model, scReClassify. One of the key methods used was ensemble learning. By combining multiple base classifiers, we were able to reduce the risk of overfitting, as ensembles tend to generalize better than single models. Specifically, we used support vector machines (SVM) and random forests (RF) as base classifiers and found that SVM performed notably better, particularly when the noise level was low. This suggests that RF might be more susceptible to overfitting, leading to less efficient correction of mislabelled cells.\n\nAdditionally, we implemented a semi-supervised learning procedure called AdaSampling. This procedure iteratively improves the accuracy of the classification model by focusing on cells that are likely to be mislabelled. By doing so, it enhances the quality of the cell labels included in the training process, thereby reducing the likelihood of overfitting.\n\nWe also varied the ensemble size to determine the minimum number of base classifiers required to achieve sufficient performance. Our findings indicated that an ensemble size of 10 was sufficient for achieving desirable performance, further supporting the effectiveness of ensemble learning in preventing overfitting.\n\nMoreover, we used principal component analysis (PCA) for dimensionality reduction. By reducing the high-dimensional gene expression data to a smaller set of principal components, we were able to focus on the most informative features, which helps in mitigating overfitting.\n\nOverall, these techniques collectively contributed to the robustness and generalizability of scReClassify, ensuring that it performs well even in the presence of mislabelled cells.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we utilized support vector machines (SVM) and random forests (RF) as base classifiers, with Platt’s method for SVM to estimate prediction probabilities and a default ensemble size of 100 for RF. The default number of iterations for model training was set to 3, but this parameter can be adjusted by users.\n\nThe datasets generated and analyzed during this study are available from the GEO, EBI, and Broad repositories. Details of these datasets are listed in Table 1 of the publication. The code and any additional materials necessary for reproducing the results are also available, ensuring that other researchers can replicate our findings and build upon our work.\n\nRegarding the license, the datasets and materials are made available under terms that allow for academic use and further research, adhering to standard practices in the field. This ensures that the community can access and utilize the resources without restrictions that would hinder scientific progress.",
  "model/interpretability": "The scReClassify framework, which relies on the AdaSampling procedure, is not inherently a black-box model. The interpretability of scReClassify can be attributed to several factors, primarily stemming from the use of base classifiers that provide probabilistic estimates.\n\nThe base classifiers used in scReClassify, such as Support Vector Machines (SVM) and Random Forests (RF), are well-understood and interpretable models. For SVM, the prediction probability for each cell is estimated using Platt's method, which converts the SVM's output into a probability. This method involves a sigmoid function that is fitted to the SVM's decision values, making the process transparent and interpretable. The parameters of this sigmoid function are estimated using maximum likelihood, providing a clear statistical basis for the probability estimates.\n\nSimilarly, Random Forests provide interpretable results through the aggregation of multiple decision trees. Each tree in the forest makes a classification based on a subset of features, and the final prediction is the mode of the classes predicted by the individual trees. The probability of a cell belonging to a particular class is estimated by counting the fraction of trees that vote for that class. This ensemble approach not only improves robustness but also retains interpretability by showing the contribution of each tree to the final decision.\n\nMoreover, the AdaSampling procedure itself is designed to iteratively improve the quality of cell labels by reducing the influence of mislabelled cells. This iterative process is transparent, as it involves clear steps of identifying and reclassifying mislabelled cells based on their estimated mislabelling probabilities. The final estimation of mislabelling probability for each cell is used to generate a weighted sampling of the training dataset, ensuring that cells with higher mislabelling probabilities have less influence in subsequent iterations.\n\nIn summary, scReClassify is not a black-box model. Its interpretability is enhanced by the use of transparent base classifiers and a clear, iterative procedure for improving cell label quality. The probabilistic estimates provided by SVM and RF, along with the iterative nature of AdaSampling, make the model's decisions understandable and traceable.",
  "model/output": "The model, scReClassify, is a classification model designed for post hoc cell type annotation in single-cell RNA sequencing (scRNA-seq) datasets. It aims to correct mislabelled cells in the initial annotation by iteratively improving the accuracy of the classification model. The model uses either support vector machine (SVM) or random forest (RF) as base classifiers, or an ensemble of these classifiers, to estimate the mislabelling probability of each cell. The final output is a refined cell type annotation for the dataset, with mislabelled cells reclassified to their correct types. The performance of the model is evaluated using metrics such as mean classification accuracy and adjusted Rand index (ARI). The model's output can also include the mislabelling probability for each cell, which can be used for weighted sampling to generate training datasets for further model training. The model is implemented as an easy-to-use R package, making it accessible for scRNA-seq data analysis.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the scReClassify framework is implemented as an easy-to-use R package. This package is designed to fine-tune cell type annotations in single-cell RNA sequencing (scRNA-seq) datasets. The package allows users to specify parameters such as the number of iterations for model training, with a default of 3 iterations used in the study.\n\nThe datasets generated and analyzed during the current study are available from the GEO, EBI, and Broad repositories. Details of the datasets are listed in a table within the publication. The package leverages base classification models, such as support vector machines (SVM) and random forests (RF), to estimate the mislabeling probability of each cell in a scRNA-seq dataset. Users can employ other classifiers capable of providing probabilistic estimates as well.\n\nThe implementation of scReClassify involves a semi-supervised learning procedure called AdaSampling, which iteratively improves the accuracy of the trained classification model by enhancing the quality of the cell labels included in the training process. The final estimation of the mislabeling probability for each cell is used to generate the training dataset, which can then be used to reclassify all cells in the original dataset. Alternatively, multiple weighted samplings can be performed to create multiple training datasets, each used to train a base classification model. An ensemble classification of all cells can be obtained by combining the classification probabilities from each base model.\n\nThe package is designed to be user-friendly and is intended to be a valuable addition to the scRNA-seq data analysis toolkit. It is hoped that scReClassify will be widely adopted by researchers in the field.",
  "evaluation/method": "The proposed method was evaluated using both simulated and real-world experimental single-cell RNA sequencing (scRNA-seq) datasets. Simulated datasets were generated using the Splatter R package, with varying numbers of cell types (3, 5, 7, and 9) and controlled levels of mislabeling (10%, 20%, 30%, 40%, and 50%). Each cell type consisted of 100 cells, and each transcriptome included 10,000 genes, with a 0.1 probability of a gene being differentially expressed.\n\nFor experimental datasets, cell type annotations from original studies were treated as the gold standard. Mislabeling was introduced by randomly flipping the labels of a percentage of cells in each cell type group to the next cell type group, similar to the simulation process.\n\nBoth simulated and experimental datasets were preprocessed by converting them into log2(FPKM+1) and removing genes with more than 80% missing values across cells. The performance of the method was assessed using mean classification accuracy and adjusted Rand index (ARI). These metrics evaluated the ability of the method to correctly recover mislabeled cells in each dataset.\n\nThe evaluation involved comparing the method's performance against baseline metrics calculated from the ground truth and initial noisy cell type annotations. The method's effectiveness was demonstrated through various levels of label noise and different ensemble sizes, showing its robustness in correcting mislabeled cells even when a large proportion of cells were initially mislabeled.",
  "evaluation/measure": "In our evaluation of cell type identification methods, we employed two primary performance metrics: mean classification accuracy and the adjusted Rand index (ARI). These metrics were chosen for their relevance and widespread use in assessing the performance of clustering and classification methods in single-cell RNA sequencing (scRNA-seq) data analysis.\n\nMean classification accuracy is a straightforward metric that measures the proportion of correctly identified cell types out of the total number of cells. It provides an intuitive understanding of how well the method performs in assigning the correct cell type labels. However, it does not account for the size differences among cell type groups, which can be a limitation in datasets with unevenly distributed cell types.\n\nThe adjusted Rand index (ARI), on the other hand, is a more nuanced metric that considers the agreement between the predicted cell type labels and the ground truth labels, adjusted for chance. ARI takes into account the sizes of the cell type groups, making it a more robust measure for datasets with varying numbers of cells per type. This metric is particularly useful in scRNA-seq data analysis, where the number of cells in each type can differ significantly.\n\nBoth metrics are commonly used in the literature for evaluating the performance of cell type identification methods. Mean classification accuracy offers a simple and interpretable measure, while ARI provides a more comprehensive assessment by adjusting for the sizes of the cell type groups. Together, these metrics give a well-rounded evaluation of the method's performance in correctly identifying cell types in scRNA-seq datasets.",
  "evaluation/comparison": "In our evaluation, we compared the performance of our method, scReClassify, with baseline performance calculated from the ground truth and the initial noisy cell type annotations. This baseline serves as a simpler comparison to understand the improvements made by scReClassify.\n\nFor simulated datasets, we introduced varying percentages of mislabelled cells and evaluated the performance using mean classification accuracy and the adjusted Rand index (ARI). The baseline performance was determined by comparing the ground truth labels with the initial annotations that included mislabelled cells. This allowed us to quantify the improvements achieved by scReClassify in correcting mislabelled cells.\n\nIn real-world experimental datasets, we treated the cell type annotation information from the original studies as the 'gold standard' for evaluation. We introduced mislabelled cells in a similar manner to the simulated datasets and compared the performance of scReClassify against this baseline. This comparison helped us assess the method's ability to recover mislabelled cells in real-world scenarios.\n\nAdditionally, we applied scReClassify to the original annotations of real-world datasets without introducing additional mislabelled cells. This step was taken to correct potentially misclassified cells in the experimental datasets, demonstrating the method's practical utility.\n\nOverall, the comparison with baseline performance provided a clear benchmark for evaluating the effectiveness of scReClassify in both simulated and real-world datasets.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The datasets generated and analyzed during the study are publicly available from the GEO, EBI, and Broad repositories. Detailed information about these datasets can be found in Table 1. This ensures that other researchers can access and utilize the data for further studies or validation of their own methods. The availability of these datasets supports reproducibility and transparency in scientific research."
}