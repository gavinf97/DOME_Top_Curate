{
  "publication/title": "A self-attention based message passing neural network for predicting molecular lipophilicity and aqueous solubility",
  "publication/authors": "The authors who contributed to the article are:\n\n- BT, who designed the study, implemented the models, and wrote the manuscript.\n- DX, who designed the study.\n- All authors contributed to the interpretation of results.\n- All authors reviewed and edited the manuscript.\n- All authors read and approved the final manuscript.",
  "publication/journal": "J Cheminform",
  "publication/year": "2020",
  "publication/doi": "10.1186/s13321-020-0414-z",
  "publication/tags": "- Machine Learning\n- Deep Learning\n- Quantitative Structure-Property Relationship (QSPR)\n- Molecular Properties\n- Lipophilicity\n- Solubility\n- Message Passing Neural Networks\n- Self-Attention Mechanisms\n- Hyperparameter Optimization\n- Chemical Informatics",
  "dataset/provenance": "The datasets used in this study were sourced from two different online databases. The lipophilicity data was obtained from CHEMBL3301361, which was deposited by AstraZeneca. This dataset contains 4200 molecules, each with an associated experimental value for lipophilicity, typically quantified by the n-octanol/water partition coefficient (logP).\n\nThe aqueous solubility data was downloaded from the Online Chemical Database and Modeling Environment (OCHEM). This dataset includes 1311 experimental records, with solubility values represented in log(mol/L) form (logS).\n\nBoth datasets have been utilized in previous studies and by the community for quantitative structure-property relationship (QSPR) research. The lipophilicity dataset, in particular, is widely recognized and has been used in various studies to develop and validate predictive models. The aqueous solubility dataset from OCHEM is also a well-known resource in the field, providing a comprehensive collection of experimental solubility data for a diverse set of compounds.",
  "dataset/splits": "In our study, we employed tenfold stratified cross-validation to split our datasets. This process involved randomly dividing each dataset into three parts: a training set, a validation set, and a test set. The training set comprised 80% of the data, the validation set 10%, and the test set the remaining 10%. This division was repeated three times with different random seeds to ensure the robustness of our model and to prevent overfitting. The stratified approach ensured that each split maintained the same distribution of the target property, which is crucial for reliable model evaluation and comparison.",
  "dataset/redundancy": "The datasets used in our study consisted of molecular lipophilicity and aqueous solubility data. The lipophilicity dataset, comprising 4200 molecules, was sourced from CHEMBL3301361, while the aqueous solubility dataset, with 1311 experimental records, was obtained from OCHEM.\n\nGiven the relatively small size of these datasets compared to typical deep learning requirements, we employed tenfold stratified cross-validation. This method involved randomly splitting each dataset into a training set (80%), a validation set (10%), and a test set (10%). The training and validation sets were used for parameter selection, while the test set was reserved for model comparisons. To ensure robustness, all experiments were repeated three times with different random seeds. This approach helped to prevent the model from merely memorizing the training data, thereby enhancing its ability to generalize to new molecules.\n\nTo address dataset redundancy, we performed initial data preprocessing. Duplicate molecules were removed, ensuring that each chemical structure in the dataset was unique. For molecules with duplicate entries, the maximum value of the related properties was retained. This step was crucial for maintaining the integrity and diversity of the datasets, ensuring that the models were trained on a representative sample of molecular structures.\n\nThe distribution of the datasets was visualized in Additional file 1: Fig. S1. This visualization provided insights into the spread and characteristics of the data, which is essential for understanding the performance and generalizability of the models. The datasets were designed to be independent, with no overlap between the training, validation, and test sets. This independence was enforced through the stratified cross-validation process, which ensured that each fold of the cross-validation contained a representative sample of the entire dataset.",
  "dataset/availability": "The datasets used in our study are publicly available. The lipophilicity data was obtained from CHEMBL3301361, deposited by AstraZeneca, and includes 4200 molecules. The aqueous solubility data was downloaded from the online chemical database and modeling environment (OCHEM) and consists of 1311 experimental records.\n\nThe datasets were split using tenfold stratified cross-validation, where each dataset was randomly divided into a training set (80%), a validation set (10%), and a test set (10%). This process was repeated three times with different random seeds to ensure the model's ability to generalize to new molecules.\n\nThe specific splits used in our experiments are not publicly released, as they were generated randomly and are not intended to be reused. However, the datasets themselves are available in their original sources, and researchers can replicate our splitting method using the described tenfold stratified cross-validation approach.\n\nThe datasets are available under the terms of their respective licenses. The CHEMBL data is available under the Creative Commons Attribution-ShareAlike 4.0 International License, and the OCHEM data is available under the Open Database License (ODbL) v1.0. These licenses allow for the sharing and adaptation of the data, provided that appropriate credit is given and any adaptations are shared under the same terms.\n\nTo enforce the proper use of the datasets, we encourage researchers to cite the original sources of the data and to adhere to the terms of the licenses under which the data is provided. Additionally, we have made our code and models publicly available on GitHub, allowing others to replicate our results and build upon our work.",
  "optimization/algorithm": "The optimization algorithm used in our study is a grid search algorithm, facilitated by the Hyperopt package. This approach is well-established in machine learning for hyperparameter tuning. It systematically works through multiple combinations of hyperparameter values, using a defined search space, to find the optimal configuration.\n\nThe machine-learning algorithm class used is not new; it is a grid search algorithm, which is a standard technique in the field of machine learning. This method is widely recognized for its effectiveness in optimizing hyperparameters, which are crucial for the performance of machine learning models.\n\nThe reason this algorithm was not published in a machine-learning journal is that it is a well-known and established technique. Grid search algorithms have been extensively studied and documented in the literature, and their implementation details are widely available. Therefore, there was no novel contribution to the field of machine learning that warranted publication in a specialized journal. Instead, the focus of our work was on applying this established method to optimize the hyperparameters of our specific models for chemical property prediction.",
  "optimization/meta": "Not applicable. The models discussed do not employ a meta-predictor approach. Instead, they focus on various neural network architectures, specifically message passing neural networks (MPN) and their self-attention-enhanced variants (SAMPN), as well as multi-target versions of these models. Additionally, a random forest model is used for comparison purposes. The optimization process involves adjusting hyperparameters using a grid search algorithm and evaluating performance using multiple metrics such as MAE, RMSE, MSE, R², and PC. The models are trained and validated using stratified cross-validation on the entire dataset.",
  "optimization/encoding": "For the data encoding and preprocessing, we began by removing duplicate molecules to ensure each chemical structure in the dataset was unique, retaining the maximum value of related properties for duplicates. Molecules that were not recognized by RDKit, a cheminformatics toolkit, were also deleted. This left us with two essential columns: 'smiles' and 'experimental value', which served as the input data for our models.\n\nEach SMILES representation was then converted into a directed graph before training the SAMPN model using the MPN encoder, adapted from Deepchem and Chemprop. The directed graphs were primarily composed of index lists of nodes and edges. For instance, a chemical bond between nitrogen (N) and carbon (C) atoms could derive two edges (C:0 → N:1 and N:0 → C:1). The number of nodes corresponded to the number of atoms, while the number of edges was double the number of bonds, considering edges as bidirectional.\n\nThe message-passing network encoder utilized molecular graph structures, where atoms were equivalent to nodes and chemical bonds to edges. This approach allowed for the gradual merging of information from distant atoms by extending radially through bonds. The passing messages were used to encode all substructures of a molecule through an adaptive learning approach, extracting useful representations suited to the target predictions.\n\nNode features were derived from attributes such as atom type, formal charge, valence, and aromaticity. Similarly, edge features were derived from bond order, ring status, and direction connection. The initial message passing involved generating messages from the merged node-edge features using a neural network. Subsequent message passing steps involved updating messages based on the merged node-edge features and previous message passing steps, ensuring that nodes could send messages to neighbor nodes only after receiving messages from all other neighbors.\n\nThis encoding process ensured that the model could generalize to new molecules effectively, avoiding mere memorization of the training data. The use of directed graphs and message-passing networks provided a robust framework for encoding molecular structures, enabling accurate predictions in our machine-learning models.",
  "optimization/parameters": "In our study, we optimized several hyperparameters to enhance the performance of our models. These hyperparameters included the activation function, steps of message passing, graph embedding size, dropout rate, and the number of layers in the fully connected network. The specific ranges and intervals for these hyperparameters were defined to ensure a comprehensive search space.\n\nThe activation function choices included Tanh, ELU, LeakyReLU, ReLU, PReLU, and SELU. The steps of message passing ranged from 2 to 6, with an interval of 1. The graph embedding size varied from 32 to 512, with an interval of 32. The dropout rate spanned from 0.0 to 0.4, with an interval of 0.05. The number of layers in the fully connected network ranged from 1 to 3, with an interval of 1.\n\nA grid search algorithm, implemented using the Hyperopt package version 0.1.2, was employed to adjust these hyperparameters. The search space was thoroughly explored to find the most suitable combination of hyperparameters. For the lipophilicity-QSPR task, one of the best combinations of hyperparameters identified was {'activation': 'ReLU', 'depth': 4, 'dropout': 0.25, 'layers of fully connected networks': 2, 'hidden size': 384}.\n\nThis combination was then used to test the final performance of all message passing neural network models, including MPN, SAMPN, Multi-MPN, and Multi-SAMPN, using tenfold stratified cross-validation on the entire dataset. The selection of these hyperparameters was crucial in achieving robust and accurate predictions for the properties of interest.",
  "optimization/features": "In our study, the input features for our models were derived directly from the molecular structures represented in SMILES format. Each molecule was converted into a directed graph, where atoms correspond to nodes and chemical bonds to edges. This approach allowed us to utilize the inherent structural information of the molecules without relying on manually selected features.\n\nThe number of features, in this case, is dynamic and depends on the molecular structure. Specifically, the number of nodes in the graph is equal to the number of atoms in the molecule, and the number of edges is double the number of bonds, considering edges as bidirectional.\n\nFeature selection, in the traditional sense, was not performed. Instead, we used the entire molecular graph as input, capturing all relevant structural information. This method ensures that no important features are inadvertently excluded, providing a comprehensive representation of each molecule.\n\nThe preprocessing steps, including the conversion of SMILES to directed graphs, were applied uniformly to the entire dataset. This process ensures that the models are trained and validated on consistent and complete feature sets, maintaining the integrity of the structural information across all molecules.",
  "optimization/fitting": "In our study, we employed several strategies to ensure that our models were neither overfitting nor underfitting the data. Overfitting is a common concern when the number of parameters in a model is much larger than the number of training points, but we mitigated this risk through several techniques.\n\nFirstly, we used a grid search algorithm with the Hyperopt package to optimize the hyperparameters of our models. This process involved systematically working through multiple combinations of hyperparameter values to find the best configuration. By doing so, we ensured that our models were not overly complex and that they generalized well to unseen data.\n\nSecondly, we implemented a self-attention mechanism in our message passing neural network (SAMPN) models. This mechanism helps the model to focus on the most relevant parts of the molecular structure, thereby reducing the risk of overfitting by not relying on every single parameter equally.\n\nAdditionally, we utilized tenfold stratified cross-validation on the entire dataset. This technique involves dividing the data into ten subsets, training the model on nine subsets, and validating it on the remaining subset. This process is repeated ten times, with each subset serving as the validation set once. Cross-validation helps to ensure that the model's performance is consistent across different subsets of the data, reducing the likelihood of overfitting.\n\nTo address underfitting, we ensured that our models had sufficient capacity to learn the underlying patterns in the data. This was achieved by carefully selecting the architecture of our neural networks, including the number of layers and the size of the hidden layers. We also used the Adam optimizer with an appropriate learning rate schedule, which helped the models to converge to a good solution without getting stuck in local minima.\n\nFurthermore, we compared our models with a baseline random forest model, which is known for its robustness and high prediction accuracy in structure-property relationship research. The fact that our models outperformed the random forest model indicates that they were not underfitting the data.\n\nIn summary, through hyperparameter optimization, the use of self-attention mechanisms, cross-validation, and careful selection of model architecture, we ensured that our models were neither overfitting nor underfitting the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was dropout, which is a regularization technique that helps to prevent overfitting by randomly setting a fraction of input units to zero at each update during training time. This forces the network to learn redundant representations and prevents it from becoming too reliant on any single neuron. In our best-performing models, we used a dropout rate of 0.25.\n\nAdditionally, we utilized tenfold stratified cross-validation. This technique involves splitting the dataset into ten subsets, training the model on nine of them, and validating it on the remaining one. This process is repeated ten times, with each subset serving as the validation set once. This approach ensures that the model generalizes well to new, unseen data and does not simply memorize the training set.\n\nFurthermore, we repeated all experiments three times with different random seeds. This step helps to ensure that the results are not dependent on a particular random initialization and provides a more reliable estimate of the model's performance.\n\nBy combining these techniques, we aimed to build models that are not only accurate but also robust and capable of generalizing to new molecular structures.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail. Specifically, we utilized a grid search algorithm with the Hyperopt package version 0.1.2 to optimize the hyper-parameters. The search space and the best combination of hyper-parameters for the lipophilicity-QSPR task are provided. For instance, one of the best combinations included the ReLU activation function, a depth of 4, a dropout rate of 0.25, 2 layers of fully connected networks, and a hidden size of 384.\n\nThe model files and optimization parameters are not explicitly mentioned as being available for download. However, the code for the MPN encoder was adapted from Deepchem and Chemprop, and both the MPN encoder and self-attention mechanism were implemented with Python and Pytorch version 1.0. The random forest model was implemented in Python 3.6.3 with the Scikit-learn package version 0.21.2.\n\nRegarding the availability and licensing of the code and models, specific details are not provided. However, it is mentioned that the scripts for the detailed calculation process are available in a Github repository. This suggests that the code and possibly the model files are accessible, but the exact licensing terms are not specified. For more information, one would need to refer to the Github repository mentioned in the study.",
  "model/interpretability": "The model we developed, the self-attention-based message-passing neural network (SAMPN), is designed to be more interpretable than traditional black-box models. Unlike many neural network models that act as black boxes, making it difficult to understand how predictions are made, SAMPN incorporates an attention mechanism that highlights the importance of different parts of a molecule in determining its properties.\n\nThis attention mechanism allows us to visualize which atoms or substructures within a molecule contribute most significantly to its lipophilicity or aqueous solubility. By assigning attention weight scores to each atom, we can identify which parts of the molecule are crucial for the property of interest. These attention weight coefficients are particularly useful for gaining insights into how specific molecular features enhance or diminish the target property.\n\nFor example, in the case of 1H-indazole, the model can indicate that the nitrogen-containing section of the molecule has strong anti-lipophilic properties. This information can guide chemists in modifying the molecule to potentially increase its lipophilicity. Similarly, for a molecule with a primary amine group, the model can show that this group contributes to the molecule's solubility due to its ability to form hydrogen bonds with water molecules.\n\nThe visualization of these attention scores on molecular graphs, using heat maps, makes it easy to see which parts of a molecule play a more important role in its properties. This interpretability is a significant advantage, as it allows chemists to optimize molecular properties directly from the chemical structures, providing a clearer understanding of the underlying mechanisms driving the predictions.",
  "model/output": "The model is a regression model. It is designed to predict continuous properties of molecules, specifically lipophilicity and aqueous solubility. These properties are quantified using logarithmic scales (logP for lipophilicity and logS for solubility), which are continuous values. The model uses various metrics to evaluate its performance, such as root mean squared error (RMSE), mean absolute error (MAE), and mean squared error (MSE), all of which are relevant for regression tasks. Additionally, the model's performance is compared using these metrics, indicating that it is indeed a regression model aimed at predicting numerical values rather than classifying data into discrete categories.\n\nThe model employs a self-attention-based message-passing neural network (SAMPN) and its variants, which are trained to learn the relationships between molecular structures and their properties. The use of metrics like RMSE and MAE further confirms that the model's output is a continuous value, making it a regression model.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the models and the prepared datasets used in this study is publicly available. It can be accessed via the SAMPN GitHub repository. This repository contains all the necessary code to implement and run the self-attention-based message-passing neural network (SAMPN) models described in the paper. The repository also includes the datasets used for developing and testing the methods, specifically for molecular lipophilicity and aqueous solubility predictions. The code and datasets are provided under a license that allows for their use and modification, facilitating further research and applications in quantitative structure–property relationship studies.",
  "evaluation/method": "The evaluation of our models involved several key steps and metrics to ensure robust and generalizable performance. We employed multiple metrics to assess the models' predictive performance, including mean absolute error (MAE), root mean squared error (RMSE), mean squared error (MSE), coefficient of determination (R²), and Pearson correlation coefficient (PC). Lower values of MAE, MSE, and RMSE indicate better predictive performance, while higher values of PC and R² signify better model fits.\n\nGiven the relatively small size of our datasets compared to typical deep learning requirements, we utilized tenfold stratified cross-validation. This process involved randomly splitting each dataset into training (80%), validation (10%), and test (10%) sets. We repeated all experiments three times with different random seeds to ensure that the models could generalize to new molecules rather than merely memorizing the training data.\n\nFor hyperparameter optimization, we used a grid search algorithm with the Hyperopt package. The search space included various hyperparameters such as activation functions, steps of message passing, graph embedding size, dropout rate, and layers of fully connected networks. We chose RMSE on the validation set as the metric to identify the most suitable combination of hyperparameters.\n\nIn the lipophilicity-QSPR task, one of the best combinations of hyperparameters was found to be {'activation': 'ReLU', 'depth': 4, 'dropout': 0.25, 'layers of fully connected networks': 2, 'hidden size': 384}. All message passing neural network models (MPN, SAMPN, Multi-MPN, and Multi-SAMPN) utilized these hyperparameters for final performance testing using tenfold stratified cross-validation on the entire dataset.\n\nTo compare our self-attention-based message-passing neural network (SAMPN) with traditional machine learning methods, we also implemented a random forest (RF) model. The RF model used extended-connectivity fingerprints (ECFP) with a fixed length of 1024 and was implemented using the Scikit-learn package in Python. We set the number of trees to 500 to balance performance and computational efficiency.\n\nThe results demonstrated that our SAMPN model outperformed both the traditional RF model and previous deep-learning models, such as Deepchem's MPN. The inclusion of the self-attention mechanism and the use of multi-target models further improved performance, indicating that these enhancements are effective in predicting lipophilicity and solubility.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our models. These metrics include mean absolute error (MAE), root mean squared error (RMSE), mean squared error (MSE), coefficient of determination (R²), and Pearson correlation coefficient (PC). These metrics provide a thorough assessment of model performance.\n\nLower values of MAE, MSE, and RMSE indicate better predictive performance, as they measure the average magnitude of errors in a set of predictions, without considering their direction. Conversely, higher values for PC and R² signify better model performance or better fits for the data, as they assess the correlation and the proportion of variance explained by the model, respectively.\n\nThe inclusion of multiple metrics ensures a rich benchmark for future studies, allowing for a more nuanced comparison of model performance. This approach is representative of current practices in the field, where a combination of error metrics and correlation measures is commonly used to evaluate predictive models. By reporting these metrics, we aim to provide a clear and comprehensive understanding of our models' strengths and areas for improvement.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of our self-attention-based message-passing neural network (SAMPN) with various methods to evaluate its performance. We compared SAMPN with traditional machine learning methods, specifically using a random forest (RF) model as a baseline. The RF model is widely recognized for its robustness, ease of use, and high prediction accuracy in structure–property relationship research. We implemented the RF model using the Scikit-learn package in Python, with extended-connectivity fingerprints (ECFP) of a fixed length of 1024 as features. We set the number of trees to 500, which provided a good balance between performance and computational efficiency.\n\nAdditionally, we built a pure message-passing neural network (MPN) model to establish a baseline without the self-attention mechanism. This allowed us to isolate the impact of the self-attention component in our SAMPN model. All configurations, except for the self-attention mechanism, were kept the same between the MPN and SAMPN models.\n\nTo further evaluate the effectiveness of our approach, we compared single-task and multi-target deep learning networks. We developed multi-MPN and multi-SAMPN models that used a merged molecule dataset from ‘Lipophilicity’ and ‘Water Solubility’. This comparison helped us understand the benefits of multi-target models in leveraging shared features between different properties.\n\nWe also compared our models with the MPN version from Deepchem, a popular deep learning library for cheminformatics. This comparison was performed on the same datasets and using the same stratified cross-validation protocol to ensure fairness. The results showed that our SAMPN model outperformed both the traditional RF model and the Deepchem MPN model in predicting lipophilicity and solubility.\n\nIn summary, our evaluation included comparisons with traditional machine learning baselines, simpler neural network baselines, and publicly available deep learning methods on benchmark datasets. This thorough comparison demonstrated the superior performance and interpretability of our SAMPN model.",
  "evaluation/confidence": "The evaluation of our models involved multiple metrics, including mean absolute error (MAE), root mean squared error (RMSE), mean squared error (MSE), coefficient of determination (R²), and Pearson correlation coefficient (PC). These metrics provide a comprehensive assessment of model performance. Importantly, the reported values for RMSE, which was used as the primary metric for hyperparameter optimization, include confidence intervals. For instance, in the lipophilicity prediction task, the RMSE for the SAMPN model is reported as 0.579 ± 0.036, and for the Multi-SAMPN model, it is 0.571 ± 0.032. These intervals indicate the variability and reliability of the performance estimates.\n\nTo ensure the robustness of our findings, we employed tenfold stratified cross-validation. This method involves randomly splitting the dataset into training, validation, and test sets multiple times with different random seeds. This process helps to ensure that the models do not overfit to the training data and can generalize well to new, unseen molecules. The use of cross-validation, along with the reported confidence intervals, provides a strong basis for claiming that our models, particularly the SAMPN and Multi-SAMPN, offer superior performance compared to traditional machine learning methods and previous deep-learning models.\n\nStatistical significance is further supported by the consistent performance improvements observed across different metrics and tasks. For example, in both lipophilicity and solubility predictions, the SAMPN and Multi-SAMPN models outperformed the MPN and Multi-MPN models, respectively. This consistency suggests that the self-attention mechanism and multi-target approach contribute significantly to the models' predictive power. Additionally, the comparison with the random forest model, a widely regarded \"gold standard\" in structure–property relationship research, further validates the superiority of our methods. The random forest model's performance was notably lower in both tasks, reinforcing the claim that our models provide a more accurate and reliable prediction of chemical properties.",
  "evaluation/availability": "The raw evaluation files are not directly available for download. However, the scripts detailing the calculation process are accessible in our GitHub repository. This allows researchers to replicate the evaluation process and verify the results presented in the study. The repository provides a transparent and reproducible way to understand how the models were evaluated, ensuring that the methods and findings can be independently validated."
}