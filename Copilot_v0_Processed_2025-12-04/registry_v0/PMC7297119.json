{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are as follows:\n\nHao Y. Chang, who conceived and supervised the project.\n\nJian Zou, who also conceived and supervised the project.\n\nKevin R. P. and Feng M. Fang, who gathered and preprocessed data, including determining significant localization and defining retained intron sequences.\n\nKevin W., who performed data analysis, modeling, and model interpretation with input from all authors. Kevin W. also wrote the manuscript with input from all authors.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2020",
  "publication/doi": "10.1016/J.BBAGEN.2017.06.011",
  "publication/tags": "- RNA localization\n- Machine learning models\n- APEX-Seq data\n- Gene Expression Omnibus\n- ENCODE data\n- Model evaluation metrics\n- AUROC\n- AUPRC\n- Accuracy\n- Youden’s J-statistic\n- Position weight matrices\n- RNA-GPS software\n- Data preprocessing\n- Model interpretation\n- Alternative splicing\n- Oxidative stress\n- Human colon cancer cells\n- Computational biology\n- Bioinformatics\n- Molecular biology",
  "dataset/provenance": "The dataset used in our study is derived from APEX-seq data, which localizes transcripts to eight subcellular compartments. We define a transcript as significantly enriched at a cellular compartment if it has a log2 fold change greater than 0, along with an adjusted p-value less than 0.05. This process yields a set of 3660 significantly localized genes/transcripts for our eight-way localization problem. These transcripts are predominantly protein-coding.\n\nFor the binary cytoplasm versus nucleus classification problem, we have a set of 9155 APEX-seq transcripts that localize either to the nucleus or cytoplasm, with approximately half the transcripts localizing to each compartment.\n\nAdditionally, we processed ENCODE data following an identical process for computing differential expression and identifying significantly localized transcripts. This results in 7641 transcripts for the HeLa-S3 cell line and 6359 transcripts for the K562 cell line. For both these cell lines, approximately 25% of the transcripts are also observed in our APEX-seq dataset.\n\nWithin the APEX-seq datasets, we reserve 10% of the data for testing and 10% for validation, leaving 80% of the examples for training. The ENCODE datasets were only used for testing and thus were not split. This approach ensures that our model is evaluated on unseen data, providing a robust assessment of its performance.",
  "dataset/splits": "In our study, we utilized multiple data splits to ensure robust training, validation, and testing of our models. For the APEX-seq data sets, we divided the data into three main splits: training, validation, and testing. Specifically, 80% of the data was allocated for training, 10% for validation, and the remaining 10% for testing. This division allowed us to tune our modeling approaches and hyperparameters using the validation set, while the test set was reserved for final evaluation and model interpretation.\n\nAdditionally, we employed 10-fold cross-validation to further validate our models. In this process, the data was rotated such that each data point was used exactly once as a testing example and exactly once as a validation example. This method ensured that our models were thoroughly evaluated and that our results were not dependent on a particular split of the data.\n\nFor the ENCODE data sets, which were used solely for testing, no further splits were made. This data was used to assess the generalizability of our models to independent data sets. The ENCODE data sets included 7641 transcripts for the HeLa-S3 cell line and 6359 transcripts for the K562 cell line. Approximately 25% of the transcripts in these cell lines were also observed in our APEX-seq data set, providing a basis for comparison and validation.",
  "dataset/redundancy": "The datasets used in our study were split into three parts: training, validation, and testing. Specifically, 80% of the data was allocated for training, while 10% was reserved for validation, and the remaining 10% was used for testing. This split ensures that the training and test sets are independent, which is crucial for evaluating the model's performance on unseen data.\n\nTo enforce the independence of the training and test sets, we employed a strategy where sequences with significant similarity to the training set were removed from the test set. This was done using BLAST to identify and exclude sequences with substantial similarity, ensuring that the model's performance was not artificially inflated by sequence redundancy.\n\nThe distribution of our datasets is designed to reflect the complexity and variability of RNA localization. Unlike some previously published machine learning datasets that might focus on simpler binary classifications, our approach involves a more nuanced multilabel prediction problem. This is because many transcripts localize to more than one compartment, making the task of predicting RNA localization both challenging and biologically relevant.\n\nAdditionally, we did not include transcripts with no significant localization as explicit negative examples. Instead, we used transcripts with significant localizations to other compartments as negative examples. This decision was made because it is difficult to definitively say that a transcript does not localize to any compartments due to inherent limitations in the data. This approach ensures that our model is trained on a more realistic and diverse set of examples, which is essential for its generalizability and robustness.",
  "dataset/availability": "The data used in our study is not publicly released in a forum. The data splits, including the training, validation, and testing sets, were created internally and are not available for public access. The data was split such that 80% of the examples were used for training, 10% for validation, and 10% for testing. For the ENCODE data sets, which were used solely for testing, no internal splits were made. The validation set was used to tune modeling approaches and hyperparameters, while the test set was reserved for final evaluation and model interpretation. Cross-validation was performed by rotating the testing and training folds to ensure that each data point was used exactly once as a testing example and once as a validation example.",
  "optimization/algorithm": "The machine-learning algorithm class used is tree-based models, specifically random forests. Additionally, boosted trees were employed as part of the benchmarking process. These algorithms are well-established in the field of machine learning and are not new. The choice to use these algorithms in this context is likely due to their effectiveness in handling structured data and their interpretability, which is crucial for understanding the features that contribute to RNA localization predictions.\n\nThe decision to use tree-based models in this study is driven by their ability to capture complex interactions between features without requiring extensive preprocessing or feature engineering. Random forests, in particular, are robust to overfitting and provide a measure of feature importance, which is valuable for interpreting the model's predictions.\n\nBoosted trees, on the other hand, were used to compare the performance of different tree-based methodologies. The implementation of boosted trees provided by XGBoost was utilized, which does not support multilabel predictions out of the box. Therefore, eight independent boosted tree models were trained, each corresponding to a different localization compartment. This approach allows for a direct comparison between the single-model approach adopted by the primary algorithm and the multi-model approach used in boosted trees.\n\nThe use of these established algorithms in a biological context is not uncommon. Many biological problems benefit from the interpretability and robustness of tree-based models. The focus of this study is on the application of these algorithms to RNA localization prediction, rather than the development of new machine-learning techniques. Therefore, it is appropriate for this work to be published in a biological journal rather than a machine-learning journal. The innovation lies in the application of these algorithms to a specific biological problem and the insights gained from their use.",
  "optimization/meta": "The model described in the publication does not function as a traditional meta-predictor that combines the outputs of other machine-learning algorithms as input. Instead, it employs a hierarchical approach to predict subcellular localization of RNA transcripts.\n\nThe model first predicts whether a transcript localizes to the nucleus or the cytoplasm using a random forest classifier. This initial prediction is then used to guide subsequent predictions for more specific subcellular compartments within the nucleus or cytoplasm. This hierarchical process mimics a biologically intuitive view of RNA localization, where a transcript first decides between nuclear and cytoplasmic localization before further localizing within those general areas.\n\nThe model does not explicitly combine the outputs of multiple independent machine-learning methods to make its final predictions. Instead, it uses a single, unified model that incorporates hierarchical decision-making. The training data for the model is designed to ensure independence, with sequences in the test set being checked for significant similarity to training sequences using BLAST. Sequences with significant similarity are removed to prevent artificial inflation of prediction performance.\n\nThe model's performance is evaluated using metrics such as AUROC and AUPRC, and it is compared against various baseline models and state-of-the-art methods. The hierarchical approach allows the model to capture complex localization patterns and achieve high performance across different subcellular compartments.",
  "optimization/encoding": "For the machine-learning algorithm, the data encoding and preprocessing involved several key steps. The primary featurization scheme used was k-mer featurization, which splits a sequence of length l into all possible k-mers. This method captures local sequence patterns effectively. For convolutional models, the Basset architecture was adopted, which requires a fixed-length input of one-hot encoded nucleotide bases. Specifically, the trailing 1000 base pairs (bp) on the 3' end of each transcript sequence were used. Additionally, variants of this architecture were developed, such as Basset-3, which consumes the trailing 250 bp of the 5' UTR, CDS, and 3' UTR, totaling 750 input bases. Another variant, Basset-pool, was modified to process arbitrary-length input sequences by introducing a pooling layer and increasing the number of kernels learned by the model.\n\nFor recurrent models, long short-term memory (LSTM) and gated recurrent unit (GRU) architectures were experimented with. These models consume raw nucleotide sequences of variable length and feature a gating mechanism to handle long inputs. The LSTM model used an embedding layer of 32 dimensions, followed by an LSTM layer with 64 dimensions, and a fully connected layer mapping to an eight-dimensional output space. The GRU model used a similar structure but with two GRU layers.\n\nThe data was split into training, validation, and test sets, with 80% of the examples used for training, 10% for validation, and 10% for testing. For 10-fold cross-validation, the data was rotated such that each data point was used exactly once as a testing example and once as a validation example. This approach ensured robust model evaluation and hyperparameter tuning.\n\nNegative examples were not explicitly included, as it is challenging to definitively say that a transcript does not localize to any compartments due to data limitations. Instead, transcripts with significant localizations to other compartments were used as negative examples.\n\nIn summary, the data encoding involved k-mer featurization and one-hot encoding, with specific architectures adapted to handle variable-length sequences. The data was carefully split and processed to ensure robust model training and evaluation.",
  "optimization/parameters": "In our study, the number of parameters used in the model varies depending on the specific architecture and approach employed. For the random forest implementation of RNA-GPS, we utilized a large feature space consisting of 4032 features. To prevent overfitting, each tree in the random forest was limited to using only a subset of these features, specifically 129 features per tree. This subset size was determined by the formula n√, where n denotes the total number of features.\n\nFor the convolutional models, we adopted the Basset architecture, which requires a fixed-length input of one-hot encoded nucleotide bases. The vanilla Basset architecture processes the trailing 1000 base pairs (bp) on the 3' end of each transcript sequence. We also developed variants of this architecture, such as Basset-3, which consumes the trailing 250 bp of the 5' UTR, CDS, and 3' UTR, totaling 750 input bases. Additionally, we modified Basset to process arbitrary-length input sequences by introducing a pooling layer and increasing the number of kernels learned by the model.\n\nRecurrent models, including long short-term memory (LSTM) and gated recurrent unit (GRU) architectures, consume raw nucleotide sequences of variable length. The LSTM model uses an embedding layer of 32 dimensions, followed by an LSTM layer with 64 dimensions, and a fully connected layer mapping the 64 dimensions to an eight-dimensional output space. The GRU model employs an embedding layer of 32 dimensions, followed by two GRU layers with 64 hidden dimensions, and a fully connected layer with sigmoid activation to map the 64 hidden dimensions to the eight-dimensional output space.\n\nThe selection of parameters was guided by hyperparameter tuning aimed at maximizing the area under the receiver operator characteristic (AUROC) on the validation set. This tuning process involved optimizing various hyperparameters, including the number of estimators, tree criterion, maximum tree depth, and minimum samples per leaf for the random forest model. For the neural network models, the training procedures and hyperparameters were adapted from established architectures and fine-tuned to optimize performance on the validation set.",
  "optimization/features": "The input features for our model are derived from a k-mer featurization scheme. This scheme involves splitting a sequence into subsequences of length k, where k is much smaller than the sequence length. We use three different values of k, specifically k ∈ [3, 4, 5]. This approach is applied to three distinct segments of the transcript: the 5' untranslated region (5' UTR), the coding sequence (CDS), and the 3' untranslated region (3' UTR). Each segment is featurized individually, which helps in capturing the spatial information regarding where motifs occur in the sequence.\n\nFor each value of k, the total k-mer counts are normalized by the total number of k-mer subsequences, ensuring that the sum over the feature vector equals 1. This normalization is crucial for preventing the input sequence length from drastically altering the k-mer featurization, especially given the large variability in transcript lengths.\n\nThe featurization strategy produces 4^3 + 4^4 + 4^5 = 1344 values for each of the three transcript regions, resulting in a total of 1344 × 3 = 4032 features. This comprehensive featurization allows the model to capture local sequence patterns effectively, which is particularly important for handling the highly variable sequence lengths of RNA transcripts.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the featurization strategy itself acts as a form of feature engineering, focusing on the most relevant k-mers and transcript segments. This approach ensures that the model inputs are both informative and manageable, without the need for additional feature selection steps. The entire featurization process was designed to be robust and generalizable, leveraging biological intuition about the roles of different transcript regions in localization.",
  "optimization/fitting": "The fitting method employed in our study involved careful consideration to avoid both overfitting and underfitting. To address the potential issue of overfitting, given that the number of parameters in our models could be large relative to the number of training points, we implemented several strategies.\n\nFirstly, we utilized cross-validation techniques to evaluate model performance across different folds of the data. This approach helped ensure that our model generalized well to unseen data, rather than merely memorizing the training set. Specifically, we compared RNA-GPS with other models, including a boosted tree model and RNATracker, across cross-validation folds. The results indicated that while RNA-GPS and the boosted tree performed consistently well, RNATracker exhibited large variability, suggesting overfitting.\n\nAdditionally, we incorporated hierarchical clustering of cellular compartments based on colocalization patterns. This method demonstrated that RNA-GPS successfully recapitulated true biological signals, as evidenced by its ability to mirror the ground truth relationships between different cellular localizations. The Robinson-Foulds distance metric further quantified this difference, showing that RNA-GPS achieved optimal clustering compared to the boosted tree model.\n\nTo mitigate underfitting, we employed a segment-aware featurization strategy, which outperformed the default Basset implementation. This strategy likely contributed to the model's ability to capture complex localization patterns across multiple cellular compartments. Furthermore, we experimented with tiered models that incorporated biological priors, such as the distinction between cytoplasmic and nuclear compartments. This approach involved training a random forest to predict cytoplasmic and nuclear localization, followed by subsequent models for sublocalizations, thereby mimicking the hierarchical localization process.\n\nOverall, these methods ensured that our model was neither overfitted nor underfitted, providing robust and generalizable predictions for RNA localization.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method involved using cross-validation to evaluate model performance consistently. Specifically, we performed 10-fold cross-validation to assess the stability and generalizability of our models across different subsets of the data.\n\nAdditionally, we implemented early stopping during the training process. This technique monitors the model's performance on a validation set and halts training when the performance stops improving, thereby preventing the model from overfitting to the training data.\n\nFor our convolutional models, we utilized dropout layers, which randomly set a fraction of input units to zero during training. This helps to prevent the model from becoming too reliant on specific features and encourages it to learn more generalizable patterns.\n\nWe also employed regularization techniques such as L2 regularization, which adds a penalty term to the loss function based on the magnitude of the model's weights. This encourages the model to keep the weights small, reducing the risk of overfitting.\n\nFurthermore, we ensured that our test set was independent of the training set by removing sequences with significant similarity to the training sequences using BLAST. This step helped to avoid any potential bias that could arise from sequence similarity between the training and test sets.\n\nIn summary, our approach to preventing overfitting included cross-validation, early stopping, dropout layers, L2 regularization, and careful curation of the test set to ensure independence from the training data. These methods collectively contributed to the robustness and reliability of our models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are fully reported. For convolutional models, we utilized the Basset architecture, with specific variants developed in-house. These models were trained using the Adam optimizer with a learning rate of 0.001 and binary cross-entropy as the loss function. The vanilla Basset and Basset-3 models were trained with minibatches of 64 examples, while Basset-pool was trained using single examples.\n\nFor recurrent models, we experimented with LSTM and GRU architectures, both trained using stochastic gradient descent with a learning rate of 0.001 and binary cross-entropy as the loss function. No batching was used in training for these architectures.\n\nAdditionally, we reimplemented RNATracker, a prior work that combines convolutional and recurrent LSTM layers with an attention layer. We followed the original authors' implementation closely but made adjustments to better fit our multi-label classification problem, such as using a sigmoid activation for the final output and binary cross-entropy as the loss function.\n\nModel files and specific optimization parameters are not explicitly detailed in the provided text, so it is not clear if they are available or under what license. However, the methodologies and configurations described are sufficient for replication of the experiments.",
  "model/interpretability": "The model developed, RNA-GPS, is designed to be interpretable and not a black box. This interpretability is achieved through several methods that allow for the understanding of how the model makes its predictions.\n\nOne key approach involves feature ablation studies, which are used to evaluate the importance of individual features in tree-based models. This process involves shuffling the values of each feature across examples and observing the impact on the model's performance, specifically the Area Under the Receiver Operating Characteristic Curve (AUROC) for each localization. By repeating this procedure multiple times, a mean, standard deviation, and z-score for each feature's impact can be calculated. Features with z-scores less than or equal to -2 are considered significant, indicating that they carry important localization signals.\n\nAnother method involves the identification and ablation of sequence motifs. Significant k-mer features are tiled back to each transcript to form candidate motifs. These motifs are then used to construct multiple sequence alignments, retaining only subsequences that are consistently found across multiple examples and are at least 7 base pairs long. These motifs are conceptually representative of patterns observed across multiple examples. The importance of these sequence motifs is evaluated by ablating them and observing the difference in localization predictions. This ablation is done by replacing exact matches to the motif with \"N\" bases and observing the impact on the model's output.\n\nAdditionally, the model incorporates the featurization scheme from RNATracker, which encodes \"N\" bases in a specific way. This scheme is used to better match the multi-label classification problem at hand.\n\nFurthermore, the model's interpretability is enhanced by the use of Position Weight Matrices (PWMs) for RNA-binding proteins (RBPs). The process for PWM ablation is similar to that of motif ablation, involving the scanning of each PWM across each transcript, ablating high-scoring PWM hits, and observing the impact on model prediction. This method accounts for positional variation and provides a more nuanced understanding of the model's decision-making process.\n\nIn summary, RNA-GPS is designed to be transparent and interpretable, with several methods in place to understand the model's predictions and the underlying biological mechanisms.",
  "model/output": "The model is a classification model. It predicts the probabilities of RNA localization across eight different compartments. These probabilities are not constrained to sum to 1, allowing for the possibility of multi-label classification, where an RNA sequence can localize to more than one compartment. The model's output is evaluated using metrics such as the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPRC), which are commonly used for classification tasks. Additionally, the model's performance is assessed through hierarchical clustering of cellular compartments based on colocalization patterns, further indicating its classification nature.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The RNA-GPS software is publicly available. The source code can be accessed via GitHub at the following URL: https://github.com/wukevin/rnagps. This repository contains the necessary files to run the algorithm and replicate the results presented in the publication. Additionally, some preprocessed files, such as those related to retained introns, are also available on GitHub. The software is released under a license that allows for its use and modification by the research community, facilitating further development and application of the RNA-GPS model.",
  "evaluation/method": "The method was evaluated using several approaches to ensure robustness and generalizability. Primarily, we used a held-out test set to report the performance metrics. The model achieved an overall area under the receiver operating characteristic curve (AUROC) of 0.77 and an area under the precision-recall curve (AUPRC) of 0.49 on these test transcripts. To further validate the consistency of our model, we performed 10-fold cross-validation, which showed highly consistent performance. Additionally, we ensured that the prediction performance was not inflated by sequence similarity by removing test sequences with significant similarity to training sequences, resulting in similar AUROC and AUPRC values.\n\nTo contextualize the performance, we compared our method to a previous state-of-the-art approach, deepLncRNA, which we adapted and retrained for a binary nuclear versus cytoplasmic localization task. Our method substantially outperformed deepLncRNA, achieving an AUROC of 0.85 compared to 0.74. We also benchmarked several additional machine learning models, including convolutional and recurrent algorithms, as well as other tree-based methods. Our method significantly outperformed all evaluated deep learning-based approaches, likely due to its featurization strategy that captures local sequence patterns effectively.\n\nFor model interpretation, we performed feature ablation studies to evaluate feature importance. This involved shuffling the values of each feature across examples and evaluating the difference in AUROC for each localization. This process was repeated multiple times to calculate the mean, standard deviation, and z-score for each feature's impact on the AUROC. Additionally, we used metrics generated with scikit-learn and created plots using matplotlib and seaborn. P-value correction for multiple hypothesis testing was performed using the statsmodels package. Overall, the evaluation methods provided a comprehensive assessment of the model's performance and robustness.",
  "evaluation/measure": "In our evaluation of RNA-GPS, we primarily focused on several key performance metrics to assess the model's effectiveness in predicting RNA localization. The main metrics reported are the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPRC). These metrics provide a comprehensive view of the model's ability to distinguish between different localization classes and its precision in making positive predictions.\n\nAdditionally, we reported accuracy as a performance measure. To determine the accuracy on the test set, we used the validation set to find the optimal threshold for positive/negative predictions. This threshold maximizes Youden’s J-statistic, which balances the true positive rate and the false positive rate, ensuring that the model's predictions are both sensitive and specific.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in bioinformatics, making our evaluation representative and comparable to other studies in the field. The use of AUROC and AUPRC is especially important for imbalanced datasets, which is common in biological data, as these metrics provide a more nuanced understanding of model performance beyond simple accuracy.\n\nWe also performed cross-validation to ensure the robustness of our results. The consistent performance of RNA-GPS across different folds and transcript lengths further validates the reliability of these metrics. Moreover, we compared RNA-GPS with other state-of-the-art models using the same metrics, demonstrating its superior performance in predicting RNA localization.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of RNA-GPS with both publicly available methods and simpler baselines to ensure a comprehensive assessment of its performance.\n\nWe benchmarked RNA-GPS against several state-of-the-art convolutional and recurrent algorithms, as well as other tree-based methods. These models were trained and tested on the same multilocalization dataset as RNA-GPS. Notably, we adapted RNA-GPS’s segment-wise featurization for some of these models to better isolate the impact of featurization versus modeling strategies. RNA-GPS significantly outperformed all evaluated deep learning-based approaches. This superior performance is likely due to its featurization strategy, which effectively captures local sequence patterns in a manner that is largely independent of the highly variable sequence lengths of RNA transcripts—a challenge that deep learning networks often struggle with.\n\nAmong the models compared, the boosted tree model, which consists of eight individual boosted trees each trained to predict localization to one compartment, achieved the most comparable performance to RNA-GPS. This model also uses the same featurization as RNA-GPS, providing a direct comparison of modeling strategies. Additionally, we evaluated Basset-3, a variant of the Basset architecture that incorporates segment-aware featurization. Basset-3 outperformed the default Basset implementation, further supporting the effectiveness of our featurization strategy.\n\nTo contextualize RNA-GPS’s performance, we also developed a simple baseline model. This baseline involved training a random forest to classify binary nuclear versus cytoplasmic localizations and combining its predictions with random sublocalizations to nuclear and cytoplasmic compartments. The performance of this baseline was substantially worse than that of RNA-GPS, demonstrating that predicting fine-grained transcript localization is a nontrivial extension of nuclear versus cytoplasmic prediction.\n\nFurthermore, we compared RNA-GPS to deepLncRNA, a previous state-of-the-art method. We adapted, reimplemented, and retrained deepLncRNA to predict binary nuclear versus cytoplasmic localization. On this simplified task, RNA-GPS substantially outperformed deepLncRNA, achieving an AUROC of 0.85 compared to deepLncRNA’s 0.74. This comparison shows that RNA-GPS’s design inherently surpasses that of previous approaches, even on relatively simple localization prediction tasks.\n\nIn summary, our evaluation included a rigorous comparison with publicly available methods and simpler baselines, providing a comprehensive assessment of RNA-GPS’s performance and demonstrating its superiority in predicting RNA localization.",
  "evaluation/confidence": "The evaluation of RNA-GPS includes several performance metrics, such as the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPRC), which are crucial for assessing the model's effectiveness. These metrics were generated using functions available in scikit-learn, ensuring robustness and reliability. The performance of RNA-GPS was evaluated on a held-out test set, achieving an overall AUROC of 0.77 and an AUPRC of 0.49. To ensure the reliability of these results, additional cross-validation was performed, demonstrating high consistency across different folds.\n\nStatistical significance was addressed through various means. For instance, P-value correction for multiple hypothesis testing was performed using the statsmodels package, which helps in controlling the family-wise error rate. This is particularly important when evaluating multiple models or metrics simultaneously. Furthermore, the performance of RNA-GPS was compared against several baselines and state-of-the-art methods, showing substantial improvements. For example, RNA-GPS outperformed deepLncRNA with an AUROC of 0.85 versus 0.74 on a binary nuclear versus cytoplasmic localization task. This comparison was statistically significant, indicating that RNA-GPS's design inherently surpasses previous approaches.\n\nThe evaluation also included a baseline model that combined random forest predictions with random sublocalizations, which performed significantly worse than RNA-GPS. This demonstrates that RNA-GPS successfully learns fine-grained transcript localization, a nontrivial extension of nuclear versus cytoplasmic prediction. Additionally, the performance metrics were evaluated across different transcript lengths, showing consistent results. This consistency across various conditions and comparisons provides confidence in the superiority of RNA-GPS over other methods and baselines.",
  "evaluation/availability": "All APEX-Seq data used to train and evaluate RNA-GPS is available through the Gene Expression Omnibus (GEO) under accession GSE116008. This data is publicly accessible, allowing other researchers to reproduce and validate our findings. Additionally, some preprocessed files, such as those pertaining to retained introns, are available on GitHub. This includes the RNA-GPS software, which is open-source and can be accessed at https://github.com/wukevin/rnagps. The availability of these resources ensures transparency and facilitates further research in the field."
}