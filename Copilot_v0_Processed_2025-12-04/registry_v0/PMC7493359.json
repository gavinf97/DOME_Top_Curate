{
  "publication/title": "Seagull: lasso, group lasso and sparse-group lasso regularization for linear regression models via proximal gradient descent",
  "publication/authors": "The authors who contributed to the article are:\n\n- Jan Klosa\n- Noah Simon\n- Pål Olof Westermark\n- Volkmar Liebscher\n- Dörte Wittenburg\n\nDörte Wittenburg is the corresponding author, and her email is wittenburg@fbn-dummerstorf.de.\n\nThe contributions of each author to the paper are not specified.",
  "publication/journal": "BMC Bioinformatics",
  "publication/year": "2020",
  "publication/doi": "10.1186/s12859-020-03725-w",
  "publication/tags": "- Optimization\n- Machine learning\n- High-dimensional data\n- R package\n- Linear regression\n- Penalization methods\n- Lasso\n- Group lasso\n- Sparse-group lasso\n- Proximal gradient descent",
  "dataset/provenance": "The dataset used in our study is publicly available and consists of blood DNA methylation profiles at approximately 1.9 million CpG sites. This data is associated with chronological age in mice, with a total of 141 samples. The dataset is accessible through the Gene Expression Omnibus (GEO) database under the accession number GSE80672. This dataset has been previously described in detail in another study, and it has been utilized by the community for various research purposes. We split the dataset into training and validation sets, ensuring that all age classes were almost equally represented in both sets. The training set consisted of 75 samples, while the validation set included 66 samples. This division allowed us to effectively evaluate the performance of our methods in predicting biological age from DNA methylation status.",
  "dataset/splits": "The dataset used in the study consisted of blood DNA methylation profiles at approximately 1.9 million CpG sites, analyzed for their association with chronological age in mice. The dataset was divided into two main splits: a training set and a validation set. The training set contained 75 samples, while the validation set had 66 samples. Both splits were designed to include almost equal representation of all age classes, ensuring a balanced distribution of data points across different age groups. This division allowed for effective training and validation of the models, enabling a precise prediction of biological age from DNA methylation status.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The dataset used in our study is publicly available in the Gene Expression Omnibus (GEO) database. It can be accessed via the following link: [GEO Database](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE80672). The dataset consists of blood DNA methylation profiles at approximately 1.9 million CpG sites and their association with chronological age in mice, with a total of 141 samples.\n\nThe data was split into training and validation sets, with 75 samples in the training set and 66 samples in the validation set. This split ensures that all age classes are almost equally represented in both sets. The R scripts used for processing and analyzing the data are available in the supplementary material, specifically in Additional files 1 and 2. These scripts provide detailed steps on how the data was prepared and analyzed.\n\nAdditionally, ready-to-use data is available at Code Ocean, which can be accessed through the following link: [Code Ocean](https://codeocean.com/capsule/6412387/tree/v1). This platform provides a reproducible environment for running the analyses described in our study.\n\nThe dataset is licensed under the Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source. This license ensures that the data can be freely used and shared by the scientific community while maintaining proper attribution.",
  "optimization/algorithm": "The optimization algorithm employed is proximal gradient descent (PGD), an extension of gradient descent tailored for optimization problems that include non-smooth components. This method is particularly useful when the gradient is not available for the entire objective function. PGD is not a new algorithm; it is a well-established technique in the field of optimization. The choice to implement PGD in this context is driven by its efficiency and suitability for handling high-dimensional data, which is common in biological and genomic studies. The implementation details and specific adaptations for this package are presented in additional supplementary materials.\n\nThe decision to publish this work in a bioinformatics journal rather than a machine-learning journal is likely due to the specific application and the target audience. The focus here is on the practical application of these optimization techniques to biological data, particularly in the context of genome-wide association studies and high-dimensional linear models. The package, seagull, is designed to provide a fast and numerically efficient implementation of lasso, group lasso, and sparse-group lasso regularization for linear regression models, which are commonly used in bioinformatics and genomics. This makes the work highly relevant to researchers in these fields, even though the underlying optimization algorithm is well-known in the machine-learning community.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data used in our study consisted of blood DNA methylation profiles at approximately 1.9 million CpG sites, which were analyzed for their association with chronological age in mice. The dataset, which is publicly available, was split into training and validation sets, each containing samples from various age classes. The training set comprised 75 samples, while the validation set included 66 samples, ensuring an almost equal representation of age classes in both sets.\n\nFor the machine-learning algorithm, we applied the sparse-group lasso variant of the seagull package. The data preprocessing involved preparing the methylation profiles for regression analysis. The methylation data were likely normalized and standardized to ensure that the values were on a comparable scale, which is crucial for the performance of regularization methods like the sparse-group lasso.\n\nThe input parameters for the seagull package were set as follows: the mixing parameter α was set to 0.95, a grid of 50 values for the penalty parameter λ was used, and the ratio ξ between the minimal and maximal λ was set to 0.001. These parameters were chosen to balance the trade-off between model complexity and prediction accuracy.\n\nThe accuracy parameter for seagull was set to 10^-6, while for the SGL package, it was set to 10^-4. These parameters influenced the convergence criteria and the number of non-zero effects identified in the model. The data and evaluation criteria used in this study are available in the supplementary material and at Code Ocean, providing transparency and reproducibility for further research.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "The study analyzed blood DNA methylation profiles at approximately 1.9 million CpG sites. These sites served as the input features for the regression models used to associate methylation data with chronological age in mice. Feature selection was inherently performed through the use of regularization techniques such as lasso, group lasso, and sparse-group lasso, which are designed to handle high-dimensional data by penalizing the model's complexity. This process effectively selects a subset of features that contribute most significantly to the prediction of the response variable.\n\nThe feature selection was conducted using the training set only, ensuring that the validation set remained independent for evaluating the model's performance. This approach helps to prevent overfitting and provides a more reliable assessment of the model's generalizability to new data.",
  "optimization/fitting": "The fitting method employed in this work addresses the challenge of high-dimensional linear models, where the number of parameters often exceeds the number of training points. This scenario is common in biological studies, such as genome-wide association studies, where the explanatory variables (e.g., genetic variants) outnumber the observations (e.g., disease records).\n\nTo mitigate over-fitting, penalization approaches were utilized. Specifically, the lasso, group lasso, and sparse-group lasso regularization techniques were implemented via proximal gradient descent. These methods introduce a penalty term to the objective function, which discourages large coefficients and promotes sparsity in the model. By doing so, they effectively reduce the complexity of the model and prevent it from fitting the noise in the data.\n\nThe strength of the penalization is controlled by a parameter λ, which was systematically varied to generate a regularization path. This path provides a sequence of solutions corresponding to different levels of penalization, allowing for the selection of an optimal model that balances bias and variance.\n\nTo ensure efficient computation, warm starts were implemented. This technique uses the solution from the previous value of λ as the starting point for the subsequent value, accelerating the convergence of the algorithm. Additionally, a backtracking line search was employed to determine an appropriate step size between consecutive iterations, further enhancing the efficiency and stability of the optimization process.\n\nThe stopping criterion for the iterative algorithm was based on the relative accuracy, which measures the gain from one iteration to the next. This criterion ensures that the algorithm converges to a solution that is sufficiently accurate, without unnecessary computations.\n\nIn summary, the fitting method employed in this work effectively addresses the challenges of high-dimensional data by using penalization techniques to prevent over-fitting and under-fitting. The use of warm starts and backtracking line search further enhances the efficiency and stability of the optimization process.",
  "optimization/regularization": "In our optimization process, we employed several techniques to prevent overfitting. One key method is the use of regularization paths, which involve solving the optimization problem for a sequence of penalty parameters. This approach helps in identifying the optimal level of regularization that balances model complexity and fit to the data.\n\nWe utilized the sparse-group lasso, which combines the lasso and group lasso penalties. The lasso penalty encourages sparsity by driving some coefficients to zero, effectively performing feature selection and reducing the risk of overfitting. The group lasso penalty, on the other hand, encourages entire groups of related features to be included or excluded together, which is particularly useful when there is an underlying group structure in the data.\n\nTo efficiently compute the regularization paths, we implemented warm starts. This technique uses the solution from the previous penalty parameter as the starting point for the next, significantly speeding up the computation and ensuring stability in the solutions.\n\nAdditionally, we employed proximal gradient descent (PGD), an iterative algorithm designed for optimization problems with non-smooth components. PGD is robust and helps in finding solutions that generalize well to unseen data, further mitigating overfitting risks.\n\nThe step size between consecutive iterations in PGD is determined using backtracking line search, which ensures that the algorithm converges efficiently. We also implemented a stopping criterion based on the relative accuracy of the solutions, which helps in terminating the iterations when further improvements are minimal, thus preventing unnecessary computations and potential overfitting.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are available. The R scripts for processing and analyzing the data are provided in the supplementary material. Additionally, ready-to-use data is available at Code Ocean. The software is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source. The license also allows for the provision of a link to the Creative Commons license and indicates if changes were made. The images or other third-party material in this article are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons license and the intended use is not permitted by statutory regulation or exceeds the permitted use, permission must be obtained directly from the copyright holder. The Creative Commons Public Domain Dedication waiver applies to the data made available in this article, unless otherwise stated in a credit line to the data.",
  "model/interpretability": "The model presented in the publication is not a blackbox. The seagull package implements several regularization techniques, including lasso, group lasso, and sparse-group lasso, which are inherently interpretable. These methods promote sparsity in the model by shrinking some coefficients to zero, effectively performing variable selection. This means that the resulting model is sparse, making it easier to interpret which features (e.g., CpG sites in methylation data) are important for predicting the outcome.\n\nFor instance, in the results section, it was shown that using seagull, only a fraction of CpG sites (5095 non-zero effects) were identified as having a significant impact on predicting biological age from DNA methylation status. This sparsity allows researchers to focus on these specific sites, providing clear insights into which genetic markers are most relevant.\n\nAdditionally, the package allows for the incorporation of weights for each penalized feature, further enhancing interpretability. By assigning different weights, researchers can prioritize certain features or groups of features based on domain knowledge or specific hypotheses, making the model's decisions more transparent and aligned with biological understanding.\n\nThe use of proximal gradient descent and warm starts for grid search also contributes to the model's interpretability. These techniques ensure that the regularization paths are computed efficiently, providing a clear trajectory of how the model's coefficients change as the penalty parameter varies. This path can be visualized and analyzed to understand the trade-offs between model complexity and predictive performance.\n\nIn summary, the seagull package offers a transparent and interpretable approach to high-dimensional linear regression, making it a valuable tool for researchers seeking to understand the underlying mechanisms of their data.",
  "model/output": "The model presented in the publication is a regression model. Specifically, it focuses on linear regression models that are used to explore the dependence between a response variable and explanatory variables. The model is designed to handle high-dimensional data, which is common in biological and life sciences research. It employs various penalization approaches, such as lasso, group lasso, and sparse-group lasso, to address issues like multicollinearity and the high dimensionality of the data. The output of the model includes regression coefficients that are used to predict the response variable, in this case, biological age from DNA methylation status. The model's performance is evaluated using criteria such as the mean squared error (MSE) of predicted age, the squared correlation coefficient (R2) between predicted and chronological age, the number of features with non-zero effects, and the execution time needed to compute the regularization path. The model's output is visualized through figures that show the relationship between observed and predicted age, as well as the path of mean squared error (MSE) for different values of the penalty parameter λ.",
  "model/duration": "The execution time for computing the entire regularization path varied significantly between the two packages compared. The seagull package demonstrated a much faster computation time. For instance, when the accuracy parameter was set to 10^-6, seagull completed the computation in approximately 2 hours and 13 minutes. In contrast, the SGL package took around 45 hours and 20 minutes to achieve similar results. This substantial difference in execution time highlights the efficiency of the seagull package, making it a more practical choice for handling large-scale datasets. The ability to incorporate weights for each penalized feature further enhances its versatility and performance in various biological applications.",
  "model/availability": "The software presented in this publication is an R package named seagull. The source code for seagull is publicly available on GitHub at https://github.com/jklosa/seagull. Additionally, the package can be installed from the Comprehensive R Archive Network (CRAN) at https://CRAN.R-project.org/package=seagull.\n\nThe package is licensed under the GNU General Public License (GPL) version 2 or later, which allows for free use, sharing, adaptation, distribution, and reproduction, provided that appropriate credit is given to the original authors and the source is cited. The license also permits the inclusion of the software in larger works, both commercial and non-commercial, as long as the terms of the GPL are followed.\n\nThe package is platform-independent and requires R version 3.5.0 or later to run. It is implemented in R and Rcpp, ensuring efficient computation. There are no restrictions on the use of this software by non-academics.\n\nFor those interested in running the algorithms without installing the package locally, the processed dataset, R scripts, and results are also available at Code Ocean: https://codeocean.com/capsule/6412387/tree/v1. This platform provides a reproducible computing environment, allowing users to run the code and reproduce the results presented in the publication.",
  "evaluation/method": "The evaluation of the method involved using publicly available high-dimensional methylation data to compare the performance of the seagull package with the established SGL package. The data consisted of blood DNA methylation profiles at approximately 1.9 million CpG sites and their association with chronological age in mice. The dataset was split into training and validation sets, ensuring that all age classes were almost equally represented in both sets.\n\nSeveral criteria were used to evaluate the performance of the two packages. These included the minimum mean squared error (MSE) of predicted age based on methylation data compared to measured chronological age, the squared correlation coefficient (R2) between predicted and chronological age, the number of features with non-zero effects, and the execution time required to compute the entire regularization path.\n\nThe results showed that both packages enabled a precise prediction of biological age from DNA methylation status. The correlation between chronological and predicted age was very high, with seagull achieving a correlation of 95.8% and identifying 5095 non-zero effects. Increasing the accuracy parameter of seagull led to an increase in the number of non-zero effects, demonstrating the flexibility of the package in regulating sparsity.\n\nDespite differences in convergence criteria, the results from seagull and SGL were similar, with a correlation of 99.5% between the regression coefficients leading to the minimum mean squared error. However, seagull computed the solution in a significantly shorter time compared to SGL, highlighting its efficiency.\n\nAdditionally, seagull offers the option to introduce weights for each penalized feature, which was investigated in a study involving SNP genotypes in a flowering plant breed. This feature enhances the versatility of seagull for various biological applications.",
  "evaluation/measure": "In our evaluation of the seagull package, we focused on several key performance metrics to assess its effectiveness and efficiency. The primary metrics we reported include the minimum mean squared error (MSE) of predicted age based on methylation data, the squared correlation coefficient (R²) between predicted and chronological age, the number of features with non-zero effects, and the execution time required to compute the entire regularization path.\n\nThe MSE provides a measure of the average squared difference between the predicted and actual chronological ages, offering insight into the accuracy of the predictions. A lower MSE indicates better predictive performance. The R² value, which represents the proportion of variance in the chronological age that is predictable from the methylation data, is another crucial metric. Higher R² values signify a stronger correlation between the predicted and actual ages.\n\nThe number of features with non-zero effects is also an important metric, as it reflects the sparsity of the model. A model with fewer non-zero effects is generally more interpretable and can help identify the most relevant CpG sites associated with age prediction. Additionally, the execution time is a critical performance measure, especially for high-dimensional data, as it indicates the computational efficiency of the package.\n\nThese metrics are widely used in the literature for evaluating the performance of regression models, particularly in the context of high-dimensional biological data. They provide a comprehensive assessment of both the accuracy and efficiency of the seagull package, making our evaluation representative and comparable to other studies in the field.",
  "evaluation/comparison": "In our evaluation, we compared the performance of our package, seagull, with an established R package, SGL. Both packages were applied to a publicly available high-dimensional methylation dataset from mice, which is described in detail in a previous study. The dataset consists of blood DNA methylation profiles at approximately 1.9 million CpG sites and their association with chronological age. We split the data into training and validation sets, ensuring that all age classes were almost equally represented in both sets.\n\nThe comparison was based on several evaluation criteria, including the minimum mean squared error (MSE) of predicted age, the squared correlation coefficient (R2) between predicted and chronological age, the number of features with non-zero effects, and the execution time required to compute the entire regularization path.\n\nBoth packages were configured with similar input parameters, such as a mixing parameter α set to 0.95, a grid of 50 values for λ, and a ratio ξ between minimal and maximal λ equal to 0.001. However, the convergence criteria differed due to the distinct meanings of the accuracy parameters in each package. In SGL, this parameter serves as an upper bound for the ℓ1-norm of the estimates, while in seagull, it is used as a relative accuracy measure.\n\nThe results demonstrated that seagull achieved a high correlation between chronological and predicted age, with a correlation coefficient of 95.8% and identified 5095 non-zero effects. Increasing the accuracy parameter of seagull by two magnitudes resulted in a significant increase in the number of non-zero effects. Despite the differences in convergence criteria, the results from both packages were similar, with a correlation of 99.5% between the regression coefficients leading to the minimum MSE. Notably, seagull computed the solution much faster than SGL, taking approximately 2 hours compared to SGL's 45 hours.\n\nAdditionally, seagull offers the flexibility to incorporate weights for each penalized feature, which was not available in SGL. This feature allows for more tailored and potentially more accurate models, as demonstrated in a study on genetic variants detection in Arabidopsis thaliana.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files are not directly available, but the data used for evaluation is publicly accessible. The methylation dataset utilized in the study can be found in the Gene Expression Omnibus (GEO) database under the accession number GSE80672. This dataset includes blood DNA methylation profiles at approximately 1.9 million CpG sites and their association with chronological age in mice.\n\nAdditionally, the R scripts used for processing and analyzing the data are provided as supplementary material. These scripts, labeled as Additional files 1 and 2, guide users through the steps of downloading, processing, and analyzing the methylation data to reproduce the results presented in the publication. These scripts are essential for anyone looking to replicate the evaluation process or apply similar methods to their own datasets.\n\nThe software package seagull, which was used for the evaluations, is freely available on the Comprehensive R Archive Network (CRAN). The package includes a vignette that provides detailed instructions on its usage. The source code for seagull is also available on GitHub, allowing for further inspection and modification if needed. The package is licensed under the GNU General Public License (GPL) version 2 or later, which permits use, sharing, adaptation, distribution, and reproduction under the terms of the license.\n\nFor those interested in the theoretical background, an additional document (Additional file 4) is provided. This document offers information about the proximal gradient descent algorithm used in the sparse-group lasso implementation within seagull. This resource can be particularly useful for researchers looking to understand the underlying mathematical and computational methods employed in the package."
}