{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Metabolites",
  "publication/year": "2020",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Metabolomics\n- Alzheimer's Disease\n- Mild Cognitive Impairment\n- Urine Analysis\n- NMR Spectroscopy\n- Mass Spectrometry\n- Statistical Analysis\n- Machine Learning\n- SVM Models\n- Logistic Regression\n- Biomarkers\n- Metabolic Profiling\n- Data Normalization\n- Feature Selection\n- Cross-Validation\n- Diagnostic Models\n- Biofluids\n- Metabolic Changes\n- Disease Diagnosis\n- Artificial Intelligence",
  "dataset/provenance": "The dataset used in this study consists of human urine samples collected from adult volunteers. The samples were obtained from 20 individuals diagnosed with Alzheimer's disease (AD), 10 individuals with mild cognitive impairment (MCI), and 29 control patients. The diagnosis and evaluation of the AD and MCI patients were conducted by a geriatrician.\n\nThe urine samples were analyzed using two complementary analytical platforms: 1H nuclear magnetic resonance (1HNMR) and mass spectrometry (MS). This multiomics approach was employed to increase the coverage of the metabolome, as urine is a highly complex biofluid. The 1HNMR platform detected approximately 150 metabolites, while the Biocrates p180 kit, used for MS, enabled the reporting of 51 metabolites. This highlights the need for using multiple analytical techniques to comprehensively study the metabolome.\n\nThe clinical parameters for each individual were also collected, including Mini-Mental State Examination (MMSE) scores, Trails A/B test results, and Clock Drawing Task (CLOX) scores. These parameters were used to assess the cognitive status of the participants and to correlate with the metabolomics data.\n\nThe dataset was preprocessed to account for dilution effects by sum normalizing the combined 1HNMR and MS data. Metabolites with more than 50% missing data were excluded, and missing measurements were imputed with the median value for the respective compound. To address the wide range of concentration values, the data were log-transformed and autoscaled before performing multivariate analysis.\n\nThe preprocessed data were then analyzed using principal component analysis (PCA) to identify potential outliers. Statistical analyses, including Student’s t-test and Mann–Whitney U test, were performed to determine significantly different metabolites between AD, MCI, and age-matched controls. Feature selection algorithms, such as least absolute shrinkage and selection operator (LASSO) and correlation-based feature selection (CFS), were applied to identify the most informative metabolites for developing predictive models. Logistic regression and support vector machine (SVM) models were built and evaluated using 10-fold cross-validation to assess their predictive power.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in our study are Support Vector Machines (SVM) and logistic regression. These are well-established algorithms in the field of machine learning and are commonly used for classification tasks.\n\nThe SVM algorithm is particularly notable for its ability to find an optimal hyperplane that separates different classes with the maximum margin. This makes it effective for tasks where classes may overlap. SVM can also handle nonlinear boundaries by using kernel functions to map the data into a higher-dimensional space.\n\nLogistic regression, on the other hand, is a simpler algorithm that models the probability of a binary outcome. It is widely used due to its interpretability and efficiency.\n\nNeither of these algorithms is new; they are standard tools in the machine-learning community. The choice to use these algorithms in our study was driven by their proven effectiveness in similar classification problems, particularly in the context of metabolomics and diagnostic tasks.\n\nThe focus of our publication is on the application of these algorithms to metabolomics data, rather than the development of new machine-learning techniques. Therefore, it is appropriate for our findings to be published in a journal focused on metabolomics and related fields, rather than a machine-learning journal. Our work contributes to the understanding of how these established algorithms can be applied to specific biological problems, providing insights that are valuable to researchers in the metabolomics community.",
  "optimization/meta": "The meta-predictor model does not use data from other machine-learning algorithms as input. Instead, it relies on specific metabolites identified through feature selection algorithms such as least absolute shrinkage and selection operator (LASSO) and correlation-based feature selection (CSF). These algorithms help in identifying the most informative metabolites from the metabolomics data.\n\nThe predictive models developed include both logistic regression and support vector machine (SVM) models. The SVM models were optimized through an exhaustive search process to find the best parameters, ensuring high accuracy. The logistic regression models were built using the R statistical package. Both models underwent a 10-fold cross-validation process to prevent overfitting and to assess their predictive power on independent samples.\n\nThe training data for these models is independent, as evidenced by the use of 10-fold cross-validation. This method ensures that each fold of the data is used once as a validation set while the remaining folds form the training set. This approach helps in evaluating the model's performance on unseen data, thereby ensuring the independence of the training data.\n\nThe performance of these models was evaluated using metrics such as the area under the curve (AUC), sensitivity, and specificity. The SVM models, in particular, showed impressive performance with high AUC values, indicating their effectiveness in diagnosing conditions such as mild cognitive impairment (MCI) and Alzheimer's disease (AD). The logistic regression models also performed well, especially in distinguishing between healthy controls and AD sufferers.",
  "optimization/encoding": "To prepare the data for the machine-learning algorithms, several preprocessing steps were undertaken. Initially, the combined 1HNMR and MS data were sum normalized to account for any dilution effects. Metabolites with more than 50% missing data were conservatively excluded. For the remaining metabolites, missing measurements were imputed with the median value of the respective compound. Given the wide range of concentration values both inter- and intra-sample, the data were log-transformed and autoscaled to ensure uniformity. Principal component analysis (PCA) was then performed on the preprocessed data to identify any potential outliers. This thorough preprocessing ensured that the data were suitable for multivariate analysis and subsequent model building.",
  "optimization/parameters": "In our study, the parameter space for the Support Vector Machine (SVM) models was designed logarithmically and exhaustively explored to achieve the best accuracy. This approach is a standard practice during the optimization process of SVM models. Specifically, we performed an exhaustive search to identify the optimal pair of parameters, C and γ, using a grid that spanned exponentially varying values. The range for C was set between 10^1 and 10^5, while γ varied from 10^-1 to 10^-6. This grid search was conducted using a 10-fold cross-validation process for each combination of C and γ, aiming to maximize the accuracy of the models. The accuracy was defined as the ratio of correctly predicted samples. This method ensured that the models were not overfitted and provided a robust assessment of their predictive power on independent samples.",
  "optimization/features": "In our study, the number of input features varied depending on the variable selection algorithm used. We employed two main algorithms for feature selection: Correlation-based Feature Selection (CFS) and Least Absolute Shrinkage and Selection Operator (LASSO). These algorithms were applied to identify the most informative metabolites from the dataset.\n\nFeature selection was indeed performed, and it was conducted using the training set only to ensure that the models were not overfitted and to maintain the integrity of the validation process. This approach helped in identifying the most discriminative metabolites for diagnosing mild cognitive impairment (MCI) and Alzheimer's disease (AD).\n\nFor instance, when comparing cognitively healthy controls to MCI sufferers, the CFS algorithm identified a panel of eight metabolites: isoleucine, acetate, trimethylamine N-oxide, kynurenine, C2, SDMA, malonate, and 5-aminopentanoate. These metabolites were used as input features for the Support Vector Machine (SVM) model, which achieved an impressive AUC of 0.90.\n\nSimilarly, when distinguishing MCI from AD, the CFS algorithm selected a different set of metabolites: glucose, guanidinoacetate, urocanate, hippuric acid, cytosine, 2- and 3-hydroxyisovalerate, 2-ketoisovalerate, tryptophan, and malonate. These metabolites were used to develop an SVM model with an AUC of 0.95.\n\nThe LASSO algorithm, on the other hand, provided a more conservative selection of metabolites. For example, when comparing MCI to AD, LASSO identified a subset of metabolites that were deemed significant for diagnosis. This subset included metabolites like glucose, guanidinoacetate, and others, which were used to build models with varying levels of specificity and sensitivity.\n\nIn summary, feature selection was a crucial step in our optimization process, and it was performed using the training set to ensure robust and generalizable models. The number of input features varied based on the selection algorithm and the specific comparison being made.",
  "optimization/fitting": "In our study, we employed a comprehensive approach to ensure that our models were neither overfitted nor underfitted. Given the complexity of metabolomics data, the number of parameters can indeed be much larger than the number of training points. To address this, we utilized a 10-fold cross-validation process. This method involves dividing the data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. By averaging the results, we obtained a robust estimate of the model's performance, which helps in ruling out overfitting.\n\nAdditionally, we performed an exhaustive search to optimize the parameters of our Support Vector Machine (SVM) models. Specifically, we searched for the best combination of the regularization parameter (C) and the kernel coefficient (γ) on a grid that spanned several orders of magnitude. This systematic approach ensured that we explored a wide range of possible parameter values, reducing the risk of underfitting by not missing potentially optimal configurations.\n\nFurthermore, we compared the performance of SVM models with logistic regression models. Both models were evaluated using the same cross-validation framework, ensuring a fair comparison. The consistent performance of both models across different validation folds further supports the robustness of our findings and helps in ruling out both overfitting and underfitting.\n\nIn summary, our use of 10-fold cross-validation, exhaustive parameter search, and comparison with multiple modeling approaches provided a rigorous framework for optimizing our models and ensuring that they generalize well to new data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was cross-validation, specifically a 10-fold cross-validation process. This technique involves partitioning the data into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. This approach helps to ensure that the model generalizes well to independent data and is not overly fitted to the training data.\n\nAdditionally, we utilized feature selection algorithms such as the least absolute shrinkage and selection operator (LASSO) and correlation-based feature selection (CFS). These methods help in identifying the most informative metabolites, reducing the dimensionality of the data, and preventing the model from becoming too complex and overfitting the training data.\n\nDuring the optimization of our support vector machine (SVM) models, we performed an exhaustive search over a logarithmically designed parameter space to find the best combination of hyperparameters. This grid search, combined with 10-fold cross-validation, ensured that we selected the optimal model that performed well on unseen data.\n\nFurthermore, we applied log-transformation and autoscaling to our data before multivariate analysis. These preprocessing steps help to normalize the data, making it more suitable for model training and reducing the risk of overfitting.\n\nIn summary, our study incorporated multiple strategies to prevent overfitting, including cross-validation, feature selection, and careful preprocessing of the data. These techniques collectively contributed to the development of robust and generalizable predictive models.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in the main text. Specifically, we mentioned that our parameter space was logarithmically designed and exhaustively visited to seek the best accuracy, which is a common practice during the optimization process of SVM models. We also detailed the performance metrics of our models, including AUC, sensitivity, and specificity values, which provide insights into the optimization parameters used.\n\nRegarding the availability of model files, we did not explicitly provide direct links to download the model files or the specific optimization schedule followed. However, the methods and results are thoroughly described, allowing replication of the models. The study is published under the Creative Commons Attribution (CC BY) license, which permits the sharing and adaptation of the work, including for commercial purposes, with appropriate credit to the original authors.\n\nFor those interested in replicating our work, the detailed descriptions of the metabolites used, the diagnostic models tested, and the performance metrics achieved should serve as a comprehensive guide. The license under which our work is published ensures that the information can be freely accessed and used, fostering reproducibility and further research in the field.",
  "model/interpretability": "The models we employed, particularly the Support Vector Machine (SVM) and logistic regression, offer varying degrees of interpretability. SVM, while powerful, is often considered a black-box model. This is because it operates by finding an optimal hyperplane in a high-dimensional space, which can be difficult to interpret directly. However, SVM can be made more interpretable by examining the support vectors—the data points that are closest to the hyperplane and thus most influential in defining it. By analyzing these support vectors, one can gain insights into which features are most critical for the classification task.\n\nOn the other hand, logistic regression is generally more transparent. It provides coefficients for each feature, indicating the direction and magnitude of their influence on the outcome. For instance, in our study, the logistic regression model used concentrations of metabolites such as 2-hydroxyisovalerate, acetate, ethanolamine, pyridoxine, 2-hydroxybutyrate, and alpha-ketoisovalerate to distinguish between cognitively healthy controls and Alzheimer's disease sufferers. The coefficients associated with these metabolites can be interpreted to understand their relative importance and the nature of their impact on the diagnosis.\n\nIn summary, while SVM offers robust performance, logistic regression provides clearer interpretability through its coefficients, making it easier to understand the contribution of individual features to the model's predictions.",
  "model/output": "The models developed in our study are primarily classification models. We employed both Support Vector Machine (SVM) and logistic regression algorithms to distinguish between different cognitive states using urinary metabolomics data. For instance, when comparing cognitively healthy controls to those with Mild Cognitive Impairment (MCI), our SVM model achieved an impressive Area Under the Curve (AUC) of 0.95, with a sensitivity of 0.75 and specificity of 0.77. Similarly, when differentiating between MCI and Alzheimer's Disease (AD), the SVM model using specific metabolites yielded an AUC of 0.95, with sensitivity and specificity values of 0.78 and 0.80, respectively. Logistic regression also performed well in certain comparisons, such as distinguishing healthy controls from AD sufferers, where it achieved an AUC of 0.90, with sensitivity and specificity values of 0.88 and 0.78, respectively. These results highlight the effectiveness of our classification models in diagnosing cognitive impairments based on urinary metabolite concentrations.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a rigorous process to ensure the robustness and generalizability of the models. A 10-fold cross-validation method was employed, which involved dividing the dataset into 10 subsets. The model was trained on 9 of these subsets and tested on the remaining one, with this process repeated 10 times, each time using a different subset as the test set. This approach allowed for a comprehensive evaluation of the model's performance, providing averages and standard deviations across the 10 rounds.\n\nThe performance of the models was assessed using several key metrics. The area under the curve (AUC) was calculated to evaluate the overall ability of the model to distinguish between different classes. Sensitivity and specificity were also reported to measure the model's performance in correctly identifying positive and negative cases, respectively.\n\nFor the comparison between healthy controls (HC) and mild cognitive impairment (MCI) sufferers, a support vector machine (SVM) model was developed using metabolites identified by the correlation-based feature selection (CFS) algorithm. This model achieved an AUC of 0.90, with sensitivity and specificity values of 0.75 and 0.77, respectively.\n\nIn the comparison between MCI and Alzheimer's disease (AD) sufferers, a different set of metabolites was used to develop an SVM model, resulting in an AUC of 0.95, with sensitivity and specificity values of 0.78 and 0.80, respectively.\n\nFor distinguishing cognitively healthy controls from AD sufferers, a logistic regression model was found to perform the best. This model utilized a specific set of metabolites and achieved an AUC of 0.90, with sensitivity and specificity values of 0.88 and 0.78, respectively.\n\nThe evaluation process also included the use of various statistical tests and data preprocessing steps to ensure the reliability of the results. Principal component analysis (PCA) was performed to identify potential outliers, and data normalization techniques such as log-transforming and autoscaling were applied to address the wide range of concentration values. Additionally, feature selection algorithms like LASSO and CFS were employed to identify the most informative metabolites for model development.\n\nOverall, the evaluation method involved a combination of cross-validation, statistical analysis, and performance metrics to thoroughly assess the effectiveness of the models in diagnosing cognitive impairment and Alzheimer's disease.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our diagnostic models. The primary metrics reported include the Area Under the Curve (AUC), sensitivity, specificity, and accuracy. These metrics were chosen for their widespread use and acceptance in the field of metabolomics and machine learning, ensuring that our results are comparable with existing literature.\n\nThe AUC is a crucial metric as it provides an aggregate measure of performance across all classification thresholds. It is particularly useful for evaluating the diagnostic ability of our models, with higher values indicating better performance. Sensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, assesses the proportion of actual negatives that are correctly identified. Both sensitivity and specificity are essential for understanding the model's ability to distinguish between different conditions, such as healthy controls, mild cognitive impairment (MCI), and Alzheimer's disease (AD).\n\nAccuracy, which is the ratio of correctly predicted samples to the total samples, provides a general measure of the model's performance. However, it is important to note that accuracy alone can be misleading, especially in imbalanced datasets. Therefore, we also report sensitivity and specificity to give a more nuanced view of the model's performance.\n\nIn addition to these metrics, we utilized a 10-fold cross-validation method to ensure the robustness and generalizability of our models. This approach helps to mitigate overfitting and provides a more reliable estimate of the model's performance on independent data. The use of cross-validation is standard practice in machine learning and metabolomics studies, further ensuring the representativeness of our reported metrics.\n\nOverall, the set of performance metrics we reported is representative of current standards in the field. By including AUC, sensitivity, specificity, and accuracy, along with cross-validation, we provide a thorough evaluation of our diagnostic models. This comprehensive approach allows for a clear and comparable assessment of our models' effectiveness in distinguishing between healthy controls, MCI sufferers, and AD sufferers.",
  "evaluation/comparison": "In our evaluation, we systematically compared the performance of two machine learning approaches: Support Vector Machines (SVM) and logistic regression. This comparison was conducted to classify the accuracy rate, sensitivity, and specificity when utilizing a panel of metabolites provided by two variable selection algorithms: Correlation-based Feature Selection (CFS) and Least Absolute Shrinkage and Selection Operator (LASSO).\n\nWe found that models built using a panel of urinary metabolites selected by the CFS method provided better Area Under the Curve (AUC) and sensitivity. However, models utilizing a panel of metabolites identified by LASSO as being important were more specific to Alzheimer's Disease (AD) and Mild Cognitive Impairment (MCI). This indicates that while CFS might be better for general classification performance, LASSO is more conservative and selects a subgroup of metabolites that are highly significant for diagnosis.\n\nAdditionally, we compared the performance of SVM and logistic regression models. Both models were evaluated using a 10-fold cross-validation process to ensure they were not overfitted and to assess their predictive power on an independent sample. The SVM algorithm searches for an optimal hyperplane separating the samples from two groups with a maximum distance to the training observations, which is called the margin. This makes SVM particularly effective when classes are overlapped. In contrast, logistic regression models the probability of a binary outcome.\n\nOur comparison also included an exhaustive search to obtain the best C-γ pair on a grid that was laid out on exponentially varying C and γ values. This process was employed to achieve the highest accuracy, which is the ratio of truly predicted samples. The area under the curve (AUC at 95% confidence interval), sensitivity, and specificity values were calculated to estimate the performance of both the logistic regression and SVM models.\n\nIn summary, our evaluation involved a thorough comparison of different machine learning approaches and variable selection algorithms to identify the most effective methods for diagnosing MCI and AD using urinary metabolites. This comparison was crucial in determining the best models for accurate and reliable diagnosis.",
  "evaluation/confidence": "The evaluation of our models included the calculation of confidence intervals for the performance metrics. Specifically, the area under the curve (AUC) values were reported with 95% confidence intervals (CI). For instance, when distinguishing healthy controls (HC) from mild cognitive impairment (MCI) sufferers, the SVM model achieved an AUC of 0.90 with a 95% CI ranging from 0.874 to 1.000. Similarly, for distinguishing MCI from Alzheimer's disease (AD), the AUC was 0.95 with a 95% CI from 0.874 to 1.000. These confidence intervals provide a measure of the reliability of the AUC estimates.\n\nStatistical significance was assessed using various tests. For normally distributed data, a Student’s t-test was employed, while non-normally distributed data were analyzed using the Mann–Whitney U test. A Bonferroni correction was applied to account for multiple comparisons, ensuring that the results were robust and not due to chance. Additionally, a one-way analysis of variance (ANOVA) was conducted to determine if sample demographics were statistically significantly different.\n\nThe models were developed using feature selection algorithms such as least absolute shrinkage and selection operator (LASSO) and correlation-based feature selection (CFS). These algorithms helped identify the most informative metabolites for model building. The models were then evaluated using a 10-fold cross-validation process to ensure they were not overfitted and to assess their predictive power on independent samples. This rigorous evaluation process, including the use of confidence intervals and statistical tests, provides a strong basis for claiming the superiority of our methods over baselines.",
  "evaluation/availability": "Not enough information is available."
}