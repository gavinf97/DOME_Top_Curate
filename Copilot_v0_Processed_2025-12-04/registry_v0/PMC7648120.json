{
  "publication/title": "MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer",
  "publication/authors": "The authors who contributed to the article are:\n\n- Almir G.V. Bitencourt\n- Peter Gibbs\n- Carolina Rossi Saccarelli\n- Isaac Dainiela\n- Roberto Lo Gullo\n- Michael J. Fox\n- Sunitha Thakur\n- Katja Pinker\n- Elizabeth A. Morris\n- Monica Morrow\n- Maxine S. Jochelson\n\nThe contributions of each author are not explicitly detailed in the provided information.",
  "publication/journal": "EBioMedicine",
  "publication/year": "2020",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Magnetic resonance imaging\n- Breast invasive ductal carcinoma\n- HER2\n- ErbB-2 receptor\n- Neoadjuvant therapy\n- Machine learning\n- Radiomics\n- Pathologic complete response\n- Breast cancer\n- HER2 overexpression",
  "dataset/provenance": "The dataset used in this study was sourced from a single center and consisted of 311 patients with HER2 overexpressing breast cancer who underwent neoadjuvant chemotherapy (NAC) and had pretreatment contrast-enhanced breast MRI. Initially, 445 consecutive patients were considered, but 70 were excluded due to the absence of pretreatment breast MRI, and 64 were excluded due to poor image quality from outside studies. Of the final 311 patients, 168 had MRI studies performed at the institution, while 143 had studies performed elsewhere. The dataset includes a variety of neoadjuvant treatment regimens, with the majority of patients receiving AC-THP (Adriamycin and Cyclophosphamide followed by Paclitaxel, Trastuzumab, and Pertuzumab). The dataset has not been used in previous papers by the community.",
  "dataset/splits": "The dataset was split into two primary sets for the prediction of pathological complete response (pCR). The data was divided at a ratio of 4:1, resulting in 80% of the data being used for the training set and 20% for the test set. Specifically, the training set consisted of 249 cases, with 150 cases showing pCR and 99 cases without pCR. The test set comprised 62 cases, with 38 cases showing pCR and 24 cases without pCR.\n\nFor the comparison between the immunohistochemistry (IHC) and fluorescence in situ hybridization (FISH) groups, the data was not split into training and test sets due to the low number of cases in the minority class. This approach was necessary to ensure that the model could be effectively trained and validated.",
  "dataset/redundancy": "The dataset used in this study consisted of 311 patients. For the prediction of pathological complete response (pCR), the data was split into training and test sets at a ratio of 4:1, meaning 80% of the data was used for training and 20% for testing. This split was done randomly, resulting in 249 cases in the training set and 62 cases in the test set. The training set included 150 cases with pCR and 99 cases without pCR, while the test set included 38 cases with pCR and 24 cases without pCR.\n\nThe training and test sets were independent, and this was enforced by the random splitting process. The distribution of the data in terms of pCR and non-pCR cases in the training and test sets is comparable to other machine learning datasets in medical imaging, where a similar split ratio is often used to ensure a sufficient number of cases for training the model while maintaining a separate set for evaluating its performance.\n\nHowever, due to the low number of cases in the minority class for the comparison between the IHC and FISH groups, this split was not feasible, and a different approach was used for that specific analysis.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is decision trees, specifically coarse decision trees. This algorithm is not new and is well-established in the field of machine learning. It was implemented using MATLAB, with the maximum number of splits set at four and utilizing Gini’s diversity index as the splitting criterion.\n\nThe decision to use this algorithm was driven by its suitability for the specific tasks at hand, which involved predicting HER2 expression levels and pathologic complete response (pCR) after neoadjuvant chemotherapy in HER2 overexpressing breast cancer patients. The algorithm's ability to handle both clinical and radiomic MRI features made it a strong choice for this study.\n\nThe focus of this research was on applying machine learning to medical imaging data, rather than developing a new algorithm. Therefore, the decision tree algorithm was chosen for its robustness and applicability to the dataset, ensuring that the study's findings were reliable and reproducible.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it directly utilizes clinical and radiomic MRI features as inputs for machine learning algorithms. The machine learning models were constructed using coarse decision trees, with a maximum of four splits and employing Gini's diversity index as the splitting criterion. The data was split into training and test sets at an 80:20 ratio for predicting pathologic complete response (pCR), ensuring that the training data was independent from the test data. This approach allowed for the validation of the model's performance on unseen data, thereby assessing its generalizability and robustness. The independence of the training data is clearly maintained, as the feature selection and model development were performed solely on the training set, with subsequent validation on the test set.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for analysis. Initially, the MRI images were segmented using ITK-SNAP software, focusing on the first post-contrast non-subtracted sequence. Enhancement maps were calculated as the percentage increase in signal from the pre-contrast image to the first post-contrast image. This process helped in highlighting the tumor regions more effectively.\n\nFor radiomics analysis, the data was reduced to a fixed bin number of 16 grey levels, which standardized the intensity values across different images. Only an interpixel distance of one was considered, ensuring that the texture features were computed based on adjacent pixels. This approach helped in capturing the local patterns within the tumor regions.\n\nThe radiomics features were computed using MATLAB and CERR software, which conformed to the Image Biomarker Standardisation Initiative (IBSI) guidelines. This ensured that the features were consistent and comparable across different studies. The analysis resulted in 102 texture parameters, sub-divided into six categories: first-order statistics, grey level co-occurrence matrices, run length matrices, size zone matrices, neighborhood grey level dependence matrices, and neighborhood grey tone difference matrices. These features provided a comprehensive description of the tumor's texture and structure.\n\nTo address the issue of non-isotropic data, each 2D directional matrix was averaged over 2D directions and slices. This step was crucial because the data was not isotropic, meaning the resolution was different in different directions. Averaging helped in creating a more uniform representation of the tumor features.\n\nAdditionally, Combat harmonisation was performed to remove the center effect, which accounted for differences between local and foreign scans. This process employed Bayes estimates to handle both additive and multiplicative scanner effects, ensuring that the pathophysiologic information related to HER2 expression or pathologic response was retained.\n\nUnivariate analysis was initially performed to identify significant parameters. Continuous variables were described using mean, standard deviation, and range. The Mann-Whitney U test was used to determine significant differences between groups. Correlation analysis was then employed to remove redundant parameters, ensuring that only the most informative features were advanced to model development. Parameters with highly positive or negative correlations were evaluated, and those with the lowest area under the receiver operating curve (AUROC) were removed.\n\nIn summary, the data encoding and preprocessing involved segmentation, enhancement mapping, grey level standardization, feature computation, averaging of directional matrices, harmonisation, and statistical analysis. These steps ensured that the data was well-prepared for the machine-learning algorithm, providing a robust foundation for predicting HER2 expression levels and pathologic response.",
  "optimization/parameters": "In our study, the number of parameters used in the models varied depending on the specific prediction task. For predicting HER2 intratumour expression levels, the final model utilized three MRI parameters: two clinical parameters (lesion type and multifocality) and one radiomic parameter (large zone emphasis). This selection was based on a combination of univariate analysis and correlation analysis to ensure that the parameters were significant and not redundant.\n\nFor predicting pathologic complete response (pCR), the model included six MRI parameters: two clinical parameters (lesion type and size) and four radiomic parameters (variance, entropy, 90th percentile, and zone length variance). These parameters were selected through a similar process of univariate analysis and correlation analysis, followed by model development using coarse decision trees and five-fold cross-validation.\n\nThe selection of parameters was guided by their statistical significance and the need to avoid redundancy. For instance, parameters with highly positive or negative correlations were evaluated, and those with the lowest area under the receiver operating curve (AUROC) were removed to ensure that the final model was efficient and effective. This approach helped in retaining the most relevant features for accurate predictions.",
  "optimization/features": "In the optimization process, both clinical and radiomic MRI parameters were utilized as input features. For the prediction of pathologic complete response (pCR), a total of six MRI parameters were used, which included two clinical parameters (lesion type and size) and four radiomic parameters (variance, first-order entropy, 90th percentile, and zone length variance).\n\nFeature selection was indeed performed to identify the most significant parameters. This selection process was conducted exclusively on the training set, ensuring that the model's performance on the test set remained unbiased. The training set consisted of 249 cases, while the test set had 62 cases. The data was split in a 4:1 ratio, with 80% of the data used for training and 20% for testing.\n\nThe feature selection involved univariate analysis to identify significant parameters, followed by correlation analysis to remove redundant parameters. Parameters with highly positive or negative correlations were evaluated, and those with the lowest area under the receiver operating curve (AUROC) were excluded. This method ensured that only the most relevant features were advanced to the modeling stage, enhancing the model's predictive accuracy.",
  "optimization/fitting": "The study utilized machine learning models to predict HER2 expression levels and pathologic complete response (pCR) in HER2 overexpressing breast cancer patients. The dataset consisted of 311 patients, with the data split into training and test sets at a ratio of 4:1 (80% training and 20% test) for predicting pCR. This split ensures that the model is trained on a sufficiently large dataset, reducing the risk of overfitting.\n\nTo address the potential issue of overfitting, especially given the complexity of radiomic features, several strategies were employed. Initially, univariate analysis was performed to identify significant parameters. Continuous variables were described using mean, standard deviation, and range. The Mann-Whitney U test was used to determine significant differences between groups. Correlation analysis was then employed to remove redundant parameters, ensuring that only the most informative features were retained for model development.\n\nFor the prediction of pCR, coarse decision trees with a maximum of four splits were used, utilizing Gini’s diversity index as the splitting criterion. This approach helps in creating a model that is not overly complex, thereby reducing the risk of overfitting. Additionally, five-fold cross-validation was implemented during the training phase to further validate the model's performance and generalizability.\n\nThe final models included both clinical and radiomic MRI parameters. For HER2 expression levels, the model utilized three MRI parameters (two clinical and one radiomic), achieving high sensitivity, specificity, and diagnostic accuracy. For pCR prediction, the model included six MRI parameters (two clinical and four radiomic), demonstrating robust performance in both the training and test sets.\n\nThe diagnostic accuracy of the models was compared with models developed using only clinical parameters, showing a significant improvement when radiomic features were included. This indicates that the models are not underfitting and are effectively capturing the relevant information from the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method was the use of coarse decision trees with a limited number of splits. Specifically, we set the maximum number of splits to four, which helps to simplify the model and reduce the risk of overfitting to the training data. Additionally, we utilized Gini's diversity index as the splitting criterion, which is effective in creating balanced and informative splits.\n\nAnother crucial technique was the use of five-fold cross-validation. This method involves dividing the training data into five subsets, training the model on four of these subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. Cross-validation helps to ensure that the model generalizes well to unseen data by providing a more comprehensive evaluation of its performance.\n\nFurthermore, we performed feature selection to retain only the most relevant parameters. This involved univariate analysis to identify significant parameters, followed by correlation analysis to remove redundant features. Parameters with highly positive or negative correlations were evaluated based on their area under the receiver operating curve (AUROC), and those with the lowest AUROC were removed. This step helps to reduce the dimensionality of the data and focus on the most informative features, thereby minimizing the risk of overfitting.\n\nFor the prediction of pathological complete response (pCR), we split the data into training and test sets at a ratio of 4:1 (80% training and 20% test). This split ensures that the model is trained on a substantial amount of data while still having a separate test set to evaluate its performance on unseen data. The feature selection process was performed purely on the training set, further ensuring that the model's performance on the test set is a true reflection of its generalization capability.\n\nIn summary, our approach to preventing overfitting included the use of coarse decision trees, five-fold cross-validation, rigorous feature selection, and a clear separation of training and test data. These techniques collectively contribute to the development of robust and generalizable machine learning models.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black box but rather a transparent one, as it utilizes a combination of clinical and radiomic MRI parameters to make predictions. The transparency of the model is evident in the selection and interpretation of the features used.\n\nFor predicting HER2 intratumour expression levels, the final model incorporated three MRI parameters: two clinical parameters (lesion type and multifocality) and one radiomic parameter (large zone emphasis). These parameters were chosen based on their statistical significance and their ability to improve the model's predictive performance. The inclusion of large zone emphasis, a radiomic feature, highlights the model's capacity to extract meaningful information from MRI images that is not immediately apparent to the human eye.\n\nSimilarly, the model for predicting pathologic complete response (pCR) included six MRI parameters: two clinical parameters (lesion type and size) and four radiomic parameters (variance, entropy, 90th percentile, and zone length variance). These radiomic features were selected through a rigorous process involving correlation and area under the curve analysis, ensuring that they contributed significantly to the model's accuracy.\n\nThe clinical parameters selected in the final models did not necessarily have a statistically significant association with the outcome in univariate analysis. This underscores the importance of the radiomic features in enhancing the model's predictive power. For instance, larger tumour size was the only clinical parameter retained that showed a statistically significant correlation to pCR in univariate analysis. However, even though ER status was a significant parameter to predict pCR in univariate analysis, it was not retained in the final model, further emphasizing the value of radiomic features.\n\nIn summary, the model's transparency is demonstrated through the clear selection and interpretation of both clinical and radiomic features. The use of radiomic parameters, in particular, adds a layer of interpretability by showing how specific image characteristics can influence the predictions made by the model. This transparency is crucial for building trust in the model's predictions and for facilitating its integration into clinical practice.",
  "model/output": "The models developed in this study are classification models. Specifically, they are designed to predict categorical outcomes rather than continuous values. The first model predicts HER2 intratumour expression levels, classifying cases as either immunohistochemistry (IHC) or fluorescence in situ hybridisation (FISH). The second model predicts pathologic complete response (pCR) after neoadjuvant chemotherapy, classifying cases as either achieving pCR or not.\n\nThe classification nature of these models is evident in the evaluation metrics provided, such as sensitivity, specificity, positive predictive value, negative predictive value, and diagnostic accuracy. These metrics are commonly used to assess the performance of classification models in medical diagnostics.\n\nThe models utilize a combination of clinical and radiomic MRI parameters. For predicting HER2 expression levels, the final model uses three parameters: two clinical (lesion type and multifocality) and one radiomic (large zone emphasis). For predicting pCR, the final model includes six parameters: two clinical (lesion type and size) and four radiomic (variance, entropy, 90th percentile, and zone length variance).\n\nThe performance of these classification models is evaluated using a training set and a test set. The training set is used to develop the model, while the test set is used to evaluate its generalizability and performance on unseen data. The results demonstrate that the inclusion of radiomic features significantly improves the diagnostic accuracy of the models compared to using clinical parameters alone. This highlights the value of radiomics in enhancing the predictive power of machine learning models in medical imaging.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and accuracy. Initially, univariate analysis was conducted to identify significant parameters, with continuous variables described using mean, standard deviation, and range. The Mann-Whitney U test was used to determine significant differences between groups. Correlation analysis was then employed to remove redundant parameters, retaining those with significant differences between groups for model development.\n\nFor predicting pathological complete response (pCR), the data was split into training and test sets at a ratio of 4:1 (80% training and 20% test). Feature selection was performed purely on the training set. Due to the low number of cases in the minority class, this approach was not feasible for the comparison between the IHC and FISH groups. Machine learning models were developed using coarse decision trees and five-fold cross-validation. The maximum number of splits was set at four, utilizing Gini’s diversity index as the splitting criterion. Model development for predicting pCR was performed on the training set and then validated on the test set.\n\nThe final model to predict HER2 intratumour expression levels utilized three MRI parameters: two clinical parameters (lesion type and multifocality) and one radiomic parameter (large zone emphasis). This model achieved a sensitivity of 99.3%, specificity of 81.3%, and diagnostic accuracy of 97.4%.\n\nFor predicting pCR, the model included six MRI parameters: two clinical parameters (lesion type and size) and four radiomic parameters (variance, first-order entropy, 90th percentile, and zone length variance). In the training set, the model achieved a sensitivity of 87.4%, specificity of 81.6%, and diagnostic accuracy of 85.1%. In the test set, the model achieved a sensitivity of 86.5%, specificity of 80.0%, and diagnostic accuracy of 83.9%. These results were independent of age and ER status and outperformed the best model developed using clinical parameters only.",
  "evaluation/measure": "In our study, we reported several performance metrics to evaluate the effectiveness of our models. For the model predicting HER2 intratumour expression levels, we provided sensitivity, specificity, positive predictive value, negative predictive value, and diagnostic accuracy. The model achieved a sensitivity of 99.3%, specificity of 81.3%, positive predictive value of 97.9%, negative predictive value of 92.9%, and diagnostic accuracy of 97.4%.\n\nFor the model predicting pathological complete response (pCR), we reported similar metrics for both the training and test sets. In the training set, the model had a sensitivity of 87.4%, specificity of 81.6%, positive predictive value of 88.0%, negative predictive value of 80.8%, and diagnostic accuracy of 85.1%. In the test set, the sensitivity was 86.5%, specificity was 80.0%, positive predictive value was 86.5%, negative predictive value was 80.0%, and diagnostic accuracy was 83.9%. All these metrics were accompanied by their respective 95% confidence intervals.\n\nAdditionally, we compared the diagnostic accuracy of our radiomics model with a model using only clinical features. The clinical features model achieved a diagnostic accuracy of 65.9% in the training set and 72.6% in the test set. The significant difference in diagnostic accuracy between the two models highlighted the value of including radiomic features.\n\nThese performance metrics are commonly reported in the literature for similar studies, making our set of metrics representative and allowing for meaningful comparisons with other research in the field. The inclusion of sensitivity, specificity, positive and negative predictive values, and diagnostic accuracy provides a comprehensive evaluation of our models' performance.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, we focused on evaluating the performance of our machine learning models using both clinical and radiomic MRI parameters within our own dataset.\n\nHowever, we did conduct a comparison with simpler baselines to assess the value of including radiomic features. Specifically, we utilized six clinical features and exhaustively tested all possible combinations. The best results obtained from this approach were a diagnostic accuracy of 65.9% for the training set and 72.6% for the test set. In contrast, our radiomics model, which included both clinical and radiomic features, achieved a significantly higher diagnostic accuracy of 85.1% in the training set and 83.9% in the test set. This comparison demonstrated the added value of incorporating radiomic features into the predictive models.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, each accompanied by confidence intervals to provide a measure of uncertainty. For instance, the model predicting HER2 intratumour expression levels achieved a sensitivity of 99.3% (277/279), specificity of 81.3% (26/32), positive predictive value of 97.9% (277/283), negative predictive value of 92.9% (26/28), and diagnostic accuracy of 97.4% (303/311). These metrics were presented with confidence intervals, indicating the reliability of our estimates.\n\nFor the prediction of pathologic complete response (pCR), the model demonstrated a sensitivity of 87.4% (95% CI: 81.1%–92.3%), specificity of 81.6% (95% CI: 72.5%–88.7%), positive predictive value of 88.0% (95% CI: 82.8%–91.8%), negative predictive value of 80.8% (95% CI: 73.2%–86.6%), and diagnostic accuracy of 85.1% (95% CI: 80.1%–89.3%) in the training set. In the test set, the model achieved a sensitivity of 86.5% (95% CI: 71.2%–95.5%), specificity of 80.0% (95% CI: 59.3%–93.2%), positive predictive value of 86.5% (95% CI: 74.3%–93.4%), negative predictive value of 80.0% (95% CI: 63.4%–90.2%), and diagnostic accuracy of 83.9% (95% CI: 72.3%–92.0%).\n\nStatistical significance was assessed to compare the diagnostic accuracy of our radiomics model with a model using only clinical features. The comparison revealed a significant difference (p = 0.029, comparison of proportion Chi-squared test), indicating that the inclusion of radiomic features significantly improved the model's performance. This statistical analysis supports the claim that our method, which integrates both clinical and radiomic MRI parameters, is superior to approaches relying solely on clinical features.",
  "evaluation/availability": "Not enough information is available."
}