{
  "publication/title": "Multiplex Networks Characterize Seizure Development",
  "publication/authors": "The authors who contributed to the article are:\n\n- ML: Conceived and conducted the analyses.\n- RG: Analyzed the results and reviewed the manuscript.\n- NA: Analyzed the results and reviewed the manuscript.\n- EL: Analyzed the results and reviewed the manuscript.\n- MM: Analyzed the results and reviewed the manuscript.\n- PV: Analyzed the results and reviewed the manuscript.\n- AT: Analyzed the results and reviewed the manuscript.\n- DD: Analyzed the results and reviewed the manuscript.",
  "publication/journal": "Frontiers in Neuroscience",
  "publication/year": "2020",
  "publication/doi": "10.3389/fnins.2020.591662",
  "publication/tags": "- Traumatic Brain Injury\n- Seizure Development\n- Multiplex Networks\n- Machine Learning\n- Random Forest Classifier\n- Epilepsy Prediction\n- Brain Imaging\n- MRI Scans\n- Feature Selection\n- Cross-Validation\n- Network Metrics\n- TBI Patients\n- Epileptogenesis\n- Patch-Based Approach\n- Clinical Validation",
  "dataset/provenance": "The dataset used in this study was sourced from the Epilepsy Bioinformatics Study for Antiepileptogenic Therapy (EpiBioS4Rx) database. This database is a large, international, multi-site Center without Walls (CWOW) that has been collecting longitudinal EEG, imaging, and blood data from human patients and an animal model. The primary goal of EpiBioS4Rx is to identify biomarkers of epileptogenesis after a traumatic brain injury and to provide therapies and treatments that may stop the development of post-traumatic epilepsy.\n\nThe dataset consists of 53 structural MRI scans of TBI subjects. Out of these, 16 subjects have experienced at least one seizure within 6 months of a TBI, while 37 have not experienced any seizures. The MRI scans were acquired within 32 days after the TBI using 3T Siemens, Philips, and GE scanners according to a magnetization-prepared rapid acquisition gradient echo (MPRAGE) sequence. The specific parameters for the MRI scans include a field of view (FOV) of 256 mm, 1 mm slice thickness, repetition time (TR) of 1,500–2,500 ms, minimum echo time (TE), inversion time (TI) of 1,100–1,500 ms, flip angle of 8–15 degrees, 256 phase-encoding steps, number of excitations (NEX) greater than 1, and 256 Hz frequency.\n\nThe data used in this study has been made available through the EpiBioS4Rx database, which is funded by the National Institute of Neurological Disorders and Stroke (NINDS) of the National Institutes of Health (NIH). The database includes a variety of clinical and demographic information, which has been used in previous studies and by the community to advance the understanding of epileptogenesis and traumatic brain injury.",
  "dataset/splits": "In our study, we employed a machine learning pipeline that involved 1,000 rounds of stratified cross-validation. For each round, we ensured balanced datasets by randomly selecting the same percentage of seizure-free subjects and seizure-affected subjects. This process resulted in two primary data splits within each round: a training set and a validation set. The training set comprised 80% of the stratified data, while the validation set consisted of the remaining 20%.\n\nThe dataset consisted of 53 structural MRI scans of TBI subjects, with 16 subjects having experienced at least one seizure within 6 months of a TBI and 37 subjects having not experienced any seizures. This distribution was maintained across the cross-validation rounds to ensure that the models were trained and validated on representative samples of the data.\n\nThe stratified approach helped in mitigating class imbalance issues, which is crucial for reliable classification models, especially in medical diagnostics where the classes are often imbalanced. By using stratified cross-validation, we aimed to enhance the generalizability of our findings and ensure that the models could accurately identify TBI patients who have developed seizures.",
  "dataset/redundancy": "In our study, we employed a rigorous machine learning pipeline to ensure the independence and robustness of our training and validation sets. The dataset consisted of 53 structural MRI scans of TBI subjects, with 16 subjects having experienced seizures and 37 remaining seizure-free. To maintain the independence of the training and test sets, we utilized a stratified cross-validation approach with 1,000 rounds. In each round, the dataset was stratified to ensure an equal percentage of seizure-free and seizure-affected subjects. This stratified set was then split into a training set (80%) and a validation set (20%).\n\nTo prevent data leakage and the \"double dipping\" problem, the feature selection and training phases were nested within each cross-validation round and were blind to the validation set. This means that the features selected and the models trained were based solely on the training set, ensuring that the validation set remained independent and unbiased. The classiﬁcation models and important features retrieved during the training phase were then used to classify the subjects in the validation set.\n\nThe distribution of our dataset is comparable to other machine learning studies in the field, with a focus on maintaining a balanced representation of both clinical classes. The use of stratified cross-validation ensures that our results are generalizable and not dependent on a particular split of the data. This approach is particularly important given the high-dimensional feature space and the relatively small sample size, which are common challenges in medical imaging studies.",
  "dataset/availability": "The data analyzed in this study is not publicly available. Access to the data must be requested and approved by the EpiBioS4Rx steering committee. This ensures that the data is used appropriately and in accordance with the study's guidelines. Requests to access these datasets should be directed to epibiossteeringcommittee@loni.usc.edu. This controlled access approach is enforced to maintain the integrity and ethical use of the data, which includes structural MRI scans and clinical information of TBI subjects. The data is subject to specific licenses and restrictions, which are managed by the steering committee to ensure compliance with ethical standards and data protection regulations.",
  "optimization/algorithm": "The machine-learning algorithm class used is the Random Forest (RF) classifier. This choice was made due to its robustness, ease of tuning, and suitability for high-dimensional feature spaces and small sample sizes. The RF model is particularly effective because it does not overfit thanks to internal bagging, which involves creating multiple decision trees and combining their results to improve the overall performance and accuracy of the model.\n\nThe RF algorithm is not new; it has been extensively used and validated in various fields, including neuroscience. The decision to use RF in this context was driven by its proven effectiveness in handling complex data and its ability to provide reliable classification models. The algorithm's internal mechanisms, such as bootstrapping and feature subset selection, make it well-suited for the task of identifying which traumatic brain injury (TBI) patients have developed seizures and which have not.\n\nThe focus of this work is on applying established machine-learning techniques to a specific medical problem rather than developing a new algorithm. Therefore, the publication is more aligned with the domain of neuroscience and medical research, where the primary goal is to advance understanding and treatment of neurological conditions. The RF classifier's performance was evaluated through rigorous cross-validation processes, ensuring the reliability and generalizability of the results. This approach aligns with the standards of the field and provides valuable insights into seizure development in TBI patients.",
  "optimization/meta": "The model employed in this study does not function as a meta-predictor. Instead, it relies on a single machine learning algorithm, specifically the Random Forest (RF) classifier. This classifier is used to analyze multiplex network features derived from brain imaging data to identify which traumatic brain injury (TBI) patients have developed seizures and which have not.\n\nThe RF classifier is utilized in a structured machine learning pipeline that includes 1,000 rounds of stratified cross-validation. In each round, the dataset is stratified to ensure a balanced representation of seizure-free and seizure-affected subjects. The training set, comprising 80% of the stratified data, is used to select important features and train the RF classifier. The remaining 20% serves as the validation set to evaluate the classifier's performance.\n\nThe internal bagging process within the RF classifier involves creating 500 bootstraps from the training set, each used to grow 500 decision trees. This method helps to prevent overfitting and enhances the robustness of the model. Each tree is constructed by randomly selecting a subset of features, equal to the square root of the total number of features, ensuring that the model generalizes well to unseen data.\n\nThe independence of the training data is maintained through the cross-validation process. Each round of cross-validation ensures that the training and validation sets are distinct, preventing any overlap that could lead to biased results. This rigorous approach helps to validate the model's performance and ensures that the features selected are truly indicative of seizure development in TBI patients.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved several key steps to prepare the data for the machine-learning algorithm. Initially, each subject's scan was preprocessed and segmented into patches. For each subject, a weighted undirected network was constructed, and various complex network features were computed. These features were then used to create a feature representation for each subject, which included the subject's network features.\n\nBefore feeding the data into the machine-learning pipeline, we removed features with null mean and variance, as well as highly correlated features (correlation coefficient greater than 0.95). This step was crucial to ensure that the features used for training were informative and not redundant.\n\nThe machine-learning pipeline involved 1,000 rounds of stratified cross-validation. In each round, the dataset was stratified to ensure a balanced representation of seizure-free subjects and seizure-affected subjects. The stratified dataset was then split into a training set (80% of the data) and a validation set (20% of the data). A nested Random Forest (RF) classifier was used on the training set to select features that exceeded the third quartile of the importance distribution, computed in terms of mean accuracy decrease. These selected features were then used to train a second RF classifier, which was evaluated on the validation set.\n\nThe RF model was chosen for its robustness, ease of tuning, and suitability for high-dimensional feature spaces and small sample sizes. Each forest was grown with 500 trees, and the internal bagging process involved forming 500 bootstraps from the training set. Each tree was grown by randomly choosing a subset of features equal to the square root of the total number of features. This approach helped to compute the out-of-bag error and the accuracy on the data left out of the training set, ensuring a reliable evaluation of the model's performance.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the scale of the patch volume. For each scale, we obtained a feature representation with dimensions M (subject network number) by 8N, where N is the number of nodes in the network. This resulted in a high-dimensional feature space, which is characteristic of our approach.\n\nThe selection of the number of features was not arbitrary but was guided by the nature of the data and the requirements of the Random Forest (RF) classifier. The RF model is particularly well-suited for high-dimensional data and small sample sizes, making it an appropriate choice for our analysis. The internal bagging process of the RF, which involves creating 500 bootstraps from the training set to grow 500 trees, helps to mitigate overfitting and ensures robust feature selection.\n\nEach tree in the forest was grown by randomly choosing a subset of features equal to the square root of the total number of features. This approach helps to decorrelate the trees and improve the generalization performance of the model. The feature selection process was further refined by removing features with null mean and variance, as well as highly correlated features (correlation coefficient > 0.95). This step ensured that only the most informative and independent features were used for classification.\n\nThe optimal patch volumes for classification were determined to be 1,000, 3,000, and 5,000 voxels, based on the mean and standard deviations of accuracy and AUC over 1,000 rounds of stratified cross-validation. These patch volumes yielded the best classification performances, indicating that they captured the most relevant information for distinguishing between the two clinical groups.\n\nIn summary, the number of parameters used in the model was determined by the dimensionality of the feature representation at each scale, and the selection of features was guided by the requirements of the RF classifier and the need to ensure robust and generalizable classification performance.",
  "optimization/features": "The input features for the machine learning pipeline are derived from multiplex network features computed for each subject. These features are obtained by segmenting each subject's scan into patches and then constructing a weighted undirected network for each subject. The feature representation consists of a subject-by-network features matrix, where the number of features (f) varies depending on the scale (V) of the patch volume. For each scale, a feature representation with 8N features is obtained, where N is the number of nodes in the network.\n\nFeature selection is performed within the machine learning pipeline to ensure that only the most relevant features are used for classification. This process involves using a nested Random Forest (RF) classifier on the training set to select features that exceed the third quartile of the importance distribution, computed in terms of mean accuracy decrease. This feature selection step is crucial for avoiding the \"double dipping\" problem, where the same data is used for both feature selection and model training. By performing feature selection within each cross-validation round and using only the training set, the risk of overfitting and biased results is minimized. The selected features are then used to train a second RF classifier, which is evaluated on the validation set to assess classification performance.",
  "optimization/fitting": "The fitting method employed in this study utilized a Random Forest (RF) classifier, which is particularly well-suited for handling high-dimensional feature spaces and small sample sizes. The number of parameters in our model is indeed much larger than the number of training points, a common scenario in complex network analyses.\n\nTo address the risk of over-fitting, several strategies were implemented. Firstly, the RF model inherently mitigates over-fitting through internal bagging. This process involves creating 500 bootstraps from the training set, each used to grow a separate tree. Each tree is constructed by randomly selecting a subset of features equal to the square root of the total number of features, ensuring that the model does not become too specialized to the training data.\n\nAdditionally, a nested cross-validation approach was used, which includes 1,000 rounds of stratified cross-validation. This method ensures that the feature selection and training phases are blind to the validation set, preventing the \"double dipping\" problem. The features selected for each round were those exceeding the third quartile of the importance distribution, computed in terms of mean accuracy decrease. This rigorous feature selection process helps in identifying the most relevant features while avoiding over-fitting.\n\nTo rule out under-fitting, the model's performance was evaluated across multiple patch volumes (1,000, 3,000, and 5,000 voxels), and the best classification performances were observed at these scales. The model's accuracy, specificity, sensitivity, and AUC were computed and found to be statistically comparable across these scales, indicating that the model generalizes well to different patch sizes.\n\nFurthermore, the removal of null mean and variance features, as well as highly correlated features (correlation > 0.95), before training the RF classifier, ensures that only informative features are used. This preprocessing step helps in reducing the dimensionality of the feature space and improving the model's ability to generalize to new data.\n\nIn summary, the use of RF with internal bagging, nested cross-validation, and careful feature selection and preprocessing helps in mitigating both over-fitting and under-fitting, ensuring a robust and reliable classification model.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our machine learning models. One of the primary methods used was internal bagging within the Random Forest (RF) classifier. This technique involves creating multiple subsets of the training data through bootstrapping, which helps to reduce overfitting by averaging the results of multiple decision trees. Each tree in the forest is grown using a random subset of features, further enhancing the model's ability to generalize to unseen data.\n\nAdditionally, we implemented a nested cross-validation approach. This method involves performing cross-validation within each round of the outer cross-validation loop. Specifically, we used a nested RF classifier to select features that exceeded the third quartile of the importance distribution, computed in terms of mean accuracy decrease. This feature selection process was nested within each cross-validation round and was blind to the validation set, thereby avoiding the \"double dipping\" problem. This ensures that the feature selection and model training phases are independent, reducing the risk of overfitting.\n\nFurthermore, we removed features with null mean and variance, as well as highly correlated features (correlation coefficient > 0.95), before training the models. This step helps to eliminate redundant and irrelevant information, making the model more efficient and less prone to overfitting.\n\nThe use of 1,000 rounds of stratified cross-validation also contributed to the robustness of our models. By ensuring that each round had a balanced dataset of seizure-free and seizure-affected subjects, we maintained the integrity of the classification process and reduced the likelihood of overfitting.\n\nOverall, these techniques collectively helped to mitigate overfitting and enhance the reliability of our classification models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the text. Specifically, the Random Forest (RF) classifier was configured with 500 trees, which is a sufficient number to reach the typical training plateau for the out-of-bag error. The feature subset for each tree was randomly chosen to be equal to the square root of the total number of features. This configuration ensures robustness and prevents overfitting, making it suitable for high-dimensional feature spaces and small sample sizes.\n\nThe optimization parameters, such as the number of cross-validation rounds (1,000) and the stratification process to balance the datasets, are also clearly described. The feature selection process, which involves removing null mean and variance features and highly correlated features (correlation coefficient > 0.95), is part of the optimization pipeline. Additionally, the use of nested cross-validation helps in avoiding the \"double dipping\" problem, ensuring that the feature selection and training phases are blind to the validation set.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the text. However, the methods and configurations described are standard practices in machine learning and can be replicated using commonly available tools and libraries. The text does not mention any specific licenses or repositories where the model files or optimization parameters can be accessed. Therefore, while the configurations and schedules are thoroughly documented, the actual model files and optimization parameters are not made explicitly available.",
  "model/interpretability": "The model employed in this study is not entirely a black box. While the Random Forest (RF) classifier, which is the core of the machine learning pipeline, is known for its robustness and ability to handle high-dimensional data, it is also recognized for its interpretability to some extent. The RF model provides insights into feature importance, allowing us to understand which features contribute most to the classification of TBI patients who have developed seizures versus those who have not.\n\nThe pipeline includes a feature selection process where a nested RF classifier is used to identify and record features that exceed the third quartile of the importance distribution. This step ensures that only the most relevant features are used for training the final RF classifier. By examining these important features, it is possible to gain insights into the underlying mechanisms of seizure development in TBI patients.\n\nAdditionally, the study goes beyond feature importance by identifying the most important network nodes or patches, which correspond to specific anatomical regions in the brain. This is achieved by considering the occurrence of important features across multiple cross-validation rounds and applying statistical tests to ensure that these occurrences are not due to chance. The anatomical regions are then labeled using Talairach labels projected in MNI 152 space, providing a clear mapping of the important features to specific brain areas.\n\nThis approach allows for a more transparent understanding of the model's decisions, as it not only identifies important features but also links them to specific anatomical regions. This interpretability is crucial for clinical applications, as it helps clinicians localize the epileptogenic focus more precisely and relate brain lesions to seizure occurrence. However, while the model provides valuable insights, it is important to note that the interpretability is still limited by the complexity of the RF algorithm and the high-dimensional nature of the data.",
  "model/output": "The model employed is a classification model. Specifically, a Random Forest (RF) classifier was used to identify which traumatic brain injury (TBI) patients have developed seizures and which have not. The classification process involved a machine learning pipeline that included 1,000 rounds of stratified cross-validation. For each round, the dataset was stratified to ensure balanced representation of seizure-free and seizure-affected subjects. The training set, comprising 80% of the stratified data, was used to select important features and train the classifier, while the remaining 20% served as the validation set. The model's performance was evaluated based on accuracy, specificity, sensitivity, and the Area Under the receiver-operating-characteristic Curve (AUC), averaged over all cross-validation rounds. The best classification performances were observed at patch volumes of 1,000, 3,000, and 5,000 voxels. The RF model was chosen for its robustness, ease of tuning, and suitability for high-dimensional feature spaces and small sample sizes. Each forest was grown with 500 trees, ensuring the out-of-bag error reached a typical training plateau. The model's output includes the classification of subjects into seizure-free and seizure-affected categories, along with the identification of important features and anatomical regions related to seizure development.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a robust machine learning pipeline designed to assess the classification performance of our models. We utilized 1,000 rounds of stratified cross-validation to ensure the reliability and generalizability of our results. In each round, the dataset was stratified to maintain an equal percentage of seizure-free and seizure-affected subjects, ensuring balanced datasets. The stratified dataset was then split into a training set (80%) and a validation set (20%).\n\nA nested Random Forest (RF) classifier was used within each cross-validation round. The first RF classifier was employed to select features that exceeded the third quartile of the importance distribution, as measured by mean accuracy decrease. These selected features were then used to train a second RF classifier, which generated the classification models. This nested approach helped to avoid the \"double dipping\" problem, ensuring that the feature selection and training phases were blind to the validation set.\n\nThe classification performance was evaluated using metrics such as accuracy, specificity, sensitivity, and the Area Under the receiver-operating-characteristic Curve (AUC). These metrics were averaged over all cross-validation rounds to provide a comprehensive assessment of the model's performance. Additionally, the 95% confidence interval for the average accuracy was computed using the Wilson score interval.\n\nThe study also compared the patch-based network approach with a standard Region of Interest (ROI)-based approach using features obtained from the FreeSurfer package. This comparison aimed to evaluate the efficacy of the proposed complex network methodology in predicting seizure development in Traumatic Brain Injury (TBI) patients.\n\nThe evaluation method ensured that the models were robust and that the selected features were genuinely important for distinguishing between the two clinical groups. The use of stratified cross-validation and the nested RF classifier approach provided a rigorous framework for assessing the classification performance and the relevance of the network features.",
  "evaluation/measure": "In our study, we evaluated the performance of our classification models using several key metrics to ensure a comprehensive assessment. The primary metrics reported are accuracy, specificity, sensitivity, and the Area Under the Curve (AUC) of the receiver-operating-characteristic curve. These metrics were chosen because they provide a well-rounded view of the model's performance across different aspects.\n\nAccuracy measures the overall correctness of the model by calculating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Specificity, on the other hand, focuses on the true negative rate, indicating how well the model identifies seizure-free subjects. Sensitivity, or the true positive rate, assesses the model's ability to correctly identify seizure-affected subjects. The AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds, offering a comprehensive measure of the model's discriminative ability.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in medical and neurological studies. They are representative of the standard practices in the field, ensuring that our results can be compared and validated against other similar studies. By reporting these metrics, we aim to provide a clear and transparent evaluation of our model's performance, highlighting its strengths and areas for potential improvement.",
  "evaluation/comparison": "In our study, we conducted a comparison between our patch-based network approach and a standard ROI-based approach to evaluate the efficacy of our complex network methodology in predicting seizure development in TBI patients. We utilized the publicly available brain segmentation package, FreeSurfer (FS) v.6.0, which automatically performs various steps such as brain extraction, intensity normalization, spatial registration, volume labeling, segmentation, and computation of morphological features from each image. This tool allowed us to obtain 182 features for each MRI scan, including subcortical and cortical gray matter parcellations, white matter parcellations, total gray and white matter volumes, and intracranial volume. These features were then used to distinguish TBI subjects who have developed epilepsy from those who have not, using the same machine learning pipeline employed for the complex network features.\n\nThe comparison involved using these FS features within the same machine learning framework that we applied to our multiplex network features. This allowed us to assess whether our patch-based approach provided any additional insights or improvements over the more traditional ROI-based method. By doing so, we aimed to validate the robustness and potential advantages of our complex network methodology in the context of seizure prediction in TBI patients.",
  "evaluation/confidence": "The evaluation of our method includes confidence intervals for the performance metrics. Specifically, for the average accuracy, we reported the 95% confidence interval computed according to the Wilson score interval. This provides a measure of the reliability of our accuracy estimates.\n\nThe classification performances at the three optimal patch volumes (1,000, 3,000, and 5,000 voxels) are statistically comparable. This means that while there are slight variations in performance metrics like accuracy and AUC across these patch volumes, these differences are not statistically significant. Therefore, any of these patch volumes can be considered effective for our classification task.\n\nAdditionally, the statistical significance of the important features was evaluated using the statistical test of equal or given proportions, followed by a Bonferroni correction for multiple comparisons. This ensures that the features identified as important are not due to chance. The most important features were determined by considering a p-value threshold adjusted for multiple comparisons, providing a robust measure of feature importance.\n\nIn summary, our evaluation includes statistical measures to ensure the reliability and significance of our results, making a strong case for the effectiveness of our method.",
  "evaluation/availability": "The data analyzed in this study is subject to specific licenses and restrictions. Access to the data must be requested and approved by the EpiBioS4Rx steering committee. Requests to access these datasets should be directed to the designated email address. The data is not publicly available for unrestricted access. This controlled access ensures that the data is used responsibly and in accordance with ethical guidelines and the study's objectives. The study was conducted with the support of the National Institute of Neurological Disorders and Stroke (NINDS) of the National Institutes of Health (NIH), and the data collection is part of the EpiBioS4Rx initiative, which aims to identify biomarkers of epileptogenesis after traumatic brain injury."
}