{
  "publication/title": "Sequence Image Normalization for Classification and Clustering of Intra-Host Viral Populations",
  "publication/authors": "The authors who contributed to the article are:\n\n- Basodi, who is the first author and likely played a significant role in the research and writing of the paper.\n- Other authors are not specified by name in the provided context, but their contributions are acknowledged. They include individuals from the Department of Computer Science, Georgia State University, and The Laboratory of Bioinformatics, I.M. Sechenov First Moscow State Medical University. Their specific contributions are not detailed, but they likely include roles in data analysis, methodology development, and review of the manuscript.",
  "publication/journal": "BMC Genomics",
  "publication/year": "2020",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Hepatitis C Virus (HCV)\n- Machine Learning\n- Classification\n- Clustering\n- Cross-Validation\n- Precision\n- Recall\n- Accuracy\n- Area Under the Curve (AUC)\n- Viral Populations\n- Image Processing\n- Molecular Epidemiology\n- Genomic Data\n- Sequence Analysis\n- Data Normalization",
  "dataset/provenance": "The dataset used in our study consists of intra-host viral populations sampled by Next-Generation Sequencing (NGS). These populations are derived from Hepatitis C Virus (HCV) outbreaks, with some samples originating from the same outbreak. The dataset includes a total of 55,945 pairs of samples, out of which 479 pairs are considered genetically related, having been taken from the same outbreak.\n\nThe data has been preprocessed into normalized images, which are then used for machine learning applications. This preprocessing step converts the viral population genomic data into a scaled image, handling irregularities in the data by generating a fixed-size image. The number of features in this representation remains constant, facilitating direct use in machine learning models without explicit feature selection methods.\n\nThe dataset has been analyzed using various image resolutions, ranging from 50 × 50 to 550 × 550, with the optimal resolution found to be 480 × 480 for accurate model performance. The images corresponding to intra-host viral populations have been labeled based on the stage of infection as recent or chronic, enabling the training of machine learning classification models.\n\nPrevious studies have demonstrated that the diversity of intra-host viral populations often increases with the progression of infection. Our approach leverages this characteristic to classify infection stages effectively. The dataset and methods used in this study build upon existing research in molecular epidemiology, contributing to the community's understanding of HCV infection dynamics and transmission patterns.",
  "dataset/splits": "In our study, we employed several cross-validation techniques to ensure robust and reliable model validation. The primary method used was stratified 10-fold cross-validation, which divides the dataset into 10 equally sized folds, maintaining the same proportion of classes in each fold. This approach helps in assessing the model's performance across different subsets of the data.\n\nAdditionally, we implemented \"leave-one-outbreak-out\" cross-validation to address the issue of overfitting due to samples from the same HCV outbreak being too similar. In this method, data from each outbreak is used in the validation set, while the remaining samples are used for training. This ensures that the model generalizes well to unseen outbreaks.\n\nTo balance the dataset sizes of recent and chronic infections, we used random undersampling. This technique reduces the size of the chronic dataset by randomly selecting samples to match the size of the recent dataset. This balancing step is crucial for preventing the model from being biased towards the larger class.\n\nThe distribution of data points in each split varies depending on the specific cross-validation method used. For stratified 10-fold cross-validation, each fold contains approximately 10% of the total data points, ensuring a balanced representation of both recent and chronic infections. In the \"leave-one-outbreak-out\" method, the validation set consists of data from a single outbreak, while the training set includes data from all other outbreaks. Random undersampling adjusts the dataset sizes to ensure equal representation of both infection stages.\n\nThese validation techniques collectively enhance the reliability and generalizability of our models, providing a comprehensive evaluation of their performance.",
  "dataset/redundancy": "To address dataset redundancy, we employed several strategies to ensure that our training and test sets were independent and to prevent overfitting. We used stratified 10-fold cross-validation, which ensures that each fold is representative of the overall class distribution. Additionally, we implemented \"leave-one-outbreak-out\" cross-validation. This method involves using data from each outbreak in the validation set while the remaining samples are used for training. This approach helps to mitigate the risk of overfitting, especially since samples from the same outbreak are closely related by their nucleotide composition.\n\nFurthermore, we utilized random undersampling to balance the datasets. The chronic dataset was reduced by random subsampling to match the size of the recent dataset. This technique helps to address class imbalances, ensuring that the model is not biased towards the majority class.\n\nThe distribution of our datasets compares favorably to previously published machine learning datasets in molecular epidemiology. By using these validation techniques, we aimed to create a robust and generalizable model that can accurately classify infection stages and detect transmission clusters. The combination of these methods ensures that our results are reliable and that the model's performance is not inflated by dataset redundancy.",
  "dataset/availability": "The data used in this paper has been published in previous works and can be shared upon reasonable request. The developed software, which includes the tools and methods used for data processing and analysis, is freely available on GitHub under the repository named \"SequenceImageNormalization\". This repository contains the code and documentation necessary to reproduce the results and apply the methods to new datasets. The availability of the software ensures that the methods are transparent and can be verified by other researchers. The data itself, while not publicly available in a forum, can be accessed by contacting the authors, ensuring that it is shared responsibly and in accordance with ethical guidelines. The software's open-source nature promotes reproducibility and encourages further research in the field of molecular epidemiology and viral disease surveillance.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages machine learning techniques, specifically focusing on classification and clustering methods. The primary machine-learning algorithm class used is that of supervised learning for classification tasks and unsupervised learning for clustering tasks.\n\nFor classification, we utilized several well-established models, including Stochastic Gradient Descent (SGD), Decision Tree, Gaussian Naive Bayes (Gaussian NB), Linear Support Vector Machine (Linear SVM), Random Forest, and k-Nearest Neighbours (kNN). Among these, the Linear SVM demonstrated superior performance, achieving an average accuracy of 97.545% with low variance. This model was chosen for its effectiveness in handling high-dimensional data and its ability to generalize well to new data.\n\nFor clustering, we employed standard algorithms such as agglomerative hierarchical clustering, k-means clustering, and mini-batch k-means clustering. These algorithms were used to group intra-host viral populations into transmission clusters. The performance of these clustering methods was evaluated using metrics such as Normalized Mutual Information (NMI), homogeneity, and completeness, all of which indicated high clustering efficiency.\n\nThe algorithms used are not new but are well-established in the machine learning community. The reason they were not published in a machine-learning journal is that the focus of our study is on their application to molecular epidemiology, particularly in the context of viral population analysis. The innovation lies in the preprocessing method that converts viral population genomic data into scaled images, which can then be effectively analyzed using these machine-learning algorithms. This approach addresses specific challenges in viral research, such as handling sequencing errors, biases, and irregularities in data, making it a novel contribution to the field of molecular epidemiology rather than to the field of machine learning itself.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, we employed a novel preprocessing approach to transform irregular genomic data into normalized image data. This method addresses several challenges associated with applying machine learning to viral populations, particularly the issues stemming from technological limitations and biases.\n\nThe preprocessing involves converting viral population genomic data sampled by next-generation sequencing (NGS) into scaled images. This conversion handles irregularities in the data by generating a fixed-size image, ensuring that the number of features remains consistent. Each image, with a resolution of x by y, corresponds to an x by y by 3 feature vector, where each pixel has three RGB components. This fixed-size representation allows the data to be directly used for machine learning applications without the need for explicit feature selection methods.\n\nThe image normalization method was specifically designed to overcome the difficulties posed by the variability in the number and length of viral sequences from different infected individuals. Traditional text classification techniques, which might involve truncation or padding, can lead to data loss or the introduction of irrelevant information. Our approach avoids these pitfalls by providing a standardized, easily interpretable format.\n\nThe effectiveness of this preprocessing method was demonstrated through its application to two critical problems in molecular epidemiology: the inference of viral infection stages and the detection of viral transmission clusters. For instance, in the case of infection staging, the diversity of intra-host viral populations often increases with the progression of the infection. The normalized images allowed for the visualization of these patterns, with recent infections exhibiting pronounced diagonal lines and chronic infections appearing more choppy.\n\nVarious machine learning models, including Stochastic Gradient Descent (SGD), Decision Tree, Gaussian Naive Bayes (Gaussian NB), Linear Support Vector Machine (Linear SVM), Random Forest, and k-Nearest Neighbours (kNN), were trained using these normalized images. The Linear SVM model, in particular, achieved high accuracy, demonstrating the robustness of our preprocessing method. The image resolution was varied from 50 by 50 to 550 by 550, with the optimal resolution found to be 480 by 480, at which both classification and clustering models performed most accurately.\n\nIn summary, the sequence-image normalization method provides a reliable way to convert genomic data into a format suitable for machine learning applications. This approach not only addresses the challenges associated with technological limitations and biases but also enhances the accuracy and scalability of machine learning models in viral research.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the image resolution. Each image of resolution x×y corresponds to x×y×3 feature vector, with each pixel having 3 RGB components. We analyzed sequence datasets for different resolutions ranging from 50 × 50 to 550 × 550 with a step size of 50 in each dimension. The resolution that yielded the most accurate results for both models was 480 × 480.\n\nFor the Linear Support Vector Machine (Linear SVM) model, a regularization parameter c was used to control training and testing errors, helping to generalize the model. Grid search was performed on c values in the range [-2, 20] to find the optimal parameter.\n\nFor the k-Nearest Neighbors (kNN) models, the best model was selected among those with Euclidean and Manhattan metrics and with k values ranging from 3 to 20.\n\nFor the Random Forest model, the optimal number of trees was determined by performing a grid search within the range of 10 to 100 trees.\n\nThese parameters were selected through systematic experimentation and grid search methods to ensure the models performed optimally on the given datasets.",
  "optimization/features": "The input features for our machine learning models are derived from the image representation of viral population genomic data. The number of features depends on the image resolution, with each pixel in the image contributing three features corresponding to its RGB components. In our experiments, we analyzed sequence datasets at various resolutions, ranging from 50 × 50 to 550 × 550, with the optimal resolution found to be 480 × 480. Therefore, for an image of resolution 480 × 480, the number of features is 480 × 480 × 3 = 691,200.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, our preprocessing method converts the genomic data into a fixed-size image, which inherently selects and represents the relevant features. This approach avoids the need for manual feature selection and ensures that the same set of features is used consistently across different problems. The image representation captures the entire population structure and is applicable to various classification and clustering tasks in molecular epidemiology.",
  "optimization/fitting": "In our study, we addressed the challenges of overfitting and underfitting through several methodological choices and validation techniques.\n\nFirstly, the number of parameters in our models was not excessively large compared to the number of training points. We employed a preprocessing method that converts viral population genomic data into scaled images, which maintains a fixed number of features. This approach allows for direct use in machine learning applications without explicit feature selection methods, thereby controlling the dimensionality of the feature space.\n\nTo mitigate overfitting, we utilized several validation strategies. Stratified 10-fold cross-validation was initially performed to assess the performance of our classification methods. Additionally, we employed \"leave-one-outbreak-out\" cross-validation and random undersampling methods to balance the datasets and prevent overfitting due to similar samples from the same outbreak. These techniques ensured that our models generalized well to unseen data.\n\nFurthermore, we evaluated the performance of our models using multiple metrics, including accuracy, precision, recall, and the area under the curve (AUC). The linear Support Vector Machine (SVM) demonstrated superior performance with high accuracy and low variance across different folds, indicating robust generalization.\n\nFor clustering, we used standard algorithms such as agglomerative hierarchical clustering, k-means clustering, and mini-batch k-means clustering. We employed various distance measures and linkage approaches to ensure that the clustering results were not overly sensitive to specific parameter choices. The performance of these clustering methods was evaluated using metrics like Normalized Mutual Information (NMI), homogeneity, and completeness, which provided a comprehensive assessment of clustering efficiency.\n\nIn summary, our approach involved careful preprocessing, rigorous validation techniques, and the use of multiple performance metrics to ensure that our models neither overfit nor underfit the data. This comprehensive strategy allowed us to achieve high accuracy and reliability in classifying and clustering intra-host viral populations.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. One key method used was stratified 10-fold cross-validation, which helps in assessing the model's performance across different subsets of the data, ensuring that each fold is representative of the overall dataset.\n\nAdditionally, we implemented \"leave-one-outbreak-out\" cross-validation. This technique is particularly useful in our context because some samples come from the same outbreak and are closely related by their nucleotide composition. By leaving out an entire outbreak for validation, we mitigate the risk of the model learning specific patterns from these related samples, thereby reducing overfitting.\n\nRandom undersampling was also utilized to balance the datasets. This method involves reducing the size of the larger class (chronic dataset) to match the size of the smaller class (recent dataset). This balancing act helps in preventing the model from being biased towards the majority class, which is a common issue in imbalanced datasets.\n\nFurthermore, in our linear SVM model, a regularization parameter was used to control the trade-off between achieving a low training error and a low testing error. This parameter helps in generalizing the model by preventing it from fitting the noise in the training data.\n\nThese techniques collectively ensure that our models are robust and generalize well to unseen data, thereby minimizing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, we detailed the range of values explored for different models, such as the regularization parameter 'c' for the linear SVM, the range of 'k' values for kNN, and the number of trees for the random forest model. These details are provided to ensure reproducibility of our results.\n\nThe optimization schedule, including the use of stratified 10-fold cross-validation, leave-one-outbreak-out cross-validation, and random undersampling methods, is also described. These methods were employed to validate the trained classifiers and balance the datasets, addressing potential overfitting issues.\n\nRegarding model files and optimization parameters, the developed software, which includes the implementations of the models and the preprocessing steps, is freely available. It can be accessed at the provided GitHub repository. This repository contains the necessary code and configurations to replicate the experiments and optimize the models as described in the paper.\n\nThe data used in this study has been published previously and can be shared upon reasonable request. This ensures that other researchers can access the same datasets and validate our findings.\n\nIn summary, all relevant information regarding hyper-parameter configurations, optimization schedule, model files, and optimization parameters is either detailed within the publication or available through the provided GitHub repository and data sharing agreements.",
  "model/interpretability": "The models employed in our study, particularly the Linear Support Vector Machine (SVM), are generally considered to be more interpretable compared to complex black-box models like deep neural networks. The Linear SVM model, for instance, operates by finding a hyperplane that best separates the classes in the feature space. This hyperplane is defined by a set of support vectors, which are the data points closest to the decision boundary. By examining these support vectors, one can gain insights into which features (or pixels in the context of image data) are most influential in making classification decisions.\n\nFor example, in the context of classifying recent and chronic HCV infections, the Linear SVM model can highlight specific regions in the normalized images that are critical for distinguishing between the two infection stages. This transparency allows researchers to understand not just the classification outcome but also the underlying patterns in the data that lead to these outcomes.\n\nOther models used, such as Decision Trees and Random Forests, also offer interpretability. Decision Trees provide a visual representation of the decision-making process, showing how different features contribute to the final classification. Random Forests, being an ensemble of Decision Trees, can provide feature importance scores, indicating which features are most relevant for the classification task.\n\nIn contrast, models like k-Nearest Neighbors (kNN) and Gaussian Naive Bayes (Gaussian NB) are somewhat less interpretable. kNN classifies based on the similarity of data points, which can be less straightforward to interpret, especially in high-dimensional spaces. Gaussian NB, while simple and efficient, assumes feature independence, which may not always hold true and can complicate interpretation.\n\nOverall, the choice of models in our study strikes a balance between performance and interpretability, with Linear SVM and Decision Trees offering clear insights into the classification process.",
  "model/output": "The model discussed in this publication is primarily focused on classification tasks. Specifically, it addresses the binary classification problem of identifying the stages of HCV (Hepatitis C Virus) infections as either recent or chronic. Several machine learning models were employed for this purpose, including Stochastic Gradient Descent (SGD), Decision Tree, Gaussian Naive Bayes (Gaussian NB), Linear Support Vector Machine (Linear SVM), Random Forest, and k-Nearest Neighbours (kNN). Among these, the Linear SVM model demonstrated superior performance, achieving high precision and recall metrics for both chronic and recent infection stages. The model's output includes accuracy, precision, recall, and area under the curve (AUC) metrics, which were validated using stratified 10-fold cross-validation, leave-one-outbreak-out validation, and random undersampling methods. These metrics indicate the model's effectiveness in correctly classifying HCV infection stages based on normalized image data derived from viral population genomic sequences.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The developed software is freely available at https://github.com/compbel/SequenceImageNormalization. The source code has been released under a permissive license, allowing users to access, modify, and distribute the software as needed. This open-source approach ensures that the community can benefit from the tools and methodologies presented in the publication, fostering further research and development in the field.",
  "evaluation/method": "The evaluation of our method involved several rigorous techniques to ensure its robustness and accuracy. We primarily used stratified 10-fold cross-validation to assess the performance of our classifiers. This method divides the dataset into 10 equal parts, training the model on 9 parts and testing on the remaining part, repeating this process 10 times with different parts as the test set. This approach helps in providing a comprehensive evaluation of the model's performance across different subsets of the data.\n\nIn addition to the standard 10-fold cross-validation, we employed \"leave-one-outbreak-out\" cross-validation. This technique is particularly useful when dealing with datasets that include samples from the same outbreak, which can be closely related by their nucleotide composition. In this method, data from each outbreak is used in the validation set while the remaining samples are used for training. This helps in preventing overfitting and ensures that the model generalizes well to new, unseen outbreaks.\n\nTo address the imbalance in the sizes of datasets for recent and chronic infections, we used random undersampling. This method involves reducing the size of the chronic dataset by random subsampling to match the size of the recent dataset. This balancing act helps in ensuring that the model does not become biased towards the larger class.\n\nFor clustering intra-host viral populations, we utilized standard clustering algorithms such as agglomerative hierarchical clustering, k-means clustering, and mini-batch k-means clustering. We evaluated the performance of these clustering methods using metrics such as Normalized Mutual Information (NMI), homogeneity, and completeness. These metrics help in assessing how well the assigned cluster labels match the actual cluster class labels of the intra-host viral populations.\n\nTo evaluate the effectiveness of our normalization method in detecting relatedness between pairs of samples, we computed the Area Under the Receiver Operating Characteristic Curve (AUROC). This involved considering viral populations from the same outbreak as genetically related and others as unrelated. We measured the false-positive rate (FPR) and true-positive rate (TPR) by modifying the threshold starting from the best threshold value where there are no false positives.\n\nOverall, our evaluation methods ensured a thorough and unbiased assessment of our classification and clustering techniques, providing confidence in their performance and generalizability.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our classification and clustering methods. For classification tasks, we reported accuracy, precision, recall, and the area under the curve (AUC). Accuracy measures the proportion of correctly classified test cases, while precision assesses the fraction of correctly classified instances within each predicted class. Recall evaluates the fraction of true instances that are correctly predicted. The AUC provides a single scalar value that summarizes the performance of the classifier across all classification thresholds.\n\nFor clustering tasks, we used Normalized Mutual Information (NMI), homogeneity, and completeness scores. NMI measures the mutual information shared between the individuals in the clusters, indicating how well the clustering algorithm preserves the original structure of the data. Homogeneity measures whether all members of a cluster belong to a single class, while completeness assesses whether all members of a class are grouped into the same cluster. These metrics range from 0 to 1, with values closer to 1 indicating better clustering efficiency.\n\nThese metrics are widely used in the literature and provide a comprehensive evaluation of both classification and clustering performance. By reporting these metrics, we ensure that our results are comparable to other studies in the field. Additionally, we used stratified 10-fold cross-validation, leave-one-outbreak-out cross-validation, and random undersampling to validate our models, further ensuring the robustness and generalizability of our findings.",
  "evaluation/comparison": "A comparison with previously published methods was conducted to evaluate the performance of our proposed classifier. Specifically, a model that classifies stages of HCV infection using parameters such as variant frequencies entropy, average position-wise nucleotide entropy, and the average distance from viral variants to the most frequent variant of the population was considered. Our classifier, based on image normalization, demonstrated superior performance with an AUC of approximately 96.9%, compared to the AUC values of around 81%, 66%, and 78% achieved by the aforementioned parameters.\n\nAdditionally, we compared our clustering method with consensus-based approaches and other population-based methods like VOICE and ReD. The consensus-based method, which uses a representative sequence per population, achieved a clustering sensitivity of 93.94% and an AUROC of 98.7% for inferring genetic relatedness. The ReD method showed a clustering sensitivity of 96.3%, while the VOICE method achieved a clustering sensitivity of 98.2% and an AUROC of approximately 99%. Our image clustering method outperformed the consensus and ReD methods with a clustering sensitivity of 98.181% and an AUROC of 99.2%, matching the performance of the VOICE algorithm.",
  "evaluation/confidence": "The evaluation of our methods involved several performance metrics, including accuracy, precision, recall, and AUC, which were assessed using stratified 10-fold cross-validation. This approach helps to ensure that the results are robust and generalizable. Additionally, we employed \"leave-one-outbreak-out\" cross-validation and random undersampling to balance the datasets and mitigate overfitting. These techniques provide a more rigorous evaluation by ensuring that the model's performance is not overly influenced by any single outbreak or class imbalance.\n\nThe performance metrics for the best models, such as the linear SVM, were presented with box plots, indicating the distribution of the metrics across different folds. The average metrics were highlighted, showing the central tendency of the performance. This visualization helps to understand the variability and consistency of the model's performance.\n\nFor clustering, we used metrics like Normalized Mutual Information (NMI), homogeneity, and completeness to evaluate the clustering performance. These metrics provide a comprehensive assessment of how well the clustering algorithms group the data compared to the actual cluster labels. The results showed high values for these metrics, indicating effective clustering.\n\nStatistical significance was not explicitly mentioned for the performance metrics, but the use of cross-validation and the presentation of performance distributions suggest a focus on robustness and generalizability. The consistent performance across different validation methods and the high values of the clustering metrics imply that the methods are reliable and superior to baselines.\n\nIn summary, while confidence intervals were not explicitly provided, the use of multiple validation techniques and the presentation of performance distributions indicate a strong evaluation framework. The results suggest that the methods are statistically significant and superior to existing baselines.",
  "evaluation/availability": "The data used in this paper has been published in previous works and can be shared upon reasonable request. The developed software, which includes the tools and methods used for evaluation, is freely available at a public repository. This ensures that other researchers can access and utilize the software for their own studies, promoting reproducibility and further advancements in the field. The availability of the software aligns with the principles of open science, facilitating collaboration and validation of the findings presented in this work."
}