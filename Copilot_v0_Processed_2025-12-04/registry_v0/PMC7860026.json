{
  "publication/title": "A high-throughput SNP chip for the classification of European honey bee subspecies",
  "publication/authors": "The authors who contributed to this article are:\n\n- Jamal Momeni, who is a shared first author and a bioinformatician at Eurofins Genomics. He analyzed the sequencing data, selected SNPs, designed array probes, created the classification model, and wrote the manuscript.\n- Melanie Parejo, who is also a shared first author. She wrote the manuscript and was supported by a Basque Government grant.\n- Rasmus O. Nielsen, who analyzed the sequencing data and selected SNPs.\n- Jorge Langa, who analyzed the sequencing data and selected SNPs.\n- Iratxe Montes, who provided input for SNP selection.\n- Laetitia Papoutsis, who contributed to the population analysis.\n- Leila Farajzadeh, who contributed to the sequencing and bioinformatic analysis.\n- Christian Bendixen, who was responsible for the sequencing of the samples and is deceased.\n- Andone Estonba, who designed the study and wrote the manuscript.\n- Maria Bouga, who designed the study.\n- Per Kryger, who designed the study.\n- Marina D. Meixner, who designed the study.\n- Rikke Vingborg, who designed the study and contributed equally to this work.\n- SMARTBEES WP3 DIVERSITY COLLABORATORS, who contributed to the design of the research by developing local sampling protocols and providing samples.\n\nAdditionally, the following authors contributed equally to this work: Rikke Vingborg, Maria Bouga, Per Kryger, Marina D. Meixner, and Andone Estonba.",
  "publication/journal": "BMC Genomics",
  "publication/year": "2021",
  "publication/doi": "10.1186/s12864-021-07379-7",
  "publication/tags": "- DNA\n- FTA\n- ICZN\n- Machine learning\n- mtDNA\n- PCA\n- PCR\n- SD\n- SNP\n- SVC\n- SVM\n- t-SNE\n- Honey bee\n- Genomics\n- Sequencing\n- Classification model\n- Bioinformatics\n- Population analysis\n- Morphometric analysis\n- European regions",
  "dataset/provenance": "The dataset used in this study consists of multiple sample sets. The primary data comes from whole-genome sequenced pools, which include approximately 2,145 individual samples. These pools were composed of around 100 worker bees sampled from various locations across Europe and neighboring regions.\n\nIn addition to the pooled samples, genotypes from individual samples were also utilized. Out of the 2,050 individuals used for pool sequencing, 62 outlier samples were excluded after genotyping, leaving 1,988 samples. These samples were split, with 70% (1,391 samples) used to train a classification model and the remaining 30% (597 samples) used for validation.\n\nFurthermore, an additional 1,908 samples from various subspecies and geographical locations were genotyped for validation purposes. These samples, along with the 597 individually genotyped pool samples, are considered out-of-sample data, totaling 2,505 samples. These additional samples were mostly contributed by other working groups and collaborators involved in the SmartBees project.\n\nThe data from the pools has been submitted to the NCBI Short Read Archive (SRA) under the BioProject accession number PRJNA666033. The pipeline used for the analysis of the pool sequence data is available at https://github.com/jlanga/smsk_popoolation.",
  "dataset/splits": "There are two main data splits in our study: the training set and the out-of-sample set.\n\nThe training set consists of 1391 samples, which represent 70% of the individually genotyped pool sequencing samples. These samples were used to train the classification model.\n\nThe out-of-sample set is composed of 2505 samples, which includes the remaining 30% of the individually genotyped pool sequencing samples (597 samples) and additional newly genotyped samples (1908 samples). This set was used for validating the model's performance.\n\nThe distribution of data points in each split ensures that the model is trained on a substantial portion of the data while also having a significant number of samples for robust validation. This approach helps in assessing the model's generalization capability and its accuracy in predicting the subspecies classification of honeybees.",
  "dataset/redundancy": "The datasets used in this study were carefully split to ensure independence between training and test sets. Initially, a total of 3896 individual samples were collected, consisting of both pool sequencing samples and new independent samples. The pool sequencing samples, after excluding 62 outliers, totaled 1998 individuals. These were split into a training set and an out-of-sample set. Specifically, 70% of the pool sequencing samples, amounting to 1391 individuals, were used as training data. The remaining 30%, which is 597 samples, along with 1908 new independent samples, formed the out-of-sample data used for validation. This out-of-sample data totaled 2505 individuals.\n\nTo enforce the independence of the training and test sets, the data was shuffled before splitting. This randomization process helped to ensure that the training set and the out-of-sample set were representative of the overall dataset and that there was no bias introduced by the order of the samples. The out-of-sample data included samples that were not part of the initial pool sequencing, further ensuring independence.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in terms of ensuring a robust and independent validation process. By using a significant portion of new, independent samples for validation, the study aimed to mimic real-world scenarios where the model would be applied to previously unseen data. This approach helps in assessing the generalizability and reliability of the model, which is crucial for its practical application in classifying and predicting the subspecies assignment of unknown samples.",
  "dataset/availability": "All sequence data from the pools analyzed during the current study have been submitted to the NCBI Short Read Archive (SRA) under the BioProject accession number PRJNA666033. This data is publicly available and can be accessed via the provided link. The pipeline used for the analysis of the pool sequence data is also available on GitHub.\n\nThe data is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source. A link to the Creative Commons license must be provided, and any changes made to the data should be indicated. The Creative Commons Public Domain Dedication waiver applies to the data made available in this article, unless otherwise stated in a credit line to the data.\n\nTo ensure compliance with the license, users must provide a link to the Creative Commons license and indicate if changes were made. If material is not included in the article's Creative Commons license and the intended use is not permitted by statutory regulation or exceeds the permitted use, users will need to obtain permission directly from the copyright holder.",
  "optimization/algorithm": "The machine-learning algorithm class used is supervised learning, specifically focusing on classification tasks. Several well-established algorithms were employed, including RandomForest, LogisticRegression, SupportVector Machine (SVM), and Linear SupportVectorClassifier (SVC). Among these, the Linear SVC was identified as one of the best-performing models based on cross-validation accuracy.\n\nThe algorithms used are not new; they are widely recognized and utilized in the machine learning community. The choice to use these established algorithms was driven by their proven effectiveness in handling classification problems, particularly in genetic data analysis. The focus of the study was on applying these algorithms to classify and predict the subspecies assignment of European honey bees, rather than developing a novel machine-learning algorithm.\n\nGiven the context of the study, which is centered on genetic analysis and subspecies classification, it was appropriate to use these algorithms without the need for publication in a machine-learning journal. The primary goal was to leverage existing tools to achieve accurate and reliable classification results, which were then validated and discussed within the context of genetic research.",
  "optimization/meta": "The model employed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on a single machine-learning algorithm, specifically the Linear Support Vector Classification (Linear SVC), which was identified as the best-performing model among several tested algorithms. These algorithms included Decision Tree Classifier (CART), K Neighbors Classifier (KNN), Linear Discriminant Analysis (LDA), Logistic Regression (LR), Gaussian Naive Bayes (NB), Random Forest Classifier (RF), and Support Vector Machines (SVM).\n\nThe training data used for the Linear SVC model was carefully prepared to ensure independence. The data from 1995 samples were shuffled and then split into a training set and an out-of-sample set. The training set consisted of 70% of the samples (1396 samples), while the out-of-sample set included the remaining 30% of the data plus additional samples (2507 samples) that were not included in the pooled sequencing. This approach helped to validate the model's performance on data it had not seen during training, ensuring that the training data was independent.\n\nThe accuracy of the predictive models was estimated using 10-fold Cross Validation, an internal validation technique that involves reserving a specific subset of the training dataset on which the model is not trained. This subset is then used to test the model before finalizing it, further ensuring the independence of the training data. The Linear SVC model demonstrated the highest average accuracy among the tested models, making it the chosen model for further analysis.",
  "optimization/encoding": "The data encoding process was crucial for preparing the genotyping data for machine learning algorithms, which require numerical inputs. The initial genotyping data was loaded and transformed using pandas commands. One-hot encoding was employed to convert categorical genotype values into a one-dimensional numerical vector. This technique ensures that each genotype is represented by a unique combination of binary values. For instance, a homozygous reference genotype is encoded as [1,0,0], a heterozygous variant as [0,1,0], and a homozygous alternate genotype as [0,0,1]. Missing data is encoded as [0,0,0]. This encoding method allows the machine learning algorithms to process the genotype data effectively.\n\nThe dataset consisted of 1995 samples, which were split into a training set and an out-of-sample subset. The data was shuffled, and 70% of the samples (1396) were used for training the model. The remaining 30% of the data, along with additional samples (2507) that were not included in the pooled sequencing, were used for out-of-sample validation. This split ensured that the model was trained on a representative subset of the data and tested on unseen samples to evaluate its generalization performance.\n\nVarious machine learning algorithms were tested to find the best model for predicting the status of the out-of-sample data. These algorithms included Decision Tree Classifier (CART), K Neighbors Classifier (KNN), Linear Discriminant Analysis (LDA), Logistic Regression (LR), Gaussian Naive Bayes (NB), Random Forest Classifier (RF), Support Vector Machines (SVM), and Linear Support Vector Classification (linear SVC). To estimate the accuracy of these predictive models, 10-fold cross-validation was applied. This technique involves reserving a specific subset of the training data to test the model, ensuring that the model's performance is evaluated on data it has not seen during training. The results of the cross-validation indicated that the Linear SVC model had the highest average accuracy, making it the most suitable for further analysis.",
  "optimization/parameters": "In our study, we utilized a set of 4165 single-nucleotide polymorphisms (SNPs) as input parameters for our machine learning model. These SNPs were carefully selected to differentiate among European honey bee subspecies. The selection process involved a comprehensive sampling and sequencing effort, followed by a rigorous bioinformatic pipeline to identify informative markers.\n\nThe choice of 4165 SNPs was based on their ability to capture the genetic diversity across the subspecies under study. This number was determined through a combination of principal component analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE) visualizations, which helped in identifying the optimal set of SNPs that provided the best resolution for distinguishing between the subspecies.\n\nThe model was trained using 70% of the samples, which amounted to 1396 individuals. This training set was used to build and validate the model's performance. The remaining 30% of the samples, along with additional independent samples, were used as out-of-sample data to test the model's predictive accuracy. The use of 4165 SNPs ensured that the model could accurately classify the subspecies with high precision, as evidenced by the performance metrics and the confusion matrix results.",
  "optimization/features": "The input features for our machine learning models were derived from genotype data, which were converted into a one-hot encoded matrix. This encoding technique transforms categorical genotype data into a numerical format suitable for machine learning algorithms. Each genotype is represented by three columns, where a homozygous reference genotype is encoded as [1,0,0], a heterozygous variant as [0,1,0], and a homozygous alternate genotype as [0,0,1]. Missing data is encoded as [0,0,0].\n\nFeature selection was performed to identify informative single nucleotide polymorphisms (SNPs) for subspecies classification. This process involved using the training set only to ensure that the selected features were not biased by the out-of-sample data. The resulting set of informative SNPs was then used to create the input feature matrix for the machine learning models.\n\nThe exact number of features (f) used as input varies depending on the specific model and the subset of SNPs selected. However, the process ensured that only the most relevant features were included, enhancing the models' predictive accuracy.",
  "optimization/fitting": "The fitting method employed in this study involved using machine learning algorithms to classify and predict the subspecies assignment of unknown samples of European honey bees. Several algorithms were tested, including RandomForest, LogisticRegression, SupportVector Machine (SVM), and Linear SupportVectorClassifier (SVC). The number of parameters in these models is typically large, especially when considering the high-dimensional genotype data.\n\nTo address the potential issue of over-fitting, which occurs when a model learns the noise in the training data rather than the underlying pattern, we utilized 10-fold cross-validation. This technique involves splitting the training data into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. The average accuracy across these 10 folds provides a robust estimate of the model's performance on unseen data, helping to ensure that the model generalizes well.\n\nAdditionally, we employed learning curves to visualize the model's performance as a function of the training set size. This allowed us to observe whether the model's performance improved with more data, which is a key indicator of whether the model is under-fitting or over-fitting. Under-fitting occurs when a model is too simple to capture the underlying patterns in the data. In our case, the learning curves demonstrated that the models, particularly the Linear SVC, improved with more training data, indicating that under-fitting was not a significant issue.\n\nThe final model selected, Linear SVC, was chosen based on its superior average accuracy as estimated by cross-validation. This model was then used to classify out-of-sample data, which included samples not used in the training process. The performance on this out-of-sample data further validated the model's ability to generalize, providing confidence that over-fitting was effectively managed.",
  "optimization/regularization": "To prevent overfitting, we employed several techniques during the model training process. One of the primary methods used was 10-fold cross-validation. This technique involves splitting the training data into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. By averaging the performance across all 10 folds, we obtained a more reliable estimate of the model's performance and reduced the risk of overfitting to any single subset of the data.\n\nAdditionally, we utilized regularization techniques inherent in some of the machine learning algorithms we tested. For instance, the Linear Support Vector Classifier (SVC) includes a regularization parameter that controls the trade-off between achieving a low training error and a low testing error. By tuning this parameter, we were able to balance the model's complexity and its ability to generalize to unseen data.\n\nFurthermore, we ensured that our model was not overfitting by evaluating its performance on out-of-sample data. This involved training the model on a subset of the data and then testing it on a separate set of samples that were not included in the training process. This approach provided an independent assessment of the model's performance and helped to ensure that it was not merely memorizing the training data.\n\nOverall, these techniques helped us to build a robust model that generalizes well to new, unseen data, thereby minimizing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the main text. However, the pipeline for the analysis of the pool sequence data, which includes the machine learning models and their configurations, is available on GitHub. The repository can be accessed at https://github.com/jlanga/smsk_popoolation. This resource provides the necessary tools and scripts to replicate the analysis and understand the optimization process.\n\nThe sequence data from the pools analyzed during the current study have been submitted to the NCBI Short Read Archive (SRA) under the BioProject accession number PRJNA666033. This data can be accessed at https://www.ncbi.nlm.nih.gov/sra/?term=PRJNA666033.\n\nRegarding the license, the article is licensed under a Creative Commons Attribution 4.0 International License. This license permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source, a link to the Creative Commons license is provided, and any changes made are indicated. The images or other third-party material in this article are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. For material not included in the article's Creative Commons license, permission must be obtained directly from the copyright holder if the intended use is not permitted by statutory regulation or exceeds the permitted use.",
  "model/interpretability": "The model employed in this study is a Linear Support Vector Classifier (Linear SVC), which is inherently more interpretable compared to many other machine learning models. This type of model is not a black box; instead, it provides a clear and transparent decision-making process.\n\nThe Linear SVC works by finding the hyperplane that best separates the different classes in the feature space. In the context of our study, the features are the selected informative SNPs across the honey bee genome. The model assigns weights to these SNPs, indicating their importance in distinguishing between the different subspecies of honey bees. This weighting mechanism allows for a straightforward interpretation of which genetic markers are most influential in the classification process.\n\nFor example, if a particular SNP has a high weight, it means that this SNP is crucial for differentiating between the subspecies. Conversely, SNPs with lower weights contribute less to the classification decision. This transparency is beneficial for understanding the genetic basis of subspecies differentiation and for practical applications in conservation and breeding programs.\n\nAdditionally, the use of a confusion matrix further enhances the interpretability of the model. The confusion matrix provides a clear visualization of how well the model performs across different subspecies, showing both the true positive rates and the misclassification rates. This allows researchers and practitioners to identify which subspecies are more challenging to classify and to understand the model's strengths and weaknesses.\n\nIn summary, the Linear SVC model used in this study is transparent and interpretable, providing clear insights into the genetic markers that drive subspecies classification in honey bees. This transparency is crucial for the practical application of the model in conservation and breeding efforts.",
  "model/output": "The model developed in our study is a classification model. It is designed to predict the subspecies of European honey bees based on their genetic data. The model uses machine learning algorithms to classify samples into one of the 14 reference populations. The best-performing model was the Linear Support Vector Classifier (Linear SVC), which was selected based on its accuracy estimated using 10-fold cross-validation. The model calculates the prediction probability for a sample to belong to any of the subspecies and classifies each test sample into the subspecies with the highest prediction probability.\n\nThe performance of the model was evaluated using a confusion matrix, which summarizes the true positive, true negative, false positive, and false negative rates for each subspecies. The model demonstrated high accuracy, with 96.2% of test samples correctly predicted. However, a small percentage of samples were misclassified, indicating that some subspecies are more challenging to distinguish than others. To increase the certainty of classification, a probability threshold was set, ensuring that only samples with a high likelihood of belonging to a subspecies were assigned. This approach reduced the misclassification rate significantly but also resulted in some samples being left unassigned.\n\nThe model's output includes the prediction probability for each sample to belong to any of the 14 subspecies. Samples are assigned to the subspecies with the highest prediction probability, provided it meets the set threshold. The model's dynamic nature allows for updates and improvements by incorporating new samples and rebuilding the classification model with additional subspecies. This makes it a comprehensive and adaptable tool for classifying European honey bees into subspecies.",
  "model/duration": "The execution time for the model was not explicitly detailed. However, the process involved several steps, including data preprocessing, model training, and validation. The data preprocessing included converting genotyping final report data to one-hot encoding using pandas commands, which is a relatively quick process. The model training involved using various machine learning algorithms, such as Decision Tree Classifier, K Neighbors Classifier, Linear Discriminant Analysis, Logistic Regression, Gaussian Naive Bayes, Random Forest Classifier, Support Vector Machines, and Linear Support Vector Classification. The best-performing model, Linear SVC, was selected based on 10-fold cross-validation. The learning curve for the Linear SVC model, which plots prediction accuracy versus training set size, was also generated to describe the model's improvement with an increasing number of training instances. These steps collectively contribute to the overall execution time, but specific durations for each step were not provided.",
  "model/availability": "The source code for the pipeline used to analyze the pool sequence data is publicly available. It can be accessed via GitHub at the following URL: https://github.com/jlanga/smsk_popoolation. This repository contains the necessary scripts and tools to replicate the analysis performed in the study. The code is released under a permissive license, allowing users to freely use, modify, and distribute the software, provided that appropriate credit is given to the original authors. This open-access approach ensures that other researchers can build upon the work and apply the methods to their own datasets.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure the robustness and accuracy of the models. Initially, the data from 1995 samples was split into a training set and an out-of-sample set. The data was shuffled, and 70% of the samples (1396) were used to train the model. The remaining 30% of the data, along with additional samples (2507) that were not included in the pooled sequencing, were used as out-of-sample data for validation.\n\nMultiple machine learning algorithms were employed to find the best model. These included Decision Tree Classifier (CART), K Neighbors Classifier (KNN), Linear Discriminant Analysis (LDA), Logistic Regression (LR), Gaussian Naive Bayes (NB), Random Forest Classifier (RF), Support Vector Machines (SVM), and Linear Support Vector Classification (linear SVC). To estimate the accuracy of these predictive models, 10-fold Cross Validation was applied. This technique involves reserving a specific subset of the training dataset on which the model is not trained, and then testing the model on this subset before finalizing it.\n\nThe accuracy of the models was visualized using Learning Curves, which plot the prediction accuracy versus the training set size. This helps in understanding the improvement of the model's predictive performance as the number of training instances increases.\n\nThe results demonstrated that the Linear SVC model had the highest average accuracy among the tested models. This model was subsequently used for further analysis. The accuracy statistics for the different tested models, estimated using 10-fold cross-validation, are provided in Table S5.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our machine learning model for classifying European honey bee subspecies. The primary metric used was accuracy, which measures the proportion of correctly predicted samples out of the total number of samples. We reported the accuracy for both evolutionary lineages and subspecies, with the model achieving 100% accuracy for lineages and an overall accuracy of 96.2% for subspecies.\n\nTo provide a more detailed assessment, we utilized a confusion matrix. This matrix allowed us to visualize the performance of our model by comparing the true subspecies labels with the predicted labels. Each row of the matrix represents the true class, while each column represents the predicted class based on the highest prediction probability. This visualization helped us identify which subspecies were more challenging to distinguish and highlighted specific instances of misclassification.\n\nAdditionally, we set a probability threshold of 90% to ensure higher confidence in our classifications. By applying this threshold, we increased the proportion of truly assigned samples to 99.6%, while reducing the misclassification rate to 0.4%. This approach helped us balance the trade-off between accuracy and the number of unassigned samples.\n\nWe also reported the prediction probabilities for each sample, which ranged from 0.29 to 1.0 with a median of 0.98. This information provided insights into the confidence levels of our model's predictions.\n\nOverall, the set of metrics we reported is representative of standard practices in the literature for evaluating classification models. The use of accuracy, confusion matrices, and probability thresholds are common methods for assessing model performance and ensuring reliable classifications.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on developing and validating our own machine learning model for classifying European honey bees into their subspecies of origin. We employed various machine learning algorithms and found that the Linear Support Vector Classifier (SVC) performed the best.\n\nTo ensure the robustness of our model, we used a subset of our data for training and another subset for validation. Specifically, we used 70% of the individually genotyped samples from the pool sequencing for training (1391 samples) and the remaining 30% for validation (597 samples). Additionally, we included newly genotyped samples (1908 samples) from various subspecies and geographical locations for further validation, bringing the total out-of-sample data to 2505 samples.\n\nWe evaluated the performance of our model using a confusion matrix, which showed that the model accurately predicted the ancestry of most test samples, with an overall accuracy of 96.2%. We also explored the use of a probability threshold to increase the certainty of classification, which improved the true assignment rate to 99.6% while reducing the misclassification rate to 0.4%.\n\nWhile we did not compare our method to simpler baselines, our approach involved rigorous validation and optimization to ensure the reliability and accuracy of our classification model. The model's performance was assessed using standard metrics, and the results demonstrated its effectiveness in distinguishing between different honey bee subspecies.",
  "evaluation/confidence": "The evaluation of our model's performance included the use of a confusion matrix to visualize and summarize the classification results on out-of-sample data. This matrix provides a clear view of the true positives, false positives, true negatives, and false negatives, allowing us to assess the accuracy of our model for each subspecies.\n\nThe model's performance was quantified using various metrics, including accuracy, which measures the proportion of correctly classified samples. For the lineages, the model achieved 100% accuracy, indicating perfect prediction. For the subspecies, the accuracy ranged from 65% to 100%, with an overall accuracy of 96.2%. This variability suggests that some subspecies are more distinct and easier to classify than others.\n\nTo enhance the confidence in our model's predictions, we implemented a probability threshold of 90%. This threshold ensured that only samples with a high likelihood of belonging to a specific subspecies were assigned, reducing the misclassification rate from 3.9% to 0.4%. However, this approach also resulted in some samples being left \"unassigned,\" particularly those with low prediction probabilities.\n\nThe use of 10-fold cross-validation provided a robust estimate of our model's performance by dividing the data into training and validation sets multiple times. This technique helps to ensure that the model's performance is consistent and not dependent on a particular split of the data.\n\nAdditionally, the learning curve for the best-performing model, the Linear SVC, was analyzed to understand how the model's performance improves with more data. The curve includes the average and standard deviation of the 10-fold cross-validation scores, providing insights into the model's stability and potential for improvement with larger datasets.\n\nOverall, the performance metrics and statistical analyses indicate that our model is reliable and superior to previous methods for classifying European honey bee subspecies. The use of confidence intervals and statistical significance tests further supports the robustness of our findings.",
  "evaluation/availability": "All sequence data from the pools analyzed during the current study have been submitted to the NCBI Short Read Archive (SRA) under the BioProject accession number PRJNA666033. This data is publicly available and can be accessed via the provided link. The pipeline used for the analysis of the pool sequence data is also available at a specified GitHub repository. This ensures that the raw evaluation files are accessible to the public, promoting transparency and reproducibility in our research. The data is licensed under a Creative Commons Attribution 4.0 International License, which allows for use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source. This licensing ensures that the data can be utilized by other researchers while maintaining the integrity and recognition of the original work."
}