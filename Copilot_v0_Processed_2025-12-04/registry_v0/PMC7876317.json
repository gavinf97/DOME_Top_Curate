{
  "publication/title": "Identification of Gene Signatures and Expression Patterns During Epithelial-to-Mesenchymal Transition From Single-Cell Expression Atlas",
  "publication/authors": "The authors who contributed to the article are:\n\n- Xiangtian Yu, who conceived the concept of the work, prepared the draft, revised the manuscript, and contributed to the article.\n- XiaoYong Pan, who performed the experiments, made analysis, prepared the draft, and contributed to the article.\n- ShiQi Zhang, who made analysis and contributed to the article.\n- Yu-Hang Zhang, who made analysis and contributed to the article.\n- Lei Chen, who performed the experiments and contributed to the article.\n- Sibao Wan, who made analysis and contributed to the article.\n- Tao Huang, who conceived the concept of the work and revised the manuscript.\n- Yu-Dong Cai, who conceived the concept of the work and revised the manuscript.",
  "publication/journal": "Frontiers in Genetics",
  "publication/year": "2021",
  "publication/doi": "10.3389/fgene.2020.605012",
  "publication/tags": "- Gene signature\n- Expression pattern\n- Epithelial-to-mesenchymal transition\n- Single cell\n- Classification\n- Machine learning\n- Random forest\n- Support vector machine\n- Rule learning\n- Functional enrichment analyses",
  "dataset/provenance": "The dataset used in this study was obtained from a previous study by Pastushenko et al. The data consists of mouse single-cell gene expression profiles. Specifically, it includes 71 epithelial YFP +Epcam + skin squamous cell carcinoma tumor cells (TCs) and 312 mesenchymal-like YFP +Epcam − skin squamous cell carcinoma TCs. These cells represent different epithelial-to-mesenchymal transition (EMT) states. Each TC was encoded with the expression levels of 49,585 genes. The dataset is publicly available and can be accessed via the NCBI Gene Expression Omnibus (GEO) database under the accession number GSE110357. This dataset has been used to reveal the detailed expression profiling of these cells, contributing to the construction of an expression profiling atlas for EMT progression at the single-cell level. The abundance of mesenchymal TCs is significantly higher than that of epithelial TCs, with mesenchymal TCs being approximately 4.4 times more abundant.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The dataset used in this study is publicly available. The mouse single-cell gene expression profiles were obtained from the study of Pastushenko et al. (2018), which can be accessed at the NCBI Gene Expression Omnibus (GEO) database under the accession number GSE110357. This dataset includes 71 epithelial YFP+Epcam+ skin squamous cell carcinoma tumor cells (TCs) and 312 mesenchymal-like YFP+Epcam− skin squamous cell carcinoma TCs. Each TC is encoded with the expression levels of 49,585 genes. The data is freely accessible to the public, allowing for reproducibility and further research. The dataset consists of different EMT states, which are crucial for understanding the mechanisms of tumor migration and invasion.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are supervised learning algorithms. Specifically, the algorithms employed are Support Vector Machine (SVM), Random Forest (RF), and Repeated Incremental Pruning to Produce Error Reduction (RIPPER).\n\nThese algorithms are not new; they are well-established in the field of machine learning. SVM is based on statistical learning theory and uses kernel techniques to map data from low-dimensional non-linear space to high-dimensional linear space. The Random Forest algorithm constructs a large number of decision trees to establish a classification prediction model. RIPPER is a rule-learning algorithm that produces interpretable classification rules.\n\nThe reason these algorithms were not published in a machine-learning journal is that they are standard methods widely used across various domains, including bioinformatics. The focus of this study is on applying these established methods to identify gene signatures and expression patterns during epithelial-to-mesenchymal transition (EMT) from single-cell expression data. The novelty lies in the application of these methods to a specific biological problem rather than the development of new machine-learning algorithms.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for the successful application of machine-learning algorithms in our study. Initially, we addressed the imbalance in the dataset, which consisted of mesenchymal and epithelial tumor cells. The mesenchymal tumor cells were approximately 4.4 times more abundant than the epithelial tumor cells. To tackle this imbalance, we employed the synthetic minority over-sampling technique (SMOTE). This method generates new samples for the minority class (epithelial tumor cells) by interpolating between existing samples, thereby balancing the class sizes. We used the SMOTE tool in Weka to create an equal number of epithelial and mesenchymal tumor cells.\n\nAdditionally, feature selection was performed to identify relevant genes for distinguishing between the two cell types. We used Boruta, a wrapper method based on random forest, to detect all relevant features associated with the target outputs. Boruta iteratively identifies relevant features by comparing the importance scores of real and shuffled features. This process involved copying the training dataset, shuffling the values of individual features to create a shuffled dataset, and then training a random forest classifier on this shuffled dataset. The importance scores of features in the original dataset were evaluated, and features with significantly higher importance scores than shuffled features were retained. This iterative process was repeated multiple times to select all relevant features.\n\nFollowing Boruta, we applied the minimum redundancy maximum relevance (mRMR) method to further refine the feature set. mRMR aims to balance the relevance between features and the target variable while minimizing redundancy between features. This was achieved by measuring feature correlation using mutual information and constructing a ranked feature list that maximizes the correlation between features and the target variable while minimizing the correlation between features. The ranked feature list was then used in incremental feature selection (IFS) with supervised classifiers to identify the optimal gene signatures for classifying different tumor cells.",
  "optimization/parameters": "In our study, we employed a systematic approach to select the optimal number of features (p) for our models. Initially, we used Boruta feature selection to identify relevant features, resulting in 237 features. These features were then ranked using the minimum redundancy maximum relevance (mRMR) method. Subsequently, we applied incremental feature selection (IFS) with three different classifiers: support vector machine (SVM), random forest (RF), and repeated incremental pruning to produce error reduction (RIPPER). The IFS process involved iteratively adding top-ranked features and evaluating the classification performance of each feature subset.\n\nFor SVM, the optimal number of features was found to be 169, which yielded the highest Matthew's correlation coefficient (MCC) of 0.967. For RF, the optimal number of features was 159, with an MCC of 0.934. RIPPER, on the other hand, achieved its best performance with 38 features, resulting in an MCC of 0.942. Although RIPPER had a slightly lower MCC compared to SVM, it provided interpretable classification rules. Notably, using the top eight features with RIPPER resulted in an MCC of 0.908, which is only 3.4% lower than its best performance, indicating that a smaller subset of features can still yield satisfactory results.",
  "optimization/features": "In our study, we initially identified 237 relevant features using the Boruta feature selection method. These features were then ranked using the minimum redundancy maximum relevance (mRMR) method. The ranked feature list was used as input for incremental feature selection (IFS) with various classifiers, including support vector machine (SVM), random forest (RF), and repeated incremental pruning to produce error reduction (RIPPER). Feature selection was performed using the training set only, ensuring that the process was supervised and aimed at detecting optimal features for accurately distinguishing different samples. The final subset of features with the optimal classification performance was obtained through this iterative process.",
  "optimization/fitting": "In our study, we employed several machine learning techniques to ensure robust model performance and to address potential issues of overfitting and underfitting.\n\nFirstly, we utilized the Boruta feature selection method, which is a wrapper method based on random forest (RF) for detecting all relevant features associated with target outputs. This method iteratively identifies relevant features by comparing the importance scores of real and shuffled features, ensuring that only the most relevant features are retained. This step significantly reduces the number of parameters, mitigating the risk of overfitting by focusing on the most informative features.\n\nNext, we applied the minimum redundancy maximum relevance (mRMR) method to further refine the feature set. mRMR balances the relevance between features and the target variable while minimizing redundancy between features. This ensures that the selected features are not only relevant but also diverse, reducing the likelihood of overfitting due to redundant information.\n\nWe then performed incremental feature selection (IFS) with supervised classifiers, including support vector machine (SVM), random forest (RF), and repeated incremental pruning to produce error reduction (RIPPER). IFS iteratively adds top-ranked features into candidate feature subsets and tests all feature subsets by building their classifiers. The subset of features with the optimal classification performance was finally obtained. This process helps in identifying the minimal set of features required for accurate classification, further reducing the risk of overfitting.\n\nTo address the issue of overfitting, we employed the synthetic minority over-sampling technique (SMOTE) to handle the imbalanced dataset. SMOTE generates new samples and adds them to the minor class, ensuring that the dataset is balanced. This technique helps in preventing the model from being biased towards the majority class and improves the generalization performance.\n\nAdditionally, we used 10-fold cross-validation to evaluate the performance of our models. This technique involves dividing the dataset into 10 subsets, training the model on 9 subsets, and testing it on the remaining subset. This process is repeated 10 times, with each subset serving as the test set once. Cross-validation provides a robust estimate of model performance and helps in identifying potential overfitting or underfitting issues.\n\nIn summary, our approach involved feature selection, balancing the dataset, and rigorous validation techniques to ensure that our models were neither overfitted nor underfitted. The use of multiple classifiers and cross-validation further strengthened the reliability and generalizability of our results.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was the random forest algorithm, which inherently helps to reduce overfitting by averaging the results of multiple decision trees. Each tree in the random forest is trained on a different subset of the data, and the final prediction is made by aggregating the votes from all the trees. This ensemble approach helps to mitigate the risk of overfitting to the training data.\n\nAdditionally, we utilized the synthetic minority over-sampling technique (SMOTE) to address the class imbalance in our dataset. By generating synthetic samples for the minority class, we were able to balance the dataset, which in turn helped to prevent the model from becoming biased towards the majority class. This technique ensured that our classifiers were trained on a more representative sample of the data, thereby reducing the likelihood of overfitting.\n\nFurthermore, we performed incremental feature selection (IFS) to identify the optimal set of features for classification. This process involved iteratively adding top-ranked features to the model and evaluating their performance. By selecting only the most relevant features, we were able to simplify the model and reduce the complexity, which is another effective way to prevent overfitting.\n\nLastly, we used the sequence minimization optimization (SMO) algorithm to train our support vector machine (SVM) model. SMO is known for its efficiency in handling large datasets and its ability to converge quickly, which helps to avoid overfitting by ensuring that the model generalizes well to unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study includes both black-box and interpretable components. The support vector machine (SVM) and random forest (RF) are considered black-box methods. These models are powerful for classification tasks but do not provide clear, human-readable rules for their predictions. They operate by mapping data into high-dimensional spaces and fitting complex decision boundaries, which makes it difficult to interpret the specific features that contribute to a given prediction.\n\nOn the other hand, the repeated incremental pruning to produce error reduction (RIPPER) algorithm was used to generate interpretable classification rules. RIPPER produces IF-ELSE rules that can be easily understood and interpreted. For instance, one of the rules generated by RIPPER is: \"If ENSMUSG00000045394 (Epcam) <= 47.481, then the tumor cell is mesenchymal.\" This rule provides a clear and straightforward criterion for classifying tumor cells based on the expression level of the Epcam gene. Another example is: \"If ENSMUSG00000031565 (Fgfr1) >= 130.294 and ENSMUSG00000051397 (Tacstd2) <= 14.977, then the tumor cell is mesenchymal.\" These rules highlight specific gene expression thresholds that are indicative of different tumor cell types, making the model's decisions more transparent and interpretable.",
  "model/output": "The model is a classification model. It was designed to distinguish between different types of tumor cells, specifically epithelial and mesenchymal tumor cells, based on gene expression data. The model employs several machine learning algorithms, including Support Vector Machine (SVM), Random Forest (RF), and Repeated Incremental Pruning to Produce Error Reduction (RIPPER). These algorithms were used to classify the tumor cells into their respective categories. The performance of the model was evaluated using metrics such as Matthew's correlation coefficient (MCC), sensitivity (SN), specificity (SP), and accuracy (ACC). The SVM algorithm achieved the highest MCC value of 0.967, indicating its superior performance in classifying the tumor cells. Additionally, the model generated interpretable classification rules using the RIPPER algorithm, which provided insights into the gene expression patterns that differentiate between epithelial and mesenchymal tumor cells.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "To evaluate the performance of our computational approach, we employed a rigorous methodology that included several key steps. Initially, we utilized the synthetic minority over-sampling technique (SMOTE) to address the class imbalance in our dataset, ensuring that the number of epithelial tumor cells (TCs) matched that of mesenchymal TCs. This step was crucial for creating a balanced dataset, which is essential for training robust machine learning models.\n\nFor performance measurement, we used Matthew’s correlation coefficient (MCC), a metric that provides a balanced measure of the quality of binary classifications. MCC takes into account true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN), offering a comprehensive evaluation of the model's performance. The formula for MCC is:\n\nMCC = (TP × TN - FP × FN) / √((TP + FP) × (TP + FN) × (TN + FP) × (TN + FN))\n\nWe applied 10-fold cross-validation to ensure that our models were evaluated on diverse subsets of the data, providing a reliable estimate of their generalizability. This process involved dividing the dataset into 10 folds, training the model on 9 folds, and testing it on the remaining fold, repeating this procedure 10 times with different folds as the test set.\n\nIn our study, we compared the performance of three different classifiers: Support Vector Machine (SVM), Random Forest (RF), and Repeated Incremental Pruning to Produce Error Reduction (RIPPER). Each classifier was evaluated using the incremental feature selection (IFS) method, which iteratively adds top-ranked features to identify the optimal subset that maximizes classification performance.\n\nThe results showed that SVM yielded the highest MCC value of 0.967, indicating its superior performance in distinguishing between epithelial and mesenchymal TCs. RF achieved an MCC of 0.934, while RIPPER, although slightly lower with an MCC of 0.942, provided interpretable classification rules. These rules can be particularly valuable for understanding the underlying biological mechanisms driving the differentiation between the two cell types.\n\nIn summary, our evaluation method involved addressing class imbalance, using a robust performance metric (MCC), employing 10-fold cross-validation, and comparing multiple classifiers to identify the most effective approach for distinguishing epithelial and mesenchymal TCs. This comprehensive evaluation ensures the reliability and validity of our findings.",
  "evaluation/measure": "In our study, we employed Matthew’s correlation coefficient (MCC) as the primary performance metric to evaluate the effectiveness of our models. MCC is a robust measure that considers true positives, true negatives, false positives, and false negatives, providing a balanced view of the classifier's performance, especially in cases of imbalanced datasets. The formula used for MCC is:\n\nMCC = (TP × TN - FP × FN) / √((TP + FP)(TP + FN)(TN + FP)(TN + FN))\n\nwhere TP, TN, FP, and FN represent true positives, true negatives, false positives, and false negatives, respectively.\n\nAdditionally, we reported sensitivity (SN), specificity (SP), and accuracy (ACC) to provide a comprehensive evaluation of our models. Sensitivity measures the proportion of actual positives correctly identified by the model, while specificity measures the proportion of actual negatives correctly identified. Accuracy gives an overall measure of the correct predictions made by the model.\n\nThe use of MCC, along with SN, SP, and ACC, ensures that our performance evaluation is thorough and representative of the model's ability to distinguish between different types of tumor cells. This set of metrics is widely accepted in the literature for evaluating classification models, particularly in bioinformatics and medical research, where imbalanced datasets are common.",
  "evaluation/comparison": "In our study, we employed several machine learning techniques to classify tumor cells (TCs) into epithelial and mesenchymal types. We utilized three primary classifiers: Support Vector Machine (SVM), Random Forest (RF), and Repeated Incremental Pruning to Produce Error Reduction (RIPPER). Each of these classifiers was evaluated using incremental feature selection (IFS) to determine the optimal set of features for classification.\n\nThe SVM classifier, implemented using the sequence minimization optimization (SMO) algorithm in Weka, demonstrated the highest performance with a Matthew's correlation coefficient (MCC) of 0.967. This indicates that SVM was highly effective in distinguishing between the two types of TCs. The RF classifier, which constructs multiple decision trees, achieved an MCC of 0.934, showing robust performance but slightly lower than SVM. RIPPER, a rule-based classifier, provided an MCC of 0.942. Although its performance was slightly lower than SVM, RIPPER offers the advantage of generating interpretable classification rules, which can be crucial for understanding the underlying biological mechanisms.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of different classifiers within our specific dataset of single-cell gene expression profiles. This approach allowed us to identify the most effective method for our particular problem of distinguishing epithelial and mesenchymal TCs.\n\nIn terms of simpler baselines, we did not explicitly compare our methods to basic or naive classifiers. Our evaluation was centered on the comparative performance of SVM, RF, and RIPPER, which are well-established machine learning techniques. The use of IFS with these classifiers ensured that we selected the most relevant features for accurate classification, thereby enhancing the performance of our models.\n\nOverall, our study highlights the effectiveness of SVM for classifying TCs, while also acknowledging the interpretability benefits of RIPPER. This comprehensive evaluation provides a solid foundation for future research in single-cell transcriptomics and tumor cell classification.",
  "evaluation/confidence": "The evaluation of our method's performance was conducted using Matthew's correlation coefficient (MCC) as the primary metric. This metric was calculated using a 10-fold cross-validation approach, which helps to ensure that the results are robust and not dependent on a particular split of the data. The MCC formula used takes into account true positives, true negatives, false positives, and false negatives, providing a comprehensive measure of the classifier's performance.\n\nThe performance of different classifiers—Support Vector Machine (SVM), Random Forest (RF), and Repeated Incremental Pruning to Produce Error Reduction (RIPPER)—was compared. SVM yielded the highest MCC value of 0.967, indicating superior performance in distinguishing between epithelial and mesenchymal tumor cells. RF and RIPPER also performed well, with MCC values of 0.934 and 0.942, respectively. These results suggest that our method is effective and reliable.\n\nHowever, specific confidence intervals for the performance metrics were not provided in the results. The statistical significance of the differences between the classifiers was also not explicitly stated. While the high MCC values indicate strong performance, the lack of confidence intervals and statistical significance tests means that the precise level of confidence in these results is not quantified. Future work could include more detailed statistical analyses to provide confidence intervals and significance tests, further validating the superiority of our method over baselines and other classifiers.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. The study utilized specific datasets and tools, such as the mouse single-cell gene expression profiles from the study of Pastushenko et al. (2018), which can be accessed via the NCBI Gene Expression Omnibus (GEO) with the accession number GSE110357. The tools used, like SMOTE in Weka and the DAVID website for functional enrichment analyses, are publicly accessible. However, the specific evaluation files generated during the study, such as those containing the performance metrics or the ranked feature lists, are not detailed as being publicly released. Therefore, it is not clear if these files are available for public access or under what license they might be shared."
}