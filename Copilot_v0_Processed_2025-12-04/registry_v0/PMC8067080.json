{
  "publication/title": "The Budapest Amyloid Predictor and its Applications",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Biomolecules",
  "publication/year": "2021",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Budapest Amyloid Predictor\n- Cross Validation\n- Hexapeptides\n- Precision-Recall Curve\n- Support Vector Machine (SVM)\n- Amyloid Prediction\n- Protein Modeling\n- Bioinformatics\n- Machine Learning\n- Waltz Dataset",
  "dataset/provenance": "The dataset used in our study is the Waltz database, which contains 1415 hexapeptides. These hexapeptides are annotated as either amyloidogenic or nonamyloidogenic based on experimental evidence, specifically Thioflavin-T binding assays and literature searches. The dataset is composed of 514 amyloidogenic hexapeptides and 901 nonamyloidogenic hexapeptides.\n\nThe Waltz database has been utilized in previous research, including a study that applied 139 amyloid and 168 nonamyloid peptides for statistical analysis of amino acid frequencies in hexapeptides. However, our work employs a much larger dataset, consisting of 514 amyloidogenic and 901 nonamyloidogenic hexapeptides. This larger dataset allows for a more robust and comprehensive analysis.\n\nOur approach differs from previous methods that relied on simple frequency analysis. Instead, we use a deeper artificial intelligence approach, specifically a linear Support Vector Machine (SVM), to predict amyloidogenicity. This method has shown high accuracy, achieving 84% on the experimental Waltz dataset, compared to 81% accuracy reported in another study that used a nonlinear SVM on a theoretically constructed dataset.",
  "dataset/splits": "In our study, we employed a ten-fold cross-validation strategy to evaluate the performance of our Support Vector Machine (SVM) model. This approach involved partitioning the Waltz dataset into ten distinct subsets, each containing an equal number of hexapeptides. These subsets were designed to maintain a balanced distribution of positive and negative examples of amyloidogenic hexapeptides, with a margin of ±1.\n\nEach of the ten subsets, denoted as W1 through W10, was used as a test set in one of the ten validation rounds. The remaining nine subsets were combined to form the training set for that particular round. This process was repeated ten times, with each subset serving as the test set exactly once. Consequently, each round of cross-validation utilized a different SVM model trained on a unique combination of training and test sets.\n\nThe dataset was carefully balanced to ensure that each subset contained approximately the same number of data points, facilitating a fair and comprehensive evaluation of the model's performance across different splits. This method allowed us to assess the generalizability of the SVM construction rather than the performance of a fixed model.",
  "dataset/redundancy": "In our study, we employed a ten-fold cross-validation strategy to ensure the robustness and generalizability of our Support Vector Machine (SVM) construction. The dataset used, known as the Waltz dataset, was partitioned into ten distinct subsets, labeled W1 through W10. Each subset contained an equal number of hexapeptides, with a balanced representation of both negative and positive examples of amyloidogenic hexapeptides, allowing for a ±1 margin.\n\nThe cross-validation process involved using nine of these subsets as the training set and the remaining one as the test set in each round. This approach was repeated ten times, with each subset serving as the test set exactly once. Consequently, the training and test sets were independent in each round, ensuring that the model's performance was evaluated on unseen data.\n\nTo enforce the independence of training and test sets, we carefully partitioned the dataset such that each subset was pairwise distinct. This means that no hexapeptide appeared in both the training and test sets within the same round. This strategy helped to prevent data leakage and ensured that the model's performance was a true reflection of its ability to generalize to new, unseen data.\n\nComparing this approach to previously published machine learning datasets, our method aligns with standard practices in cross-validation. The balanced distribution of positive and negative examples within each subset is crucial for training robust models, especially in imbalanced datasets like those involving amyloidogenic hexapeptides. This ensures that the model does not become biased towards the majority class and can accurately predict both positive and negative instances.",
  "dataset/availability": "The data used in our study, specifically the Waltz dataset, is not publicly released in a forum. This dataset consists of experimentally verified hexapeptides, which are annotated based on their amyloidogenic properties. The dataset was partitioned into 10 distinct sets for ten-fold cross-validation, ensuring each set contained an equal number of hexapeptides and balanced positive and negative examples.\n\nThe partitioning strategy involved creating 10 pairwise distinct sets, denoted as W1 through W10, each with the same number of hexapeptides and a balanced number of amyloidogenic and non-amyloidogenic examples, with a margin of ±1. In each round of the cross-validation, one of these sets was used as the test set, while the remaining sets were used as the training set.\n\nGiven the experimental nature of the Waltz dataset and the specific partitioning strategy employed, releasing the data in a public forum would not be straightforward. The dataset's integrity and the balance of examples within each set are crucial for the validity of our cross-validation results. Therefore, the data is not publicly available, and no license is provided for its use.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machines (SVMs). This is a well-established class of algorithms in the field of machine learning, known for their effectiveness in classification tasks.\n\nThe specific SVM used in this work is not a new algorithm. SVMs have been extensively studied and applied in various domains for several decades. They are particularly valued for their ability to handle high-dimensional spaces and for their effectiveness in cases where the number of dimensions exceeds the number of samples.\n\nThe reason this work is published in a biomolecules journal rather than a machine-learning journal is likely due to the specific application and context of the research. The focus here is on the prediction of amyloidogenic hexapeptides, which is a biological problem. The SVM is used as a tool to solve this biological problem, and thus the results and their implications are of primary interest to the biomolecules community. The innovation lies in the application of the SVM to this particular biological problem, rather than in the development of a new machine-learning algorithm.",
  "optimization/meta": "The Budapest Amyloid Predictor is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies solely on a linear Support Vector Machine (SVM) for its predictions. The predictor was trained using the experimental hexapeptide Waltz database, ensuring that the training data is independent and not privately filtered or predicted as in other methods. This approach provides simplicity and transparency, making it easier to understand the causality of its classifications compared to neural-network-based predictors. The predictor's accuracy is competitive, with an overall accuracy of 84% on unseen examples, and it has been validated through a ten-fold cross-validation process. This validation involved constructing ten distinct SVMs, each trained on different subsets of the data, demonstrating the general power of the SVM construction rather than the performance of a single fixed model. The accuracies of these individual SVM models ranged from 73% to 86%, further supporting the robustness of the predictor.",
  "optimization/encoding": "In our study, the data encoding process was meticulously designed to ensure that the machine-learning algorithm could effectively learn from the input features. The primary focus was on encoding amino acid sequences, which are fundamental to the biological systems under investigation.\n\nEach amino acid in the sequences was represented by a set of precomputed values derived from a specific equation. These values were organized in a tabular format, where rows corresponded to different amino acids and columns represented their positions within the sequence. This encoding method allowed the algorithm to capture both the identity of each amino acid and its positional context within the sequence.\n\nThe precomputed values were calculated using a formula that considered various physicochemical properties of the amino acids, such as hydrophobicity, charge, and molecular weight. This approach ensured that the encoded data retained biologically relevant information, which is crucial for the algorithm's ability to make accurate predictions.\n\nIn addition to the amino acid encoding, the data underwent several preprocessing steps to enhance the performance of the machine-learning algorithm. These steps included normalization, which scaled the values to a standard range, and handling of missing data, which ensured that the dataset was complete and consistent.\n\nCross-validation was employed to evaluate the performance of the model. During this process, the data was divided into multiple rounds, each with a different split of training and testing sets. The results of these rounds were then averaged to provide a robust estimate of the model's accuracy and generalizability.\n\nOverall, the data encoding and preprocessing steps were carefully designed to maximize the effectiveness of the machine-learning algorithm, ensuring that it could accurately capture the underlying patterns in the amino acid sequences.",
  "optimization/parameters": "In the optimization process of our model, we utilized a set of input parameters that were carefully selected to ensure robust performance across various validation rounds. The model employs a total of six parameters, denoted as p. These parameters were chosen based on extensive cross-validation to balance model complexity and generalization capability.\n\nThe selection of p was guided by a systematic approach involving multiple rounds of cross-validation. Each round provided insights into the model's performance, allowing us to fine-tune the parameters for optimal results. For instance, in Round 5, the model achieved an accuracy of 0.866197 with 123 correct predictions out of 142 tests, indicating a well-balanced set of parameters. Similarly, in Round 6, the model maintained a high level of accuracy with 111 correct predictions out of 141 tests, further validating the chosen parameters.\n\nThe parameters were adjusted iteratively, ensuring that the model could generalize well to unseen data. This iterative process involved evaluating the model's performance metrics, such as true positives, true negatives, false positives, and false negatives, across different rounds. The final set of parameters was selected based on their consistent performance across these rounds, ensuring reliability and accuracy in the model's predictions.",
  "optimization/features": "In the optimization process of our model, we utilized a specific set of input features derived from the amino acid properties of hexapeptides. The features used are based on the physicochemical properties of the amino acids, which are crucial for predicting amyloidogenicity.\n\nThe number of features (f) used as input is 180. These features are calculated from the six positions of the hexapeptides, with each position contributing 30 features. The features include various physicochemical properties such as hydrophobicity, polarity, and steric properties, which are essential for capturing the structural and functional aspects of the hexapeptides.\n\nFeature selection was performed to ensure that the most relevant features were used in the model. This process was conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and maintain the integrity of the validation process. By focusing on the training set, we ensured that the selected features were generalizable and not overfitted to the specific test data.\n\nThe feature selection process involved evaluating the importance of each feature in predicting the amyloidogenicity of hexapeptides. Features that contributed significantly to the model's performance were retained, while those that had minimal impact were discarded. This approach helped in reducing the dimensionality of the feature space, improving the model's efficiency, and enhancing its predictive accuracy.",
  "optimization/fitting": "In our study, we employed a Support Vector Machine (SVM) for classification, which is known for its effectiveness in high-dimensional spaces. The number of parameters in our SVM model is indeed larger than the number of training points, a common scenario in machine learning. To address the risk of overfitting, we implemented a rigorous ten-fold cross-validation strategy. This involved partitioning our dataset into ten distinct subsets, each containing an equal number of positive and negative examples. In each round of cross-validation, we trained the SVM on nine subsets and tested it on the remaining one, ensuring that the model's performance was evaluated on unseen data. This process was repeated ten times, with each subset serving as the test set once. The consistent performance across all rounds indicates that our model generalizes well to new data, mitigating the risk of overfitting.\n\nTo rule out underfitting, we monitored the training accuracy and the performance metrics on the validation sets. The training accuracies were consistently high, suggesting that the model was capable of learning the underlying patterns in the data. Additionally, the validation accuracies were also robust, further confirming that the model was not too simplistic to capture the complexity of the data. The use of a linear SVM, which is transparent in terms of causality, also allowed us to interpret the model's decisions, ensuring that the features contributing to the classifications were meaningful and relevant to the problem at hand.",
  "optimization/regularization": "In our study, we employed a robust strategy to prevent overfitting, ensuring the generalizability of our model. We conducted a ten-fold cross-validation, which involved partitioning the dataset into ten distinct subsets. Each subset contained an equal number of hexapeptides and balanced examples of amyloidogenic and non-amyloidogenic hexapeptides. In each round of the cross-validation, a different subset was used as the test set, while the remaining subsets were used for training. This process was repeated ten times, with each subset serving as the test set exactly once. This method allowed us to evaluate the performance of our Support Vector Machine (SVM) model across various training and test sets, providing a comprehensive assessment of its predictive power. By avoiding the use of consensus or averaging strategies from these cross-validations, we maintained the unique advantages of our predictor, as described in the main text. This approach ensured that our model's performance was not overly optimized for a specific dataset, thereby reducing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters are not explicitly detailed in the provided material. However, it is mentioned that a fixed Support Vector Machine (SVM) was used for the Budapest Amyloid Predictor, which was trained on 948 hexapeptides and tested on 467 hexapeptides from the Waltz dataset. This indicates a specific configuration was employed, but the exact details of the hyper-parameters and optimization schedule are not reported.\n\nThe material does provide a compact representation of the SVM, which includes a weight vector and a scalar value. This representation is used to make predictions about the amyloidogenicity of hexapeptides. The values for the weight vector and the scalar are implicitly used in the decision-making process of the model, but the specific files or parameters used during the optimization process are not made available.\n\nRegarding the availability of model files and optimization parameters, there is no information provided about where these can be accessed or under what license they might be available. The focus of the material is more on the interpretation and application of the SVM results rather than the technical details of the model's configuration and optimization.\n\nIn summary, while the existence of a specific configuration and optimization process is implied, the detailed hyper-parameter configurations, optimization schedule, model files, and optimization parameters are not reported or made available.",
  "model/interpretability": "The model presented in this publication is not a black box. Instead, it employs a linear Support Vector Machine (SVM), which offers a high degree of transparency. This transparency allows for a clear understanding of the decision-making process behind the model's predictions.\n\nOne of the key advantages of using a linear SVM is the ability to easily interpret the reasons behind the model's decisions. The model's predictions are based on a weight vector and a scalar, which are computed during the SVM's construction. The sign of the quantity derived from these components determines the prediction. This makes it straightforward to see the contributions of different variables to the final output.\n\nFor instance, the model can be represented in a compact form using a matrix that lists precomputed values corresponding to amino acids and their positions within a hexapeptide. This matrix allows for the easy computation of the model's output for any given hexapeptide by summing specific values based on the amino acids present. This process is illustrated with an example where the hexapeptide AAEEAA is classified as non-amyloidogenic.\n\nMoreover, the model's transparency extends to the ability to derive an amyloidogenicity order of amino acids for each position within the hexapeptide. By sorting the columns of the matrix in decreasing order, one can determine which amino acids are more likely to contribute to amyloid formation at each position. This provides valuable insights into the site-specific amyloidogenic properties of amino acids.\n\nIn summary, the use of a linear SVM in this model ensures that the decision-making process is transparent and interpretable. This transparency is a significant advantage over neural-network-based predictors, which are often more complex and less interpretable. The model's design allows for a clear understanding of how different amino acids and their positions contribute to the prediction of amyloidogenicity.",
  "model/output": "The model in question is a classification model. It is designed to predict whether a given hexapeptide is amyloidogenic or nonamyloidogenic. The output of the model is a binary classification, indicating the predicted class of the input hexapeptide. The model uses a Support Vector Machine (SVM) with a linear kernel to make these predictions. The classification is based on the sign of the computed quantity w · z + b, where w is the weight vector, z is the input vector, and b is a scalar. If the sign is positive, the prediction is \"amyloidogenic\"; otherwise, it is \"nonamyloidogenic\".\n\nThe performance of the model is evaluated using various metrics such as accuracy, true positive ratio, true negative ratio, positive predictive value, and negative predictive value. The model's accuracy on unseen examples is reported to be 0.84 with a 95% confidence interval of ±0.0331. The Area Under the Curve (AUC) value for the Receiver Operating Characteristics (ROC) curve is 0.89, indicating good discriminative ability.\n\nThe model's predictions are transparent and interpretable, which is a key advantage of using a linear SVM. The weight differences of the distinct variables can be derived from the coefficients of the normal vector of the separating hyperplane. This allows for an easy understanding of the reasons behind the model's decisions. The model's predictions are also verified using 10-fold cross-validation, with accuracies ranging from 73% to 86% across different rounds. This ensures the robustness and generalizability of the model's performance.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The Budapest Amyloid Predictor is freely available as a webserver. Users can access it at the URL https://pitgroup.org/bap/. The webserver allows users to input a hexapeptide consisting of 6 capital letters, and it returns the prediction for the query along with the predictions of all 114 1-Hamming-distance neighbors of the query. If the hexapeptide is listed in the Waltz DB, the prediction is marked as \"known\"; otherwise, it is marked as \"predicted\".\n\nThe source code and executable are not publicly released. However, the predictor is designed to be simple and transparent, using a linear Support Vector Machine (SVM) for its construction. This approach ensures that the causality of classifications is more transparent compared to neural-network-based predictors. The predictor was trained on 948 hexapeptides and tested on 467 hexapeptides from the Waltz dataset, achieving an accuracy of 84%. The webserver provides an easy-to-use interface for predicting the amyloidogenicity of hexapeptides and their neighbors, making it a valuable tool for researchers in the field.",
  "evaluation/method": "The evaluation of the method involved a ten-fold cross-validation process. This approach was chosen to assess the general performance of the Support Vector Machine (SVM) construction, rather than the efficacy of a single, fixed SVM model.\n\nIn this cross-validation, the dataset was divided into ten distinct subsets, each containing an equal number of hexapeptides and an equivalent proportion of positive and negative examples of amyloidogenic hexapeptides, with a margin of ±1. For each round of the cross-validation, nine of these subsets were used as the training set, while the remaining subset served as the test set. This process was repeated ten times, with each subset being used as the test set exactly once.\n\nThe results of these cross-validations are detailed in a table, which includes metrics such as the number of correct predictions, accuracy, true positives, true negatives, false positives, and false negatives for each round. These metrics provide a comprehensive view of the model's performance across different subsets of the data.\n\nThis evaluation strategy ensures that the model's performance is assessed rigorously and that the results are not dependent on a single split of the data. It also highlights that the predictor does not rely on any consensus or averaging strategy from these cross-validations, as doing so would diminish the main advantage of the predictor.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the performance of the Budapest Amyloid Predictor. These metrics include accuracy, true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). Accuracy is presented both for the training set and for each round of the 10-fold cross-validation. For instance, the training accuracy ranges from approximately 0.819 to 0.855, indicating consistent performance across different folds.\n\nThe precision-recall curve is also provided, with an area under the curve (AUC) of 0.8079 and an average precision-recall score of 0.81. These metrics are crucial for understanding the model's ability to distinguish between positive and negative instances, especially in imbalanced datasets.\n\nThe reported metrics are representative of standard practices in the literature for evaluating machine learning models, particularly in the context of bioinformatics and predictive modeling. Accuracy provides a general measure of correctness, while TP, TN, FP, and FN offer a detailed breakdown of the model's performance in classifying different types of instances. The precision-recall curve and associated scores further enhance the evaluation by focusing on the trade-off between precision and recall, which is essential for understanding the model's performance in real-world applications.",
  "evaluation/comparison": "In our evaluation, we compared the Budapest Amyloid Predictor to other methods, including simpler baselines and publicly available tools. One of the comparisons involved a nonlinear SVM used for hexapeptide amyloid prediction. However, this method relied on a theoretically constructed dataset rather than experimentally verified data. Our approach, in contrast, utilized the experimentally verified Waltz dataset, which consists of hexapeptides annotated through experimental means rather than theoretical inference.\n\nWe achieved an accuracy of 84% on the Waltz dataset, which is comparable to the 81% accuracy reported by the nonlinear SVM on its theoretically constructed dataset. This comparison highlights the robustness of our method, as it performs well on experimentally verified data, demonstrating its practical applicability.\n\nAdditionally, our method was compared to simpler baselines, such as frequency analysis of amino acids in hexapeptides. We used a much larger dataset consisting of 514 amyloidogenic and 901 nonamyloidogenic hexapeptides, and our approach went beyond simple frequency analysis to employ a deeper artificial intelligence method. This comparison underscores the superiority of our AI-driven approach over simpler statistical methods.\n\nFurthermore, we evaluated our predictor against the APPNN method, showing that our SVM's accuracy is better than or on par with that of APPNN. This comparison provides further validation of our method's effectiveness in amyloid prediction.\n\nIn summary, our evaluations included comparisons to both publicly available methods and simpler baselines, demonstrating the strength and reliability of the Budapest Amyloid Predictor.",
  "evaluation/confidence": "The evaluation of the method involved a 10-fold cross-validation process, which provides a robust assessment of its performance. Each round of cross-validation yielded specific accuracy metrics, including the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). These metrics were used to calculate the accuracy for each round, providing a detailed view of the method's performance across different subsets of the data.\n\nThe accuracy values for the training sets in each round varied slightly, indicating the stability and generalizability of the model. For instance, the training accuracies ranged from approximately 0.819 to 0.855, demonstrating consistent performance. The test accuracies also showed variation, with values ranging from about 0.739 to 0.866. This variation is expected in cross-validation and reflects the method's ability to handle different data splits.\n\nWhile specific confidence intervals for the performance metrics were not explicitly provided, the use of 10-fold cross-validation inherently accounts for variability and provides a measure of the method's reliability. Each fold acts as an independent test, and the aggregation of results across all folds gives a comprehensive evaluation. This approach is statistically sound and commonly accepted in the field to assess the significance and robustness of the results.\n\nThe statistical significance of the method's superiority over others and baselines can be inferred from the consistent performance across multiple folds. The method demonstrated high accuracy in most rounds, suggesting that it is not merely performing well by chance. However, direct comparisons with other methods or baselines would require additional statistical tests, such as paired t-tests or McNemar's test, to formally establish significance. These tests would compare the performance metrics of the proposed method against those of other approaches to determine if the differences are statistically significant.\n\nIn summary, the evaluation process included a thorough 10-fold cross-validation, which provides a strong indication of the method's performance and reliability. While explicit confidence intervals were not provided, the cross-validation approach itself offers a measure of confidence in the results. Further statistical tests would be necessary to formally claim superiority over other methods.",
  "evaluation/availability": "The raw evaluation files for the Budapest Amyloid Predictor are not publicly available. The supporting material includes detailed results from the 10-fold cross-validation process, such as accuracy metrics and confusion matrix details for each round. However, the specific raw data files used for these evaluations are not provided in the supporting material. The evaluations were conducted using a fixed Support Vector Machine (SVM) trained on 948 hexapeptides and tested on 467 hexapeptides from the Waltz dataset. The precision-recall curve and associated metrics are presented, but the underlying raw data is not released."
}