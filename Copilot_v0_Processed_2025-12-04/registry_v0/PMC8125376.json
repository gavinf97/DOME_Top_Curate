{
  "publication/title": "Comparison of Targeted and Untargeted Approaches in Breath Analysis for the Discrimination of Lung Cancer from Benign Pulmonary Diseases and Healthy Persons",
  "publication/authors": "The authors who contributed to the article are:\n\n- **A.T.** - Conceptualization, Formal analysis, Methodology, Project administration, Resources, Supervision, Validation, Writing—original draft, Writing—review and editing\n- **M.K.** - Data curation, Formal analysis, Investigation, Methodology, Validation, Visualization, Writing—original draft\n- **D.K.** - Data curation, Investigation\n- **G.D.A.** - Formal analysis, Methodology, Writing—original draft\n- **C.H.** - Funding acquisition, Resources, Writing—review and editing\n- **K.G.** - Funding acquisition, Resources, Writing—review and editing",
  "publication/journal": "Molecules",
  "publication/year": "2021",
  "publication/doi": "10.3390/molecules26092609",
  "publication/tags": "- Breath analysis\n- Volatile organic compounds\n- Lung cancer\n- Machine learning\n- Random forests\n- Feature selection\n- Chromatographic peaks\n- Diagnostic efficiency\n- Non-targeted approach\n- Smoking habit",
  "dataset/provenance": "The dataset used in this study originates from air samples collected from various population subgroups. These samples were processed using the XCMS Online platform to identify informative features, specifically chromatographic peaks and corresponding ions (m/z). The initial processing identified 358 informative features, which were then manually evaluated and verified. This evaluation led to the exclusion of 28 peaks due to poor chromatographic characteristics and an additional 53 compounds due to interference or contamination issues. Ultimately, 29 peaks were considered for further investigation.\n\nThe specific number of data points is not explicitly stated, but the dataset includes features identified as differentiated between population subgroups. These features were used in machine learning analyses to classify different groups, such as cancer patients (Ca+) and healthy controls (HC). The machine learning models, particularly random forests, demonstrated high accuracy in classifying these groups, with correct classification rates ranging from 86% to 94% depending on the subset of features used.\n\nThe data used in this study has not been previously published or used by the community, as it contains sensitive information at an individual level and is not publicly available. The study protocol was approved by the Scientific Council of the General University Hospital of Larissa, and informed consent was obtained from all subjects involved. The work was supported by a postdoctoral scholarship program implemented by the University of Thessaly and funded by the Stavros Niarchos Foundation.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study are not publicly available. This decision was made because the dataset contains sensitive information at an individual level. The study involved breath analysis of different population groups, including patients diagnosed with lung cancer, patients with pathological CT findings not diagnosed with lung cancer, and healthy controls. The data includes chromatographic peaks and corresponding ions (m/z) that were identified as significantly differentiated between these population subgroups. The raw files were processed using XCMS Online, and the results were manually cross-checked and reprocessed to ensure the reliability of the dataset.\n\nThe study utilized machine learning methods, specifically random forests, to analyze the data. Feature selection was performed to identify subsets of informative metabolites that could efficiently separate the groups. The best-performing algorithm achieved high accuracy and area under the curve (AUC) values, demonstrating the discriminatory power of the identified compounds.\n\nGiven the sensitive nature of the data, it was deemed necessary to keep it confidential to protect the privacy of the participants. Therefore, the data are not released in a public forum, and no specific license is provided for public access. The confidentiality of the data was enforced through institutional review board approval and informed consent from all subjects involved in the study. The study protocol was approved by the Scientific Council of the General University Hospital of Larissa, ensuring that ethical standards were maintained throughout the research process.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the random forest. This algorithm is not new; it is a well-established ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nRandom forests are known for their robustness and ability to handle large datasets with high dimensionality, making them suitable for our analysis of breath compound levels. The algorithm's strength lies in its ability to reduce overfitting by averaging multiple decision trees, which improves the model's generalization to new data.\n\nThe reason this algorithm was not published in a machine-learning journal is that our focus was on applying established machine-learning techniques to a specific biomedical problem—namely, the discrimination between different patient groups based on breath analysis. Our primary contribution lies in the application of these methods to a novel dataset and the insights gained from this application, rather than the development of a new algorithm.\n\nWe chose random forests because they consistently outperformed other algorithms, such as naive Bayes and logistic regression, in our comparative analyses. This superior performance was evident in various comparisons, including distinguishing between cancer patients and healthy controls, as well as between cancer and non-cancer patients. The use of random forests, combined with feature selection, significantly improved the accuracy and discriminatory power of our models.",
  "optimization/meta": "The meta-predictor described in this publication does not use data from other machine-learning algorithms as input. Instead, it relies on the direct analysis of volatile organic compounds (VOCs) identified through targeted and untargeted approaches.\n\nThe machine learning methods used in this study include naive Bayes, logistic regression, and random forest. However, random forests consistently outperformed the other algorithms, so all results are shown for this specific type of algorithm.\n\nThe feature selection process within the appropriate Weka module was performed in two steps. The first step involved a wrapper that evaluates various subsets of the features using the Best_First method to maximize the performance of the random forest, based on the metric of the area under the curve (AUC). This step performed 10-fold cross-validation to assess how many times a feature was selected. Features selected in at least 50% of the cross-validations formed a subset that was fed into the second step. The second step repeated the feature selection using the full training set to select a final subset of features.\n\nRegarding the independence of training data, the use of 10-fold cross-validation in the first step of feature selection ensures that the data is split into training and validation sets multiple times, which helps to maintain independence and reduce overfitting. The second step uses the full training set, but the initial selection process ensures that the features are robust and generalizable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, retention indices for compounds were calculated using analytical standards with C5 to C12 alkanes, following a specific formula that relates the retention time of a compound to the retention times of adjacent n-alkanes. This process ensured that the retention indices were standardized and comparable across different analyses.\n\nChromatographic peak areas were normalized using an external standard method. This involved dividing the instrument response by the geometric mean peak areas of three monoaromatic compounds—benzene, toluene, and ethylbenzene—from a standard mixture analyzed on the same day. This normalization step helped to account for variations in instrument response and ensured consistency in the data.\n\nFor the machine learning analyses, the Waikato Environment for Knowledge Analysis (Weka) was employed. The data were prepared for comparison between different groups, such as cases versus controls or group 1 versus group 2. Three machine learning methods were initially considered: naive Bayes, logistic regression, and random forest. However, random forests consistently outperformed the other algorithms, so all results are presented using this method.\n\nFeature selection was a crucial part of the preprocessing. It was performed in two steps using a wrapper that evaluates various subsets of features. The first step involved 10-fold cross-validation to assess how often each feature was selected. Features that were selected in at least 50% of the cross-validations formed a subset for the second step. In the second step, the wrapper used the full training set to select a final subset of features, aiming to maximize the performance of the random forest based on the area under the curve (AUC) metric.\n\nThis two-step feature selection process helped to identify subsets of informative metabolites that could more efficiently separate the groups from each other. The final selected features were then used in the random forest algorithm to achieve high classification accuracy.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the specific analysis and the feature selection process. Initially, we considered a set of 29 volatile organic compounds (VOCs) identified through an untargeted approach. However, to enhance the model's performance, we employed a two-step feature selection process using a wrapper method with the Best_First search algorithm. This process aimed to identify the most informative subsets of features that could efficiently separate the groups being compared.\n\nThe first step of feature selection involved 10-fold cross-validation, where features that were selected in at least 50% of the cross-validations formed a subset for the second step. In the second step, the wrapper method used the full training set to select a final subset of features. This iterative process helped in reducing the number of parameters while maximizing the performance of the random forest algorithm, as measured by the area under the curve (AUC).\n\nFor instance, when discriminating between cancer-positive (Ca+) and healthy control (HC) groups, using all 29 features resulted in an accuracy of 86% (AUC: 0.94). After the two steps of feature selection, the accuracy improved to 91% (AUC: 0.96) using a subset of eight features. Similarly, for discriminating between cancer-negative (Ca−) patients and HC, the accuracy increased from 90% (AUC: 0.94) with all 29 features to 94% (AUC: 0.97) with a subset of seven compounds.\n\nIn another analysis, combining 19 VOCs from a targeted approach with the 29 VOCs from the untargeted approach initially resulted in an accuracy of 45% (AUC: 0.44) using all 48 variables. After feature selection, the accuracy improved to 73% (AUC: 0.72) using just three features: thiophene from the targeted approach and acetaldoxime and N-methyl acetamide from the untargeted approach.\n\nThus, the number of parameters (p) used in the model was dynamically selected through a rigorous feature selection process, ensuring that only the most informative features were retained to enhance the model's discriminatory power.",
  "optimization/features": "In our study, the number of input features varied depending on the analysis. Initially, we used a set of 29 features identified through an untargeted approach. However, we also conducted analyses using a targeted approach with 19 features. Additionally, we explored combinations of these features to optimize the performance of our machine learning models.\n\nFeature selection was indeed performed to enhance the discriminatory power of our models. This process involved two successive steps. In the first step, we used a wrapper method with 10-fold cross-validation to evaluate various subsets of features. This step helped us identify features that were selected in at least 50% of the cross-validations. In the second step, we repeated the feature selection using the full training set, focusing on the informative subset identified in the first step. This two-step process ensured that the feature selection was robust and based on the training data only, preventing overfitting and improving the generalizability of our models.",
  "optimization/fitting": "The fitting method employed in this study utilized random forests, a machine learning algorithm known for its robustness and ability to handle high-dimensional data. The number of features initially considered was indeed large, with 29 features identified through an untargeted approach. However, through a two-step feature selection process, the number of features was reduced to a more manageable subset, typically ranging from three to nine, depending on the specific comparison being made.\n\nTo address the potential issue of over-fitting, especially given the initial large number of features relative to the training points, a rigorous cross-validation strategy was implemented. Specifically, 10-fold cross-validation was used during the feature selection process. This involved dividing the data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process was repeated 10 times, ensuring that each subset was used once as the validation set. The features that were selected in at least 50% of these cross-validations were carried forward to the next step, where a final subset of features was selected using the full training set. This approach helped to ensure that the selected features were generalizable and not merely capturing noise in the data.\n\nUnder-fitting was mitigated by the use of random forests, which are capable of capturing complex relationships in the data. The algorithm's ability to handle non-linear interactions and interactions between features allowed it to model the data more accurately. Additionally, the feature selection process ensured that the most informative features were retained, further enhancing the model's performance.\n\nIn summary, the fitting method involved a careful balance between avoiding over-fitting and under-fitting. The use of 10-fold cross-validation during feature selection and the inherent strengths of the random forest algorithm contributed to a robust and reliable model.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our machine learning models. One of the primary methods used was feature selection, which involved a two-step process. Initially, we performed feature selection using a wrapper method that evaluated various subsets of features with 10-fold cross-validation. This step helped in identifying features that were consistently informative across different subsets of the data. Features that were selected in at least 50% of the cross-validations were then subjected to a second round of feature selection. In this round, the wrapper method used the full training set to select a final subset of features, thereby reducing the risk of overfitting by focusing on the most relevant features.\n\nAdditionally, we utilized 10-fold cross-validation during the training of our random forest models. This technique involves dividing the data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. Cross-validation helps in assessing the model's performance on unseen data and ensures that the model generalizes well to new, independent datasets.\n\nBy combining feature selection with cross-validation, we were able to build models that not only performed well on the training data but also generalized effectively to new data, thereby mitigating the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available within the text of the publication. Specifically, we utilized the Waikato Environment for Knowledge Analysis (Weka) for our machine learning analyses. The methods employed included naive Bayes, logistic regression, and random forest, with a focus on random forest due to its superior performance. We performed 10-fold cross-validation for each comparison, ensuring robust and reliable results.\n\nThe feature selection process involved a two-step wrapper method using WrapperSubsetEval and the Best_First method to maximize the performance of the random forest algorithm. The metric used for evaluation was the area under the curve (AUC). The first step of feature selection involved 10-fold cross-validation to assess the frequency of feature selection, while the second step used the full training set to select the final subset of features.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the publication. The focus was on the methodology and results rather than the specific model files or detailed optimization schedules. However, the general approach and parameters used for optimization are thoroughly described, allowing for reproducibility of the methods.\n\nFor those interested in accessing the data or further details, it is important to note that the data are not publicly available due to the sensitive information at an individual level. This restriction ensures the privacy and confidentiality of the participants involved in the study.",
  "model/interpretability": "The model employed in this study is not a blackbox. The machine learning analyses were conducted using the Waikato Environment for Knowledge Analysis (Weka), specifically utilizing random forest methods. Random forests are inherently interpretable due to their structure, which consists of multiple decision trees. Each tree in the forest makes a decision based on a subset of features, and the final prediction is an aggregate of these decisions.\n\nFeature selection was a crucial part of the process, performed in two steps using a wrapper that evaluates various subsets of features. The first step involved 10-fold cross-validation to assess how frequently each feature was selected. Features that were chosen in at least 50% of the cross-validations were then subjected to a second round of feature selection using the full training set. This approach ensured that only the most informative metabolites were retained, enhancing the model's interpretability.\n\nFor instance, in the analysis comparing patients diagnosed with lung cancer (Ca+) to those with pathological CT findings but not diagnosed with lung cancer (Ca−), the model initially used all 29 volatile organic compounds (VOCs) identified by the untargeted approach. However, after feature selection, the model's performance improved significantly when using only three specific metabolites: thiophene from the targeted approach and acetaldoxime and N-methyl acetamide from the untargeted approach. This reduction in the number of features not only improved accuracy but also made the model more interpretable by highlighting the key compounds that contributed to the discrimination between the groups.\n\nSimilarly, in other analyses, such as distinguishing between Ca+ patients and healthy controls (HC), the model's performance was optimized by selecting a subset of eight features out of the initial 29 VOCs. This process of feature selection and the resulting focus on a smaller set of key compounds provide clear examples of how the model's decisions can be interpreted and understood.\n\nIn summary, the use of random forests and the rigorous feature selection process make the model transparent and interpretable. The examples provided illustrate how specific compounds were identified as critical for distinguishing between different patient groups, offering insights into the underlying biological processes.",
  "model/output": "The model employed in this study is a classification model. It was used to discriminate between different groups of subjects based on their breath compound levels. Specifically, the model was applied to distinguish between patients diagnosed with lung cancer (Ca+), patients with pathological CT findings not diagnosed with lung cancer (Ca−), and healthy controls (HC). The model's performance was evaluated using metrics such as accuracy and the area under the curve (AUC), which are typical for classification tasks.\n\nThe machine learning analyses were conducted using the Waikato Environment for Knowledge Analysis (Weka), with random forest being the primary algorithm due to its superior performance compared to naive Bayes and logistic regression. The random forest model was used to classify subjects into the appropriate groups based on the features derived from breath compound levels.\n\nFeature selection was performed in two steps to identify the most informative metabolites that could efficiently separate the groups. The first step involved 10-fold cross-validation to assess the frequency of feature selection, and the second step used the full training set to select the final subset of features. This process helped in improving the model's accuracy and AUC.\n\nThe results showed that the untargeted approach, which identified 29 differentiated features, achieved comparable or marginally better accuracy than the targeted approach when discriminating healthy individuals from patients. For example, using all 29 features, the model achieved an accuracy of 86% (AUC: 0.94) for distinguishing Ca+ from HC, which improved to 91% (AUC: 0.96) after feature selection. Similarly, the discrimination between Ca− patients and HC was also efficient, with accuracies ranging from 90% to 94% after feature selection.\n\nHowever, the model's performance was less effective when trying to discriminate between Ca+ and Ca− patients. Using all 29 VOCs, the accuracy was only 53% (AUC: 0.54), but this improved to 75% (AUC: 0.82) after feature selection. The inclusion of targeted metabolites did not significantly enhance the model's discriminatory power in this context.\n\nIn summary, the model is a classification model that uses random forest algorithms to distinguish between different groups of subjects based on breath compound levels. The feature selection process improved the model's performance, particularly in distinguishing healthy controls from patients.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not applicable.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach using machine learning techniques to assess the discriminatory power of breath analysis for different population groups. The primary algorithm employed was random forests, which consistently outperformed other methods such as naive Bayes and logistic regression. To ensure robust evaluation, 10-fold cross-validation was used for each comparison, including group 1 vs. group 2 or cases vs. controls.\n\nFeature selection was a critical part of the evaluation process. It was performed in two steps using a wrapper that evaluates various subsets of features. The first step involved 10-fold cross-validation to assess how frequently each feature was selected. Features that were chosen in at least 50% of the cross-validations formed a subset for the second step. In the second step, the wrapper used the full training set to select a final subset of features, aiming to maximize the performance of the random forest based on the area under the curve (AUC) metric.\n\nThe evaluation included various analyses to compare the performance of targeted and untargeted approaches. For instance, when using all 29 features identified by the untargeted approach, the correct classification of cancer-positive patients (Ca+) and healthy controls (HC) was 86% with an AUC of 0.94. After feature selection, using a subset of eight features, the correct classification improved to 91% with an AUC of 0.96. Similar improvements were observed for other comparisons, such as discriminating between cancer-negative patients (Ca−) and healthy controls, where the accuracy increased from 90% to 94% after feature selection.\n\nAdditionally, the method was evaluated for its ability to discriminate between cancer-positive and cancer-negative patients, both with and without considering smoking as a confounding factor. The results showed that the untargeted approach, combined with machine learning algorithms and feature selection, identified sets of compounds with sufficient discriminatory power. For example, the accuracy ranged from 75% to 77% when using three to five untargeted metabolites to discriminate between cancer and non-cancer patients.\n\nIn summary, the evaluation method involved rigorous cross-validation and feature selection processes, demonstrating the effectiveness of the untargeted approach in identifying informative metabolites for breath analysis. The random forest algorithm, in particular, showed high performance in classifying different population groups, highlighting the potential of this method for diagnostic purposes.",
  "evaluation/measure": "In the evaluation of our machine learning models, we primarily focused on two key performance metrics: accuracy and the area under the curve (AUC). These metrics were chosen for their ability to provide a comprehensive evaluation of the models' discriminatory power.\n\nAccuracy is reported as the percentage of correctly classified instances out of the total number of instances. It provides a straightforward measure of how often the model's predictions match the actual outcomes. However, accuracy alone can be misleading, especially when dealing with imbalanced datasets. Therefore, we also reported the AUC, which measures the model's ability to distinguish between positive and negative classes across all possible classification thresholds. An AUC of 1 indicates perfect discrimination, while an AUC of 0.5 suggests no discriminatory power.\n\nThese metrics are widely used in the literature for evaluating machine learning models in similar contexts, making our results comparable to other studies in the field. The use of both accuracy and AUC ensures that our evaluation is robust and representative of the models' true performance.\n\nIn addition to these primary metrics, we also performed feature selection to identify subsets of informative metabolites that could more efficiently separate the groups. This process involved two steps of feature selection using a wrapper that evaluates various subsets of features, maximizing the performance of the random forest based on the AUC metric. This approach allowed us to refine our models and improve their discriminatory power, particularly in distinguishing between cancer-positive (Ca+) and cancer-negative (Ca−) patients.\n\nThe results of our machine learning analyses were consistently better when using the untargeted approach compared to the targeted approach, especially after feature selection. This suggests that the untargeted approach identifies more informative metabolites for discriminating between different patient groups. The use of random forests, which outperformed other algorithms like naive Bayes and logistic regression, further supports the robustness of our findings.",
  "evaluation/comparison": "In our study, we focused on comparing the efficiency of targeted and untargeted breath analysis methods for discriminating lung cancer patients from healthy individuals and those with benign pulmonary diseases. We did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, we conducted an internal comparison between targeted and untargeted approaches using our own dataset.\n\nFor the targeted approach, we used a predefined set of 19 volatile organic compounds (VOCs) that were measured in breath samples. The untargeted approach, on the other hand, involved identifying 29 informative VOCs from the breath samples without prior selection. Both approaches were evaluated using machine learning methods, specifically random forests, which consistently outperformed other algorithms like naive Bayes and logistic regression.\n\nWe did not compare our methods to simpler baselines. Instead, we focused on optimizing the performance of our machine learning models by using feature selection techniques. This involved a two-step process where we first identified a subset of informative features through 10-fold cross-validation and then refined this subset using the full training set. This approach helped us achieve better discrimination between different groups of participants.\n\nThe untargeted approach yielded slightly better results in discriminating lung cancer patients from healthy controls, with an accuracy of 91.0% and an AUC of 0.96, compared to 89.1% accuracy and 0.97 AUC for the targeted analysis. However, the untargeted approach significantly improved the efficiency of discrimination between lung cancer patients and those with benign pulmonary diseases, increasing the accuracy of classification from 52.9% to 75.3% and the AUC from 0.55 to 0.82.",
  "evaluation/confidence": "The evaluation of our machine learning methods, particularly the random forest algorithm, was conducted with a focus on robustness and statistical significance. We employed 10-fold cross-validation to ensure that our performance metrics, such as accuracy and the area under the curve (AUC), were reliable and not subject to overfitting. This cross-validation process provides a measure of the model's performance across different subsets of the data, giving us confidence in the generalizability of our results.\n\nConfidence intervals for the performance metrics were not explicitly provided in the results. However, the use of 10-fold cross-validation inherently accounts for variability in the data, offering a form of implicit confidence interval by averaging performance across multiple folds. This approach helps to mitigate the risk of reporting overly optimistic performance estimates.\n\nStatistical significance was assessed through various means. For instance, we compared the performance of different feature sets and observed significant improvements in accuracy and AUC after feature selection. Specifically, the performance of random forests improved from 58% accuracy (AUC: 0.54) to 72% accuracy (AUC: 0.78) after two steps of feature selection, indicating that the selected features were statistically significant in enhancing the model's discriminatory power.\n\nAdditionally, we conducted analyses to determine if smoking was a confounding factor. The results showed that even when focusing on non-smokers, the random forest algorithm achieved significant performance improvements after feature selection, reaching 77% accuracy with an AUC of 0.85. This suggests that the identified features are robust and not merely artifacts of smoking habits.\n\nIn summary, while explicit confidence intervals for the performance metrics were not provided, the use of 10-fold cross-validation and the observed statistical significance in performance improvements provide a strong basis for claiming the superiority of our method. The results indicate that the random forest algorithm, combined with feature selection, is effective in discriminating between different patient groups based on breath analysis.",
  "evaluation/availability": "The raw evaluation files are not publicly available. This is due to the fact that they contain sensitive information at an individual level. Therefore, access to these files is restricted to protect the privacy and confidentiality of the subjects involved in the study."
}