{
  "publication/title": "Predicting COVID-19 Prognostic Biomarkers",
  "publication/authors": "The authors who contributed to the article are:\n\n- Sardar, who led the research and prediction of COVID-19 prognostic biomarkers.\n- Filbin, who provided the clinical and normalized protein expression profile data for the study.\n- Frank, who developed the WEKA tool used for training and validation of the machine learning-based classification models.\n- Jiao, who contributed to the pathway analysis using the DAVID tool.\n- Wang, who provided the drug target information from the TTD database.\n- Lalmuanawma, who demonstrated the mitigation potential of AI technology for various pandemics and infectious diseases.\n- Overmyer, who also demonstrated the mitigation potential of AI technology for various pandemics and infectious diseases.\n- Graziani, who contributed to the research on protein-based biomarkers.\n- Kaur, who also contributed to the research on protein-based biomarkers.\n- Kermali, who also contributed to the research on protein-based biomarkers.\n- Sardar, who performed integrated data analysis on COVID-19 genomes.\n- Yan, who developed a machine learning model to predict clinical biomarkers associated with individual patients' mortality.\n- Yao, who aimed to predict disease severity among COVID-19 patients using an ML-based model.\n- Shen, who identified clinical features and proteins related to the survival/death of COVID-19 patients.\n- Wynants, who also identified clinical features and proteins related to the survival/death of COVID-19 patients.\n- Yan, who also identified clinical features and proteins related to the survival/death of COVID-19 patients.\n- Sharma, who contributed to the feature selection techniques in machine learning-based classification studies.\n- Jablonka, who also contributed to the feature selection techniques in machine learning-based classification studies.\n- Kumar, who also contributed to the feature selection techniques in machine learning-based classification studies.\n- Mete, who used the leave-one-out cross-validation (LOOCV) technique for classification problems.\n- Nath, who also used the leave-one-out cross-validation (LOOCV) technique for classification problems.\n- Jiang, who also used the leave-one-out cross-validation (LOOCV) technique for classification problems.\n- Gu, who contributed to the research on the dysregulation of APOM associated with hepatitis B virus (HBV) infected patients.\n- Saha, who contributed to the research on angiopoietin (AGP) associated with COVID-19 and cancer patients.\n- Cai, who contributed to the research on the anti-fibrotic activity of Q96PL1_SG3A2 in the lungs.",
  "publication/journal": "Frontiers in Genetics",
  "publication/year": "2021",
  "publication/doi": "10.1101/2020.02.27.20028027",
  "publication/tags": "- Machine learning\n- Biomarkers discovery\n- COVID-19\n- Feature selection\n- Proteomics\n- Bioinformatics\n- Artificial intelligence\n- Prognostic biomarkers\n- Clinical parameters\n- Survival prediction",
  "dataset/provenance": "The dataset used in this study was obtained from the Olink website. It includes clinical and normalized protein expression profile data for 306 COVID-19 patients and 78 control subjects. The data is contained in three files: \"MGH_COVID_OLINK_NPX.txt,\" which includes protein data with relative quantification values in Olink’s proprietary Normalized Protein expression (NPX) units; \"MGH_COVID_Clinical_Info.txt,\" which contains essential clinical data associated with each sample; and \"variable_descriptions.xlsx,\" which provides a description of the clinical variables presented. The clinical and protein data, although present in different files, are linked based on subject IDs. This dataset has been utilized to train machine learning algorithms for predicting the prognosis of COVID-19 positive patients, focusing on identifying features such as proteins and clinical parameters associated with disease severity and survival.",
  "dataset/splits": "The dataset was split into five divisions, labeled P1 through P5. These splits were created to address the imbalance between the number of survivors and deaths in the clinical and proteomics data. Each of the five divisions contained an almost equal number of survivor data points. The dataset of dead patients was used in conjunction with each of these divisions for training and validating the models. This approach ensured that the models were evaluated across different subsets of the data, providing a more robust assessment of their performance.",
  "dataset/redundancy": "The datasets used in this study were split to address the imbalance between the number of survivors and deaths. The survivor’s data were divided into five almost equal-sized divisions, labeled P1 to P5. These divisions were used to train and validate the models alongside the dataset of deceased patients. This approach ensured that each model was evaluated across different subsets of the data, enhancing the robustness of the findings.\n\nThe training and test sets were not entirely independent due to the limited number of patient records. To optimize the use of available data, the leave-one-out cross-validation (LOOCV) technique was employed. This method involves training and validating the models such that each record is used for both training and testing, ensuring that all data points contribute to the model's evaluation.\n\nThe distribution of the datasets in this study is comparable to previously published machine learning datasets in the context of COVID-19 prognosis. The imbalance between survivors and deceased patients is a common challenge in medical datasets, and the use of techniques like LOOCV and splitting the survivor data into multiple divisions is a standard practice to mitigate this issue. This approach helps in developing more reliable and generalizable models, despite the limitations imposed by the available data.",
  "dataset/availability": "The data used in this study is available for public access. The clinical and normalized protein expression profile data for 306 COVID-19 patients and 78 control subjects were downloaded from the Olink website. The specific files accessed include \"MGH_COVID_OLINK_NPX.txt,\" \"MGH_COVID_Clinical_Info.txt,\" and \"variable_descriptions.xlsx.\" These files contain protein data with relative quantification values in Olink’s proprietary Normalized Protein expression (NPX) units, essential clinical data associated with each sample, and a worksheet describing the clinical variables, respectively.\n\nThe data splits used in the study were enforced by dividing the survivor’s data into five almost equal-sized divisions (P1–P5). The models were trained and validated using each of these five divisions along with the dataset of dead patients. This approach ensured that the data was utilized optimally, especially given the limited number of patient records available.\n\nThe data is linked based on subject IDs, ensuring that the clinical and protein data, though present in different files, are accurately correlated. This linkage is crucial for the integrity and reliability of the analysis conducted. The data preprocessing steps, including handling missing values and ensuring data balance, were meticulously followed to maintain the quality of the dataset used for training and validating the machine learning models.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are not new. They are well-established techniques available in the WEKA (Waikato Environment for Knowledge Analysis) data mining software, specifically version 3.8.2. WEKA is a popular and widely used tool in the machine learning community, providing a collection of algorithms for data preprocessing, classification, regression, clustering, association rules, and visualization.\n\nThe algorithms employed include various classification techniques such as IterativeClassifierOptimizer and RandomForest. These algorithms were chosen for their robustness and effectiveness in handling classification problems, particularly in the context of medical data analysis.\n\nThe focus of this study is on applying these established machine-learning algorithms to predict COVID-19 prognostic biomarkers using clinical and proteomics data. The goal is to leverage these algorithms to identify key features associated with survival and to develop predictive models that can assist in the early prognosis of COVID-19 patients.\n\nThe decision to use WEKA and its algorithms is driven by their proven track record in similar studies and their ability to handle the complexities of the data at hand. The study aims to contribute to the field of COVID-19 research by demonstrating the potential of these machine-learning techniques in identifying prognostic biomarkers, rather than introducing new algorithms.",
  "optimization/meta": "Not applicable",
  "optimization/encoding": "In our study, data preprocessing was a crucial step to ensure the quality and reliability of the machine learning models. We began by checking the data for any experimental impurities using semiautomated methods. For clinical data, missing values were replaced with \"-1.\" This allowed us to utilize the clinical data of 42 deceased patients and 264 survivors for training classification models based on clinical information for days 0–7.\n\nFor proteomics data, missing protein expression values were more prevalent, with 165 and 248 patients having missing data for days 3 and 7, respectively. Consequently, we only used proteomics data from day 0 for the classification model generation. Additionally, records with missing protein expression values for a COVID-19 positive patient who died within 28 days of hospitalization and for 15 survivors were excluded from the study. This resulted in a dataset of 41 deceased patients and 249 survivors for training and validating the machine learning models.\n\nThe imbalance between the number of survivors and deaths in both clinical and proteomics data was addressed by splitting the survivors' data into five almost equal-sized divisions (P1–P5). We then trained and validated the models using each of these divisions along with the dataset of deceased patients. This approach helped in mitigating the class imbalance issue and ensured that the models were robust and generalizable.\n\nThe data was encoded and pre-processed to be compatible with the WEKA machine learning tool, which was used for training and validating various classification models. All techniques available in WEKA (v3.8.2) were employed to develop the models. For clinical data, five types of models were generated based on different time points and selected clinical parameters. For proteomics data, two types of models were created, one using all 1,428 protein parameters and another based on feature selection.\n\nFeature selection techniques available in WEKA were applied to identify the most significant clinical and proteomics features. This step was essential to enhance the performance of the models by focusing on the most relevant features. The leave-one-out cross-validation (LOOCV) technique was used to optimize the use of available data, ensuring that each record was used for both training and testing. This method is particularly useful when the dataset is limited, as it maximizes the utilization of the available information.",
  "optimization/parameters": "In our study, we utilized a range of clinical and proteomics parameters to develop predictive models for COVID-19 prognosis. Initially, we trained and evaluated models using all 33 clinical parameters available on Day 0. To identify the most significant features, we applied various feature selection techniques available in the WEKA toolkit. This process led to the selection of three key clinical parameters: age, absolute lymphocyte count on Day 0, and creatinine level on Day 0. Additionally, nine clinical parameters were identified as crucial, including preexisting heart disease(s), preexisting hypertension, preexisting kidney disease(s), D-dimer level on Day 0, GI symptoms at presentation, and cardiac event-troponin level within the first 72 hours of presentation.\n\nFor proteomics data, we started with expression values of 1,428 proteins. Through feature selection, we narrowed down to 45 proteins that were enriched in various pathways, such as angiogenesis, interleukin, cytokine, chemokine, and VEGF signaling. These selected features were used to develop more accurate and efficient models.\n\nThe selection of parameters was driven by the need to enhance model performance and reduce overfitting. By focusing on the most relevant features, we aimed to create robust models that could generalize well to new data. The chosen parameters were validated through cross-validation techniques, ensuring their significance in predicting COVID-19 outcomes.",
  "optimization/features": "In our study, we utilized both clinical and proteomics data to develop machine learning-based classification models. For the clinical data, we initially considered all 33 clinical parameters available on Day 0. However, recognizing that not all features contribute equally to classification, we employed feature selection techniques to identify the most significant parameters. This process involved using various feature selection methods available in WEKA, applied to the dataset consisting of 33 clinical parameters from Days 0 to 3. Through this selection, we narrowed down to three key clinical parameters: age, absolute lymphocyte count (Day 0), and creatinine level (Day 0). Additionally, we identified nine clinical parameters that were frequently selected by multiple techniques, including age, absolute lymphocyte count (Day 0), creatinine level (Day 0), preexisting heart disease(s), preexisting hypertension, preexisting kidney disease(s), D-dimer level (Day 0), any GI-related symptoms at the time of hospital presentation, and cardiac event-Trop_72 (hs-cTn = > 100 within the first 72 hours of presentation).\n\nFor the proteomics data, we initially used the expression values of all 1,428 proteins available on Day 0. Similar to the clinical data, we performed feature selection to identify the most relevant proteins. This resulted in a subset of 45 proteins that were deemed significant for classification.\n\nFeature selection was performed using the training set only, ensuring that the models were evaluated on unseen data during the validation phase. This approach helped in optimizing the performance of our classification models by focusing on the most informative features.",
  "optimization/fitting": "The study involved training and evaluating a large number of machine learning models using clinical and proteomics data. The number of parameters was indeed much larger than the number of training points, particularly when using all 1,428 proteins for model development. To address the risk of overfitting, several strategies were employed.\n\nFirstly, feature selection techniques were applied to identify the most significant clinical and proteomics features. This reduced the dimensionality of the data and helped in focusing on the most relevant features for classification. Various feature selection methods available in WEKA were utilized to ensure that only the most informative features were used in the models.\n\nSecondly, leave-one-out cross-validation (LOOCV) was used as the primary validation technique. LOOCV is a robust method that ensures each data point is used for both training and testing, thereby maximizing the use of available data and providing a reliable estimate of model performance. This technique has been widely used in classification problems to mitigate overfitting.\n\nAdditionally, the performance of the models was evaluated using multiple statistical measures, including sensitivity, specificity, accuracy, and Matthew's correlation coefficient (MCC). Models with the highest MCC values and balanced sensitivity and specificity were considered the best prediction models. This multi-faceted evaluation approach helped in selecting models that generalize well to unseen data.\n\nTo rule out underfitting, the study involved training and evaluating thousands of models using different combinations of parameters and input features. This extensive exploration ensured that the models were complex enough to capture the underlying patterns in the data. The use of advanced machine learning techniques available in WEKA, such as RandomForest, AdaBoostM1, and LogitBoost, further helped in building robust models that could handle the complexity of the data.\n\nIn summary, the study employed feature selection, LOOCV, and comprehensive model evaluation to address the challenges of overfitting and underfitting, ensuring the development of reliable and generalizable classification models.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was feature selection. We applied various feature selection techniques available in WEKA to identify the most significant clinical and proteomics features. This process helped in reducing the dimensionality of the data and focusing on the most relevant features, thereby minimizing the risk of overfitting.\n\nAdditionally, we utilized cross-validation techniques, specifically leave-one-out cross-validation (LOOCV). This method ensures that each record in the dataset is used for both training and testing, providing a comprehensive evaluation of the model's performance and helping to prevent overfitting by ensuring that the model generalizes well to unseen data.\n\nMoreover, we trained and evaluated multiple models using different combinations of parameters and input features. This extensive experimentation allowed us to identify the best-performing models and reduce the likelihood of overfitting by comparing the performance across various configurations.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, we utilized the WEKA machine learning models, and the techniques employed, such as IterativeClassiﬁerOptimizer, RandomForest, and RandomSubSpace, are detailed in the results section. The performance metrics, including sensitivity, specificity, accuracy, and Mathew’s correlation coefficient (MCC), are also provided for various models.\n\nThe optimization schedule and model files are not explicitly detailed in the publication. However, the methods and techniques used for feature selection and model training are thoroughly described. The leave-one-out cross-validation (LOOCV) technique was employed to optimize the use of available data, ensuring that each record was used for both training and testing.\n\nRegarding the availability and licensing of the configurations and parameters, the WEKA software, which was used for developing the models, is open-source and freely available. The specific configurations and parameters used in our study can be inferred from the descriptions provided in the publication. However, the exact model files and optimization schedules are not made publicly available.\n\nFor those interested in replicating or building upon our work, the detailed descriptions of the methods and techniques should provide a solid foundation. Additionally, the use of open-source tools like WEKA ensures that the necessary software is accessible to the research community.",
  "model/interpretability": "The models developed in this study are not entirely black-box, as we have employed various techniques to enhance their interpretability. We utilized feature selection methods to identify the most significant clinical parameters and proteins that contribute to the classification of COVID-19 patients' survival outcomes. For instance, three key clinical parameters—age, absolute lymphocyte count on Day 0, and creatinine level on Day 0—were consistently selected as important features across multiple models. Additionally, nine clinical parameters, including preexisting heart disease, hypertension, and D-dimer levels, were identified as crucial for predicting patient outcomes.\n\nIn the proteomics data, we initially used all 1,428 protein expression values but later applied feature selection algorithms to narrow down to 45 proteins that significantly impact the model's predictions. These proteins are enriched in pathways such as angiogenesis, interleukin signaling, and cytokine signaling, providing biological insights into the disease mechanisms.\n\nThe use of WEKA's machine learning techniques, such as RandomSubSpace and IterativeClassiﬁerOptimizer, allowed us to train models that not only achieved high accuracy but also highlighted the most influential features. For example, the RandomSubSpace technique identified nine shortlisted clinical parameters, while the IterativeClassiﬁerOptimizer technique achieved high accuracy with a subset of selected features. These techniques help in understanding which clinical parameters and proteins are most relevant for predicting COVID-19 prognosis, making the models more interpretable.\n\nFurthermore, the CovidPrognosis webserver, developed using LAMP server technologies, provides a user-friendly interface for predictions based on these models. The webserver allows users to input clinical parameters and view the model's predictions, along with the underlying features that contribute to these predictions. This transparency helps clinicians and researchers understand the basis of the model's decisions, enhancing trust and facilitating further research.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the survival outcomes of COVID-19 patients based on clinical and proteomics data. The classification models were trained and validated using various machine learning techniques available in the WEKA package. These models were evaluated using statistical measures such as sensitivity, specificity, accuracy, and Matthew's correlation coefficient (MCC). The performance of the models was assessed to determine their effectiveness in classifying patients into survived and died categories. The best-performing models achieved high accuracy, sensitivity, and specificity values, indicating their reliability in predicting COVID-19 prognosis. The models were developed using different sets of clinical parameters, including Day 0, Day 3, Day 7, and Days 0–7 clinical parameter values. Additionally, feature selection techniques were applied to identify the most significant clinical and proteomics features for model training. The use of leave-one-out cross-validation (LOOCV) ensured optimal utilization of the available data for training and validation. The models were evaluated using a variety of classification algorithms, and the best-performing models were selected based on their performance metrics. The results demonstrate the potential of machine learning-based classification models in predicting COVID-19 prognosis and identifying key prognostic biomarkers.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The CovidPrognosis webserver has been developed to facilitate the use of the machine learning models created for predicting COVID-19 prognosis. This webserver is built using efficient and open-source Linux-Apache-MySQL-PHP/Perl/Python (LAMP) server technologies. The user interface is designed with HTML, CSS, PHP (v7.1.28), and AJAX, ensuring a seamless user experience.\n\nThe webserver allows users to input clinical parameters for Day 0 or Days 0, 3, and 7. Based on these inputs, the server predicts the survival chances of the patient. The webserver is freely available for scientific use and clinical validation at http://14.139.62.220/covidprognosis/. Detailed descriptions of the clinical parameters and how to use the webserver are provided on the website at http://14.139.62.220/covidprognosis/help.php.\n\nThe source code for the webserver is not explicitly mentioned as being released. However, the webserver itself serves as a method to run the algorithm, providing an executable interface for users to input data and receive predictions. The webserver is regularly updated with the latest COVID-19 datasets to enhance its efficiency, reliability, and utility. This ensures that the models remain relevant and accurate as new data becomes available.",
  "evaluation/method": "The evaluation of the models was conducted using leave-one-out cross-validation (LOOCV) due to the limited number of patient records available. This technique ensures that each record is used for both training and testing, optimizing the use of the available data. The performance of the models was assessed using several statistical measures, including sensitivity, specificity, accuracy, and Matthew's correlation coefficient (MCC). Sensitivity measures the proportion of actual positives correctly identified, while specificity measures the proportion of actual negatives correctly identified. Accuracy provides the overall correctness of the model, and MCC offers a balanced measure that considers true and false positives and negatives. The models with the highest MCC values and nearly equal sensitivity and specificity were considered the best prediction models. This comprehensive evaluation approach ensures that the models are robust and reliable for classifying COVID-19 patients based on clinical and proteomic data.",
  "evaluation/measure": "In our study, we evaluated the performance of our machine learning models using several statistical measures to ensure a comprehensive assessment. The primary metrics reported include sensitivity, specificity, accuracy, and Matthew's correlation coefficient (MCC). Sensitivity, also known as recall, measures the proportion of actual positives correctly identified by the model. Specificity, on the other hand, measures the proportion of actual negatives correctly identified. Accuracy provides an overall measure of the model's correctness by calculating the proportion of true results (both true positives and true negatives) among the total number of cases examined. MCC is a balanced measure that takes into account true and false positives and negatives, providing a value between -1 and 1, where 1 indicates a perfect prediction, 0 indicates a prediction no better than random, and -1 indicates total disagreement between prediction and observation.\n\nAdditionally, we reported the Receiver Operating Characteristic (ROC) curve, which plots the true positive rate against the false positive rate at various threshold settings. The area under the ROC curve (AUC-ROC) provides a single scalar value that summarizes the performance of the model across all classification thresholds.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in medical and biological studies. They provide a robust and representative evaluation of model performance, ensuring that our findings are comparable with other studies in the field. The use of MCC is particularly important in imbalanced datasets, as it accounts for both sensitivity and specificity, providing a more nuanced evaluation of model performance. The ROC curve and AUC-ROC further enhance the evaluation by considering the trade-off between sensitivity and specificity across different thresholds.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized a specific dataset for training and validating the machine learning models, but these datasets are not released to the public. The models were developed using the WEKA tool, and various techniques available within WEKA were employed to train and validate the classification models. The performance of the models was evaluated using statistical measures such as sensitivity, specificity, accuracy, and Matthew's correlation coefficient (MCC). The results of these evaluations are presented in the publication, but the raw data used for these evaluations is not accessible to the public. Therefore, while the methods and results are transparent, the underlying data remains proprietary."
}