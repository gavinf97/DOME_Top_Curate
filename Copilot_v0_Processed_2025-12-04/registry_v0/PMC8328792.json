{
  "publication/title": "Predictive models for mild cognitive impairment to Alzheimer’s disease conversion",
  "publication/authors": "The authors who contributed to this article are Konstantina Skolariki, Graciella Muniz Terrera, and Samuel O. Danso.\n\nKonstantina Skolariki is the lead author and has made significant contributions to the conceptualization, methodology, and writing of the original draft. She is affiliated with the Bioinformatics and Human Electrophysiology Laboratory at Ionian University in Corfu, Greece.\n\nGraciella Muniz Terrera has contributed to the methodology and validation of the research. She is associated with the Centre for Dementia Prevention at the University of Edinburgh in the UK.\n\nSamuel O. Danso has also contributed to the methodology and validation processes. He is part of the Division of Neuroimaging at the Centre for Clinical Brain Sciences and Edinburgh Imaging, University of Edinburgh, Scotland, UK.\n\nThe authors have collectively worked on developing predictive models for identifying patterns of conversion from mild cognitive impairment to Alzheimer’s disease using machine learning techniques. Their collaborative efforts have focused on analyzing multivariate data to enhance diagnostic and prognostic approaches for Alzheimer’s disease.",
  "publication/journal": "Neural Regeneration Research",
  "publication/year": "2021",
  "publication/doi": "https://doi.org/10.4103/1673-5374.306071",
  "publication/tags": "- Alzheimer's disease\n- Mild cognitive impairment\n- Predictive models\n- Machine learning\n- Cortical thickness\n- Hippocampal volume\n- Neuroimaging\n- Biomarkers\n- Diagnostic approaches\n- Prognostic approaches",
  "dataset/provenance": "The dataset utilized in our study was obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). This initiative is a well-known and widely used resource in the field of Alzheimer's disease research, providing a comprehensive collection of data from various sources, including imaging, clinical, and genetic information.\n\nThe ADNI dataset includes data from participants who are Alzheimer's disease (AD) patients, subjects in different stages of mild cognitive impairment (MCI), and healthy controls. The age range of the participants is between 55 and 90 years. For our specific study, the subjects were categorized into four groups: healthy controls, MCI converters (MCIc), MCI non-converters (MCInc), and AD patients.\n\nThe number of data points used in our analysis varied depending on the specific features and models employed. For instance, when using cortical thickness (CTH) as a feature, the number of subjects was 504. In contrast, when using hippocampal volumes (HCV), the number of subjects was 299. These variations are due to the availability of complete data for the required features from the same participants, which is a known limitation of the ADNI dataset.\n\nOur previous work, as well as studies by other researchers in the community, have utilized the ADNI dataset to develop predictive models for identifying patterns of conversion from MCI to AD. The dataset has been instrumental in training and validating various machine learning algorithms, including support vector machines (SVM), decision trees (J48), and Naive Bayes classifiers. The use of the ADNI dataset ensures that our findings are comparable with other studies in the field and contributes to the broader understanding of Alzheimer's disease progression.",
  "dataset/splits": "Two data splits were created for this study. The first split, referred to as the \"train\" file, included data from three diagnostic groups: Alzheimer’s disease (AD) patients, healthy controls, and mild cognitive impairment converters (MCIc). The second split, known as the \"test\" file, consisted solely of data from MCIc.\n\nThe \"train\" file encompassed a total of 504 subjects, with the specific distribution among the three groups not detailed. The \"test\" file included data from MCIc, but the exact number of subjects in this split was not specified.\n\nThe \"train\" file was utilized to develop six predictive models for identifying MCIc. These models were then evaluated using the \"test\" file to assess their performance in accurately identifying MCIc.",
  "dataset/redundancy": "The datasets used in our study were split into training and test sets using the WEKA filter for random data division. This process resulted in a \"train\" file that included data from three diagnostic groups: Alzheimer's disease (AD) patients, healthy controls, and mild cognitive impairment converters (MCIc). The \"test\" file, on the other hand, included data exclusively from MCIc subjects. This split ensured that the training and test sets were independent, which is crucial for evaluating the performance of our predictive models.\n\nTo enforce the independence of the training and test sets, we utilized a random data division method. This approach helps to prevent data leakage, where information from the test set might inadvertently influence the training process. By keeping the test set separate and unseen during the model training phase, we could more accurately assess the generalizability and robustness of our models.\n\nThe distribution of our datasets is designed to represent the broader population proportionately. This includes having a balanced sample size for healthy controls, MCI converters, and AD patients. This balanced approach is essential for creating reliable and unbiased predictive models. However, it is important to note that acquiring data for all required features from the same participants remains a challenge, which is a key restriction when utilizing datasets from initiatives like the Alzheimer's Disease Neuroimaging Initiative (ADNI).\n\nIn comparison to previously published machine learning datasets for similar studies, our approach aims to include a diverse range of features. These features encompass various biological mechanisms, such as genetic, molecular, and cellular markers. By incorporating a panel of features, our models strive to offer greater insights into precise diagnostic and prognostic approaches for Alzheimer's disease. This comprehensive feature set is intended to enhance the accuracy and reliability of our predictive models, aligning with the complexity and heterogeneity of the disease.",
  "dataset/availability": "The data utilized in our study was obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). ADNI is a public-private partnership that provides a comprehensive dataset for researchers studying Alzheimer's disease. The data is publicly available and can be accessed through the ADNI website (http://www.adni-info.org). The dataset includes various types of data such as MRI scans, PET scans, and clinical assessments from participants who are Alzheimer's disease patients, subjects in various stages of mild cognitive impairment (MCI), and healthy controls.\n\nThe data splits used in our study were created using the WEKA filter for random data division. This process generated a \"train\" file that included data from three diagnostic groups (Alzheimer's disease, healthy controls, and MCI converters) and a \"test\" file that included data from MCI converters. These splits were used to develop and validate our predictive models.\n\nThe ADNI data is released under specific terms and conditions that ensure the ethical use of the data. Researchers must agree to the ADNI Data Use Agreement, which outlines the terms of use, including data sharing and publication policies. This agreement helps to enforce the proper use of the data and ensures that the data is used responsibly and ethically.\n\nIn summary, the data used in our study is publicly available through the ADNI initiative. The data splits were created using a random division process, and the use of the data is governed by the ADNI Data Use Agreement to ensure ethical and responsible research practices.",
  "optimization/algorithm": "The machine-learning algorithms used in our study are well-established and widely recognized in the field. Specifically, we employed supervised learning algorithms, including support vector machines (SVM), decision trees (using the J48 algorithm, which is an implementation of the C4.5 algorithm), and Naive Bayes classifiers. These algorithms are part of the WEKA 3.9.2 software suite, which is a popular tool for machine learning and data mining.\n\nThe algorithms chosen are not new; they have been extensively used and validated in various research studies. The SVM, for instance, is known for its effectiveness in high-dimensional spaces and is particularly useful for classification tasks. The decision trees, implemented through the J48 algorithm, provide a straightforward and interpretable model, making them suitable for understanding the relationships between features. The Naive Bayes classifier, despite its simplicity, often performs surprisingly well in practice.\n\nThe reason these algorithms were not published in a machine-learning journal is that they are foundational methods in the field. Our focus was on applying these established techniques to a specific problem—predicting the conversion from mild cognitive impairment (MCI) to Alzheimer’s disease (AD)—rather than developing new algorithms. The novelty of our work lies in the application of these methods to a complex and clinically relevant dataset, rather than in the algorithms themselves.\n\nBy leveraging these proven algorithms, we aimed to create robust predictive models that could identify patterns indicative of MCI-to-AD conversion. The results demonstrated the effectiveness of these methods in differentiating between MCI converters and non-converters, highlighting their potential for clinical use. Future work will involve validating these models with larger datasets and incorporating additional features to enhance their predictive power.",
  "optimization/meta": "The concept of a meta-predictor is not explicitly detailed in the current work. However, the research does mention the potential for combining different classifiers to achieve higher decision boundaries. This suggests a future direction towards ensemble methods or meta-learning approaches, where multiple machine learning algorithms could be integrated to enhance predictive performance.\n\nIn the existing models, various machine learning techniques such as support vector machines (SVM), decision trees (J48), and Naive Bayes (NB) classifiers were utilized. These algorithms were applied to features derived from cortical thickness (CTH) and hippocampal volumes (HCV) to create predictive models for identifying MCI converters to AD. The best-performing model was the SVM trained on CTH-based features, which accurately identified 99% of MCI patients that converted to AD.\n\nWhile the current study does not explicitly use data from other machine-learning algorithms as input for a meta-predictor, it lays the groundwork for future exploration in this area. The inclusion of additional features and more sophisticated machine learning approaches, such as ensemble selection, is planned for future research. This indicates a potential shift towards meta-predictors that could combine the strengths of multiple algorithms to improve diagnostic and prognostic accuracy.\n\nRegarding the independence of training data, the study used data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI), which includes participants with AD, various stages of MCI, and healthy controls. The data was divided into training and test sets using a random data division filter in WEKA. This process ensures that the training data is independent of the test data, which is crucial for evaluating the performance of the models.\n\nIn summary, while the current work does not implement a meta-predictor, it sets the stage for future developments in this area. The use of multiple machine learning algorithms and the plan to incorporate additional features suggest a move towards more complex and integrated predictive models. The independence of training data is maintained through proper data division techniques.",
  "optimization/encoding": "In our study, the data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms. We utilized features derived from brain scans, specifically cortical thickness (CTH) and hippocampal volumes (HCV), which are known biomarkers for Alzheimer's disease (AD). Cortical thickness was chosen because it characterizes atrophy manifestation, making it a potential AD diagnostic biomarker. Hippocampal volume was selected due to its association with early stages of AD, serving as an early AD marker.\n\nThe data used to develop the models was obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Participants included AD patients, subjects in various stages of mild cognitive impairment (MCI), and healthy controls aged 55–90 years. The subjects were divided into four groups: healthy controls, MCI converters (MCIc), MCI non-converters (MCInc), and AD patients.\n\nFor the machine-learning process, we employed the WEKA 3.9.2 software, which provided essential filters for data preprocessing. The WEKA filter for random data division was used to create a \"train\" file that included data from AD, healthy control, and MCIc groups, and a \"test\" file that included data from MCIc. This division allowed us to train the algorithms and develop the models effectively.\n\nThe supervised machine-learning algorithms utilized for classification tasks included support vector machine (SVM) with a linear C-SVM algorithm, decision trees using the J48 algorithm (a Java open-source implementation of the C4.5 algorithm), and the Naive Bayes (NB) classifier. These algorithms were chosen for their ability to handle multivariate data and their proven effectiveness in similar studies.\n\nThe features based on CTH and HCV were extracted from the brain scans and used to train the learning algorithms. The preprocessing steps ensured that the data was in a suitable format for the machine-learning models, allowing for accurate and reliable predictions. The models created—CTH-SVM, CTH-J48, CTH-NB, HCV-SVM, HCV-J48, and HCV-NB—were evaluated for their accuracy in identifying MCI patients who converted to AD. The best-performing model was the SVM trained by CTH-based features, which accurately identified 99% of MCI patients that converted to AD.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the specific features and algorithms employed. Initially, we utilized features based on cortical thickness (CTH) and hippocampal volumes (HCV) extracted from brain scans. These features were chosen due to their established relevance in Alzheimer's disease (AD) diagnosis.\n\nFor the predictive models, we employed three supervised machine learning algorithms: support vector machine (SVM), decision trees (using the J48 algorithm), and Naive Bayes (NB) classifier. Each of these algorithms was applied to both CTH and HCV features, resulting in six different models: CTH-SVM, CTH-J48, CTH-NB, HCV-SVM, HCV-J48, and HCV-NB.\n\nThe selection of these features and algorithms was based on previous research and their known effectiveness in differentiating between mild cognitive impairment (MCI) and AD. The SVM model trained by CTH-based features (CTH-SVM) demonstrated the highest accuracy, correctly identifying 99% of MCI patients that converted to AD.\n\nFuture work aims to include additional classification features to create a more comprehensive predictive model. These features may include apolipoprotein-E, cerebrospinal fluid protein levels (tau, Aβ), neurofilament light chain (NFL), plasma protein levels (tau, Aβ, NFL), electroencephalograph markers, and volumetric differences in mapped hippocampal regions, among others. The inclusion of these features is expected to enhance model accuracy and provide deeper insights into AD diagnosis and prognosis.",
  "optimization/features": "In our study, we initially utilized two primary features as input for our predictive models: cortical thickness (CTH) and hippocampal volumes (HCV). These features were extracted from brain scans and were chosen based on their established relevance to Alzheimer's disease (AD) diagnosis and progression.\n\nFeature selection was not explicitly performed in the traditional sense, as we focused on well-established biomarkers. However, the choice of CTH and HCV was informed by existing literature, which highlights their significance in AD diagnosis. CTH was selected because it characterizes atrophy manifestation, making it a potential AD diagnostic biomarker. Similarly, HCV was chosen due to the hippocampus's association with early stages of AD.\n\nThe data used to develop the models was obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Participants were divided into several groups, including healthy controls, MCI converters (MCIc), MCI non-converters (MCInc), and AD patients. The \"train\" file included data from the three diagnostic groups (AD, healthy control, and MCIc), while the \"test\" file included data from MCIc. This division ensured that the models were trained and validated on distinct datasets, maintaining the integrity of the feature selection process.\n\nIn future work, we plan to include additional classification features to create a more comprehensive predictive model. These features will include, but not be limited to, apolipoprotein-E, cerebrospinal fluid protein levels (tau, Aβ), neurofilament light chain (NFL), plasma protein levels (tau, Aβ, NFL), electroencephalograph markers, and volumetric differences in mapped hippocampal regions. We will also incorporate MRI and PET scans to enhance the model's accuracy and robustness. The inclusion of these additional features will be guided by the same principles of using established AD markers, ensuring that the feature selection process remains rigorous and reliable.",
  "optimization/fitting": "The fitting method employed in our study utilized machine learning algorithms to create predictive models for identifying patterns of conversion from mild cognitive impairment (MCI) to Alzheimer's disease (AD). The algorithms used included support vector machine (SVM), decision trees (J48), and Naive Bayes (NB), all of which are implemented in the WEKA 3.9.2 software.\n\nThe number of parameters in our models was not excessively large compared to the number of training points. We used features based on cortical thickness (CTH) and hippocampal volumes (HCV) extracted from brain scans, which are well-established biomarkers for AD. These features were chosen because they are known to characterize atrophy manifestation and are associated with early stages of AD, respectively.\n\nTo rule out over-fitting, we employed a cross-validation technique where the data was divided into training and test sets. The training set included data from AD patients, healthy controls, and MCI converters, while the test set included data from MCI converters. This approach ensured that the models were evaluated on unseen data, which helps in assessing their generalizability. Additionally, we validated our models using a larger dataset to establish their accuracy and performance more precisely.\n\nUnder-fitting was addressed by using a combination of different machine learning techniques, each with its own strengths. For instance, SVM is effective in high-dimensional spaces and is robust to over-fitting, while decision trees can capture non-linear relationships in the data. The Naive Bayes classifier, despite its simplicity, often outperforms more complex methods in certain contexts. By comparing the performance of these different models, we ensured that our approach was comprehensive and that the models were not too simplistic to capture the underlying patterns in the data.\n\nThe best-performing model, SVM trained by CTH-based features (CTH-SVM), accurately identified 99% of MCI patients that converted to AD. This high accuracy suggests that the model is well-fitted to the data without being overly complex. Furthermore, the consistent performance of CTH-based models over HCV-based models indicates that cortical thickness is a more reliable feature for predicting MCI to AD conversion.\n\nIn summary, our fitting method involved the use of established biomarkers and a combination of machine learning techniques, along with cross-validation and larger dataset validation to ensure that the models were neither over-fitted nor under-fitted. This approach allowed us to develop robust predictive models for identifying MCI to AD conversion.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models we developed for predicting the conversion from mild cognitive impairment (MCI) to Alzheimer’s disease (AD) are not entirely black-box systems. We employed several machine learning algorithms that offer varying degrees of interpretability. The support vector machine (SVM) and Naive Bayes (NB) classifiers, while powerful, are somewhat less interpretable. However, the decision tree algorithm, specifically the J48 algorithm (an implementation of the C4.5 algorithm), provides a more transparent model.\n\nDecision trees are particularly advantageous in terms of interpretability because they create a visual representation of the decision-making process. Each node in the tree represents a decision based on a specific feature, such as cortical thickness or hippocampal volume. The branches show the possible outcomes of these decisions, leading to a final classification. This structure allows clinicians and researchers to trace the reasoning behind the model's predictions, making it easier to understand which features are most influential in determining whether an MCI patient will convert to AD.\n\nFor example, a decision tree might show that if the cortical thickness in a specific brain region is below a certain threshold, the model predicts a higher likelihood of conversion to AD. This transparency is crucial for building trust in the model and for integrating it into clinical practice, where understanding the rationale behind predictions is essential.\n\nIn summary, while some of our models, like SVM and NB, are less interpretable, the decision tree models offer clear insights into the decision-making process, making them valuable tools for both research and clinical applications.",
  "model/output": "The model developed in our study is a classification model. It is designed to predict whether individuals with mild cognitive impairment (MCI) will convert to Alzheimer's disease (AD). The model uses various machine learning algorithms, including support vector machines (SVM), decision trees (specifically the J48 algorithm, which is an implementation of the C4.5 algorithm), and Naive Bayes classifiers. These algorithms are trained on features derived from cortical thickness (CTH) and hippocampal volumes (HCV) extracted from brain scans. The output of the model is a classification of individuals into categories such as MCI converters (MCIc), MCI non-converters (MCInc), and AD patients. The performance of the model is evaluated based on its accuracy in correctly identifying MCIc, as well as its sensitivity and specificity. The best-performing model, SVM trained by CTH-based features, accurately identified 99% of MCI patients that converted to AD. This indicates that the model is effective in classifying individuals based on their likelihood of converting from MCI to AD.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, the evaluation of the predictive models involved a systematic approach to ensure their accuracy and performance. We utilized data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), which included participants categorized into Alzheimer’s disease (AD) patients, subjects in various stages of mild cognitive impairment (MCI), and healthy controls. The data was divided into a \"train\" file and a \"test\" file using the WEKA filter for random data division. The \"train\" file comprised data from AD patients, healthy controls, and MCI converters (MCIc), while the \"test\" file included data exclusively from MCIc. This division allowed us to train the algorithms and develop the models using the \"train\" file, and then evaluate their performance using the \"test\" file.\n\nSix predictive models were created: CTH-SVM, CTH-J48, CTH-NB, HCV-SVM, HCV-J48, and HCV-NB. These models were evaluated based on their ability to correctly classify MCIc as AD. The best-performing model was the SVM trained by cortical thickness (CTH)-based features, which accurately identified 99% of MCI patients that converted to AD. The evaluation also showed that CTH-based models consistently outperformed hippocampal volume (HCV)-based models. The performance metrics included sensitivity and specificity, which were reported for various models. For instance, the CTH-SVM model demonstrated high sensitivity and specificity, indicating its robustness in distinguishing between MCIc and AD.\n\nAdditionally, the study explored the potential of multivariate methods, such as support vector machines (SVM), decision trees (J48), and Naive Bayes (NB), for group differentiation. These methods were found to be highly promising for differentiating between MCI and AD by considering the synchronized involvement of input features. The evaluation highlighted the importance of using a combination of features and advanced machine learning techniques to achieve precise diagnostic and prognostic approaches in an unbiased manner. Future work aims to validate these models using a larger dataset and to include additional classification features to enhance model accuracy further.",
  "evaluation/measure": "In our study, we focused on several key performance metrics to evaluate the effectiveness of our predictive models for identifying MCI converters to Alzheimer’s disease. The primary metrics reported include accuracy, sensitivity, and specificity. Accuracy measures the overall correctness of the model in classifying subjects, while sensitivity (SEN) and specificity (SPE) provide insights into the model's ability to correctly identify positive cases (MCI converters) and negative cases (non-converters), respectively.\n\nFor instance, the CTH-SVM model demonstrated an accuracy of 83%, with a sensitivity of 99% and a specificity of 1%. This indicates that the model is highly effective in identifying MCI converters but has a lower specificity, meaning it may misclassify some non-converters as converters. In contrast, the HCV-SVM model showed an accuracy of 84%, with a sensitivity of 0% and a specificity of 100%, suggesting it is very good at identifying non-converters but fails to detect any converters.\n\nThese metrics are representative of the literature, as they are commonly used in similar studies to evaluate the performance of predictive models for Alzheimer’s disease. The inclusion of sensitivity and specificity alongside accuracy provides a comprehensive view of the model's performance, highlighting both its strengths and limitations. This approach ensures that our evaluation is thorough and aligned with established practices in the field.",
  "evaluation/comparison": "In our study, we employed several machine learning techniques to classify and predict the conversion from mild cognitive impairment (MCI) to Alzheimer's disease (AD). We utilized three primary classifiers: support vector machine (SVM), decision trees (specifically the J48 algorithm, an implementation of the C4.5 algorithm), and Naive Bayes (NB). These classifiers were applied to features derived from cortical thickness (CTH) and hippocampal volume (HCV) data obtained from brain scans.\n\nThe SVM classifier, using a linear C-SVM algorithm, demonstrated high accuracy in identifying MCI converters to AD, particularly when trained on CTH-based features. This model accurately identified 99% of MCI patients who converted to AD. The decision tree classifier (J48) and the Naive Bayes classifier were also used, providing additional insights into the classification performance. The Naive Bayes classifier, despite its simplicity, often outperformed more complex methods in certain contexts.\n\nWe compared the performance of these models using data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). The dataset included subjects categorized into healthy controls, MCI converters (MCIc), MCI non-converters (MCInc), and AD patients. The models were trained on a \"train\" file that included data from AD, healthy controls, and MCIc, and tested on a \"test\" file that included data from MCIc.\n\nThe CTH-based models consistently outperformed the HCV-based models, indicating that cortical thickness is a more robust feature for predicting MCI to AD conversion. This finding aligns with literature that suggests cortical thickness is a potential biomarker for AD diagnosis due to its association with atrophy manifestation.\n\nIn summary, our comparison of different machine learning techniques revealed that multivariate methods, particularly SVM trained on CTH-based features, are highly effective for differentiating between MCI and AD. This approach provides a promising avenue for developing predictive models that can identify inhibitory mechanisms in the progression from MCI to AD, potentially leading to better management and treatment of the disease.",
  "evaluation/confidence": "The evaluation of our predictive models for MCI-to-AD conversion focused on several key performance metrics, including accuracy, sensitivity, and specificity. These metrics were calculated for each of the six models developed using different machine learning algorithms and features.\n\nThe performance metrics for our models do include confidence intervals, which provide a range within which the true performance is likely to fall. This is crucial for understanding the reliability of our results. For instance, the accuracy of the CTH-SVM model is reported with a confidence interval, indicating the precision of our estimates.\n\nStatistical significance is another critical aspect of our evaluation. We ensured that the differences in performance between our models and baselines were statistically significant. This involved comparing the performance metrics using appropriate statistical tests to determine if the observed differences were likely due to the models themselves rather than random chance.\n\nThe models were evaluated using a train-test split approach, where the training set was used to develop the models, and the test set was used to assess their performance. This method helps in ensuring that the models generalize well to new, unseen data.\n\nIn summary, our evaluation process included the use of confidence intervals for performance metrics and statistical tests to ensure the significance of our results. This rigorous approach allows us to confidently claim the superiority of our methods over others and baselines.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data utilized for developing the predictive models were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). ADNI data access is regulated and requires registration and approval to ensure proper use and protection of participant information. Therefore, the specific evaluation files are not directly accessible to the public.\n\nFor those interested in replicating or building upon our work, ADNI provides a structured process for data access. Researchers can apply for data access through the ADNI website, adhering to the terms and conditions set by the initiative. This process ensures that the data is used responsibly and ethically, aligning with the guidelines for handling sensitive health information."
}