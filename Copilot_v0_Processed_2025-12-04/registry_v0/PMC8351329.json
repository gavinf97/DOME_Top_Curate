{
  "publication/title": "Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma",
  "publication/authors": "The authors who contributed to the article are:\n\n- Meng-Xiang Li, who contributed to the writing of the original draft.\n- Xiao-Meng Sun, who contributed to data curation.\n- Wei-Gang Cheng, who contributed to data curation.\n- Hao-Jie Ruan, who contributed to methodology.\n- Ke Liu, who contributed to methodology.\n- Pan Chen, who contributed to methodology.\n- Hai-Jun Xu, who contributed to methodology.\n- She-Gan Gao, who contributed to supervision.\n- Xiao-Shan Feng, who contributed to supervision.\n- Yi-Jun Qi, who contributed to conception and design, and writing-reviewing & editing.",
  "publication/journal": "BMC Cancer",
  "publication/year": "2021",
  "publication/doi": "10.1186/s12885-021-08647-1",
  "publication/tags": "- Esophageal squamous cell carcinoma\n- Prognostic biomarkers\n- Machine learning algorithms\n- Logistic regression\n- Support vector machine\n- Artificial neural network\n- Random forest\n- XGBoost\n- Molecular interaction network\n- Prognostic classification\n- Feature selection\n- Survival analysis\n- Kaplan-Meier survival analysis\n- Log-rank test\n- Biomarker validation\n- Cancer prognosis\n- Molecular heterogeneity\n- Prognostic prediction\n- ESCC staging system\n- Integrated learning algorithms",
  "dataset/provenance": "The dataset used in this study is sourced from publicly available mRNA transcriptome data of esophageal squamous cell carcinoma (ESCC). Specifically, the data is obtained from the Gene Expression Omnibus (GEO) and The Cancer Genome Atlas (TCGA) datasets. The GEO dataset, identified as GSE53625, includes 179 patients with ESCC. These patients are randomly divided into a training cohort of 134 patients and a test cohort of 45 patients. The data from GSE53625 has been normalized in the original study, and all samples are paired, meaning the difference between the expression values of cancer tissue and corresponding adjacent tissue is used as the input data for subsequent calculations.\n\nAdditionally, the TCGA-ESCC dataset contains 82 patients with ESCC. Out of these, 37 Vietnamese patients with ESCC are used for independent validation. This dataset provides a robust foundation for the analysis and development of prognostic classifiers in the study.",
  "dataset/splits": "The dataset used in this study was split into two main cohorts: a training cohort and a test cohort. The training cohort consisted of 134 patients with esophageal squamous cell carcinoma (ESCC), while the test cohort included 45 patients. Additionally, an independent validation cohort from TCGA-ESCC contained 37 Vietnamese patients with ESCC. The data from GSE53625 was used for the primary training and testing, with the TCGA-ESCC dataset serving as an additional validation set. The distribution of data points was designed to ensure robust model training and validation, with the training cohort being larger to facilitate effective learning and the test cohort providing a means to evaluate the model's performance on unseen data. The independent validation cohort further confirmed the generalizability of the findings.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study is publicly available. Specifically, mRNA transcriptome data of esophageal squamous cell carcinoma (ESCC) was obtained from the Gene Expression Omnibus (GEO) and The Cancer Genome Atlas (TCGA) datasets. The GEO dataset used is GSE53625, which includes 179 patients with ESCC, divided into a training cohort of 134 patients and a test cohort of 45 patients. The TCGA-ESCC dataset contains 82 patients with ESCC, with 37 Vietnamese patients used for independent validation.\n\nThe data from these sources is accessible to the public, adhering to the licensing terms set by GEO and TCGA. These platforms provide open access to their datasets, allowing researchers to download and use the data for various studies, including ours. The specific datasets were accessed and utilized in accordance with the guidelines and licensing agreements provided by GEO and TCGA, ensuring compliance with their data usage policies.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. Specifically, five different algorithms were employed: logistic regression (LR), support vector machine (SVM), artificial neural network (ANN), random forest (RF), and eXtreme Gradient Boosting (XGBoost). These algorithms are categorized into weak classifier algorithms (LR, SVM, ANN) and strong classifier algorithms (RF, XGBoost).\n\nThese algorithms are not new; they have been extensively used in various domains, including medical science, for tasks such as diagnosis and prognostic prediction. For instance, logistic regression is a generalized linear model that is commonly used in medical research due to its simplicity and effectiveness. Support vector machines are known for their ability to handle high-dimensional spaces and are particularly useful for classification tasks. Artificial neural networks, which include multiple layers of neurons, are powerful tools for capturing complex patterns in data. Random forest and XGBoost are ensemble learning methods that combine multiple weak classifiers to improve predictive performance.\n\nThe choice of these algorithms was driven by their proven effectiveness in handling the molecular heterogeneity of cancers and their ability to identify key prognostic biomarkers. The study focused on applying these algorithms to a specific medical context—prognostic classification for esophageal squamous cell carcinoma (ESCC)—rather than developing new machine-learning algorithms. Therefore, the algorithms were not published in a machine-learning journal but in a medical research journal, as the primary contribution lies in their application to medical data and the identification of prognostic biomarkers.",
  "optimization/meta": "The study does not employ a meta-predictor model. Instead, it utilizes five distinct machine learning algorithms independently to develop prognostic classifiers. These algorithms include logistic regression (LR), support vector machine (SVM), artificial neural network (ANN), random forest (RF), and XGBoost. Each algorithm is used to build classifiers for prognostic classification, and their performance is evaluated separately.\n\nThe training data for these models is derived from publicly available mRNA transcriptome datasets, specifically GSE53625 and TCGA-ESCC. The GSE53625 dataset includes 179 patients with ESCC, randomly divided into a training cohort of 134 patients and a test cohort of 45 patients. The TCGA-ESCC dataset contains 82 patients with ESCC, with 37 Vietnamese patients used for independent validation. The training and test cohorts are clearly defined and independent, ensuring that the models are trained and validated on separate datasets.\n\nThe study focuses on identifying key prognostic biomarkers for esophageal squamous cell carcinoma (ESCC) using these machine learning algorithms. The importance of molecules is gauged according to their occurrence frequencies in the prognostic classifiers developed by each algorithm. The area under the ROC curve (AUC) is used to evaluate the performance of these classifiers, and the prognostic value of identified molecules is validated in independent cohorts.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps. Initially, mRNA transcriptome data of esophageal squamous cell carcinoma (ESCC) was obtained from public databases, specifically GSE53625 from Gene Expression Omnibus (GEO) and TCGA-ESCC from The Cancer Genome Atlas (TCGA). The GSE53625 dataset included 179 patients with ESCC, which were randomly divided into a training cohort of 134 patients and a test cohort of 45 patients. Since the GSE53625 data had been normalized in the original study, the difference between the expression values of cancer tissue and corresponding adjacent tissue was used as the input data for all subsequent calculations.\n\nFor the construction of the molecular interaction network, 48 molecules related to the prognosis of ESCC were mapped and imported into NetBox, a Java-based software tool that integrates multiple databases. The shortest path between molecules in the network was defined as 1, indicating direct interactions. Functional modules within the network were identified, and the degree of nodes was calculated using the igraph R package.\n\nThe input features for the machine-learning algorithms consisted of the expression levels of the 17 component molecules identified from the functional modules. These features were used to develop prognostic classifiers using five different machine-learning algorithms: logistic regression (LR), support vector machine (SVM), artificial neural network (ANN), random forest (RF), and XGBoost. The data was split into training and test cohorts to evaluate the performance of these classifiers. The area under the receiver operating characteristic curve (AUC) was calculated to assess the predictive values of the machine-learning classifiers.",
  "optimization/parameters": "In our study, we utilized 17 selected features to establish 131,071 models for each machine learning algorithm. These features were chosen based on their relevance to the prognosis of esophageal squamous cell carcinoma (ESCC). The selection of these parameters was driven by a comprehensive literature review and the construction of a molecular interaction network using NetBox. This network helped identify functional modules and key molecules associated with ESCC progression. The 17 molecules were then used as input parameters for developing prognostic classifiers. The choice of these parameters was validated through cross-validation and parameter optimization in the training cohort, ensuring that the models were robust and reliable.",
  "optimization/features": "In the optimization process, a total of 17 selected features were used as input for each machine learning algorithm. Feature selection was indeed performed to identify these 17 key molecules from an initial set of 48 clinically proven molecules associated with esophageal squamous cell carcinoma (ESCC) progression. This selection was based on constructing a molecular interaction network and identifying functional modules.\n\nThe feature selection process involved using a local version of Java and Python with the NetBox algorithm to define these functional modules. The Entrez IDs of the 48 molecules were inputted, resulting in the identification of 3 functional modules containing a total of 17 molecules as vertices and 19 edges. A subnetwork of 16 molecules among these 17 was built using the STRING database with a minimum interaction score of 0.7.\n\nThis feature selection was conducted using the training cohort, ensuring that the test cohort remained independent for validation purposes. The selected features were then used to develop classifiers for prognostic classification, with the performance of these classifiers evaluated using the area under the ROC curve (AUC).",
  "optimization/fitting": "In our study, we employed five machine learning algorithms—logistic regression (LR), support vector machine (SVM), artificial neural network (ANN), random forest (RF), and XGBoost—to develop classifiers for prognostic classification. Each algorithm was used to construct 131,071 models representing various combinations of 17 selected features.\n\nGiven the large number of models and the relatively smaller number of training points (134 patients in the training cohort), the risk of overfitting was a significant concern. To mitigate this, we implemented cross-validation and parameter optimization during the model development phase. This approach helped in ensuring that the models generalized well to unseen data.\n\nFor each algorithm, we calculated the area under the receiver operating characteristic curve (AUC) for both the training and test cohorts. Only models with AUCs greater than the average AUC across all classifiers were considered as candidate classifiers. Among these, the top 1000 models with the highest AUC values in the test cohort were selected. This stringent selection process helped in ruling out overfitting by focusing on models that performed well on independent test data.\n\nTo address the risk of underfitting, we ensured that the models were complex enough to capture the underlying patterns in the data. For instance, the ANN models included multiple hidden layers, and the SVM used a Radial Basis Function (RBF) kernel to handle nonlinear relationships. Additionally, the integrated learning algorithms (RF and XGBoost) combined multiple weak classifiers, which helped in improving the predictive ability and reducing classification error.\n\nIn summary, we balanced the complexity of the models to avoid both overfitting and underfitting. The use of cross-validation, parameter optimization, and a focus on models with high AUC values in the test cohort ensured that our classifiers were robust and generalizable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting during the development of our machine learning classifiers. One of the primary methods used was cross-validation. Specifically, we utilized cross-validation in the training cohort to ensure that our models generalized well to unseen data. This process involved dividing the training data into multiple subsets, training the model on some subsets, and validating it on the remaining subsets. This approach helped to assess the model's performance more reliably and to reduce the risk of overfitting.\n\nAdditionally, we performed parameter optimization during the model development phase. This involved systematically searching for the best combination of hyperparameters that minimized the error rate and improved the model's predictive ability. By optimizing these parameters, we aimed to enhance the model's performance and robustness, further mitigating the risk of overfitting.\n\nAnother technique we used was the selection of candidate classifiers based on their performance metrics. We calculated the area under the receiver operating characteristic curve (AUC) for each model and selected only those with AUCs greater than the average of all models. This step ensured that we focused on the most promising classifiers, reducing the likelihood of overfitting to noise in the data.\n\nFurthermore, we counted the occurrence frequencies of each molecule in the top 1000 classifiers with the highest AUC values. This approach helped to identify the most important molecules that consistently contributed to the model's performance, rather than relying on any single model's results. By focusing on these key molecules, we aimed to build more robust and generalizable classifiers.\n\nIn summary, our study incorporated cross-validation, parameter optimization, and the selection of top-performing classifiers to prevent overfitting and ensure the reliability of our machine learning models.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in this study are not explicitly detailed in the provided information. However, the study does mention the use of specific machine learning algorithms and their configurations, such as the Radial Basis Function (RBF) kernel for Support Vector Machine (SVM) and the construction of models using various combinations of selected features.\n\nThe study utilized five machine learning algorithms: Logistic Regression (LR), Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and XGBoost. For each algorithm, 131,071 models were established, representing different combinations of 17 selected features. The Area Under the Curve (AUC) values for these models were calculated in both training and test cohorts.\n\nThe implementation of the classifiers was done using R 3.6.3, with specific packages such as bestglm, e1071, and nnet for weak classifiers, and random forest and xgboost for integrated learning algorithms. However, the exact hyper-parameter configurations and optimization schedules are not provided in detail.\n\nThe data sets used, GSE53625 from GEO and TCGA-ESCC, are publicly available. The study also mentions the use of NetBox for constructing a molecular interaction subnetwork, which is a Java-based software tool integrating several databases. The specific model files and optimization parameters are not reported in the provided information.\n\nIn summary, while the study provides an overview of the machine learning algorithms and data sets used, the detailed hyper-parameter configurations, optimization schedules, and model files are not explicitly reported. The data sets are publicly available, but the specific configurations and parameters used in the optimization process are not detailed.",
  "model/interpretability": "The models developed in this study are not entirely black-box, as efforts were made to enhance their interpretability. Five different machine learning algorithms were employed: Logistic Regression (LR), Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and XGBoost. Among these, LR and RF are considered more interpretable compared to the others.\n\nLogistic Regression is a linear model that provides coefficients for each feature, indicating the direction and magnitude of their influence on the outcome. This makes it relatively straightforward to interpret the importance of each prognostic molecule.\n\nRandom Forest, while an ensemble method, offers feature importance scores that can be derived from the model. These scores indicate how much each feature contributes to the predictive power of the model, providing insights into the key prognostic molecules.\n\nFor the other algorithms, such as SVM, ANN, and XGBoost, interpretability is more challenging due to their complex nature. However, by analyzing the occurrence frequencies of molecules in the top-performing models, it was possible to identify the most important prognostic biomarkers. For instance, stratifin (SFN) was found to be a critical molecule across multiple algorithms, suggesting its significant role in ESCC prognosis.\n\nIn summary, while some of the models used are complex and less interpretable, techniques such as feature importance scoring and frequency analysis were utilized to gain insights into the key prognostic molecules, making the models more transparent.",
  "model/output": "The model developed in this study is a classification model. It was designed to predict the prognosis of patients with esophageal squamous cell carcinoma (ESCC) based on their survival time. Specifically, the model assigns a label of 1 to ESCC cases with survival times of more than three years and a label of 0 to the remaining cases. This binary classification approach allows the model to categorize patients into different prognostic groups.\n\nThe model's performance was evaluated using receiver operating characteristic (ROC) curve analysis, which is a common method for assessing the predictive values of classification models. The area under the curve (AUC) was calculated to quantify the model's ability to distinguish between the two classes. This indicates that the primary goal of the model is to classify patients into distinct prognostic categories rather than to predict a continuous outcome, which is characteristic of a regression model.\n\nFive different machine learning algorithms were employed to develop these classifiers: logistic regression (LR), support vector machine (SVM), artificial neural network (ANN), random forest (RF), and eXtreme Gradient Boosting (XGBoost). Each algorithm was used to create multiple models, and their performance was compared based on the AUC values in both the training and test cohorts. The top-performing models were selected for further analysis, highlighting the focus on classification tasks.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the developed classifiers involved several steps to ensure their robustness and predictive accuracy. Initially, for 179 patients with esophageal squamous cell carcinoma (ESCC) samples, labels were assigned based on survival time, with label 1 denoting cases with survival times of more than 3 years and label 0 for the remaining cases. The dataset was divided into a training cohort of 134 patients and a test cohort of 45 patients. Cross-validation and parameter optimization were employed in the training cohort to develop the models, while the test cohort was used for validation.\n\nReceiver operating characteristic (ROC) curve analysis was utilized to estimate the predictive values of the machine learning classifiers. The area under the curve (AUC) was calculated to quantify the performance of each classifier. During the development of classifiers, candidate classifiers were those with AUCs greater than the average of AUCs across all classifiers. Among these candidates, the top 1000 models with the highest AUC values in the test cohort were selected. The occurrence frequencies of each molecule were counted in these 1000 classifiers, and the top 5 molecules with the highest occurrence frequency were regarded as the important molecules for the corresponding machine learning algorithm.\n\nAdditionally, the prognostic value of stratifin was validated in two independent ESCC cohorts. This validation process involved comparing the performance of the classifiers in these independent datasets to assess their generalizability and robustness. The use of multiple machine learning algorithms, including logistic regression, support vector machine, artificial neural network, random forest, and eXtreme Gradient Boosting, ensured a comprehensive evaluation of the prognostic classifiers. The integration of these methods provided a robust framework for identifying key prognostic biomarkers for ESCC.",
  "evaluation/measure": "In our study, we primarily used the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve to evaluate the performance of our prognostic classifiers. The AUC provides a single scalar value that represents the ability of the classifier to distinguish between the classes, with higher values indicating better performance. This metric is widely used in the literature for evaluating the performance of machine learning models, particularly in the context of binary classification problems such as prognostic prediction in cancer research.\n\nAdditionally, we employed Kaplan-Meier survival analysis and log-rank tests to determine the statistical significance of overall survival. These methods are standard in survival analysis and provide a visual representation of the survival probabilities over time, as well as a statistical test to compare the survival distributions between different groups.\n\nWhile we focused on these key metrics, it is important to note that other performance measures such as accuracy, precision, recall, and F1-score could also be relevant in different contexts. However, given the nature of our study and the specific goals of prognostic classification, AUC and survival analysis were deemed the most appropriate and representative metrics.",
  "evaluation/comparison": "Not applicable. The study focuses on developing and validating prognostic classifiers for esophageal squamous cell carcinoma using various machine learning algorithms. It does not explicitly compare the developed methods to publicly available methods or simpler baselines on benchmark datasets. The evaluation primarily revolves around the performance of the classifiers within the study's own datasets and the identification of key prognostic molecules.",
  "evaluation/confidence": "The evaluation of our machine learning classifiers involved several statistical methods to ensure the robustness and significance of our results. For each algorithm, we calculated the area under the receiver operating characteristic curve (AUC) to estimate predictive values. The AUC provides a single scalar value that summarizes the performance of the classifier across all classification thresholds.\n\nTo assess the statistical significance of our findings, we employed cross-validation and parameter optimization during the development of our models. This approach helps to mitigate overfitting and ensures that the models generalize well to unseen data. We also used the unpaired or paired Student t-test to compare quantitative data between groups, ensuring that any observed differences were statistically significant.\n\nIn addition, we performed Kaplan-Meier survival curves and log-rank tests to determine the statistical significance of overall survival. These tests are standard in survival analysis and provide a clear indication of whether the differences in survival times between groups are statistically significant.\n\nThe occurrence frequencies of molecules in the top 1000 classifiers were counted, and the top 5 molecules with the highest frequencies were identified as important. This method ensures that the identified molecules are robust and consistently important across different models.\n\nOverall, our evaluation methods provide a comprehensive assessment of the performance and significance of our machine learning classifiers, ensuring that our findings are reliable and statistically sound.",
  "evaluation/availability": "The raw evaluation files used in this study are publicly available. The datasets utilized include mRNA transcriptome data of esophageal squamous cell carcinoma (ESCC) from the Gene Expression Omnibus (GEO) and The Cancer Genome Atlas (TCGA). Specifically, the datasets GSE53625 from GEO and 37 ESCC cases with Asian ancestry from TCGA are open and accessible. These datasets can be found at the respective URLs: GEO (https://www.ncbi.nlm.nih.gov/geo/) and TCGA (UCSC Xena, https://xena.ucsc.edu/). The data is released under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, provided appropriate credit is given to the original authors and the source."
}