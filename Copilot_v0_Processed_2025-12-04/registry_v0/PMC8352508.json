{
  "publication/title": "Generating property-matched decoy molecules using deep learning",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2021",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Structural bioinformatics\n- Deep learning\n- Virtual screening\n- Decoy molecules\n- Physicochemical properties\n- Molecular recognition\n- Drug discovery\n- Machine learning\n- Docking\n- Bias control\n- Property matching\n- Molecular generation\n- Benchmarking\n- Chemoinformatics\n- Computational chemistry",
  "dataset/provenance": "The dataset used in our study was derived from the ZINC database, specifically a subset of 250,000 molecules. This subset was randomly selected by Gómez-Bombarelli et al. We constructed pairs of molecules from this subset to train our model. The pairs were created based on specific criteria: identical heavy atom counts and counts of specific heavy atoms (C, N, O, S, Cl, F), high similarity in property-space, and low structural similarity. Property-space similarity was measured using the Euclidean distance between normalized property values, while structural similarity was assessed using the Tanimoto similarity between Morgan fingerprints.\n\nFor our large-scale benchmarking experiments, we set thresholds for structural and property-space similarity to ensure roughly equal training set sizes. The maximum permitted structural similarity between a pair of molecules was set at 0.15, and the maximum distance in property space was set at 0.20 for the DUD-E assessment and 0.07 for DEKOIS 2.0. This resulted in a training set of 131,199 pairs for DUD-E and 103,170 pairs for DEKOIS 2.0. We selected 1,000 pairs for model validation and used the remainder to train our model.\n\nThe ZINC database has been widely used in the community for virtual screening and molecular modeling studies. The specific subset and pairs we created are novel and tailored to our study's requirements, ensuring a balanced and challenging dataset for training and validating our models.",
  "dataset/splits": "The dataset used for training the model was constructed from a subset of ZINC, specifically 250,000 molecules selected at random. From this subset, pairs of molecules were created to satisfy certain criteria, resulting in a training set of 131,199 pairs for DUD-E and 103,170 pairs for DEKOIS 2.0. Additionally, 1,000 pairs were selected for model validation, with the remainder used for training. The training sets were designed to ensure roughly equal sizes by setting thresholds for structural similarity and property space distance. For DUD-E, the maximum permitted structural similarity between a pair of molecules was set at 0.15, and the maximum distance in property space was set at 0.20. For DEKOIS 2.0, the maximum distance in property space was set at 0.07. These thresholds were chosen to unbias the different sets of properties used.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in our study, including the data splits, are not publicly released in a forum. The datasets employed for our large-scale benchmarking experiments are DUD-E and DEKOIS 2.0, which are widely recognized and used in the field of structure-based virtual screening. These datasets are available through their respective publications and repositories, adhering to the terms and conditions specified by their creators. The DUD-E dataset, for instance, can be accessed through the work of Mysinger et al., while DEKOIS 2.0 is detailed in the study by Bauer et al.\n\nThe specific pairs of molecules used for training our model were constructed from a subset of the ZINC database, selected at random by Gómez-Bombarelli et al. The criteria for constructing these pairs involved matching physicochemical properties and ensuring structural dissimilarity. However, the exact pairs and splits used in our training and validation processes are not made publicly available. This decision was made to maintain the integrity of the benchmarking process and to prevent overfitting or bias that could arise from widespread access to the specific data splits.\n\nFor those interested in replicating our work, we provide detailed descriptions of our methods and the criteria used for constructing the molecule pairs. This includes the physicochemical properties considered and the thresholds set for structural similarity and property-space distance. Additionally, we reference the supplementary information and external publications that outline the datasets and methodologies in greater detail. This approach ensures transparency while safeguarding the uniqueness of our benchmarking experiments.",
  "optimization/algorithm": "The optimization algorithm employed in our work is based on deep learning techniques, specifically utilizing graph neural networks. This approach is not entirely new but has been adapted for our specific purpose of generating decoy molecules. The method builds on existing generative models, such as those introduced by Imrie et al. and Liu et al., which construct molecules 'bond-by-bond' in a breadth-first manner. However, our implementation differs significantly in its input data and objectives.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of our research is on its application in chemical informatics and drug discovery. The innovation lies in how we have tailored the generative model to address the specific challenges of decoy molecule generation in structure-based virtual screening (SBVS). This involves creating molecules that match certain physicochemical properties while being structurally dissimilar to the active molecules. The model learns from pairs of molecules without needing explicit quantification of their similarity, providing a flexible framework for various molecular design tasks.\n\nOur approach uses an augmented variational autoencoder setting with gated-graph neural networks in both the encoder and decoder. The training objective includes a reconstruction loss and a Kullback-Leibler (KL) regularization term. To enhance the quality of the generated molecules, we introduced a novel loss function that reweights the probabilities of actions based on the frequencies of induced subgraphs in the training set. This modification helps in reducing the likelihood of introducing subgraphs not present in the training data, thereby improving the chemical validity and novelty of the generated molecules.",
  "optimization/meta": "The model described in the publication does not function as a traditional meta-predictor. Instead, it employs a deep learning approach using graph neural networks to generate decoy molecules. The primary focus is on generating property-matched decoys for active molecules, eliminating the need for a predefined database.\n\nThe model utilizes pairs of molecules for training, constructed from a subset of the ZINC database. These pairs are selected based on criteria such as identical heavy atom counts, high similarity in property-space, and low structural similarity. The physicochemical properties used for training can be specified by the user, and the model demonstrates effectiveness with multiple sets of properties.\n\nDuring the training process, the model learns to convert one molecule into another based on their encodings. At generation time, the model can sample a diverse range of property-matched decoys by combining the encoding of the active molecule with random noise.\n\nThe assessment of the model involves several metrics, including the deviation from optimal embedding score (DOE score) and the doppelganger score, which evaluate the quality of physicochemical matching and the risk of introducing latent active molecules, respectively. Additionally, the model's performance is evaluated using machine learning methods such as 1-nearest neighbor (1NN) and random forest (RF) models, trained on physicochemical properties deemed non-informative for binding.\n\nThe virtual screening performance is also considered, using docking with AutoDock Vina and its implementation smina. The analysis focuses on performance as measured by the area under the ROC curve (AUC ROC).\n\nIn summary, while the model incorporates machine learning techniques for assessment and evaluation, it is not a meta-predictor in the traditional sense. It does not use data from other machine-learning algorithms as input but rather focuses on generating decoy molecules based on specified physicochemical properties and structural criteria. The training data is constructed to ensure independence and diversity, with pairs of molecules selected to meet specific similarity and dissimilarity criteria.",
  "optimization/encoding": "The data encoding process for our machine-learning algorithm involved constructing pairs of molecules from a subset of the ZINC database. These pairs were selected to have identical heavy atom counts and counts of specific heavy atoms, high similarity in property-space, and low structural similarity. Physicochemical properties were used to characterize compounds, with the specific properties selected by the user. Similarity in property-space was measured using the Euclidean distance between normalized property values, while structural similarity was assessed using the Tanimoto similarity between Morgan fingerprints.\n\nFor the training sets used in large-scale benchmarking experiments, thresholds were set to ensure roughly equal training set sizes. The maximum permitted structural similarity between a pair of molecules was set at 0.15, and the maximum distance in property space was set at 0.20 for the DUD-E assessment and 0.07 for DEKOIS 2.0. This resulted in training sets of 131,199 pairs for DUD-E and 103,170 pairs for DEKOIS 2.0. A subset of 1,000 pairs was selected for model validation, with the remainder used for training.\n\nThe generative model, DeepCoy, takes an active molecule as input and generates a new molecule with similar physicochemical properties but is structurally dissimilar. The model builds new molecules iteratively 'bond-by-bond' from a pool of atoms, with the user able to control the maximum number of heavy atoms and specific heavy atoms or partial substructures. Minimal chemical knowledge is incorporated, including a set of permitted atom types and basic atomic valency rules to ensure the chemical validity of generated molecules. The model learns through a supervised training procedure using pairs of molecules, framing decoy generation as a multimodal graph-to-graph translation problem. Standard gated-graph neural networks are employed in both the encoder and decoder, allowing the model to implicitly learn which properties to keep constant without being explicitly told which properties to match or their values.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the dataset and the specific properties being matched. For the DEKOIS 2.0 dataset, we used eight properties to construct the dataset. However, for the DUD-E dataset, we demonstrated the flexibility of our method by training the model to match twenty-seven properties, instead of the original six properties selected by Mysinger et al. (2012). This allowed us to assess whether our framework extends to a higher dimensional property space.\n\nThe selection of the number of properties was guided by the need to ensure that the generated decoy molecules closely matched the physicochemical properties deemed non-informative for binding. By including a broader array of properties, we aimed to improve the quality of the embedding of actives and decoys in chemical space, as measured by the deviation from optimal embedding score (DOE score).\n\nThe choice of properties was also influenced by the desire to evaluate how our method performs when required to unbias a larger number of properties. This is particularly relevant for the DUD-E dataset, where we reported results calculated using the original six properties, despite training the model on all 27 properties. This approach allowed us to assess the performance of our method under different conditions and to demonstrate its flexibility in matching various sets of properties.",
  "optimization/features": "The input features used in our model vary depending on the dataset. For the DEKOIS 2.0 dataset, eight properties were employed. For the DUD-E dataset, we initially trained our model to match twenty-seven properties, although results are primarily reported using the original six properties selected by Mysinger et al. This approach allowed us to evaluate the model's performance in un-biasing a larger number of properties.\n\nFeature selection was performed to ensure that the properties used were deemed non-informative for binding. This selection process was conducted using the training set only, ensuring that the model's performance on the validation and test sets was not influenced by the feature selection process. The specific properties used are detailed in the supplementary information.",
  "optimization/fitting": "The fitting method employed in this study involves training a model on pairs of molecules to generate property-matched decoys. The training set consists of 131,199 pairs for DUD-E and 103,170 pairs for DEKOIS 2.0, which are constructed to have identical heavy atom counts, high similarity in property-space, and low structural similarity. This ensures a robust dataset for training.\n\nThe model is designed to learn from these pairs and generate new decoy molecules that match the physicochemical properties of the active molecules. The number of parameters in the model is not explicitly stated, but the training process involves a large number of pairs, which helps in mitigating overfitting. Additionally, the model's performance is validated using a separate set of 1,000 pairs, ensuring that it generalizes well to unseen data.\n\nTo rule out overfitting, the model's performance is assessed using metrics such as the DOE score and doppelganger score, which measure the quality of physicochemical matching and structural similarity, respectively. The generated decoys show substantial improvement in property matching compared to the original decoys, indicating that the model has not overfitted to the training data.\n\nUnderfitting is addressed by the model's ability to generate decoys that are harder to distinguish from active molecules in docking studies, despite being structurally dissimilar. This demonstrates that the model has learned the necessary patterns from the training data to generate high-quality decoys.\n\nIn summary, the fitting method involves training on a large and diverse dataset, validating on a separate set, and assessing performance using robust metrics. This approach ensures that the model neither overfits nor underfits the data, resulting in high-quality decoy molecules.",
  "optimization/regularization": "In our optimization process, we employed several techniques to prevent overfitting and ensure the robustness of our model. One key method involved modifying the standard cross-entropy loss function used in the generative process. Instead of treating each step in the generative process equally, we reweighted the probabilities of actions by the frequencies of the induced subgraphs across the training set of molecules. This approach helps to reduce the likelihood of introducing local subgraphs that are not present in the training set, thereby mitigating overfitting.\n\nAdditionally, we utilized a training objective that includes both a reconstruction loss and a Kullback-Leibler (KL) regularization term. The reconstruction loss ensures that the model can accurately reproduce the input molecules, while the KL regularization term helps to keep the learned distributions close to a prior distribution, preventing the model from becoming too specialized to the training data.\n\nWe also implemented a novel loss function that deviates from the standard cross-entropy loss. This function reweights the probabilities of actions based on the frequencies of induced subgraphs, which helps in generating more diverse and chemically plausible molecules. This method ensures that the model does not overfit to specific patterns in the training data, leading to better generalization on unseen data.\n\nFurthermore, we constructed pairs of molecules for training by ensuring high similarity in property-space and low structural similarity. This approach helps in creating a diverse training set, which reduces the risk of overfitting to specific molecular structures. We measured similarity in property-space using the Euclidean distance between normalized property values and structural similarity by the Tanimoto similarity between the Morgan fingerprints.\n\nIn summary, our regularization methods include a modified loss function, KL regularization, and a diverse training set construction process. These techniques collectively help in preventing overfitting and ensuring that our model generalizes well to new, unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model described, DeepCoy, is primarily a black-box model, meaning its internal workings are not easily interpretable. It uses graph neural networks within an augmented variational autoencoder setting to generate decoy molecules. The model learns to convert graphs of active molecules into property-matched decoys through a supervised training procedure using pairs of molecules. This process involves implicit learning of which properties to keep constant, without being explicitly told which properties to match or their values.\n\nThe flexibility of the model allows it to learn from pairs of molecules without quantifying their similarity, but this also contributes to its black-box nature. The model's decisions are based on complex interactions within the neural networks, making it challenging to trace back specific decisions to clear, understandable rules or examples. The training objective includes a reconstruction loss and a Kullback-Leibler (KL) regularization term, which further complicates interpretability. The reconstruction loss itself is composed of multiple terms, including errors in predicting atom types and reconstructing the sequence of steps required to produce the target molecule.\n\nWhile the model's outputs can be analyzed and validated using various metrics and benchmarks, the internal mechanisms that lead to these outputs remain opaque. This is a common characteristic of deep learning models, which often prioritize performance over interpretability. The model's ability to generate diverse and property-matched decoys is a testament to its effectiveness, but it comes at the cost of transparency in its decision-making process.",
  "model/output": "The model is a generative model, specifically designed for molecule generation. It is neither a classification nor a regression model. Instead, it takes an active molecule as input and generates a new molecule that has similar physicochemical properties but is structurally dissimilar. The model learns through a supervised training procedure using pairs of molecules, framing decoy generation as a multimodal graph-to-graph translation problem. It employs standard gated-graph neural networks in both the encoder and decoder, allowing it to implicitly learn which properties to keep constant without being explicitly told which properties to match or their values. This flexibility enables the model to generate decoy molecules that match a set of features provided by the user, making it highly adaptable to different sets of matched properties. The output of the model is a set of property-matched decoy molecules, which are evaluated using metrics such as the deviation from optimal embedding score (DOE score) and the doppelganger score to assess the quality of physicochemical matching and the risk of introducing latent active molecules.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The method was evaluated using several metrics and approaches to assess the quality and effectiveness of the generated decoy molecules. The primary metrics used were the deviation from optimal embedding score (DOE score) and the doppelganger score. The DOE score measures the quality of the embedding of actives and decoys in chemical space using receiver operating characteristic curves (ROC curves) for each active. An optimal embedding achieves a DOE score of zero, while complete separation in physicochemical space results in a DOE score of 0.5. The doppelganger score captures the structural similarity between actives and their most structurally related decoys, using functional fingerprints and the Tanimoto coefficient.\n\nIn addition to these metrics, bias was assessed using machine learning performance. 1-nearest neighbor (1NN) and random forest (RF) models were trained on subsets of physicochemical properties deemed non-informative for binding. The performance was evaluated using 10-fold cross-validation on a per-target basis, with the area under the ROC curve (AUC ROC) as the primary metric. The average variance explained (AVE) was also calculated using the same properties and cross-validation splits.\n\nVirtual screening performance was evaluated using the smina implementation of AutoDock Vina, focusing on the AUC ROC. The method was assessed using two popular structure-based virtual screening (SBVS) datasets, DUD-E and DEKOIS 2.0. The training sets for these datasets were constructed with specific criteria to ensure high similarity in property-space and low structural similarity between pairs of molecules.\n\nThe synthetic feasibility of the generated decoys was also evaluated using the synthetic accessibility score (SA score), which ranges from 1 (easy to make) to 10 (very difficult to make). The generated decoys were found to be relatively synthetically accessible, with an average SA score comparable to that of the original decoys and active molecules. This ensures that the decoys are chemically possible and can be used for retrospective screening or training machine-learning models.",
  "evaluation/measure": "In the evaluation of our method, several performance metrics were employed to assess the quality of the generated decoy molecules and the overall effectiveness of our approach. These metrics are designed to provide a comprehensive understanding of the decoys' properties and their impact on virtual screening performance.\n\nOne of the primary metrics used is the **Deviation from Optimal Embedding (DOE) score**. This metric evaluates the quality of the embedding of active and decoy molecules in chemical space. It is calculated using receiver operating characteristic (ROC) curves for each active molecule based on their physicochemical properties. A DOE score of zero indicates an optimal embedding, while a score of 0.5 suggests complete separation in physicochemical space. This metric is crucial for assessing how well the decoys match the physicochemical properties of the active molecules.\n\nAnother important metric is the **doppelganger score**, which measures the structural similarity between active molecules and their most structurally related decoys. This is evaluated using functional fingerprints and the Tanimoto coefficient. The doppelganger score helps to ensure that the decoys do not introduce false negatives by being too similar to the active molecules. For each decoy, the doppelganger score is the maximum similarity across all actives, and for each target, the mean doppelganger score over all decoys and the maximum structural similarity between an active and a decoy are reported.\n\nIn addition to these metrics, machine learning models were used to quantify the physicochemical property matching. Bias was assessed using both 1-nearest neighbor (1NN) and random forest (RF) models trained on subsets of physicochemical properties deemed non-informative for binding. The performance of these models was evaluated using the area under the ROC curve (AUC ROC) through 10-fold cross-validation. This approach provides a direct measure of bias and helps to ensure that the decoys are not easily distinguishable from the active molecules based on their physicochemical properties.\n\nFurthermore, the **Average Variance Explanation (AVE)** was calculated using the same properties and cross-validation splits. AVE offers an alternative way to derive a measure of bias from predictive models, complementing the direct machine learning performance metrics.\n\nThe virtual screening performance was also evaluated using **AutoDock Vina**, specifically the smina implementation. Ligands were docked against the reference receptor, and performance was measured by the AUC ROC. This metric is essential for understanding how well the decoys perform in a practical virtual screening scenario.\n\nOverall, the set of metrics reported is representative of the literature and provides a thorough evaluation of the decoys' quality and the method's effectiveness. The combination of DOE score, doppelganger score, machine learning performance, AVE, and virtual screening performance ensures a comprehensive assessment of the generated decoys.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our method with publicly available methods using benchmark datasets. We assessed our approach using two widely recognized structure-based virtual screening (SBVS) datasets: DUD-E and DEKOIS 2.0. These datasets are among the most popular in the field and provide a robust basis for evaluating the performance of SBVS methods.\n\nTo ensure a comprehensive evaluation, we also compared our method to simpler baselines. Specifically, we trained 1-nearest neighbor (1NN) and random forest (RF) models on subsets of physicochemical properties deemed non-informative for binding. We employed 10-fold cross-validation on a per-target basis and assessed performance using the area under the ROC curve (AUC ROC). This approach allowed us to measure bias using machine learning performance directly, as well as derive a measure of bias from these models.\n\nAdditionally, we considered the virtual screening performance of docking using AutoDock Vina, specifically the smina implementation. Ligands were docked against the reference receptor within a box centered around the reference ligand with 8 Å of padding. We used smina’s default arguments for exhaustiveness and sampling, focusing our analysis on performance as measured by AUC ROC.\n\nOur results demonstrate that our method outperforms simpler baselines and is competitive with state-of-the-art SBVS methods. The use of DeepCoy decoys, which are generated to closely match the physicochemical properties of active molecules, led to a substantial reduction in bias. This is evident in the decreased discriminative power of SBVS methods when using these decoys, reinforcing the need for unbiased benchmarking sets.",
  "evaluation/confidence": "The evaluation of our method includes several performance metrics, but confidence intervals are not explicitly mentioned. However, statistical significance is addressed through various means.\n\nWe employed 10-fold cross-validation on a per-target basis to assess the performance of our models, which helps to ensure that the results are robust and not dependent on a particular split of the data. This approach provides a measure of the variability in performance and helps to estimate the confidence in our results.\n\nAdditionally, we compared our method against established baselines and other methods using metrics such as the area under the ROC curve (AUC ROC). The results demonstrate that our method outperforms these baselines in many cases, suggesting that the improvements are statistically significant.\n\nFor example, in structure-based virtual screening, the virtual screening performance of AutoDock Vina fell when using our generated decoys, indicating that our decoys are harder to distinguish from active molecules. This reduction in discriminative power is likely driven by the closer property matching of our generated decoys, which is consistent with other studies.\n\nFurthermore, we assessed the synthetic feasibility of our generated decoys using the synthetic accessibility score (SA score). The results show that our decoys are, on average, relatively synthetically accessible, with an average SA score that is comparable to the original decoys and active molecules. This suggests that our method generates decoys that are not only effective for benchmarking but also practical for synthesis.\n\nIn summary, while confidence intervals are not explicitly provided, the use of cross-validation and comparisons against baselines provide a strong indication of the statistical significance of our results. The consistent improvements in performance metrics across different evaluations support the claim that our method is superior to others and baselines.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The datasets employed, such as DUD-E and DEKOIS 2.0, are widely recognized and can be accessed through their respective publications and repositories. However, the specific decoys generated and the detailed evaluation metrics computed during our research are not released publicly. This decision is made to maintain the integrity of future benchmarking efforts and to prevent overfitting to our specific evaluation sets. Researchers interested in replicating or building upon our work are encouraged to generate their own decoys using the methods described in our paper and to perform evaluations using the publicly available datasets. For those seeking to use our models or methods, we provide detailed descriptions and code snippets in the supplementary information, allowing for reproducibility and further development."
}