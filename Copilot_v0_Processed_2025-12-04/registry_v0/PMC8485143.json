{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Computational and Mathematical Methods in Medicine",
  "publication/year": "2021",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- COVID-19\n- Biomarkers\n- Feature Selection\n- mRMR\n- IFS\n- SVM\n- Gene Expression\n- Bioinformatics\n- Machine Learning\n- Diagnostic Methods",
  "dataset/provenance": "The dataset used in this study was obtained from the Gene Expression Omnibus (GEO) database. Specifically, the expression profile GSE152075 was downloaded. This dataset was generated using the Illumina NextSeq 500 platform (Homo sapiens) and includes mRNA sequencing results from throat swab samples. The samples consist of 54 negative and 430 positive COVID-19 cases. The expression matrix underwent preprocessing to remove genes with an average value less than 1 and a maximum value less than 5. The remaining genes were standardized using the edgeR package, resulting in a total of 16,032 genes. This dataset has not been used in previous papers by the community.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study is publicly available. The expression profile dataset (GSE152075) was obtained from the Gene Expression Omnibus (GEO) database, which is accessible via the NCBI website. This dataset includes mRNA sequencing results from throat swab samples of 54 negative and 430 positive COVID-19 cases, sequenced using the Illumina NextSeq 500 platform.\n\nThe data was processed to remove genes with an average value less than 1 and a maximum value less than 5. The remaining genes were standardized using the edgeR package, resulting in a total of 16,032 genes. The specific details of the acquired genes after standardization are provided in Supplementary Table 1.\n\nThe data splits used for training and validation were managed through the incremental feature selection (IFS) method, which involved constructing SVM classifiers for different feature gene sets. The performance of these classifiers was evaluated using leave-one-out cross-validation (LOOCV), and the results were presented using the Matthews correlation coefficient (MCC).\n\nThe data and the methods used for its processing and analysis are thoroughly documented in the study, ensuring reproducibility and transparency. The supplementary materials, including the lists of genes and the results of the feature selection process, are available to support further research and validation.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is Support Vector Machine (SVM). SVM is a well-established and widely used method for classification tasks in machine learning. It is not a new algorithm; it has been extensively studied and applied in various fields, including bioinformatics.\n\nThe reason SVM was used in this context is its effectiveness in constructing classifiers, particularly when dealing with high-dimensional data, which is common in gene expression profiles. SVM works by creating a decision boundary, or hyperplane, that best separates different classes in the feature space. This hyperplane is defined to be as far away as possible from the nearest data points of each class, known as support vectors.\n\nThe choice of SVM for this study was driven by its proven efficacy in handling complex datasets and its ability to generalize well to unseen data. The algorithm's robustness and reliability make it a suitable choice for classifying COVID-19 positive and negative samples based on gene expression data.\n\nThe study focuses on applying SVM to a specific biological problem rather than introducing a new machine-learning algorithm. Therefore, it is published in a journal that aligns with the biological and medical aspects of the research, highlighting the practical application of SVM in the context of COVID-19 diagnosis.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. Instead, it employs a Support Vector Machine (SVM) classifier, which is a standalone machine-learning method. The SVM classifier is constructed using feature sets derived from gene expression profiles. The feature selection process involves the minimum-redundancy maximum-relevancy (mRMR) method and incremental feature selection (IFS). The mRMR method ranks genes based on their relevance to the classification task while minimizing redundancy. The IFS method then selects the optimal feature genes by evaluating the performance of SVM classifiers built on different subsets of these ranked genes. The performance is assessed using leave-one-out cross-validation (LOOCV) and the Matthews correlation coefficient (MCC). This approach ensures that the selected feature genes are both relevant and non-redundant, leading to an effective classifier for distinguishing between COVID-19 positive and negative samples.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps. Initially, the expression profile GSE152075 was downloaded from the Gene Expression Omnibus (GEO) database. This dataset included mRNA sequencing results from throat swab samples of 54 negative and 430 positive COVID-19 cases, obtained through the Illumina NextSeq 500 platform.\n\nThe expression matrix underwent filtering to remove genes with an average value less than 1 and a maximum value less than 5. The remaining genes were standardized using the edgeR package, resulting in a set of 16,032 genes. This standardization process ensured that the gene expression data was normalized, making it suitable for further analysis.\n\nFeature genes were then ranked using the minimum-redundancy maximum-relevancy (mRMR) method. This method combines max relevance and minimal redundancy to select features that are highly relevant to the classification task while minimizing redundancy among the selected features. The mRMR algorithm was applied to score and rank the feature genes in the expression profiles.\n\nFollowing the mRMR method, incremental feature selection (IFS) was performed to identify the optimal feature genes. Feature sets were constructed with varying numbers of genes, and support vector machine (SVM) classifiers were built for each set. The performance of these classifiers was evaluated using leave-one-out cross-validation (LOOCV) and presented using the Matthews correlation coefficient (MCC). The feature set with the highest MCC value was selected, and the genes in this set were designated as the optimal feature genes.\n\nTo address sample imbalance, the imblearn package was used to amplify the number of small samples to match the number of large samples. This step ensured that the classifier was trained on a balanced dataset, improving its performance and reliability.\n\nIn summary, the data encoding and preprocessing involved filtering and standardization of the gene expression data, ranking of feature genes using mRMR, selection of optimal feature genes using IFS, and balancing the dataset using imblearn. These steps prepared the data for effective machine-learning analysis and classification.",
  "optimization/parameters": "In the optimization process, the number of parameters, p, used in the model varied as part of the incremental feature selection (IFS) method. Initially, a feature set F was constructed with N ranging from 1 to 500, meaning that the number of parameters could be any integer value within this range. The specific value of p was determined through the IFS method, which involved constructing a support vector machine (SVM) classifier for each subset of features and evaluating their performance using leave-one-out cross-validation (LOOCV). The Matthews correlation coefficient (MCC) was used as the evaluation metric. The subset with the highest MCC value was selected as the optimal feature set, and the number of features in this set became the final value of p. This approach ensured that the model used the most informative features, thereby optimizing its performance.",
  "optimization/features": "In the study, feature selection was performed to identify the most relevant genes from the expression profiles of COVID-19 positive and negative samples. The minimum-redundancy maximum-relevancy (mRMR) method was used to rank the genes based on their importance. This method ensures that the selected features are both relevant to the classification task and minimally redundant.\n\nThe feature selection process involved constructing a feature set F, where N ranged from 1 to 500. This means that the number of features used as input varied, but the maximum number of features considered was 500. The incremental feature selection (IFS) method was then applied to further refine this set. The IFS method involves constructing a support vector machine (SVM) classifier for each subset of features and evaluating their performance using leave-one-out cross-validation (LOOCV). The Matthews correlation coefficient (MCC) was used as the performance metric.\n\nThe training set was used exclusively for feature selection. This ensures that the selected features are generalizable and not overfitted to the training data. The top 66 feature genes, which yielded the highest MCC value, were identified as the optimal feature genes. These genes were then used for further analysis, including principal component analysis (PCA) and functional enrichment analysis, to determine their potential as novel biomarkers for COVID-19.",
  "optimization/fitting": "The fitting method employed in this study involved the use of Support Vector Machines (SVM) for classifier construction. The number of parameters in the SVM model is indeed much larger than the number of training points, as we constructed feature sets ranging from 1 to 500 genes. To address the potential issue of over-fitting, several strategies were implemented.\n\nFirstly, the incremental feature selection (IFS) method was used to identify the optimal set of feature genes. This method systematically evaluates the performance of SVM classifiers based on different groups of feature genes, ensuring that only the most relevant features are selected. The performance of each classifier was assessed using leave-one-out cross-validation (LOOCV), which is a rigorous method that helps to prevent over-fitting by ensuring that each data point is used once as a validation set while the model is trained on the remaining data points.\n\nAdditionally, the Matthews correlation coefficient (MCC) was used to evaluate the performance of the classifiers. MCC provides a balanced measure of the quality of binary classifications, taking into account true and false positives and negatives. By selecting the feature set with the highest MCC value, we ensured that the model generalizes well to unseen data.\n\nTo further mitigate over-fitting, the imbalanced dataset was addressed using the imblearn package, which amplifies the number of small samples to match the number of large samples. This balancing step helps in training a more robust model that is not biased towards the majority class.\n\nUnder-fitting was ruled out by ensuring that the model had sufficient complexity to capture the underlying patterns in the data. The use of SVM, which is known for its effectiveness in high-dimensional spaces, along with the careful selection of feature genes through IFS, ensured that the model was neither too simple nor too complex. The high performance metrics, including an MCC value of 0.894, sensitivity of 0.991, specificity of 0.889, and accuracy of 0.979 for the top 66 feature genes, indicate that the model is well-fitted to the data without under-fitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method used was the incremental feature selection (IFS) approach, which helped in identifying the optimal set of feature genes. This method systematically evaluated different subsets of features to construct support vector machine (SVM) classifiers, ensuring that only the most relevant features were retained. By doing so, we minimized the risk of overfitting by avoiding the inclusion of irrelevant or redundant features.\n\nAdditionally, we addressed the issue of sample imbalance, which can lead to overfitting. To mitigate this, we used the Python package imblearn to amplify the number of small samples to match the number of large samples. This balancing step ensured that our classifiers were trained on a more representative dataset, reducing the likelihood of overfitting to the majority class.\n\nFurthermore, we utilized leave-one-out cross-validation (LOOCV) to evaluate the performance of our classifiers. LOOCV is a rigorous validation technique that helps in assessing the model's generalization ability by training on all but one sample and testing on the left-out sample. This process was repeated for each sample in the dataset, providing a comprehensive evaluation of the model's performance and helping to identify any signs of overfitting.\n\nOverall, these techniques collectively contributed to the prevention of overfitting, ensuring that our models were robust and capable of generalizing well to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the text. Specifically, the Support Vector Machine (SVM) classifier was constructed using the Python package sklearn, and the specific algorithm details are provided. The optimal hyperplane for the SVM is defined by the weight vector \\( w \\), the input feature vector \\( x \\), and the deviation \\( b \\). These parameters were determined by inputting feature vectors and classes in the training set to classify the prediction set.\n\nThe incremental feature selection (IFS) method was employed to screen optimal feature genes, and the performance of the classifiers was evaluated using leave-one-out cross-validation (LOOCV) and presented by the Matthews correlation coefficient (MCC). The IFS curve, which plots the MCC value against the feature set, was used to identify the training set with the highest MCC value.\n\nRegarding the availability of model files and optimization parameters, the study does not explicitly mention the provision of these files. However, the methods and parameters used are thoroughly described, allowing for reproducibility. The mRMR algorithm routine was downloaded from a specified website, and the Python package imblearn was used to handle sample imbalance.\n\nFor detailed information on the feature genes and their selection process, supplementary tables are provided. Supplementary Table 1 contains the acquired genes after standardization, Supplementary Table 2 lists the top 500 feature genes screened by the mRMR method, and Supplementary Table 3 includes the top 66 feature genes selected by the IFS method.\n\nThe study was funded by the 2020 Yantai Science and Technology Innovation Development Plan, and the supplementary materials are available for further reference. The specific license or access details for the supplementary materials or model files are not mentioned, but the methods and parameters are clearly documented within the publication.",
  "model/interpretability": "The model employed in this study is not a blackbox. The interpretability of the model is ensured through the use of Support Vector Machines (SVM) and Principal Component Analysis (PCA).\n\nSVM is a transparent model because it provides a clear decision boundary, or hyperplane, which separates different classes. This hyperplane is defined by support vectors, which are the data points closest to the boundary. The specific algorithm involves creating a decision boundary between two types to predict the type of input samples. The decision boundary is defined as far away from the nearest data points (support vectors) in each class as possible. This makes it possible to understand which features are most important for the classification task.\n\nAdditionally, the use of Incremental Feature Selection (IFS) further enhances the interpretability of the model. IFS helps in selecting the optimal feature genes by constructing feature sets and evaluating their performance using the Matthews Correlation Coefficient (MCC). The IFS curve, which plots the MCC values against the number of feature genes, allows for the identification of the most relevant features. In this study, the top 66 feature genes were identified as optimal, providing a clear set of biomarkers for COVID-19.\n\nPCA is another technique used to enhance the interpretability of the model. PCA reduces the dimensionality of the data while retaining the most important information. By mapping each data point to the principal components, PCA helps in visualizing the separation between positive and negative samples in a two-dimensional plane. This visualization provides insights into how the optimal feature genes can effectively distinguish between the two classes.\n\nOverall, the combination of SVM, IFS, and PCA ensures that the model is transparent and interpretable, allowing for a clear understanding of the features that contribute to the classification of COVID-19 samples.",
  "model/output": "The model employed in this study is a classification model. Specifically, a Support Vector Machine (SVM) classifier was utilized to distinguish between COVID-19 positive and negative samples. The SVM classifier was constructed to create a decision boundary, or hyperplane, that effectively separates the two classes based on the feature genes selected through the incremental feature selection (IFS) method. The performance of the classifier was evaluated using leave-one-out cross-validation (LOOCV) and the Matthews correlation coefficient (MCC), which measures the quality of binary classifications. The top 66 feature genes, identified through the IFS method, were used to build the final SVM classifier, which demonstrated high accuracy, sensitivity, and specificity in classifying the samples.",
  "model/duration": "The execution time for the model involved several stages. Initially, the expression profiles were downloaded and preprocessed, which included filtering and standardization of genes. This step was facilitated using the edgeR package. Following this, feature gene selection was performed using the minimum-redundancy maximum-relevancy (mRMR) method, which ranked the genes based on their importance. This process was computationally intensive but efficient due to the algorithm's design.\n\nSubsequently, incremental feature selection (IFS) was conducted to identify the optimal feature genes. This involved constructing multiple support vector machine (SVM) classifiers for different feature sets and evaluating their performance using leave-one-out cross-validation (LOOCV). The Matthews correlation coefficient (MCC) was used as the primary metric for evaluation. This step was time-consuming due to the iterative nature of the IFS method and the need to train and validate numerous models.\n\nPrincipal component analysis (PCA) was then performed on the samples to assess the discriminatory power of the optimal feature genes. This step was relatively quick compared to the previous stages. Finally, functional enrichment analysis and protein-protein interaction (PPI) network analysis were conducted to gain insights into the biological significance of the identified feature genes. These analyses provided valuable information but added to the overall execution time.\n\nIn summary, the model's execution time was primarily influenced by the feature selection and classification stages, which required significant computational resources and time. The use of efficient algorithms and parallel processing techniques helped mitigate some of the computational burden, but the iterative nature of the IFS method remained a key factor in the overall execution time.",
  "model/availability": "The source code for the mRMR algorithm routine was downloaded from a specific website. However, no information is provided about the release of the source code for the other methods used in the study, such as the SVM classifiers or the PCA implementation. Additionally, no executable, web server, virtual machine, or container instance is mentioned as being available for running the algorithm.\n\nThe study does not specify the licensing terms under which the mRMR algorithm routine is released. Therefore, it is not clear whether the code is open-source or proprietary, or if there are any restrictions on its use.",
  "evaluation/method": "The evaluation method employed in this study involved a rigorous process to ensure the robustness and accuracy of the identified biomarkers. The incremental feature selection (IFS) method was used to construct support vector machine (SVM) classifiers for different feature gene sets. The performance of these classifiers was evaluated using leave-one-out cross-validation (LOOCV), which is a type of cross-validation where each learning set is created by taking all the samples except one, and the test set is the sample that was left out. This process is repeated such that each sample in the dataset is used once as the test set.\n\nThe performance of the classifiers was quantified using the Matthews correlation coefficient (MCC), a metric that provides a balanced measure of the quality of binary classifications. The MCC values were plotted against the number of feature genes to create an IFS curve. The set of feature genes corresponding to the highest MCC value on this curve was selected as the optimal feature genes. This approach ensured that the selected genes were not only relevant but also provided the best classification performance.\n\nAdditionally, principal component analysis (PCA) was conducted to visualize the separation between positive and negative COVID-19 samples based on the optimal feature genes. The PCA results demonstrated a clear distinction between the two sample types, further validating the effectiveness of the selected biomarkers.",
  "evaluation/measure": "In the evaluation of our study, we focused on several key performance metrics to assess the effectiveness of our selected feature genes in classifying COVID-19 cases. The primary metric used was the Matthews correlation coefficient (MCC), which is known for providing a balanced measure even when the classes are of very different sizes. This is particularly important in the context of imbalanced datasets, such as those encountered in medical diagnostics.\n\nIn addition to MCC, we also reported sensitivity, specificity, and accuracy. Sensitivity, or the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. Accuracy provides an overall measure of the correctness of the model's predictions.\n\nThe reported values for these metrics were as follows: an MCC value of 0.894, a sensitivity of 0.991, a specificity of 0.889, and an accuracy of 0.979. These metrics were derived from the top 66 feature genes selected through the incremental feature selection (IFS) method, which were used to train a support vector machine (SVM) classifier.\n\nThese performance metrics are representative of those commonly used in the literature for evaluating classification models, particularly in the context of biomedical research. The use of MCC, along with sensitivity, specificity, and accuracy, ensures a comprehensive evaluation of the model's performance, taking into account both the true positive and true negative rates, as well as the overall correctness of the predictions. This set of metrics provides a robust assessment of the model's ability to distinguish between positive and negative COVID-19 cases, making it a reliable tool for diagnostic purposes.",
  "evaluation/comparison": "Not applicable. The study focuses on identifying novel COVID-19 biomarkers using specific feature selection strategies and does not involve a comparison with publicly available methods or simpler baselines on benchmark datasets. The research primarily employs the minimum-redundancy maximum-relevancy (mRMR) method and the incremental feature selection (IFS) method to screen and validate feature genes. The performance of the selected feature genes is evaluated through support vector machine (SVM) classifiers, principal component analysis (PCA), and protein-protein interaction (PPI) network analysis. The study does not discuss or compare its methods with other publicly available or simpler baseline methods.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe performance metrics presented in this study include the Matthews correlation coefficient (MCC), sensitivity, specificity, and accuracy. These metrics were used to evaluate the classification effectiveness of the top 66 feature genes-based SVM classifier. The MCC value reported was 0.894, sensitivity was 0.991, specificity was 0.889, and accuracy was 0.979. These values indicate a high level of confidence in the classifier's performance.\n\nHowever, it is important to note that confidence intervals for these metrics were not explicitly provided. The statistical significance of these results in comparison to other methods or baselines was also not discussed. Therefore, while the reported metrics suggest strong performance, the lack of confidence intervals and statistical significance analysis means that the confidence in these results is somewhat limited. Further statistical analysis would be beneficial to fully assess the superiority of this method over others.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. The study utilized expression profile data from the Gene Expression Omnibus (GEO) database, specifically dataset GSE152075, which was obtained through the Illumina NextSeq 500 platform. This dataset includes mRNA sequencing results from throat swab samples of COVID-19 positive and negative individuals. However, the specific evaluation files generated during the analysis, such as those related to feature gene selection and classification, are not detailed in terms of public availability or licensing. Therefore, it is not clear whether these raw evaluation files are accessible to the public or under what conditions they might be shared."
}