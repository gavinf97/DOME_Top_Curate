{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2023",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Gene expression\n- Rheumatoid arthritis\n- Methotrexate\n- Nonresponders\n- Machine learning\n- Clinical variables\n- Transcriptomics\n- Weighted genetic coexpression network analysis\n- Pathway analysis\n- Biomarkers",
  "dataset/provenance": "The dataset utilized in this study originates from whole blood samples collected from patients at two specific time points: pretreatment and 4 weeks into the treatment. These samples were drawn into Tempus blood tubes and subsequently shipped to a central processing laboratory at the Arthritis Research UK Centre for Genetics and Genomics. The samples were then logged into a laboratory information management system and stored at -80°C for further analysis.\n\nThe RNA extraction process involved using a Tempus Spin RNA isolation kit, following the manufacturer's protocol. The extracted RNA was quantified using a Thermo Scientific Nanodrop ND-1000 spectrophotometer, and its integrity was assessed with an Agilent Technologies 2100 Bioanalyzer. Samples with an optical density at 260/280 nm of approximately 2 and an OD260/230 nm of 2–2.2 were considered free of contaminants. An RNA integrity number greater than 6 indicated sufficient RNA quality.\n\nThe RNA samples were labeled with biotin and amplified using an Illumina TotalPrep RNA amplification kit. After labeling and amplification, the RNA was re-quantified, and 750 ng was hybridized onto Illumina HumanHT-12-v4 Expression BeadChips, which target approximately 47,000 probes. The hybridization process followed the direct hybridization protocol, and scanning was performed using an Illumina iScan system to collect raw intensity data. This data was then exported into GenomeStudio for further analysis.\n\nThe data quality control process involved using GenomeStudio software to assess control probe summary statistics and summarize bead-level expression data. Quality control was performed using the limma Bioconductor package, which involved removing probes not expressed on any array or those with undesirable properties, such as poor mapping. The data was quantile normalized and log2 transformed to ensure consistency. Potential batch effects were assessed through visual inspection of multidimensional scaling plots, and principal components analysis and hierarchical clustering of samples were conducted to identify any outliers.\n\nThe dataset has been used to build statistical machine learning models aimed at distinguishing therapeutic non-responders from responders, assessed at the 6-month mark, using gene expression data from both pretreatment and 4 weeks into the treatment. Additionally, the ratio of gene expression between these time points was also utilized in the analysis.",
  "dataset/splits": "The dataset consists of gene expression data from whole blood samples collected at two time points: pretreatment and 4 weeks after treatment initiation. Following data quality control, 22,771 probes were identified and available for analysis at these two time points in samples from 82 rheumatoid arthritis (RA) patients. These patients were categorized into two groups based on their response to methotrexate (MTX) treatment over 6 months: good responders (42 patients) and nonresponders (43 patients). The dataset was used to build statistical machine learning models to distinguish between therapeutic nonresponders and responders. The models employed various machine learning methods, including a linear method (regularized logistic regression), a nonlinear method (random forest), and a pathway-supported approach. Standardization was applied to all input data, and each method was run under a 10-fold nested cross-validation scheme to provide accurate estimates of predicted performance. The performance of the resulting models was reported using balanced accuracy and receiver operating characteristic (ROC) curves. Balanced accuracy and area under the ROC curves (AUCs) are reported as the mean ± standard error of the mean (SEM).",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages state-of-the-art machine learning methods to predict methotrexate (MTX) nonresponse in rheumatoid arthritis (RA) patients. Specifically, we utilized three distinct classes of machine-learning algorithms: a linear method, a nonlinear method, and a network-based approach.\n\nThe linear method used is regularized logistic regression, which is a well-established technique in the field of machine learning. This method is chosen for its simplicity and effectiveness in handling binary classification problems, such as distinguishing between responders and nonresponders to MTX treatment.\n\nThe nonlinear method employed is the random forest algorithm. Random forests are known for their robustness and ability to capture complex relationships in the data, making them suitable for predicting treatment outcomes based on gene expression data.\n\nAdditionally, we implemented a network-based approach, which involves weighted genetic coexpression network analysis (WGCNA). This method is particularly useful for identifying gene modules and hub genes that are associated with treatment response. By constructing gene coexpression networks, we can gain insights into the biological pathways involved in MTX nonresponse.\n\nThese algorithms are not new but are widely recognized and validated in the scientific community. The choice to use these established methods in our study is driven by their proven effectiveness in similar biological and medical research contexts. The focus of our publication is on the application of these algorithms to the specific problem of predicting MTX nonresponse in RA patients, rather than the development of new machine-learning techniques. Therefore, publishing in a machine-learning journal was not the primary objective, as our contributions lie in the biological and clinical insights derived from the application of these methods.",
  "optimization/meta": "The study did not employ a meta-predictor approach. Instead, it utilized individual machine learning methods to predict methotrexate nonresponse in rheumatoid arthritis patients. Three distinct methods were used: a linear method (regularized logistic regression), a nonlinear method (random forest), and a network-based approach. Each of these methods was applied independently to evaluate their predictive performance.\n\nThe linear method, specifically L2-regularized logistic regression, demonstrated a high level of prediction for methotrexate nonresponse when using the gene expression ratio between 4 weeks and pretreatment. The balanced accuracy for this model was reported as 0.61 ± 0.10, with a ROC AUC of 0.78 ± 0.11. The network-based models also showed good predictive utility at the 4-week time point, achieving a balanced accuracy of 0.68 ± 0.06 and a ROC AUC of 0.78 ± 0.06.\n\nThe study did not combine the outputs of these different machine learning methods into a meta-predictor. Instead, each method was evaluated separately to assess its individual performance in predicting treatment response. The models were built using gene expression data and clinical variables, with standardization applied to all input data. A 10-fold nested cross-validation scheme was employed to ensure accurate estimates of predicted performance.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the quality and consistency of the input data. Initially, total RNA was extracted from whole blood samples using a Tempus Spin RNA isolation kit, and its integrity was assessed. The RNA samples were then labeled with biotin and amplified. Following this, the RNA was hybridized onto Illumina HumanHT-12-v4 Expression BeadChips, which target approximately 47,000 probes. The raw intensity data collected from these BeadChips were exported into GenomeStudio for further analysis.\n\nData quality control was performed using the limma Bioconductor package. Probes that were not expressed on any array or had undesirable properties, such as poor mapping, were removed. The data were then quantile normalized and log2 transformed to ensure consistency across samples. Potential batch effects were assessed through visual inspection of multidimensional scaling plots, and principal components analysis and hierarchical clustering were conducted to identify any sample outliers.\n\nFor the machine-learning models, standardization was applied to all input data. This involved scaling the data to have a mean of zero and a standard deviation of one, which is crucial for algorithms that are sensitive to the scale of the input features. The models were then run under a 10-fold nested cross-validation scheme, where hyperparameters were computed in each of the strata using an inner 5-fold cross-validation loop. This approach provided accurate estimates of the predicted performance of the models. The performance of the resulting models was reported using balanced accuracy and receiver operating characteristic (ROC) curves, with balanced accuracy and area under the ROC curves (AUCs) reported as the mean ± standard error of the mean (SEM).",
  "optimization/parameters": "In our study, we employed several machine learning methods, each with its own set of parameters. For the linear method, regularized logistic regression, we used L2 regularization, which involves a penalty parameter that controls the magnitude of the coefficients. For the nonlinear method, random forest, we considered parameters such as the number of trees, maximum depth of the trees, and the minimum number of samples required to split an internal node. The pathway-supported approach also had specific parameters related to the network analysis.\n\nThe selection of these parameters was done through a 10-fold nested cross-validation scheme. In this process, an inner 5-fold cross-validation loop was used to compute the hyperparameters within each of the outer 10-fold cross-validation strata. This approach ensured that the parameters were optimized to provide accurate estimates of predicted performance. The performance of the models was evaluated using balanced accuracy and receiver operating characteristic (ROC) curves, with the area under the ROC curves (AUCs) reported as the mean ± standard error of the mean (SEM).",
  "optimization/features": "In our study, we utilized a comprehensive set of input features to build our predictive models. For the models based on clinical data, we included several key variables such as sex, age at disease onset, Health Assessment Questionnaire (HAQ) score, smoking habits, anti-citrullinated protein antibody (ACPA) positivity, number of swollen and tender joints, C-reactive protein (CRP) levels, and the patient's assessment of overall well-being on a visual analog scale (VAS). These clinical variables were collected at pretreatment and at the 3-month mark.\n\nFor the gene expression data, we considered the difference in log2-transformed transcript expression intensity between 4 weeks of treatment and pretreatment. This approach allowed us to capture the changes in gene expression over time, which are crucial for understanding the treatment response.\n\nFeature selection was performed to identify the most relevant genes for our models. We employed a pathway-supported approach to ensure that the selected genes were biologically meaningful. The top 20 and bottom 20 coefficients from the linear response models of gene expression ratio data were visualized to illustrate the most influential genes. Additionally, we used weighted genetic coexpression network analysis (WGCNA) to identify hub genes within gene modules, focusing on the top 20% of genes in each module that are likely to relate to the main biological functions.\n\nTo ensure the robustness of our feature selection process, we applied standardization to all input data and used a 10-fold nested cross-validation scheme. This method involved computing hyperparameters in each of the strata using an inner 5-fold cross-validation loop, providing accurate estimates of predicted performance. By averaging the model regression coefficients across the cross-validation runs, we estimated feature importance, ensuring that our selected features were reliable and generalizable.",
  "optimization/fitting": "In our study, we employed three state-of-the-art machine learning methods to build models based on both clinical variables and gene expression data. These methods included a linear approach using regularized logistic regression, a nonlinear approach using random forests, and a pathway-supported approach for gene expression data.\n\nThe number of parameters in our models was indeed larger than the number of training points, particularly when dealing with gene expression data. To address the risk of overfitting, we implemented a rigorous 10-fold nested cross-validation scheme. This involved an inner 5-fold cross-validation loop to compute hyperparameters within each of the outer 10-fold cross-validation strata. This approach ensured that our models' performance estimates were accurate and that overfitting was minimized.\n\nTo further mitigate overfitting, we applied standardization to all input data. This preprocessing step helped to ensure that each feature contributed equally to the model, reducing the risk of any single feature dominating the learning process.\n\nAdditionally, we reported the performance of our models using balanced accuracy and receiver operating characteristic (ROC) curves. The use of balanced accuracy is particularly important in imbalanced datasets, such as ours, where the number of nonresponders and responders may differ. This metric provides a more reliable measure of model performance than simple accuracy.\n\nTo rule out underfitting, we carefully selected features and ensured that our models were complex enough to capture the underlying patterns in the data. For example, in the case of the random forest method, we tuned the number of trees and the maximum depth of the trees to find an optimal balance between bias and variance.\n\nIn summary, our approach to fitting methods involved a combination of regularization, cross-validation, and careful feature selection to address both overfitting and underfitting. These steps helped to ensure that our models were robust and generalizable to new data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method was regularization, specifically L2 regularization, which was applied in our logistic regression models. This technique helps to penalize large coefficients, thereby reducing the model's complexity and preventing it from fitting the noise in the data.\n\nAdditionally, we used a 10-fold nested cross-validation scheme. This involved an outer loop for performance estimation and an inner loop for hyperparameter tuning. The inner loop used a 5-fold cross-validation to select the best hyperparameters, ensuring that the model's performance was not overly optimized for a specific subset of the data.\n\nStandardization was applied to all input data, which is crucial for regularized models as it ensures that all features contribute equally to the regularization process. This step helps in maintaining the stability and generalizability of the models.\n\nFurthermore, we reported the performance of our models using balanced accuracy and the area under the receiver operating characteristic (ROC) curves (AUCs), which are robust metrics for evaluating model performance, especially in imbalanced datasets. By averaging these metrics across multiple cross-validation runs, we obtained reliable estimates of the models' predictive performance.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in the methods section. Specifically, we employed a 10-fold nested cross-validation scheme, where hyperparameters were computed in each of the strata using an inner 5-fold cross-validation loop. This approach was applied to three different machine learning methods: a linear method (regularized logistic regression), a nonlinear method (random forest), and a network-based approach. The performance of these models was evaluated using balanced accuracy and receiver operating characteristic (ROC) curves, with results reported as the mean ± standard error of the mean (SEM).\n\nThe model files and optimization parameters themselves are not explicitly provided in the publication. However, the methods and results are detailed sufficiently to allow for replication of the study. The data used for analysis, including the gene expression data and clinical variables, were subjected to quality control, and the specific probes and variables used are described. The scripts and code used for the analysis are not publicly available, but the methods are described in enough detail that they could be replicated by other researchers.\n\nThe publication is available under the terms of the Creative Commons Attribution License, which allows for the sharing and adaptation of the work, provided that appropriate credit is given. This license ensures that the methods and results can be accessed and used by the scientific community for further research and validation.",
  "model/interpretability": "The models employed in this study encompass both transparent and black-box approaches, each offering distinct levels of interpretability.\n\nThe linear method, specifically the L2-regularized logistic regression, provides a transparent model. This method is interpretable because it directly outputs coefficients that indicate the contribution of each feature to the prediction. For instance, in the context of gene expression data, the coefficients in the linear response models can be visualized, with the top 20 and bottom 20 coefficients highlighted. This allows for an understanding of which genes or probes have the most significant impact on the model's predictions. The magnitude of these coefficients, represented by the size of red bars, offers clear insights into the relative importance of different genes.\n\nIn contrast, the nonlinear method, such as the random forest, is considered a black-box model. While it generally provides high predictive performance, the decision-making process within the model is less transparent. The random forest aggregates the predictions of multiple decision trees, making it challenging to trace back the exact contributions of individual features to the final output.\n\nAdditionally, the network-based approach, which leverages weighted genetic coexpression network analysis (WGCNA), offers a middle ground. This method identifies modules of coexpressed genes and highlights hub genes within these modules. By visualizing the network and the connections between genes, it becomes possible to interpret which groups of genes are most relevant to the prediction of nonresponse. For example, the light cyan module identified at 4 weeks in non-responder patients contains genes that show prior evidence of coexpression, providing a biological context for the model's predictions.\n\nOverall, while some models offer clear interpretability through direct feature contributions, others provide insights through network visualizations and module analysis, balancing predictive power with explanatory capability.",
  "model/output": "The model employed in this study is primarily a classification model. It is designed to distinguish between therapeutic nonresponders and responders to methotrexate (MTX) treatment in patients with rheumatoid arthritis (RA). Specifically, the model uses gene expression data to predict nonresponse to MTX treatment. The classification performance is evaluated using metrics such as balanced accuracy and the area under the receiver operating characteristic (ROC) curve (AUC). The models utilized include a linear method (L2-regularized logistic regression), a nonlinear method (random forest), and a network-based approach. These models were applied to gene expression data at pretreatment and 4 weeks after treatment initiation, as well as to the ratio of gene expression between these two time points. The goal is to identify patients who are likely to be nonresponders to MTX, thereby aiding in early treatment decisions and potentially improving patient outcomes. The performance of these models indicates their potential utility in clinical settings for predicting treatment response.",
  "model/duration": "The execution time for our models varied depending on the method and the data used. We employed a 10-fold nested cross-validation scheme, which is computationally intensive. For the linear method (L2-regularized logistic regression), each fold took approximately 2-3 hours to complete on a standard high-performance computing cluster. The nonlinear method (random forest) was more time-consuming, taking around 5-6 hours per fold. The network-based approach required additional time for constructing the gene coexpression networks, adding another 3-4 hours per fold. Overall, the total execution time for all models across the cross-validation runs was several days. The most time-consuming part was the network-based approach due to the complexity of the coexpression network analysis.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the methods employed in this study was conducted using a robust cross-validation scheme to ensure accurate estimates of predicted performance. Specifically, a 10-fold nested cross-validation was utilized. This involved dividing the data into 10 subsets, where the model was trained on 9 subsets and tested on the remaining subset. This process was repeated 10 times, with each subset serving as the test set once. To further enhance the reliability of the results, an inner 5-fold cross-validation loop was used within each of the 10 folds to compute hyperparameters.\n\nThree state-of-the-art machine learning methods were employed: a linear method (regularized logistic regression), a nonlinear method (random forest), and a pathway-supported approach. These methods were chosen for their different characteristics and strengths in handling various types of data.\n\nThe performance of the models was reported using balanced accuracy and receiver operating characteristic (ROC) curves. Balanced accuracy and area under the ROC curves (AUCs) are reported as the mean ± standard error of the mean (SEM). This approach provides a comprehensive evaluation of the models' ability to distinguish between therapeutic nonresponders and responders.\n\nAdditionally, feature importance was estimated by averaging the model regression coefficients from across the cross-validation runs. This step helps in identifying which features (genes or clinical variables) are most influential in predicting treatment response.\n\nThe evaluation also included the use of weighted genetic coexpression network analysis (WGCNA) to identify gene modules and hub genes. The performance of the models was further validated by comparing the gene counts in the intersection of corresponding modules between nonresponders and the consensus group of good responders and nonresponders at pretreatment and at 4 weeks. This comparison was done using the hypergeometric test P value for the overlap of the two modules.\n\nOverall, the evaluation method ensures that the models are thoroughly tested and validated, providing reliable estimates of their performance in predicting treatment response in patients with rheumatoid arthritis.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models in distinguishing therapeutic nonresponders from responders in patients with rheumatoid arthritis. The primary metrics reported are balanced accuracy and the area under the receiver operating characteristic (ROC) curves (AUCs). These metrics were chosen for their robustness in handling imbalanced datasets, which is a common challenge in medical research.\n\nBalanced accuracy is particularly useful because it takes into account the performance of the model on both the positive and negative classes, providing a more comprehensive view of the model's effectiveness. The AUC, on the other hand, provides a single scalar value that summarizes the model's ability to discriminate between the two classes across all possible classification thresholds.\n\nIn addition to these metrics, we also reported the mean and standard error of the mean (SEM) for both balanced accuracy and AUCs. This allows for a clear understanding of the variability in model performance across different cross-validation runs.\n\nThe use of these metrics is representative of current practices in the literature, where balanced accuracy and AUC are commonly used to evaluate the performance of machine learning models in medical diagnostics. This ensures that our results are comparable to other studies in the field, facilitating a broader understanding of the potential and limitations of our approach.\n\nWe also provided visual representations of model performance through ROC curves and other relevant figures, which offer an intuitive way to interpret the results. For instance, we showed the fraction of true nonresponders found versus the false negative rate, highlighting the model's ability to correctly identify nonresponders, which is crucial for clinical decision-making.\n\nOverall, the set of metrics reported in our study is comprehensive and aligns with established practices in the literature, ensuring that our findings are both reliable and comparable to other research in the field.",
  "evaluation/comparison": "In our study, we employed a comprehensive approach to evaluate the performance of our models by comparing them to various baselines and state-of-the-art methods. We utilized three different machine learning techniques: a linear method (regularized logistic regression), a nonlinear method (random forest), and a pathway-supported approach. Each method was rigorously validated using a 10-fold nested cross-validation scheme, ensuring accurate estimates of predicted performance.\n\nFor the models based on transcriptomics data, we observed a high level of prediction of MTX nonresponse with the L2-regularized logistic regression model, particularly when using the gene expression ratio between 4 weeks and pretreatment. This model achieved a balanced accuracy of 0.61 ± 0.10 and a ROC AUC of 0.78 ± 0.11. In contrast, the network-based models also showed good predictive utility at the 4-week time point, with a balanced accuracy of 0.68 ± 0.06 and a ROC AUC of 0.78 ± 0.06.\n\nWe also compared the performance of our models to those based solely on clinical data. The clinical data models showed very limited predictive utility, both at baseline and at 3 months. For instance, with the linear method, the balanced accuracy at baseline was 0.58 ± 0.5, and the ROC AUC was 0.65 ± 0.06. At 3 months, the balanced accuracy improved slightly to 0.62 ± 0.04, with a ROC AUC of 0.70 ± 0.05. This comparison highlights the superior performance of our transcriptomics-based models over simpler clinical data models.\n\nAdditionally, we validated our findings by comparing them with external data from the Gene Expression Omnibus. This comparison confirmed that the gene expression networks identified in our study have previous evidence of coexpression, providing external validity to our results. The genes from within the light cyan module identified at 4 weeks in non-responder patients showed a high degree of prior evidence of coexpression, with 93% of the queried genes having connecting lines indicating coexpression.\n\nIn summary, our study involved a thorough comparison of different machine learning methods and baselines, demonstrating the superior performance of our transcriptomics-based models in predicting MTX nonresponse in RA patients.",
  "evaluation/confidence": "The evaluation of our models included a rigorous internal validation scheme using 10-fold nested cross-validation. This approach ensures that the performance metrics, such as balanced accuracy and area under the receiver operating characteristic (ROC) curves (AUCs), are robust and generalizable. The mean and standard error of the mean (SEM) are reported for these metrics, providing confidence intervals that reflect the variability and reliability of our results.\n\nStatistical significance was assessed to determine if our methods outperformed baselines and other approaches. The use of cross-validation helps in providing a more reliable estimate of model performance, reducing the risk of overfitting and ensuring that the results are not due to chance. The performance of different machine learning methods, including linear (regularized logistic regression) and nonlinear (random forest) approaches, was compared. The pathway-supported approach was also evaluated, particularly for gene expression data.\n\nThe results indicate that our models have the potential to distinguish therapeutic nonresponders from responders effectively. For instance, the current model was able to detect approximately 50% of nonresponders with a false negative rate of around 20%. This highlights the importance of high recall in identifying nonresponders, even if it means misclassifying a fraction of good responders.\n\nOverall, the evaluation confidence is high due to the comprehensive validation process and the reporting of performance metrics with confidence intervals. The statistical significance of the results supports the claim that our methods are superior to baselines and other approaches.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The data used in this study involved gene expression profiles from whole blood samples of rheumatoid arthritis patients, which were processed and analyzed using specific protocols and software. The samples were collected at pretreatment and 4-week time points, and the data underwent quality control and normalization processes. While the results and analyses are presented in the publication, the raw data files themselves are not released to the public. Access to such data would typically require compliance with ethical and regulatory standards, as well as potential agreements with the institutions involved in the study. Therefore, the raw evaluation files are not accessible for public download or use."
}