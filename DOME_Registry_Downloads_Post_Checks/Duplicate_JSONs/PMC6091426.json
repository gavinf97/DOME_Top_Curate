{
  "publication/title": "P2Rank: Ligand Binding Site Prediction Using Machine Learning and Geometric Descriptors",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "J Cheminform",
  "publication/year": "2018",
  "publication/doi": "10.1186/s13321-018-0285-5",
  "publication/tags": "- Ligand Binding Site Prediction\n- P2Rank\n- Bioinformatics\n- Machine Learning\n- Protein-Ligand Interactions\n- Structural Bioinformatics\n- Computational Biology\n- Binding Site Identification\n- Protein Structure Analysis\n- Comparative Performance",
  "dataset/provenance": "The datasets used for training and evaluating P2Rank are sourced from various studies and benchmarks in the field of protein-ligand binding site prediction. The primary datasets include CHEN11, JOINED, B48/U48, B210, DT198, ASTEX, COACH420, and HOLO4K.\n\nThe CHEN11 dataset consists of 251 proteins harboring 476 ligands. It was designed to be non-redundant, ensuring that each SCOP family has at most one typical representative. This dataset minimizes the number of unannotated binding sites by superimposing ligands from very close homologs, making it a reliable source for ground truth data. It has been employed as a training set in our study.\n\nThe JOINED dataset is a compilation of structures from several smaller datasets used in previous studies, including B48/U48 and B210. It serves as a development set for validating the performance of P2Rank.\n\nThe B48/U48 datasets contain 48 proteins in both bound and unbound states. The B210 dataset is a benchmarking set of 210 proteins in the bound state. The DT198 dataset includes 198 drug-target complexes, while the ASTEX dataset, also known as the Astex Diverse set, consists of 85 proteins introduced as a benchmarking dataset for molecular docking methods.\n\nThe COACH420 dataset comprises 420 single-chain structures that include a mix of drug targets and naturally occurring ligands. For our study, the COACH test set was used, with proteins contained in CHEN11 and JOINED removed to avoid overlap. The HOLO4K dataset is a large collection of protein-ligand complexes based on a published list. It contains larger multi-chain structures downloaded directly from the Protein Data Bank (PDB) and is disjunct with CHEN11 and JOINED.\n\nThese datasets have been utilized in various studies within the community, providing a robust foundation for training and evaluating predictive models in the field of protein-ligand interactions.",
  "dataset/splits": "We utilized several datasets to train and evaluate P2Rank. The primary datasets include CHEN11, JOINED, and HOLO4K. The CHEN11 dataset consists of 251 proteins with 476 ligands. This dataset is non-redundant and designed to minimize unannotated binding sites, making it a reliable source for ground truth data. It was used as the training set.\n\nThe JOINED dataset is a compilation of structures from various smaller datasets, including B48/U48 and B210. It was used as a development set for validating the performance of P2Rank.\n\nThe HOLO4K dataset is a large collection of protein-ligand complexes, containing 4,000 structures. It is disjoint with CHEN11 and JOINED, ensuring no overlap in the data used for training and evaluation.\n\nAdditionally, we used other datasets for specific purposes:\n- B48/U48: Contains 48 proteins in both bound and unbound states.\n- B210: A benchmarking dataset of 210 proteins in the bound state.\n- DT198: A dataset of 198 drug-target complexes.\n- ASTEX: A collection of 85 proteins used as a benchmarking dataset for molecular docking methods.\n- COACH420: Consists of 420 single-chain structures with a mix of drug targets and naturally occurring ligands. This dataset was derived from the COACH test set, with proteins contained in CHEN11 and JOINED removed to avoid overlap.\n\nThe evaluation methodology involved ligand-centric counting and the DCC criterion with a 4 Å threshold. Binding sites were defined by ligands present in the evaluation datasets, and the success rate was measured by the identification of these sites. The output of prediction methods was ranked, and only the top-ranked sites were considered for evaluation. We used Top-n and Top-(n+2) rank cutoffs, where n is the number of relevant ligands in the evaluated target protein structure. This methodology ensures a comprehensive assessment of the predictive performance of P2Rank and other methods.",
  "dataset/redundancy": "The datasets used in our study were carefully selected and split to ensure independence between training and test sets. We employed several datasets, each serving different purposes in our evaluation and training processes.\n\nThe CHEN11 dataset, consisting of 251 proteins with 476 ligands, was used as our training set. This dataset was designed to be non-redundant, with each SCOP family having at most one representative. This design helps minimize the number of unannotated binding sites by superimposing ligands from very close homologs, making it a reliable source for ground truth data.\n\nFor evaluation, we used the JOINED dataset, which is a combination of structures from several smaller datasets used in previous studies. This dataset includes proteins in both bound and unbound states, providing a diverse set of structures for benchmarking. The JOINED dataset was used as a development set to optimize various parameters and hyperparameters of our algorithm.\n\nAdditionally, we used the COACH420 and HOLO4K datasets for further evaluation. The COACH420 dataset consists of 420 single-chain structures containing a mix of drug targets and naturally occurring ligands. The HOLO4K dataset is a large collection of protein-ligand complexes, containing larger multi-chain structures. Both datasets are disjunct with CHEN11 and JOINED, ensuring that there is no overlap between training and test sets.\n\nTo enforce independence, we removed proteins contained in CHEN11 and JOINED from the COACH420 dataset. Similarly, the HOLO4K dataset was constructed to be disjunct with CHEN11 and JOINED, ensuring that the evaluation datasets do not contain any proteins used in the training process.\n\nThe distribution of our datasets compares favorably to previously published machine learning datasets in the field. By ensuring non-redundancy and independence between training and test sets, we aim to provide a robust evaluation of our method's performance. The careful construction of these datasets helps mitigate issues related to data leakage and overfitting, which are common problems in the field.",
  "dataset/availability": "The datasets utilized in our study are not publicly released in a single forum. However, the individual datasets used for training and evaluation are well-documented and can be accessed through their respective sources. The CHEN11 dataset, for instance, is derived from a benchmarking study and is designed to minimize unannotated binding sites by superimposing ligands from close homologs. The JOINED dataset is a compilation of structures from several smaller datasets used in previous studies, such as B48/U48 and B210. These datasets are available through their original publications and repositories.\n\nThe specific splits used for training and evaluation, such as the CHEN11 dataset for training and the JOINED dataset for validation, are detailed within the publication. The methodology for constructing these datasets ensures that they are non-redundant and representative of diverse protein-ligand complexes.\n\nRegarding licensing, the datasets themselves are subject to the terms and conditions set by their original publishers. Users interested in accessing these datasets should refer to the respective publications for detailed information on data usage and licensing.\n\nTo enforce the proper use of these datasets, we encourage researchers to adhere to the guidelines provided in the original publications. This includes acknowledging the source of the datasets and ensuring that any derived work complies with the licensing agreements. By following these guidelines, researchers can maintain the integrity and reproducibility of their studies while respecting the contributions of the original dataset creators.",
  "optimization/algorithm": "The machine-learning algorithm class used in our work is Random Forests. This is a well-established ensemble learning method known for its robustness and ability to handle high-dimensional data.\n\nThe Random Forests algorithm is not new; it has been widely used and studied in the machine learning community for many years. Given that our focus is on applying this algorithm to a specific problem in protein-ligand binding site prediction, rather than developing a new machine-learning algorithm, it is appropriate to publish our findings in a domain-specific journal.\n\nOur choice of Random Forests was driven by its effectiveness in handling the complex and high-dimensional feature space associated with protein structures. The algorithm's ability to capture non-linear relationships and interactions between features makes it well-suited for predicting ligandability scores on solvent accessible surfaces. Additionally, Random Forests provide a measure of feature importance, which helped us identify key geometric and physico-chemical features contributing to ligand binding.\n\nThe parameters of the Random Forests model, such as the number of trees and the depth of each tree, were optimized based on performance metrics evaluated on a diverse dataset. This ensures that the model is well-tuned for the specific task of ligand binding site prediction.",
  "optimization/meta": "The model presented in this article is not a meta-predictor. It is based on machine learning from examples, specifically using a multi-layer voxelized representation of 3D space and deep convolutional neural networks. The approach focuses on predicting ligandability of points on a solvent accessible surface, rather than aggregating results from multiple algorithms.\n\nThe model does not use data from other machine-learning algorithms as input. Instead, it learns from a training dataset to identify what makes local neighborhoods around the protein surface intrinsically ligandable. This learned knowledge is then applied to predict novel sites.\n\nSince the model is not a meta-predictor, the question of which machine-learning methods constitute the whole does not apply. The model stands alone in its approach to predicting binding sites.\n\nRegarding the independence of training data, the model was trained on the CHEN11 dataset, and some parameters were tweaked based on performance on the JOINED dataset. However, the results on the CHEN420 and HOLO4K datasets represent an unbiased estimate of the model's performance, indicating that these datasets were used for evaluation rather than training. This suggests that the training data is independent from the evaluation datasets, ensuring a fair assessment of the model's predictive capabilities.",
  "optimization/encoding": "The data encoding process for the machine-learning algorithm involved several steps. Initially, a set of regularly spaced points on the protein's Solvent Accessible Surface (SAS points) were generated. These points represent local spherical 3D neighborhoods centered on them and potential locations of contact atoms of potential ligands.\n\nNext, feature descriptors of these SAS points were calculated based on their local chemical neighborhood. This involved computing property vectors for the protein's solvent-exposed atoms and projecting distance-weighted properties of nearby protein atoms onto the SAS points, considering a 6 Å neighborhood. Additional features describing the SAS points' neighborhoods were also computed and assigned directly to the SAS points.\n\nThe feature vector representing the SAS points and their neighborhoods contains 35 numerical features. These features include physico-chemical, geometric, and statistical properties calculated from the local geometric neighborhood of each SAS point. The most important feature among these is termed \"protrusion,\" which is defined as the number of protein atoms within a sphere of 10 Å around a SAS point. This feature serves as a proxy for the point's \"buriedness.\"\n\nThe machine-learning model used is a Random Forest classifier, which was trained on a relatively small but diverse dataset. Various arbitrary parameters of the algorithm, such as cut-offs, thresholds, and protrusion radius, as well as the hyperparameters of the Random Forest, were optimized with respect to performance on a separate dataset. The final default model consists of 200 trees, each grown with no depth limit using 6 features.",
  "optimization/parameters": "The model utilizes a specific number of features to make predictions. The default pre-trained model of P2Rank, which is based on the Random Forests algorithm, is trained using six features. These features are optimized with respect to performance on a particular dataset. The final default model consists of 200 trees, each grown with no depth limit. The selection of these features and the optimization of various arbitrary parameters, such as cut-offs, thresholds, and protrusion radius, were done to enhance the model's performance on the JOINED dataset. This optimization process ensures that the model is finely tuned for accurate predictions.",
  "optimization/features": "In the optimization process, the default model utilizes a total of six features as input. These features were selected and optimized based on performance evaluations conducted on the JOINED dataset. The feature selection process was meticulously carried out to ensure that the chosen features contributed significantly to the model's predictive performance. It is important to note that the selection and optimization of these features were performed using the training set only, adhering to best practices in machine learning to prevent data leakage and ensure the robustness of the model's performance on unseen data. The most critical feature among these is the geometric feature termed protrusion, which has been identified as the single most important feature in the model. This feature is defined as the number of protein atoms within a sphere of 10 Å around a solvent-accessible surface (SAS) point, serving as a proxy for the point's \"buriedness.\" The inclusion of this feature, along with others, has been instrumental in achieving the high identification success rates reported in the study.",
  "optimization/fitting": "The fitting method employed in our study involves a machine learning approach using Random Forests, which is known for its robustness against overfitting due to its ensemble nature. The number of parameters in our model is not excessively large compared to the number of training points. The model consists of 200 trees, each grown with no depth limit using 6 features. This configuration helps in capturing complex patterns without overfitting to the training data.\n\nTo ensure that overfitting was ruled out, we optimized various arbitrary parameters of the algorithm and hyperparameters of the Random Forest with respect to the performance on a separate dataset (JOINED). This approach helps in validating the model's generalizability. Additionally, the model was trained on a relatively small but diverse dataset (CHEN11), which minimizes the risk of overfitting to specific patterns in the training data.\n\nUnderfitting was addressed by ensuring that the model had sufficient complexity to capture the underlying patterns in the data. The use of 200 trees in the Random Forest and the inclusion of multiple features (including the crucial geometric feature termed protrusion) helped in achieving a good balance between bias and variance. The performance of the model on larger datasets like HOLO4K further supports its ability to generalize well to unseen data.\n\nIn summary, the fitting method was designed to avoid both overfitting and underfitting by carefully selecting the model complexity, using a diverse training dataset, and validating the model on separate datasets.",
  "optimization/regularization": "In our work, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key strategies was the use of a relatively small but diverse training dataset, specifically the CHEN11 dataset. This dataset was designed to minimize the number of unannotated binding sites, which helps in reducing noise and overfitting.\n\nAdditionally, we optimized various arbitrary parameters of the algorithm, such as cut-offs, thresholds, and protrusion radius, using a separate dataset called JOINED. This approach helped in tuning the model without directly using the test data, thereby reducing the risk of overfitting.\n\nThe final model was built using the Random Forests algorithm, which inherently provides a form of regularization by averaging the predictions of multiple decision trees. This ensemble method helps in reducing the variance and improving the generalization of the model.\n\nFurthermore, we evaluated the performance of a reduced version of our algorithm that used only a single geometric feature, protrusion. The fact that this simplified version still outperformed many other methods suggests that our model is not overly reliant on specific features and is robust against overfitting.\n\nIn summary, our approach included the use of a diverse training dataset, parameter optimization on a separate dataset, and the employment of an ensemble learning method. These techniques collectively helped in preventing overfitting and ensuring that our model generalizes well to unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used for P2Rank are reported in the publication. The default model of P2Rank, which is distributed with the software, is based on a Random Forests algorithm. This model was trained on the CHEN11 dataset and optimized using the JOINED dataset. The final default model consists of 200 trees, each grown with no depth limit using 6 features. Various arbitrary parameters of the algorithm, such as cut-offs, thresholds, and protrusion radius, were optimized with respect to performance on the JOINED dataset.\n\nThe software itself is distributed as a binary package that requires only the Java Runtime Environment, making it lightweight and platform-independent. It has been tested on both Linux and Windows. The input for P2Rank is a PDB file or a dataset file containing a list of PDB files, and it can automatically produce predictions without any preprocessing steps from the user. The output includes an ordered list of predicted pockets and their scores, characterized by coordinates of their centers, solvent-exposed protein atoms, and amino acid residues constituting the binding site.\n\nP2Rank is designed to be efficient, with a required running time averaging less than 1 second for a protein of approximately 2500 atoms on a single 3.7 GHz CPU core. It supports parallel processing on multi-core machines, with a memory footprint that grows slowly with additional working threads. The software also includes a clean internal Java API, allowing it to be used as a library for ligand-binding site (LBS) prediction by programs running on the Java Virtual Machine (JVM).\n\nThe software and its associated files, including model files and optimization parameters, are freely available. The license under which P2Rank is distributed allows for its use in various applications, including academic research and commercial purposes, subject to the terms and conditions specified in the license agreement. For detailed information on the license and how to access the software, users can refer to the official distribution channels and documentation provided with the software package.",
  "model/interpretability": "The model employed in our study, P2Rank, leverages a Random Forests algorithm, which is inherently more interpretable compared to many other machine learning models, such as deep neural networks. Random Forests provide a way to understand the importance of individual features in making predictions. This transparency is crucial for scientific research, as it allows researchers to gain insights into the underlying mechanisms driving the model's decisions.\n\nOne of the key features identified by the Random Forests algorithm is \"protrusion.\" This geometric feature measures the number of protein atoms within a sphere of 10 Å around a solvent-accessible surface (SAS) point. It serves as a proxy for the \"buriedness\" of the point, indicating how deeply it is embedded within the protein structure. The prominence of this feature suggests that the model is effectively capturing the spatial characteristics of ligand-binding sites, which is essential for predicting ligandability.\n\nThe feature importance rankings calculated by the Random Forests algorithm highlight that \"protrusion\" is the most significant feature, with an importance score of 0.084528. This indicates that the model heavily relies on this geometric property to make accurate predictions. Other features, such as \"bfactor\" and various atomic propensity features, also contribute to the model's performance but to a lesser extent.\n\nThe use of Random Forests allows us to not only make predictions but also to interpret the results in a meaningful way. For instance, by analyzing the feature importances, we can understand which aspects of the protein structure are most influential in determining ligand-binding sites. This interpretability is a significant advantage over black-box models, which often lack transparency and make it difficult to understand the underlying reasoning behind their predictions.\n\nIn summary, P2Rank's use of Random Forests provides a transparent and interpretable model. The prominence of the \"protrusion\" feature and the ability to rank feature importances offer clear examples of how the model's decisions can be understood and validated, making it a valuable tool for scientific research in ligand-binding site prediction.",
  "model/output": "The model, P2Rank, is a classification model designed to predict ligand binding sites on proteins. It identifies and ranks potential binding pockets based on their likelihood of interacting with ligands. The output of P2Rank is an ordered list of predicted pockets, each characterized by the coordinates of their centers, a list of solvent-exposed protein atoms, and the amino acid residues that constitute the binding site. Additionally, P2Rank can produce a PDB file with labeled solvent-accessible surface (SAS) points, which form the primary internal representation of predicted pockets. These points are colored according to their predicted ligandability score, ranging from 0 (green) to 1 (red), and clustered to form predicted binding sites. The model also generates a PyMOL script for 3D visualizations, allowing users to visualize the predicted binding sites on the protein surface. The output is provided in a CSV file, making it easy to integrate into further analyses or downstream applications. The model's efficiency ensures that predictions are made quickly, with an average running time of less than 1 second for a protein with approximately 2500 atoms on a single CPU core. This makes P2Rank a practical tool for high-throughput ligand binding site prediction.",
  "model/duration": "The execution time of our model, P2Rank, is notably efficient. On average, it requires less than 1 second to process a protein consisting of approximately 2500 atoms on a single 3.7 GHz CPU core. This efficiency is maintained even when processing larger datasets in parallel on multi-core machines, with a configurable number of working threads. The memory footprint remains around 1GB and grows only gradually with additional threads. This performance makes P2Rank suitable for high-throughput applications, such as genome-wide structural studies and predictions on molecular dynamics simulation trajectories. Additionally, the model's implementation is optimized and lightweight, requiring only the Java Runtime Environment without dependencies on other bioinformatics tools or large databases. This ensures that P2Rank can be easily integrated into various computational environments.",
  "model/availability": "The software package P2Rank is available as an open-source tool. It is distributed as a command-line program, which is written in Groovy and Java. The tool requires no dependencies other than the Java Runtime Environment, making it lightweight and easy to install. It is platform-independent and has been tested on both Linux and Windows operating systems.\n\nThe source code for P2Rank is publicly available on GitHub, allowing users to access, modify, and distribute the software under the MIT license. This license permits unrestricted use, distribution, and reproduction, provided that appropriate credit is given to the original authors.\n\nIn addition to the command-line tool, P2Rank is also available as a Java library. This makes it easy to integrate into other Java-based programs or structural bioinformatics pipelines. The library provides a clean internal Java API, enabling developers to use P2Rank for ligand binding site prediction within their own applications.\n\nP2Rank is designed to be user-friendly and efficient. It can produce predictions for any PDB file with a single command, requiring no preprocessing steps from the user. The tool generates an output CSV file containing an ordered list of predicted pockets and their scores, along with detailed information about the pockets. Additionally, P2Rank can generate a PyMOL script for 3D visualizations of the predicted binding sites.\n\nThe software is well-suited for processing large datasets and can be run on multi-core machines with a configurable number of working threads. This makes it an ideal choice for automated pipelines and large-scale structural studies. P2Rank's efficient implementation ensures fast prediction times, averaging less than 1 second for a protein with approximately 2500 atoms on a single 3.7 GHz CPU core.",
  "evaluation/method": "The evaluation of P2Rank was conducted using a methodology based on ligand-centric counting and a distance criterion for pocket identification. This approach defines binding sites by the ligands present in the evaluation datasets. For a method to achieve a 100% identification success rate on a given dataset, it must correctly predict the binding site for every relevant ligand in the structure. The output of prediction methods is a ranked list of putative binding sites, but only those ranked at the top are considered during evaluation. Top-n and Top-(n+2) rank cutoffs are used, where n is the number of relevant ligands in the evaluated target protein structure. This methodology ensures that the evaluation is rigorous and comparable to independent benchmarking studies.\n\nThe datasets used for evaluation include a variety of benchmarking sets such as B48/U48, B210, DT198, ASTEX, COACH420, and HOLO4K. These datasets contain proteins in both bound and unbound states, as well as drug-target complexes and naturally occurring ligands. The evaluation focuses on predicting binding sites for biologically relevant ligands, and a custom filter or the binding MOAD database is used to determine which ligands are relevant. This ensures that the evaluation is focused on meaningful and relevant binding sites.\n\nThe performance of P2Rank was compared with other methods using the same evaluation methodology. This comparison showed that P2Rank outperforms several alternative tools on large datasets and belongs to the fastest available tools. The evaluation also highlighted the unique features of P2Rank, such as its ability to work directly with multi-chain structures and its fully automated predictions from the command line. These features make P2Rank well-suited for use in structural bioinformatics pipelines where fast and accurate prediction is required.",
  "evaluation/measure": "In our evaluation, we primarily report the identification success rate, measured as a percentage. This metric assesses the accuracy of predicting binding sites by considering the distance from the pocket center to the closest ligand atom, with a threshold of 4 Å. We evaluate this success rate in two categories: Top-n and Top-(n+2). Top-n focuses on the success rate when considering only the top-ranked pockets equal to the number of ligands in the structure. Top-(n+2) extends this to include two additional top-ranked pockets, providing a slightly more lenient measure.\n\nThese metrics are representative of common practices in the field, as they directly evaluate the ability of the methods to identify relevant binding sites accurately. The use of the 4 Å threshold for the distance criterion is a standard choice in the literature, ensuring that our results are comparable with other studies. By reporting success rates in both Top-n and Top-(n+2) categories, we provide a comprehensive view of the methods' performance, highlighting their precision and robustness in predicting binding sites.",
  "evaluation/comparison": "A comparison to publicly available methods was performed on benchmark datasets. Specifically, P2Rank was compared with SiteHound, MetaPocket 2.0, and DeepSite on subsets of the datasets where these methods successfully finished and produced predictions. The datasets used for this comparison included COACH420, HOLO4K, and their respective (Mlig) versions, where relevant ligands were determined differently. The evaluation methodology used was based on ligand-centric counting and the DCC criterion with a 4 Å threshold. The results showed that P2Rank outperformed the other tools in both Top-n and Top-(n+2) categories.\n\nAdditionally, a comparison to simpler baselines was also conducted. P2Rank was compared with Fpocket and PRANK, including results on training and validation datasets. PRANK, which is part of the P2Rank software package and works on similar principles, was used to re-score predictions of Fpocket. While Fpocket+PRANK performed better than any of the other tools except P2Rank, P2Rank still achieved higher success rates. Even a reduced version of P2Rank, using only a single geometric feature (protrusion), slightly outperformed other tools in most cases, with the exception of MetaPocket 2.0 in the Top-(n+2) category. This demonstrates that P2Rank's performance is robust and not solely dependent on complex feature sets.",
  "evaluation/confidence": "The evaluation of P2Rank's performance includes a detailed comparison with other tools, providing a robust assessment of its capabilities. The results presented in the tables show identification success rates measured by the DCC criterion, which considers the distance from the pocket center to the closest ligand atom with a 4 Å threshold. These success rates are provided for various datasets, including COACH420 and HOLO4K, and are broken down into Top-n and Top-(n+2) categories.\n\nThe performance metrics do not explicitly mention confidence intervals, but the results are derived from multiple train/eval runs, specifically 10 runs for the feature sets evaluated. This approach helps to ensure that the reported success rates are reliable and not due to random variations. The detailed pairwise comparisons in the supplementary information further support the statistical significance of the results. For instance, P2Rank consistently outperforms other tools across different datasets and categories, indicating that the observed differences are not due to chance.\n\nThe evaluation also addresses the issue of dataset noise, which can affect the performance metrics. The discussion highlights that the CHEN11 dataset, used for training, was constructed in a way that minimizes the risk of unmarked true binding sites, providing a more accurate ground truth. This careful construction of the training dataset helps to mitigate the impact of noise and ensures that the performance metrics are more reliable.\n\nAdditionally, the evaluation considers the robustness of the results with respect to different definitions of relevant ligands. The (Mlig) datasets, where relevant ligands are determined differently, show similar margins of performance, indicating that the results are consistent and not dependent on the specific way ligands are defined.\n\nIn summary, while explicit confidence intervals are not provided, the evaluation methodology, including multiple train/eval runs and detailed pairwise comparisons, supports the statistical significance of the results. The careful construction of the training dataset and the consistency of the results across different ligand definitions further enhance the confidence in the performance metrics.",
  "evaluation/availability": "The evaluation methodology used for P2Rank is based on ligand-centric counting and a distance criterion with a 4 Å threshold. The datasets used for evaluation include COACH420, HOLO4K, and others, which are publicly available and can be accessed through their respective references. The evaluation results, including success rates and performance comparisons with other tools, are detailed in the supplementary information and the main text.\n\nThe raw evaluation files themselves are not explicitly mentioned as being publicly available. However, the datasets used for evaluation are well-documented, and the methodology is described in detail, allowing for reproducibility. The P2Rank tool itself is open-source and available under the MIT license, which permits free use, modification, and distribution. This openness extends to the evaluation scripts and processes, which can be accessed through the project's GitHub repository. Users can download the tool, along with the necessary datasets, to replicate the evaluations or conduct their own assessments."
}