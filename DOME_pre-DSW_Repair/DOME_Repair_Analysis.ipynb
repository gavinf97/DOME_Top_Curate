{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf6507b",
   "metadata": {},
   "source": [
    "# DOME Registry Pre-Repair Analysis\n",
    "\n",
    "This notebook is designed to analyze the DOME registry data, search for specific papers, and cross-reference user metadata before any DSW (Daily Study Workflow) repair operations are performed. It provides tools to verify the state of annotations and curator mappings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c9302af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dome-Recommendations-Annotated-Articles_20250202.tsv...\n",
      "Enriching data with Europe PMC API...\n",
      "Processing 188/188: PMID 24977146\n",
      "Enrichment complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Informazioni cronologiche</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Journal name</th>\n",
       "      <th>Publication year</th>\n",
       "      <th>DOME version</th>\n",
       "      <th>Provenance</th>\n",
       "      <th>Dataset splits</th>\n",
       "      <th>Redundancy between data splits</th>\n",
       "      <th>Availability of data</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>...</th>\n",
       "      <th>Evaluation method</th>\n",
       "      <th>Performance measures</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Availability of evaluation</th>\n",
       "      <th>Indirizzo email</th>\n",
       "      <th>EPMC_title</th>\n",
       "      <th>EPMC_authors</th>\n",
       "      <th>EPMC_pub_year</th>\n",
       "      <th>EPMC_doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/23/2022 16:36:18</td>\n",
       "      <td>33465072</td>\n",
       "      <td>PLoS Comput Biol.</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes, N_pos: 13128  N_neg: 32766</td>\n",
       "      <td>5-fold cross-validation</td>\n",
       "      <td>Correlation Feature Selection is used.</td>\n",
       "      <td>yes, described at S1 table: https://deposition...</td>\n",
       "      <td>Naive Bayes, SVM, Random Forests</td>\n",
       "      <td>...</td>\n",
       "      <td>5-fold cross validation</td>\n",
       "      <td>ROC  curves and AUC values</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>andrewhatos@gmail.com</td>\n",
       "      <td>Genome-wide prediction of topoisomerase IIβ bi...</td>\n",
       "      <td>Martínez-García PM, García-Torres M, Divina F,...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.1371/journal.pcbi.1007814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/28/2022 0:44:11</td>\n",
       "      <td>33679869</td>\n",
       "      <td>Front Genet.</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>public databases: 901 samples from The Cancer ...</td>\n",
       "      <td>10-fold cross validation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no, they claim: \"Publicly available datasets w...</td>\n",
       "      <td>Spathial, Random forest, LASSO</td>\n",
       "      <td>...</td>\n",
       "      <td>10-fold cross validation</td>\n",
       "      <td>AUCs for 2-, 3-, and 5-year OS were 0.527, 0.5...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>andrewhatos@gmail.com</td>\n",
       "      <td>Construction and Comprehensive Analyses of a M...</td>\n",
       "      <td>Sun S, Fei K, Zhang G, Wang J, Yang Y, Guo W, ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.3389/fgene.2020.617174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/28/2022 16:40:10</td>\n",
       "      <td>34419924</td>\n",
       "      <td>EBioMedicine.</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>samples from Stanford Health Care and Stanford...</td>\n",
       "      <td>The final analysis included for discovery coho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conatact (hoganca@stanford.edu) is provided ri...</td>\n",
       "      <td>gradient boosted decision trees and random for...</td>\n",
       "      <td>...</td>\n",
       "      <td>novel experiments.</td>\n",
       "      <td>AUC, sensitivity, specificity</td>\n",
       "      <td>costeffective comare to PCR tests and could be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes, https://github.com/stanfordmlgroup/influe...</td>\n",
       "      <td>andrewhatos@gmail.com</td>\n",
       "      <td>Nasopharyngeal metabolomics and machine learni...</td>\n",
       "      <td>Hogan CA, Rajpurkar P, Sowrirajan H, Phillips ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.1016/j.ebiom.2021.103546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/29/2022 23:01:05</td>\n",
       "      <td>34112769</td>\n",
       "      <td>Nat Commun  .</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clinical data collected by the authors N_neg 3...</td>\n",
       "      <td>N_pos: Discovery 227 and Validation 77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All data included in this study is available u...</td>\n",
       "      <td>composite model  with several stepp with diffe...</td>\n",
       "      <td>...</td>\n",
       "      <td>independent dataset</td>\n",
       "      <td>Accuracy (94.81% for the C4 prediction model, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>andrewhatos@gmail.com</td>\n",
       "      <td>A new molecular classification to drive precis...</td>\n",
       "      <td>Soret P, Le Dantec C, Desvaux E, Foulquier N, ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.1038/s41467-021-23472-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/28/2022 12:23:43</td>\n",
       "      <td>32915751</td>\n",
       "      <td>IEEE J Biomed Health Inform.</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>two public COVID-19 CT datasets:   -   https:/...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>preprocessed data: https://drive.google.com/fi...</td>\n",
       "      <td>deep learning, novel approach</td>\n",
       "      <td>...</td>\n",
       "      <td>four-fold cross-validation</td>\n",
       "      <td>Accuracy, F1 score, Sensitivity, Precision, AUC</td>\n",
       "      <td>firstly comparision to COVID-Net method https:...</td>\n",
       "      <td>outperforming the original COVID-Net trained o...</td>\n",
       "      <td>no</td>\n",
       "      <td>andrewhatos@gmail.com</td>\n",
       "      <td>Contrastive Cross-Site Learning With Redesigne...</td>\n",
       "      <td>Wang Z, Liu Q, Dou Q.</td>\n",
       "      <td>2020</td>\n",
       "      <td>10.1109/jbhi.2020.3023246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Informazioni cronologiche      PMID                   Journal name  \\\n",
       "0        3/23/2022 16:36:18  33465072              PLoS Comput Biol.   \n",
       "1         3/28/2022 0:44:11  33679869                   Front Genet.   \n",
       "2        3/28/2022 16:40:10  34419924                  EBioMedicine.   \n",
       "3        3/29/2022 23:01:05  34112769                  Nat Commun  .   \n",
       "4        3/28/2022 12:23:43  32915751   IEEE J Biomed Health Inform.   \n",
       "\n",
       "   Publication year  DOME version  \\\n",
       "0              2021           1.0   \n",
       "1              2021           1.0   \n",
       "2              2021           1.0   \n",
       "3              2021           1.0   \n",
       "4              2020           1.0   \n",
       "\n",
       "                                          Provenance  \\\n",
       "0                    yes, N_pos: 13128  N_neg: 32766   \n",
       "1  public databases: 901 samples from The Cancer ...   \n",
       "2  samples from Stanford Health Care and Stanford...   \n",
       "3  Clinical data collected by the authors N_neg 3...   \n",
       "4  two public COVID-19 CT datasets:   -   https:/...   \n",
       "\n",
       "                                      Dataset splits  \\\n",
       "0                            5-fold cross-validation   \n",
       "1                           10-fold cross validation   \n",
       "2  The final analysis included for discovery coho...   \n",
       "3             N_pos: Discovery 227 and Validation 77   \n",
       "4                                                 no   \n",
       "\n",
       "           Redundancy between data splits  \\\n",
       "0  Correlation Feature Selection is used.   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                      no   \n",
       "\n",
       "                                Availability of data  \\\n",
       "0  yes, described at S1 table: https://deposition...   \n",
       "1  no, they claim: \"Publicly available datasets w...   \n",
       "2  Conatact (hoganca@stanford.edu) is provided ri...   \n",
       "3  All data included in this study is available u...   \n",
       "4  preprocessed data: https://drive.google.com/fi...   \n",
       "\n",
       "                                           Algorithm  ...  \\\n",
       "0                   Naive Bayes, SVM, Random Forests  ...   \n",
       "1                     Spathial, Random forest, LASSO  ...   \n",
       "2  gradient boosted decision trees and random for...  ...   \n",
       "3  composite model  with several stepp with diffe...  ...   \n",
       "4                      deep learning, novel approach  ...   \n",
       "\n",
       "            Evaluation method  \\\n",
       "0     5-fold cross validation   \n",
       "1    10-fold cross validation   \n",
       "2          novel experiments.   \n",
       "3        independent dataset    \n",
       "4  four-fold cross-validation   \n",
       "\n",
       "                               Performance measures   \\\n",
       "0                         ROC  curves and AUC values   \n",
       "1  AUCs for 2-, 3-, and 5-year OS were 0.527, 0.5...   \n",
       "2                      AUC, sensitivity, specificity   \n",
       "3  Accuracy (94.81% for the C4 prediction model, ...   \n",
       "4    Accuracy, F1 score, Sensitivity, Precision, AUC   \n",
       "\n",
       "                                          Comparison  \\\n",
       "0                                                NaN   \n",
       "1                                                 no   \n",
       "2  costeffective comare to PCR tests and could be...   \n",
       "3                                                 no   \n",
       "4  firstly comparision to COVID-Net method https:...   \n",
       "\n",
       "                                          Confidence  \\\n",
       "0                                                NaN   \n",
       "1                                                no    \n",
       "2                                                NaN   \n",
       "3                                                 no   \n",
       "4  outperforming the original COVID-Net trained o...   \n",
       "\n",
       "                          Availability of evaluation        Indirizzo email  \\\n",
       "0                                                NaN  andrewhatos@gmail.com   \n",
       "1                                                 no  andrewhatos@gmail.com   \n",
       "2  yes, https://github.com/stanfordmlgroup/influe...  andrewhatos@gmail.com   \n",
       "3                                                 no  andrewhatos@gmail.com   \n",
       "4                                                 no  andrewhatos@gmail.com   \n",
       "\n",
       "                                          EPMC_title  \\\n",
       "0  Genome-wide prediction of topoisomerase IIβ bi...   \n",
       "1  Construction and Comprehensive Analyses of a M...   \n",
       "2  Nasopharyngeal metabolomics and machine learni...   \n",
       "3  A new molecular classification to drive precis...   \n",
       "4  Contrastive Cross-Site Learning With Redesigne...   \n",
       "\n",
       "                                        EPMC_authors EPMC_pub_year  \\\n",
       "0  Martínez-García PM, García-Torres M, Divina F,...          2021   \n",
       "1  Sun S, Fei K, Zhang G, Wang J, Yang Y, Guo W, ...          2020   \n",
       "2  Hogan CA, Rajpurkar P, Sowrirajan H, Phillips ...          2021   \n",
       "3  Soret P, Le Dantec C, Desvaux E, Foulquier N, ...          2021   \n",
       "4                              Wang Z, Liu Q, Dou Q.          2020   \n",
       "\n",
       "                       EPMC_doi  \n",
       "0  10.1371/journal.pcbi.1007814  \n",
       "1     10.3389/fgene.2020.617174  \n",
       "2   10.1016/j.ebiom.2021.103546  \n",
       "3    10.1038/s41467-021-23472-7  \n",
       "4     10.1109/jbhi.2020.3023246  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_epmc_metadata(pmid):\n",
    "    \"\"\"\n",
    "    Fetches Title, Authors, PubYear, and DOI from Europe PMC API for a given PMID.\n",
    "    \"\"\"\n",
    "    if not pmid or str(pmid) == 'nan':\n",
    "        return None, None, None, None\n",
    "        \n",
    "    url = \"https://www.ebi.ac.uk/europepmc/webservices/rest/search\"\n",
    "    params = {\n",
    "        'query': f'EXT_ID:{pmid} SRC:MED',\n",
    "        'format': 'json',\n",
    "        'resultType': 'core'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        result_list = data.get('resultList', {}).get('result', [])\n",
    "        \n",
    "        if result_list:\n",
    "            top_result = result_list[0]\n",
    "            title = top_result.get('title', '')\n",
    "            authors = top_result.get('authorString', '')\n",
    "            pub_year = top_result.get('pubYear', '')\n",
    "            doi = top_result.get('doi', '')\n",
    "            return title, authors, pub_year, doi\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching PMID {pmid}: {e}\")\n",
    "        \n",
    "    return None, None, None, None\n",
    "\n",
    "# Load the TSV\n",
    "tsv_file = \"Dome-Recommendations-Annotated-Articles_20250202.tsv\"\n",
    "print(f\"Loading {tsv_file}...\")\n",
    "df_recs = pd.read_csv(tsv_file, sep='\\t')\n",
    "\n",
    "# Ensure columns exist\n",
    "new_cols = ['EPMC_title', 'EPMC_authors', 'EPMC_pub_year', 'EPMC_doi']\n",
    "for col in new_cols:\n",
    "    if col not in df_recs.columns:\n",
    "        df_recs[col] = None\n",
    "\n",
    "# Iterate and Enrich\n",
    "print(\"Enriching data with Europe PMC API...\")\n",
    "total = len(df_recs)\n",
    "\n",
    "for index, row in df_recs.iterrows():\n",
    "    pmid = row.get('PMID')\n",
    "    \n",
    "    # Skip if already filled (optional, but good for retries)\n",
    "    # or if PMID is missing\n",
    "    if pd.isna(pmid):\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing {index + 1}/{total}: PMID {pmid}\", end='\\r')\n",
    "    \n",
    "    title, authors, year, doi = fetch_epmc_metadata(pmid)\n",
    "    \n",
    "    df_recs.at[index, 'EPMC_title'] = title\n",
    "    df_recs.at[index, 'EPMC_authors'] = authors\n",
    "    df_recs.at[index, 'EPMC_pub_year'] = year\n",
    "    df_recs.at[index, 'EPMC_doi'] = doi\n",
    "    \n",
    "    # Be nice to the API\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"\\nEnrichment complete.\")\n",
    "df_recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99f7e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading users from dome_users_20260202.json...\n",
      "User OIDs mapped successfully.\n",
      "Saved enriched data with User OIDs to Dome-Recommendations-Annotated-Articles_20250202_Enriched.tsv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Integrate User OIDs\n",
    "users_file = \"dome_users_20260202.json\"\n",
    "try:\n",
    "    print(f\"Loading users from {users_file}...\")\n",
    "    with open(users_file, 'r', encoding='utf-8') as f:\n",
    "        users_data = json.load(f)\n",
    "        \n",
    "    # Create Email -> OID mapping\n",
    "    email_to_oid = {}\n",
    "    for u in users_data:\n",
    "        email = u.get('email')\n",
    "        oid = u.get('_id', {}).get('$oid')\n",
    "        if email and oid:\n",
    "            email_to_oid[email.strip()] = oid\n",
    "            \n",
    "    # Apply to DataFrame\n",
    "    # Target column is 'Indirizzo email' based on file inspection\n",
    "    if 'Indirizzo email' in df_recs.columns:\n",
    "        df_recs['User_OID'] = df_recs['Indirizzo email'].apply(lambda x: email_to_oid.get(str(x).strip(), 'Unknown'))\n",
    "        print(\"User OIDs mapped successfully.\")\n",
    "    else:\n",
    "        print(\"Warning: 'Indirizzo email' column not found in TSV.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error mapping users: {e}\")\n",
    "\n",
    "# 2. Reorder columns (EPMC info after PMID)\n",
    "cols = list(df_recs.columns)\n",
    "if 'PMID' in cols:\n",
    "    pmid_idx = cols.index('PMID')\n",
    "    \n",
    "    # Remove EPMC cols if they are in the list currently\n",
    "    active_new_cols = [c for c in new_cols if c in cols]\n",
    "    for col in active_new_cols:\n",
    "        cols.remove(col)\n",
    "        \n",
    "    # Insert them back after PMID\n",
    "    for i, col in enumerate(active_new_cols):\n",
    "        cols.insert(pmid_idx + 1 + i, col)\n",
    "        \n",
    "    df_recs = df_recs[cols]\n",
    "\n",
    "# 3. Save (Overwriting/Creating the single enriched file)\n",
    "output_file = \"Dome-Recommendations-Annotated-Articles_20250202_Enriched.tsv\"\n",
    "df_recs.to_csv(output_file, sep='\\t', index=False)\n",
    "print(f\"Saved enriched data with User OIDs to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4ee62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming TSV columns to match DOME JSON schema...\n",
      "Detected 45 standard schema keys from JSON.\n",
      "Dropping 11 unwanted columns: ['optimization/done', 'publication/skip', 'publication/done', 'evaluation/done', 'dataset/done', 'model/done', 'optimization/skip', 'evaluation/skip', 'dataset/skip', 'model/skip', 'DOME version']\n",
      "Saved schema-aligned file to v1_Dome-Recommendations-Schema_Aligned.tsv\n",
      "Columns: ['timestamp', 'PMID', 'EPMC_title', 'EPMC_authors', 'EPMC_pub_year', 'EPMC_doi', 'publication/journal', 'publication/year', 'dataset/provenance', 'dataset/splits', 'dataset/redundancy', 'dataset/availability', 'optimization/algorithm', 'optimization/meta', 'optimization/encoding', 'optimization/parameters', 'optimization/features', 'optimization/fitting', 'optimization/regularization', 'Availability of  configuration', 'model/interpretability', 'model/output', 'Execution time ', 'model/availability', 'evaluation/method', 'Performance measures ', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/availability', 'user_email', 'User_OID', 'publication/doi', 'reviewState', 'model/duration', 'optimization/config', 'publication/authors', 'update', 'publication/pmid', 'score', 'uuid', 'publication/title', 'publication/updated', 'evaluation/measure', 'publication/tags', 'public', 'shortid']\n"
     ]
    }
   ],
   "source": [
    "# 4. Standardize Column Names and Sync with JSON Schema\n",
    "\n",
    "raw_reviews_file = \"dome_review_raw_human_20260202.json\"\n",
    "\n",
    "# Known TSV -> DOME JSON Key Mapping\n",
    "# Based on the TSV headers provided and DOME schema conventions\n",
    "column_map = {\n",
    "    'Journal name': 'publication/journal',\n",
    "    'Publication year': 'publication/year',\n",
    "    \n",
    "    'Provenance': 'dataset/provenance',\n",
    "    'Dataset splits': 'dataset/splits',\n",
    "    'Redundancy between data splits': 'dataset/redundancy',\n",
    "    'Availability of data': 'dataset/availability',\n",
    "    \n",
    "    'Algorithm': 'optimization/algorithm',\n",
    "    'Meta-predictions': 'optimization/meta',\n",
    "    'Data encoding': 'optimization/encoding',\n",
    "    'Parameters': 'optimization/parameters',\n",
    "    'Features': 'optimization/features',\n",
    "    'Fitting': 'optimization/fitting',\n",
    "    'Regularization': 'optimization/regularization',\n",
    "    'Availability of configuration': 'optimization/config',\n",
    "    \n",
    "    'Interpretability': 'model/interpretability',\n",
    "    'Output': 'model/output',\n",
    "    'Execution time': 'model/duration',\n",
    "    'Availability of software': 'model/availability',\n",
    "    \n",
    "    'Evaluation method': 'evaluation/method',\n",
    "    'Performance measures': 'evaluation/measure',\n",
    "    'Comparison': 'evaluation/comparison',\n",
    "    'Confidence': 'evaluation/confidence',\n",
    "    'Availability of evaluation': 'evaluation/availability',\n",
    "    \n",
    "    # Metadata/Extra\n",
    "    'Informazioni cronologiche': 'timestamp',\n",
    "    'Indirizzo email': 'user_email'\n",
    "}\n",
    "\n",
    "# 1. Rename Columns\n",
    "print(\"Renaming TSV columns to match DOME JSON schema...\")\n",
    "df_recs.rename(columns=column_map, inplace=True)\n",
    "\n",
    "# 2. Extract Full Schema from JSON\n",
    "# We flatten the keys from the first few records to get a list of all possible \"section/field\" keys\n",
    "all_json_keys = set()\n",
    "try:\n",
    "    with open(raw_reviews_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    for entry in data[:10]: # Check first 10 to cover bases\n",
    "        for section, content in entry.items():\n",
    "            if isinstance(content, dict):\n",
    "                for field in content.keys():\n",
    "                    if not field.startswith('$'): # Skip mongo internal keys\n",
    "                        all_json_keys.add(f\"{section}/{field}\")\n",
    "            else:\n",
    "                if not section.startswith('_'):\n",
    "                    all_json_keys.add(section)\n",
    "                    \n",
    "    print(f\"Detected {len(all_json_keys)} standard schema keys from JSON.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading JSON schema: {e}\")\n",
    "    # Fallback default keys if file read fails\n",
    "    all_json_keys = {\n",
    "        'publication/title', 'publication/authors', 'publication/doi', 'publication/year', 'publication/journal',\n",
    "        'publication/tags',\n",
    "        'dataset/provenance', 'dataset/splits', 'dataset/redundancy', 'dataset/availability',\n",
    "        'optimization/algorithm', 'optimization/meta', 'optimization/encoding', 'optimization/parameters', \n",
    "        'optimization/features', 'optimization/fitting', 'optimization/regularization', 'optimization/config',\n",
    "        'model/interpretability', 'model/output', 'model/duration', 'model/availability',\n",
    "        'evaluation/method', 'evaluation/measure', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/availability'\n",
    "    }\n",
    "\n",
    "# 3. Add Missing Schema Columns\n",
    "for key in all_json_keys:\n",
    "    if key not in df_recs.columns:\n",
    "        df_recs[key] = None # Add as empty\n",
    "\n",
    "# 4. Remove unwanted columns\n",
    "# Filter for exact columns ending in '/done' or '/skip'\n",
    "cols_to_drop = [c for c in df_recs.columns if c.endswith('/skip') or c.endswith('/done')]\n",
    "\n",
    "if 'DOME version' in df_recs.columns:\n",
    "    cols_to_drop.append('DOME version')\n",
    "\n",
    "if cols_to_drop:\n",
    "    print(f\"Dropping {len(cols_to_drop)} unwanted columns: {cols_to_drop}\")\n",
    "    df_recs.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Re-Save with Version prefix\n",
    "output_file_schema = \"v1_Dome-Recommendations-Schema_Aligned.tsv\"\n",
    "df_recs.to_csv(output_file_schema, sep='\\t', index=False)\n",
    "print(f\"Saved schema-aligned file to {output_file_schema}\")\n",
    "print(\"Columns:\", list(df_recs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f40d65f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging EPMC data into main schema columns...\n",
      "Merged EPMC_title -> publication/title\n",
      "Merged EPMC_authors -> publication/authors\n",
      "Merged EPMC_doi -> publication/doi\n",
      "Dropped source columns: ['EPMC_title', 'EPMC_authors', 'EPMC_doi']\n",
      "Saved final merged file to v4_Dome-Recommendations-Final_Merged.tsv\n",
      "Final Column Order: ['user_email', 'User_OID', 'timestamp', 'PMID', 'publication/title', 'publication/authors', 'publication/journal', 'publication/year', 'EPMC_pub_year', 'publication/doi', 'publication/tags', 'dataset/provenance', 'dataset/splits', 'dataset/redundancy', 'dataset/availability', 'optimization/algorithm', 'optimization/meta', 'optimization/encoding', 'optimization/parameters', 'optimization/features', 'optimization/fitting', 'optimization/regularization', 'optimization/config', 'model/interpretability', 'model/output', 'model/duration', 'model/availability', 'evaluation/method', 'evaluation/measure', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/availability', 'Availability of  configuration', 'Execution time ', 'Performance measures ', 'reviewState', 'update', 'publication/pmid', 'score', 'uuid', 'publication/updated', 'public', 'shortid']\n"
     ]
    }
   ],
   "source": [
    "# 5. Merge EPMC Data and Finalize Order\n",
    "\n",
    "print(\"Merging EPMC data into main schema columns...\")\n",
    "\n",
    "# List of merge pairs: (Source, Target)\n",
    "merge_pairs = [\n",
    "    ('EPMC_title', 'publication/title'),\n",
    "    ('EPMC_authors', 'publication/authors'),\n",
    "    ('EPMC_doi', 'publication/doi')\n",
    "]\n",
    "\n",
    "for src, tgt in merge_pairs:\n",
    "    if src in df_recs.columns and tgt in df_recs.columns:\n",
    "        # Use EPMC data to fill/overwrite\n",
    "        # If you only want to fill missing values, use .fillna() instead\n",
    "        # Here we overwrite as per instructions which implies using the fetched data\n",
    "        df_recs[tgt] = df_recs[src]\n",
    "        print(f\"Merged {src} -> {tgt}\")\n",
    "    else:\n",
    "        print(f\"Skipping merge {src} -> {tgt} (Column missing)\")\n",
    "\n",
    "# Cleanup: Drop the temporary EPMC columns that were merged\n",
    "cols_to_drop = [src for src, tgt in merge_pairs]\n",
    "df_recs.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "print(f\"Dropped source columns: {cols_to_drop}\")\n",
    "\n",
    "\n",
    "# Define the canonical field order based on DOME JSON structure\n",
    "field_order = [\n",
    "    # Metadata (Note: EPMC columns removed/moved)\n",
    "    'user_email', 'User_OID', 'timestamp', 'PMID',\n",
    "    \n",
    "    # Publication\n",
    "    'publication/title', \n",
    "    'publication/authors', \n",
    "    'publication/journal', \n",
    "    'publication/year', \n",
    "    'EPMC_pub_year', # Moved here for ordering\n",
    "    'publication/doi',\n",
    "    'publication/tags',\n",
    "    \n",
    "    # Dataset\n",
    "    'dataset/provenance', \n",
    "    'dataset/splits', \n",
    "    'dataset/redundancy', \n",
    "    'dataset/availability',\n",
    "    \n",
    "    # Optimization\n",
    "    'optimization/algorithm', \n",
    "    'optimization/meta', \n",
    "    'optimization/encoding', \n",
    "    'optimization/parameters', \n",
    "    'optimization/features', \n",
    "    'optimization/fitting', \n",
    "    'optimization/regularization', \n",
    "    'optimization/config',\n",
    "    \n",
    "    # Model\n",
    "    'model/interpretability', \n",
    "    'model/output', \n",
    "    'model/duration', \n",
    "    'model/availability',\n",
    "    \n",
    "    # Evaluation\n",
    "    'evaluation/method', \n",
    "    'evaluation/measure', \n",
    "    'evaluation/comparison', \n",
    "    'evaluation/confidence', \n",
    "    'evaluation/availability'\n",
    "]\n",
    "\n",
    "# Append any remaining columns that weren't explicitly ordered (just in case)\n",
    "for col in df_recs.columns:\n",
    "    if col not in field_order:\n",
    "        field_order.append(col)\n",
    "\n",
    "# Reindex the DataFrame\n",
    "final_cols = [c for c in field_order if c in df_recs.columns]\n",
    "df_recs = df_recs[final_cols]\n",
    "\n",
    "# Final Save\n",
    "output_file_final = \"v4_Dome-Recommendations-Final_Merged.tsv\"\n",
    "df_recs.to_csv(output_file_final, sep='\\t', index=False)\n",
    "print(f\"Saved final merged file to {output_file_final}\")\n",
    "print(\"Final Column Order:\", list(df_recs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c938ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing ID and Timestamp columns...\n",
      "Dropping placeholder 'publication/pmid' column...\n",
      "Renaming 'PMID' -> 'publication/pmid'...\n",
      "Dropping placeholder 'update' column...\n",
      "Renaming 'timestamp' -> 'update'...\n",
      "Saved standardized data to v5_Dome-Recommendations-Standardized_Columns.tsv\n",
      "Current Columns: ['user_email', 'User_OID', 'update', 'publication/pmid', 'publication/title', 'publication/authors', 'publication/journal', 'publication/year', 'EPMC_pub_year', 'publication/doi', 'publication/tags', 'dataset/provenance', 'dataset/splits', 'dataset/redundancy', 'dataset/availability', 'optimization/algorithm', 'optimization/meta', 'optimization/encoding', 'optimization/parameters', 'optimization/features', 'optimization/fitting', 'optimization/regularization', 'optimization/config', 'model/interpretability', 'model/output', 'model/duration', 'model/availability', 'evaluation/method', 'evaluation/measure', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/availability', 'Availability of  configuration', 'Execution time ', 'Performance measures ', 'reviewState', 'score', 'uuid', 'publication/updated', 'public', 'shortid']\n"
     ]
    }
   ],
   "source": [
    "# 6. Standardization: Map Legacy IDs and Timestamps\n",
    "\n",
    "print(\"Standardizing ID and Timestamp columns...\")\n",
    "\n",
    "# Check current columns to avoid errors\n",
    "cols = df_recs.columns\n",
    "\n",
    "# 1. Handle PMID -> publication/pmid\n",
    "# Drop the empty placeholder column if it exists\n",
    "if 'publication/pmid' in cols:\n",
    "    print(\"Dropping placeholder 'publication/pmid' column...\")\n",
    "    df_recs.drop(columns=['publication/pmid'], inplace=True)\n",
    "\n",
    "# Rename the actual data column\n",
    "if 'PMID' in cols:\n",
    "    print(\"Renaming 'PMID' -> 'publication/pmid'...\")\n",
    "    df_recs.rename(columns={'PMID': 'publication/pmid'}, inplace=True)\n",
    "else:\n",
    "    print(\"Warning: 'PMID' column not found.\")\n",
    "\n",
    "# 2. Handle timestamp -> update\n",
    "# Drop the empty placeholder column if it exists\n",
    "if 'update' in cols:\n",
    "    print(\"Dropping placeholder 'update' column...\")\n",
    "    df_recs.drop(columns=['update'], inplace=True)\n",
    "\n",
    "# Rename the actual data column\n",
    "if 'timestamp' in cols:\n",
    "    print(\"Renaming 'timestamp' -> 'update'...\")\n",
    "    df_recs.rename(columns={'timestamp': 'update'}, inplace=True)\n",
    "else:\n",
    "    print(\"Warning: 'timestamp' column not found.\")\n",
    "\n",
    "# Save Version 5 (stacking on previous v4)\n",
    "output_file_v5 = \"v5_Dome-Recommendations-Standardized_Columns.tsv\"\n",
    "df_recs.to_csv(output_file_v5, sep='\\t', index=False)\n",
    "print(f\"Saved standardized data to {output_file_v5}\")\n",
    "print(\"Current Columns:\", list(df_recs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f486371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migrating legacy data to schema columns...\n",
      "Migrating 'Availability of  configuration' -> 'optimization/config'...\n",
      "Dropped legacy column 'Availability of  configuration'\n",
      "Migrating 'Execution time ' -> 'model/duration'...\n",
      "Dropped legacy column 'Execution time '\n",
      "Migrating 'Performance measures ' -> 'evaluation/measure'...\n",
      "Dropped legacy column 'Performance measures '\n",
      "Saved migrated data to v6_Dome-Recommendations-Migrated_Legacy_Data.tsv\n",
      "Current Columns: ['user_email', 'User_OID', 'update', 'publication/pmid', 'publication/title', 'publication/authors', 'publication/journal', 'publication/year', 'EPMC_pub_year', 'publication/doi', 'publication/tags', 'dataset/provenance', 'dataset/splits', 'dataset/redundancy', 'dataset/availability', 'optimization/algorithm', 'optimization/meta', 'optimization/encoding', 'optimization/parameters', 'optimization/features', 'optimization/fitting', 'optimization/regularization', 'optimization/config', 'model/interpretability', 'model/output', 'model/duration', 'model/availability', 'evaluation/method', 'evaluation/measure', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/availability', 'reviewState', 'score', 'uuid', 'publication/updated', 'public', 'shortid']\n"
     ]
    }
   ],
   "source": [
    "# 7. Standardization: Data Migration for Config, Duration, and Measure\n",
    "\n",
    "print(\"Migrating legacy data to schema columns...\")\n",
    "\n",
    "# List of migration mappings: (Legacy Source Column, Target Schema Column)\n",
    "# precise names taken from dataframe columns\n",
    "migration_map = [\n",
    "    ('Availability of  configuration', 'optimization/config'),\n",
    "    ('Execution time ', 'model/duration'),\n",
    "    ('Performance measures ', 'evaluation/measure')\n",
    "]\n",
    "\n",
    "for legacy_col, target_col in migration_map:\n",
    "    # Ensure source exists\n",
    "    if legacy_col in df_recs.columns:\n",
    "        # We want to fill the target with legacy data. \n",
    "        # If target exists, we overwrite. If not, we rename (less likely if schema enforced, but safe).\n",
    "        if target_col in df_recs.columns:\n",
    "            print(f\"Migrating '{legacy_col}' -> '{target_col}'...\")\n",
    "            df_recs[target_col] = df_recs[legacy_col]\n",
    "            \n",
    "            # Drop the legacy column\n",
    "            df_recs.drop(columns=[legacy_col], inplace=True)\n",
    "            print(f\"Dropped legacy column '{legacy_col}'\")\n",
    "        else:\n",
    "             print(f\"Target column '{target_col}' missing. Renaming '{legacy_col}' to '{target_col}'.\")\n",
    "             df_recs.rename(columns={legacy_col: target_col}, inplace=True)\n",
    "    else:\n",
    "        print(f\"Legacy column '{legacy_col}' not found in dataframe.\")\n",
    "\n",
    "# Save Version 6\n",
    "output_file_v6 = \"v6_Dome-Recommendations-Migrated_Legacy_Data.tsv\"\n",
    "df_recs.to_csv(output_file_v6, sep='\\t', index=False)\n",
    "print(f\"Saved migrated data to {output_file_v6}\")\n",
    "print(\"Current Columns:\", list(df_recs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c99c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enforcing final schema order (restoring missing empty columns)...\n",
      "Preserving extra columns: ['reviewState', 'score', 'uuid', 'publication/updated', 'public', 'shortid']\n",
      "Saved final ordered data to v7_Dome-Recommendations-Final_Schema_Ordered.tsv\n",
      "Final Columns: ['user_email', 'User_OID', 'update', 'publication/pmid', 'publication/title', 'publication/authors', 'publication/journal', 'publication/year', 'EPMC_pub_year', 'publication/doi', 'publication/tags', 'dataset/provenance', 'dataset/splits', 'dataset/redundancy', 'dataset/availability', 'optimization/algorithm', 'optimization/meta', 'optimization/encoding', 'optimization/parameters', 'optimization/features', 'optimization/fitting', 'optimization/regularization', 'optimization/config', 'model/interpretability', 'model/output', 'model/duration', 'model/availability', 'evaluation/method', 'evaluation/measure', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/availability', 'reviewState', 'score', 'uuid', 'publication/updated', 'public', 'shortid']\n"
     ]
    }
   ],
   "source": [
    "# 8. Standardization: Enforce Final Schema Order\n",
    "\n",
    "print(\"Enforcing final schema order (restoring missing empty columns)...\")\n",
    "\n",
    "# Define the definitive desired order (updating names to current versions)\n",
    "target_schema_order = [\n",
    "    # Metadata\n",
    "    'user_email', 'User_OID', 'update', 'publication/pmid',\n",
    "    \n",
    "    # Publication\n",
    "    'publication/title', \n",
    "    'publication/authors', \n",
    "    'publication/journal', \n",
    "    'publication/year', \n",
    "    'EPMC_pub_year', \n",
    "    'publication/doi',\n",
    "    'publication/tags',\n",
    "    \n",
    "    # Dataset\n",
    "    'dataset/provenance', \n",
    "    'dataset/splits', \n",
    "    'dataset/redundancy', \n",
    "    'dataset/availability',\n",
    "    \n",
    "    # Optimization\n",
    "    'optimization/algorithm', \n",
    "    'optimization/meta', \n",
    "    'optimization/encoding', \n",
    "    'optimization/parameters', \n",
    "    'optimization/features', \n",
    "    'optimization/fitting', \n",
    "    'optimization/regularization', \n",
    "    'optimization/config',\n",
    "    \n",
    "    # Model\n",
    "    'model/interpretability', \n",
    "    'model/output', \n",
    "    'model/duration', \n",
    "    'model/availability',\n",
    "    \n",
    "    # Evaluation\n",
    "    'evaluation/method', \n",
    "    'evaluation/measure', \n",
    "    'evaluation/comparison', \n",
    "    'evaluation/confidence', \n",
    "    'evaluation/availability'\n",
    "]\n",
    "\n",
    "# 1. Add missing columns from schema as empty\n",
    "for col in target_schema_order:\n",
    "    if col not in df_recs.columns:\n",
    "        print(f\"Adding missing schema column: {col}\")\n",
    "        df_recs[col] = None  # Add empty column\n",
    "\n",
    "# 2. Reorder columns\n",
    "# Identify any extra columns in dataframe not in schema to append at end\n",
    "extra_cols = [c for c in df_recs.columns if c not in target_schema_order]\n",
    "if extra_cols:\n",
    "    print(f\"Preserving extra columns: {extra_cols}\")\n",
    "\n",
    "# Create final ordering\n",
    "final_order = target_schema_order + extra_cols\n",
    "df_recs = df_recs[final_order]\n",
    "\n",
    "# Save Version 7\n",
    "output_file_v7 = \"v7_Dome-Recommendations-Final_Schema_Ordered.tsv\"\n",
    "df_recs.to_csv(output_file_v7, sep='\\t', index=False)\n",
    "print(f\"Saved final ordered data to {output_file_v7}\")\n",
    "print(\"Final Columns:\", list(df_recs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54abafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying final column reordering...\n",
      "Appending remaining columns: ['score']\n",
      "Saved reordered data to v8_Dome-Recommendations-System_Cols_Reordered.tsv\n",
      "Final Columns: ['public', 'shortid', 'uuid', 'reviewState', 'user_email', 'User_OID', 'update', 'publication/pmid', 'publication/title', 'publication/authors', 'publication/journal', 'publication/year', 'EPMC_pub_year', 'publication/doi', 'publication/updated', 'publication/tags', 'dataset/provenance', 'dataset/splits', 'dataset/redundancy', 'dataset/availability', 'optimization/algorithm', 'optimization/meta', 'optimization/encoding', 'optimization/parameters', 'optimization/features', 'optimization/fitting', 'optimization/regularization', 'optimization/config', 'model/interpretability', 'model/output', 'model/duration', 'model/availability', 'evaluation/method', 'evaluation/measure', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/availability', 'score']\n"
     ]
    }
   ],
   "source": [
    "# 9. Standardization: Final Reordering (System Columns & Publication Update)\n",
    "\n",
    "print(\"Applying final column reordering...\")\n",
    "\n",
    "# Define the precise final order\n",
    "final_reorder = [\n",
    "    # System Columns (Moved to start)\n",
    "    'public', 'shortid', 'uuid', 'reviewState',\n",
    "    \n",
    "    # Metadata\n",
    "    'user_email', 'User_OID', 'update', 'publication/pmid',\n",
    "    \n",
    "    # Publication\n",
    "    'publication/title', \n",
    "    'publication/authors', \n",
    "    'publication/journal', \n",
    "    'publication/year', \n",
    "    'EPMC_pub_year', \n",
    "    'publication/doi',\n",
    "    'publication/updated', # Moved/Added here\n",
    "    'publication/tags',\n",
    "    \n",
    "    # Dataset\n",
    "    'dataset/provenance', \n",
    "    'dataset/splits', \n",
    "    'dataset/redundancy', \n",
    "    'dataset/availability',\n",
    "    \n",
    "    # Optimization\n",
    "    'optimization/algorithm', \n",
    "    'optimization/meta', \n",
    "    'optimization/encoding', \n",
    "    'optimization/parameters', \n",
    "    'optimization/features', \n",
    "    'optimization/fitting', \n",
    "    'optimization/regularization', \n",
    "    'optimization/config',\n",
    "    \n",
    "    # Model\n",
    "    'model/interpretability', \n",
    "    'model/output', \n",
    "    'model/duration', \n",
    "    'model/availability',\n",
    "    \n",
    "    # Evaluation\n",
    "    'evaluation/method', \n",
    "    'evaluation/measure', \n",
    "    'evaluation/comparison', \n",
    "    'evaluation/confidence', \n",
    "    'evaluation/availability'\n",
    "]\n",
    "\n",
    "# Ensure publication/updated exists\n",
    "if 'publication/updated' not in df_recs.columns:\n",
    "    print(\"Adding missing 'publication/updated' column...\")\n",
    "    df_recs['publication/updated'] = None\n",
    "\n",
    "# Reorder\n",
    "# Check for any remaining columns not in our explicit list to append at the end\n",
    "current_cols = df_recs.columns.tolist()\n",
    "remaining_cols = [c for c in current_cols if c not in final_reorder]\n",
    "\n",
    "if remaining_cols:\n",
    "    print(f\"Appending remaining columns: {remaining_cols}\")\n",
    "\n",
    "# Construct final list\n",
    "full_order = final_reorder + remaining_cols\n",
    "\n",
    "# Filter to ensure we don't ask for columns that don't exist (though we expect them to)\n",
    "# effectively reindexing\n",
    "df_recs = df_recs.reindex(columns=full_order)\n",
    "\n",
    "# Save Version 8\n",
    "output_file_v8 = \"v8_Dome-Recommendations-System_Cols_Reordered.tsv\"\n",
    "df_recs.to_csv(output_file_v8, sep='\\t', index=False)\n",
    "print(f\"Saved reordered data to {output_file_v8}\")\n",
    "print(\"Final Columns:\", list(df_recs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90bcc9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying STRICT final column reordering and validation...\n",
      "Added 14 missing columns empty to match schema: ['_id/$oid', 'dataset/done', 'dataset/skip', 'evaluation/done', 'evaluation/skip', 'model/done', 'model/skip', 'optimization/done', 'optimization/skip', 'user/$oid', 'publication/done', 'publication/skip', 'created/$date', 'updated/$date']\n",
      "Mapping User_OID -> user/$oid\n",
      "Warning: The following columns are present but NOT in the strict schema list and will be dropped: ['user_email', 'User_OID', 'EPMC_pub_year', 'score']\n",
      "Saved strict schema ordered data to v9_Dome-Recommendations-Strict_Schema_Ordered.tsv\n",
      "Final Columns: ['_id/$oid', 'dataset/availability', 'dataset/provenance', 'dataset/redundancy', 'dataset/splits', 'dataset/done', 'dataset/skip', 'evaluation/availability', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/measure', 'evaluation/method', 'evaluation/done', 'evaluation/skip', 'model/availability', 'model/duration', 'model/interpretability', 'model/output', 'model/done', 'model/skip', 'optimization/algorithm', 'optimization/config', 'optimization/encoding', 'optimization/features', 'optimization/fitting', 'optimization/meta', 'optimization/parameters', 'optimization/regularization', 'optimization/done', 'optimization/skip', 'user/$oid', 'publication/pmid', 'publication/updated', 'publication/authors', 'publication/journal', 'publication/title', 'publication/doi', 'publication/year', 'publication/done', 'publication/skip', 'publication/tags', 'public', 'created/$date', 'updated/$date', 'uuid', 'reviewState', 'shortid', 'update']\n"
     ]
    }
   ],
   "source": [
    "# 10. Standardization: Final Strict Schema Enforcement (Version 9)\n",
    "\n",
    "print(\"Applying STRICT final column reordering and validation...\")\n",
    "\n",
    "# The definitive DOME Schema Order\n",
    "strict_order = [\n",
    "    '_id/$oid',\n",
    "    'dataset/availability',\n",
    "    'dataset/provenance',\n",
    "    'dataset/redundancy',\n",
    "    'dataset/splits',\n",
    "    'dataset/done',\n",
    "    'dataset/skip',\n",
    "    'evaluation/availability',\n",
    "    'evaluation/comparison',\n",
    "    'evaluation/confidence',\n",
    "    'evaluation/measure',\n",
    "    'evaluation/method',\n",
    "    'evaluation/done',\n",
    "    'evaluation/skip',\n",
    "    'model/availability',\n",
    "    'model/duration',\n",
    "    'model/interpretability',\n",
    "    'model/output',\n",
    "    'model/done',\n",
    "    'model/skip',\n",
    "    'optimization/algorithm',\n",
    "    'optimization/config',\n",
    "    'optimization/encoding',\n",
    "    'optimization/features',\n",
    "    'optimization/fitting',\n",
    "    'optimization/meta',\n",
    "    'optimization/parameters',\n",
    "    'optimization/regularization',\n",
    "    'optimization/done',\n",
    "    'optimization/skip',\n",
    "    'user/$oid',\n",
    "    'publication/pmid',\n",
    "    'publication/updated',\n",
    "    'publication/authors',\n",
    "    'publication/journal',\n",
    "    'publication/title',\n",
    "    'publication/doi',\n",
    "    'publication/year',\n",
    "    'publication/done',\n",
    "    'publication/skip',\n",
    "    'publication/tags',\n",
    "    'public',\n",
    "    'created/$date',\n",
    "    'updated/$date',\n",
    "    'uuid',\n",
    "    'reviewState',\n",
    "    'shortid',\n",
    "    'update'\n",
    "]\n",
    "\n",
    "# Validation: Check for missing columns and add them\n",
    "missing_cols = []\n",
    "for col in strict_order:\n",
    "    if col not in df_recs.columns:\n",
    "        missing_cols.append(col)\n",
    "        df_recs[col] = None # Add missing column as empty\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Added {len(missing_cols)} missing columns empty to match schema: {missing_cols}\")\n",
    "\n",
    "# Validation checks on current dataframe\n",
    "# We will check if the columns exist (we just ensured they do) \n",
    "# and potentially map some of our intermediate names to these final names if needed.\n",
    "\n",
    "# Mappings based on prior steps:\n",
    "# User_OID -> user/$oid\n",
    "# user_email -> (drop or keep? assuming drop as not in strict list) but maybe user/$oid IS the user column?\n",
    "# Assuming User_OID from previous step maps to user/$oid\n",
    "\n",
    "if 'User_OID' in df_recs.columns:\n",
    "    print(\"Mapping User_OID -> user/$oid\")\n",
    "    df_recs['user/$oid'] = df_recs['User_OID']\n",
    "\n",
    "# Note: previous steps created 'update', 'publication/pmid', 'publication/updated' so those are good.\n",
    "\n",
    "# Apply the strict reorder\n",
    "# This drops any columns NOT in the strict_order list (unless we append them, but user asked to flag errors if order/columns don't match or add if missing, implying strict list)\n",
    "# \"if a column would be missing add the empty column ... If column does not match order flag errors\"\n",
    "\n",
    "current_cols = df_recs.columns.tolist()\n",
    "extra_cols_found = [c for c in current_cols if c not in strict_order]\n",
    "if extra_cols_found:\n",
    "    print(f\"Warning: The following columns are present but NOT in the strict schema list and will be dropped: {extra_cols_found}\")\n",
    "\n",
    "# Create Version 9 with strict order\n",
    "df_v9 = df_recs.reindex(columns=strict_order)\n",
    "\n",
    "# Save Version 9\n",
    "output_file_v9 = \"v9_Dome-Recommendations-Strict_Schema_Ordered.tsv\"\n",
    "df_v9.to_csv(output_file_v9, sep='\\t', index=False)\n",
    "print(f\"Saved strict schema ordered data to {output_file_v9}\")\n",
    "print(\"Final Columns:\", list(df_v9.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59c19364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 'publication/pmcid' column...\n",
      "Inserted 'publication/pmcid' after 'publication/pmid'\n",
      "Saved data with PMCID to v10_Dome-Recommendations-With_PMCID.tsv\n",
      "Final Columns: ['_id/$oid', 'dataset/availability', 'dataset/provenance', 'dataset/redundancy', 'dataset/splits', 'dataset/done', 'dataset/skip', 'evaluation/availability', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/measure', 'evaluation/method', 'evaluation/done', 'evaluation/skip', 'model/availability', 'model/duration', 'model/interpretability', 'model/output', 'model/done', 'model/skip', 'optimization/algorithm', 'optimization/config', 'optimization/encoding', 'optimization/features', 'optimization/fitting', 'optimization/meta', 'optimization/parameters', 'optimization/regularization', 'optimization/done', 'optimization/skip', 'user/$oid', 'publication/pmid', 'publication/pmcid', 'publication/updated', 'publication/authors', 'publication/journal', 'publication/title', 'publication/doi', 'publication/year', 'publication/done', 'publication/skip', 'publication/tags', 'public', 'created/$date', 'updated/$date', 'uuid', 'reviewState', 'shortid', 'update']\n"
     ]
    }
   ],
   "source": [
    "# 11. Standardization: Add PMCID Column (Version 10)\n",
    "\n",
    "print(\"Adding 'publication/pmcid' column...\")\n",
    "\n",
    "# Work with the latest dataframe\n",
    "df_final = df_v9.copy()\n",
    "\n",
    "# target position\n",
    "target_col = 'publication/pmid'\n",
    "new_col = 'publication/pmcid'\n",
    "\n",
    "if target_col in df_final.columns:\n",
    "    # Get index and add 1 to insert after\n",
    "    col_index = df_final.columns.get_loc(target_col) + 1\n",
    "    df_final.insert(col_index, new_col, None)\n",
    "    print(f\"Inserted '{new_col}' after '{target_col}'\")\n",
    "else:\n",
    "    print(f\"Target '{target_col}' not found, appending '{new_col}' at end.\")\n",
    "    df_final[new_col] = None\n",
    "\n",
    "# Save Version 10\n",
    "output_file_v10 = \"v10_Dome-Recommendations-With_PMCID.tsv\"\n",
    "df_final.to_csv(output_file_v10, sep='\\t', index=False)\n",
    "print(f\"Saved data with PMCID to {output_file_v10}\")\n",
    "print(\"Final Columns:\", list(df_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee523939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading v10_Dome-Recommendations-With_PMCID.tsv to extract PMIDs...\n",
      "Found 176 unique PMIDs to fetch.\n",
      "Fetching metadata from Europe PMC...\n",
      "Processing 176/176: 24977146\n",
      "Fetched data for 176 records.\n",
      "Saved EPMC source metadata to epmc_source_metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 12. Generate EPMC Source Metadata File\n",
    "\n",
    "input_v10_file = \"v10_Dome-Recommendations-With_PMCID.tsv\"\n",
    "output_epmc_file = \"epmc_source_metadata.tsv\"\n",
    "\n",
    "print(f\"Loading {input_v10_file} to extract PMIDs...\")\n",
    "try:\n",
    "    df_v10 = pd.read_csv(input_v10_file, sep='\\t')\n",
    "    # Convert to string, drop NA, get unique\n",
    "    pmids = df_v10['publication/pmid'].dropna().astype(str).unique()\n",
    "    # Filter out empty strings or non-numeric looking PMIDs if necessary, but API handles validation\n",
    "    pmids = [p for p in pmids if p.strip() and p != 'nan']\n",
    "    print(f\"Found {len(pmids)} unique PMIDs to fetch.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {input_v10_file} not found. Make sure previous block was run.\")\n",
    "    pmids = []\n",
    "\n",
    "def fetch_full_epmc_metadata(pmid):\n",
    "    \"\"\"\n",
    "    Fetches comprehensive metadata from Europe PMC.\n",
    "    \"\"\"\n",
    "    # Clean PMID (remove .0 if it was parsed as float)\n",
    "    pmid_str = str(pmid).replace('.0', '')\n",
    "    \n",
    "    url = \"https://www.ebi.ac.uk/europepmc/webservices/rest/search\"\n",
    "    query = f'EXT_ID:{pmid_str} SRC:MED'\n",
    "    params = {'query': query, 'format': 'json', 'resultType': 'core'}\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, params=params)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        result_list = data.get('resultList', {}).get('result', [])\n",
    "        \n",
    "        if not result_list:\n",
    "            return None\n",
    "            \n",
    "        item = result_list[0]\n",
    "        \n",
    "        # Extract Mesh Terms\n",
    "        mesh_list = item.get('meshHeadingList', {}).get('meshHeading', [])\n",
    "        mesh_terms = \"; \".join([m.get('descriptorName', '') for m in mesh_list])\n",
    "        \n",
    "        # Extract Keywords\n",
    "        kw_list = item.get('keywordList', {}).get('keyword', [])\n",
    "        keywords = \"; \".join(kw_list) if kw_list else \"\"\n",
    "        \n",
    "        return {\n",
    "            'publication/pmid': pmid_str,\n",
    "            'epmc_title': item.get('title'),\n",
    "            'epmc_authors': item.get('authorString'),\n",
    "            'epmc_journal': item.get('journalInfo', {}).get('journal', {}).get('title'),\n",
    "            'epmc_year': item.get('pubYear'),\n",
    "            'epmc_doi': item.get('doi'),\n",
    "            'epmc_pmcid': item.get('pmcid'),\n",
    "            'epmc_mesh': mesh_terms,\n",
    "            'epmc_keywords': keywords\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {pmid}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch Data\n",
    "if len(pmids) > 0:\n",
    "    epmc_data = []\n",
    "    print(\"Fetching metadata from Europe PMC...\")\n",
    "\n",
    "    for i, pmid in enumerate(pmids):\n",
    "        print(f\"Processing {i+1}/{len(pmids)}: {pmid}\", end='\\r')\n",
    "        meta = fetch_full_epmc_metadata(pmid)\n",
    "        if meta:\n",
    "            epmc_data.append(meta)\n",
    "        time.sleep(0.1) # Rate limit courtesy\n",
    "\n",
    "    print(f\"\\nFetched data for {len(epmc_data)} records.\")\n",
    "\n",
    "    # Create DataFrame and Save\n",
    "    if epmc_data:\n",
    "        df_epmc = pd.DataFrame(epmc_data)\n",
    "\n",
    "        # Reorder columns nicely\n",
    "        cols = ['publication/pmid', 'epmc_pmcid', 'epmc_doi', 'epmc_year', 'epmc_journal', 'epmc_title', 'epmc_authors', 'epmc_mesh', 'epmc_keywords']\n",
    "        # Ensure all cols exist\n",
    "        for c in cols:\n",
    "            if c not in df_epmc.columns: df_epmc[c] = None\n",
    "            \n",
    "        df_epmc = df_epmc[cols]\n",
    "\n",
    "        df_epmc.to_csv(output_epmc_file, sep='\\t', index=False)\n",
    "        print(f\"Saved EPMC source metadata to {output_epmc_file}\")\n",
    "    else:\n",
    "        print(\"No metadata fetched.\")\n",
    "else:\n",
    "    print(\"No PMIDs to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412ea82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67dc45ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing interactive comparison interface...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02169a4858e4b6eac337a1b723ab1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<< Previous', disabled=True, style=ButtonStyle()), Label(value='Record 1 of…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc343422a58947c4aa07cff8f024b8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 13. Interactive Comparison Tool\n",
    "\n",
    "print(\"Initializing interactive comparison interface...\")\n",
    "\n",
    "# Load Data (ensure consistent strings for joining)\n",
    "try:\n",
    "    df_v10 = pd.read_csv(\"v10_Dome-Recommendations-With_PMCID.tsv\", sep='\\t')\n",
    "    df_epmc = pd.read_csv(\"epmc_source_metadata.tsv\", sep='\\t')\n",
    "    \n",
    "    # Pre-processing keys\n",
    "    df_v10['publication/pmid'] = df_v10['publication/pmid'].fillna('').astype(str).str.replace('.0', '')\n",
    "    df_epmc['publication/pmid'] = df_epmc['publication/pmid'].fillna('').astype(str).str.replace('.0', '')\n",
    "    \n",
    "    # Merge for easier navigation\n",
    "    # Left join to verify all v10 records, even if EPMC failed\n",
    "    df_merged = pd.merge(df_v10, df_epmc, on='publication/pmid', how='left')\n",
    "    \n",
    "    # Fields to compare\n",
    "    comparison_fields = [\n",
    "        ('Title', 'publication/title', 'epmc_title'),\n",
    "        ('Authors', 'publication/authors', 'epmc_authors'),\n",
    "        ('Journal', 'publication/journal', 'epmc_journal'),\n",
    "        ('Year', 'publication/year', 'epmc_year'),\n",
    "        ('DOI', 'publication/doi', 'epmc_doi')\n",
    "    ]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    df_merged = pd.DataFrame()\n",
    "\n",
    "# Navigation logic\n",
    "current_index = 0\n",
    "total_records = len(df_merged)\n",
    "\n",
    "# Widgets\n",
    "w_output = widgets.Output() # For display area\n",
    "w_prev = widgets.Button(description=\"<< Previous\", disabled=True)\n",
    "w_next = widgets.Button(description=\"Next >>\")\n",
    "w_status = widgets.Label(value=f\"Record 1 of {total_records}\")\n",
    "\n",
    "def display_record(index):\n",
    "    if index < 0 or index >= total_records: return\n",
    "    \n",
    "    row = df_merged.iloc[index]\n",
    "    pmid = row['publication/pmid']\n",
    "    \n",
    "    with w_output:\n",
    "        w_output.clear_output()\n",
    "        print(f\"=== CHECKING PMID: {pmid} ===\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'FIELD':<15} | {'DOME (v10)':<40} | {'EPMC (Source)':<40}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for label, dome_col, epmc_col in comparison_fields:\n",
    "            val_dome = str(row.get(dome_col, ''))[:40] # Truncate for display\n",
    "            val_epmc = str(row.get(epmc_col, ''))[:40]\n",
    "            \n",
    "            # Simple diff indicator\n",
    "            match = \" \" if val_dome == val_epmc else \"*\" \n",
    "            print(f\"{match} {label:<13} | {val_dome:<40} | {val_epmc:<40}\")\n",
    "            \n",
    "        print(\"-\" * 80)\n",
    "        print(\"Raw EPMC Mesh Terms:\")\n",
    "        print(row.get('epmc_mesh', 'N/A'))\n",
    "\n",
    "def on_prev(b):\n",
    "    global current_index\n",
    "    current_index = max(0, current_index - 1)\n",
    "    update_ui()\n",
    "\n",
    "def on_next(b):\n",
    "    global current_index\n",
    "    current_index = min(total_records - 1, current_index + 1)\n",
    "    update_ui()\n",
    "    \n",
    "def update_ui():\n",
    "    w_status.value = f\"Record {current_index + 1} of {total_records}\"\n",
    "    w_prev.disabled = (current_index == 0)\n",
    "    w_next.disabled = (current_index == total_records - 1)\n",
    "    display_record(current_index)\n",
    "\n",
    "w_prev.on_click(on_prev)\n",
    "w_next.on_click(on_next)\n",
    "\n",
    "# Layout\n",
    "if not df_merged.empty:\n",
    "    display(widgets.HBox([w_prev, w_status, w_next]))\n",
    "    display(w_output)\n",
    "    display_record(0)\n",
    "else:\n",
    "    print(\"No data available to verify.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28593daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repairing publication metadata with official EPMC data...\n",
      "Update 'publication/pmcid' from 'epmc_pmcid': 169 records to be updated.\n",
      "Update 'publication/journal' from 'epmc_journal': 188 records to be updated.\n",
      "Update 'publication/year' from 'epmc_year': 188 records to be updated.\n",
      "Saved repaired data to v11_Dome-Recommendations-EPMC_Metadata_Repaired.tsv\n",
      "Final Columns: ['_id/$oid', 'dataset/availability', 'dataset/provenance', 'dataset/redundancy', 'dataset/splits', 'dataset/done', 'dataset/skip', 'evaluation/availability', 'evaluation/comparison', 'evaluation/confidence', 'evaluation/measure', 'evaluation/method', 'evaluation/done', 'evaluation/skip', 'model/availability', 'model/duration', 'model/interpretability', 'model/output', 'model/done', 'model/skip', 'optimization/algorithm', 'optimization/config', 'optimization/encoding', 'optimization/features', 'optimization/fitting', 'optimization/meta', 'optimization/parameters', 'optimization/regularization', 'optimization/done', 'optimization/skip', 'user/$oid', 'publication/pmid', 'publication/pmcid', 'publication/updated', 'publication/authors', 'publication/journal', 'publication/title', 'publication/doi', 'publication/year', 'publication/done', 'publication/skip', 'publication/tags', 'public', 'created/$date', 'updated/$date', 'uuid', 'reviewState', 'shortid', 'update']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86327/1773540367.py:44: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['PMC7845959' 'PMC7933593' 'PMC8385175' 'PMC8192578' 'PMC8545175'\n",
      " 'PMC6708480' 'PMC6690680' 'PMC6242780' 'PMC5821274' 'PMC4606520'\n",
      " 'PMC7816647' 'PMC5930664' 'PMC1847686' 'PMC4706063' 'PMC2701298'\n",
      " 'PMC7734183' 'PMC7297119' 'PMC9328381' 'PMC8485143' 'PMC7073919'\n",
      " 'PMC6902683' 'PMC2752621' 'PMC8336795' 'PMC8225676' 'PMC8093828'\n",
      " 'PMC8100172' 'PMC7794018' 'PMC6548586' 'PMC5773889' 'PMC7735824'\n",
      " 'PMC7406221' 'PMC6457539' 'PMC7446623' 'PMC5870574' 'PMC4894951'\n",
      " 'PMC7707106' 'PMC8843059' 'PMC8067080' 'PMC8469072' 'PMC7473040'\n",
      " 'PMC7721480' 'PMC7237030' 'PMC6732622' 'PMC6851483' 'PMC6459551'\n",
      " 'PMC6532836' 'PMC5923460' 'PMC6214495' 'PMC5923460' 'PMC5034704'\n",
      " 'PMC4460208' 'PMC7237030' 'PMC3009519' 'PMC5656045' 'PMC8230313'\n",
      " 'PMC5104375' 'PMC2660303' 'PMC4315323' 'PMC7725002' 'PMC7068237'\n",
      " 'PMC4315436' 'PMC5976622' 'PMC7648120' 'PMC6495231' 'PMC2638158'\n",
      " 'PMC5738356' 'PMC7648120' 'PMC7333383' 'PMC3864407' 'PMC2665034'\n",
      " 'PMC2559987' 'PMC6657583' 'PMC6832773' 'PMC6478501' 'PMC8288037'\n",
      " 'PMC4507953' 'PMC4507953' 'PMC6908647' 'PMC6172579' 'PMC7442807'\n",
      " 'PMC3542245' 'PMC5821114' 'PMC8328792' 'PMC7596958' 'PMC6929456'\n",
      " 'PMC5113897' 'PMC7591939' 'PMC4931851' 'PMC8175075' 'PMC7142336'\n",
      " 'PMC3967921' 'PMC5610945' 'PMC6923882' 'PMC6436896' 'PMC5550971'\n",
      " 'PMC4589233' 'PMC7860026' 'PMC7569858' 'PMC6737184' 'PMC6629660'\n",
      " 'PMC6386402' 'PMC7352871' 'PMC7520974' 'PMC7497297' 'PMC7598837'\n",
      " 'PMC6896948' 'PMC3396452' 'PMC8150043' 'PMC7054390' 'PMC7327047'\n",
      " 'PMC4378968' 'PMC5377911' 'PMC7387776' 'PMC6428110' 'PMC7864437'\n",
      " 'PMC7250142' 'PMC4113968' 'PMC5517062' 'PMC1421439' 'PMC5517062'\n",
      " 'PMC5650527' 'PMC4606520' 'PMC6679781' 'PMC4834164' 'PMC4466774'\n",
      " 'PMC8100175' 'PMC6214550' 'PMC6664791' 'PMC8351329' 'PMC5650527'\n",
      " 'PMC4606520' 'PMC6237755' 'PMC7431967' 'PMC7602301' 'PMC8042551'\n",
      " 'PMC7602301' 'PMC7658686' 'PMC8259419' 'PMC7156652' 'PMC6036478'\n",
      " 'PMC4289375' 'PMC7493359' 'PMC5775817' 'PMC6036855' 'PMC4208705'\n",
      " 'PMC3292016' 'PMC7680913' 'PMC8443583' 'PMC7162491' 'PMC7760368'\n",
      " 'PMC6394031' 'PMC6743778' 'PMC5930664' 'PMC5860171' 'PMC3169429'\n",
      " 'PMC3340366' 'PMC2791337' 'PMC2275242' 'PMC4388847' 'PMC8261512'\n",
      " 'PMC8351329' 'PMC8019900' 'PMC6510637' 'PMC8185002' 'PMC7718328'\n",
      " 'PMC8125376' 'PMC5079830' 'PMC7751093' 'PMC4058174']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_repaired.loc[mask, target] = df_repaired.loc[mask, source]\n"
     ]
    }
   ],
   "source": [
    "# 14. Data Repair: Overwrite DOME with EPMC Metadata (Version 11)\n",
    "\n",
    "print(\"Repairing publication metadata with official EPMC data...\")\n",
    "\n",
    "# Start from v10 (already loaded as df_v10, but good to ensure freshness if cells skipped)\n",
    "# We use df_merged created in previous step or rebuild it if needed\n",
    "if 'df_merged' not in locals() or df_merged.empty:\n",
    "    print(\"re-merging for repair operation...\")\n",
    "    df_v10 = pd.read_csv(\"v10_Dome-Recommendations-With_PMCID.tsv\", sep='\\t')\n",
    "    df_epmc = pd.read_csv(\"epmc_source_metadata.tsv\", sep='\\t')\n",
    "    \n",
    "    # Pre-processing keys\n",
    "    df_v10['publication/pmid'] = df_v10['publication/pmid'].fillna('').astype(str).str.replace('.0', '')\n",
    "    df_epmc['publication/pmid'] = df_epmc['publication/pmid'].fillna('').astype(str).str.replace('.0', '')\n",
    "    \n",
    "    df_merged = pd.merge(df_v10, df_epmc, on='publication/pmid', how='left')\n",
    "\n",
    "# Create a copy for the new version\n",
    "df_repaired = df_merged.copy()\n",
    "\n",
    "# List of fields to overwrite: (Target DOME Col, Source EPMC Col)\n",
    "overwrite_map = [\n",
    "    ('publication/pmcid', 'epmc_pmcid'),\n",
    "    ('publication/journal', 'epmc_journal'),\n",
    "    ('publication/year', 'epmc_year'),\n",
    "    # You asked for PMCID, Journal, Year. \n",
    "    # Did you want Title/Authors? \"same for publciation/journal and publication/year\" implies those specific ones.\n",
    "    # I will stick to what was explicitly asked plus PMCID.\n",
    "]\n",
    "\n",
    "count_repairs = 0\n",
    "for target, source in overwrite_map:\n",
    "    # Only overwite if source is available (not null/nan)\n",
    "    # We use numpy where or apply. \n",
    "    # Logic: If epmc_source is valid, use it. Else keep original.\n",
    "    \n",
    "    mask = df_repaired[source].notna() & (df_repaired[source].astype(str).str.strip() != '')\n",
    "    \n",
    "    # Log how many will change\n",
    "    n_changes = mask.sum()\n",
    "    print(f\"Update '{target}' from '{source}': {n_changes} records to be updated.\")\n",
    "    \n",
    "    # Apply update\n",
    "    df_repaired.loc[mask, target] = df_repaired.loc[mask, source]\n",
    "    count_repairs += 1\n",
    "\n",
    "# Cleanup: Remove the appended EPMC columns from the merge (keys starting with epmc_)\n",
    "epmc_cols = [c for c in df_repaired.columns if c.startswith('epmc_')]\n",
    "df_repaired.drop(columns=epmc_cols, inplace=True)\n",
    "\n",
    "# Save Version 11\n",
    "output_file_v11 = \"v11_Dome-Recommendations-EPMC_Metadata_Repaired.tsv\"\n",
    "df_repaired.to_csv(output_file_v11, sep='\\t', index=False)\n",
    "print(f\"Saved repaired data to {output_file_v11}\")\n",
    "print(\"Final Columns:\", list(df_repaired.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9143d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking JSON Source Uniqueness (Public Entries Only)...\n",
      "Loaded 354 total records from JSON.\n",
      "Analyzing 281 records marked as 'public': true\n",
      "\n",
      "Potential Duplicates Found (Public Only): 9 groups\n",
      "------------------------------------------------------------\n",
      "Group 1 (2 records):\n",
      "  - OID: 63516fedb9c880af1f305b1b\n",
      "    Title:   Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\n",
      "    Journal: Food Chem\n",
      "  - OID: 63516fedb9c880af1f305b29\n",
      "    Title:   Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\n",
      "    Journal: Food Chem\n",
      "------------------------------------------------------------\n",
      "Group 2 (2 records):\n",
      "  - OID: 63516fedb9c880af1f305b25\n",
      "    Title:   MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\n",
      "    Journal: EBioMedicine\n",
      "  - OID: 63516fedb9c880af1f305b72\n",
      "    Title:   MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\n",
      "    Journal: EBioMedicine\n",
      "------------------------------------------------------------\n",
      "Group 3 (2 records):\n",
      "  - OID: 63516fedb9c880af1f305b34\n",
      "    Title:   Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\n",
      "    Journal: BMC Cancer\n",
      "  - OID: 63516fedb9c880af1f305baf\n",
      "    Title:   Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\n",
      "    Journal: BMC Cancer\n",
      "------------------------------------------------------------\n",
      "Group 4 (2 records):\n",
      "  - OID: 63516fedb9c880af1f305b42\n",
      "    Title:   Prediction of plant lncRNA by ensemble machine learning classifiers.\n",
      "    Journal: BMC Genomics\n",
      "  - OID: 63516fedb9c880af1f305b46\n",
      "    Title:   Prediction of plant lncRNA by ensemble machine learning classifiers.\n",
      "    Journal: BMC Genomics\n",
      "------------------------------------------------------------\n",
      "Group 5 (2 records):\n",
      "  - OID: 63516fedb9c880af1f305b64\n",
      "    Title:   From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\n",
      "    Journal: Drug Discov Today\n",
      "  - OID: 63516fedb9c880af1f305b68\n",
      "    Title:   From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\n",
      "    Journal: Drug Discov Today\n",
      "------------------------------------------------------------\n",
      "Group 6 (2 records):\n",
      "  - OID: 63516fedb9c880af1f305b7e\n",
      "    Title:   Classification of pallidal oscillations with increasing parkinsonian severity.\n",
      "    Journal: J Neurophysiol\n",
      "  - OID: 63516fedb9c880af1f305bae\n",
      "    Title:   Classification of pallidal oscillations with increasing parkinsonian severity.\n",
      "    Journal: J Neurophysiol\n",
      "------------------------------------------------------------\n",
      "Group 7 (3 records):\n",
      "  - OID: 63516fedb9c880af1f305b97\n",
      "    Title:   KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\n",
      "    Journal: Comput Math Methods Med\n",
      "  - OID: 63516fedb9c880af1f305b9f\n",
      "    Title:   KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\n",
      "    Journal: Comput Math Methods Med\n",
      "  - OID: 63516fedb9c880af1f305ba8\n",
      "    Title:   KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\n",
      "    Journal: Comput Math Methods Med\n",
      "------------------------------------------------------------\n",
      "Group 8 (2 records):\n",
      "  - OID: 65e843f41502715bfe53cd1e\n",
      "    Title:   P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\n",
      "    Journal: Journal of cheminformatics\n",
      "  - OID: 6638a2f7b30933003cc215b9\n",
      "    Title:   P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\n",
      "    Journal: Journal of cheminformatics\n",
      "------------------------------------------------------------\n",
      "Group 9 (2 records):\n",
      "  - OID: 6809f90dea60466a7ca5aac2\n",
      "    Title:   SPOT-Disorder2: Improved Protein Intrinsic Disorder Prediction by Ensembled Deep Learning\n",
      "    Journal: Genomics, Proteomics & Bioinformatics\n",
      "  - OID: 680a4d01ea60466a7ca5ab48\n",
      "    Title:   SPOT-Disorder2: Improved Protein Intrinsic Disorder Prediction by Ensembled Deep Learning\n",
      "    Journal: Genomics, Proteomics & Bioinformatics\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import collections\n",
    "\n",
    "# 14b. JSON Source Uniqueness Check\n",
    "# Check DOME Registry JSON for internal duplicates based on Title and Journal (Normalized)\n",
    "# *Updated*: Only checks entries where \"public\": true\n",
    "\n",
    "print(\"Checking JSON Source Uniqueness (Public Entries Only)...\")\n",
    "\n",
    "json_file = \"dome_review_raw_human_20260202.json\"\n",
    "\n",
    "try:\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    print(f\"Loaded {len(json_data)} total records from JSON.\")\n",
    "    \n",
    "    # Filter for Public Entries\n",
    "    public_entries = [e for e in json_data if e.get('public') is True]\n",
    "    print(f\"Analyzing {len(public_entries)} records marked as 'public': true\")\n",
    "    \n",
    "    # Normalization Helper\n",
    "    def normalize_flexible(text):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        # 1. Lowercase\n",
    "        # 2. Split by whitespace and rejoin with single space (handles multiple spaces/tabs)\n",
    "        # 3. Strip punctuation? Maybe just keep alphanumeric for 'key' purposes\n",
    "        # The user asked for \"caps, spaces\" flex.\n",
    "        return \"\".join(c for c in text if c.isalnum()).lower()\n",
    "\n",
    "    # Store entries\n",
    "    # Key: (Normalized Title, Normalized Journal) -> List of {OID, Original Title, Original Journal}\n",
    "    groups = collections.defaultdict(list)\n",
    "    \n",
    "    for entry in public_entries:\n",
    "        oid = entry.get('_id', {}).get('$oid', 'N/A')\n",
    "        title = entry.get('publication', {}).get('title', '')\n",
    "        journal = entry.get('publication', {}).get('journal', '')\n",
    "        \n",
    "        # Create Key\n",
    "        norm_title = normalize_flexible(title)\n",
    "        norm_journal = normalize_flexible(journal)\n",
    "        \n",
    "        # Only group if we actually have a title (journal might be empty, that's common)\n",
    "        if norm_title:\n",
    "            key = (norm_title, norm_journal)\n",
    "            groups[key].append({\n",
    "                'oid': oid,\n",
    "                'title': title,\n",
    "                'journal': journal\n",
    "            })\n",
    "            \n",
    "    # Find Duplicates\n",
    "    # Groups with > 1 entry\n",
    "    dupes = [entries for key, entries in groups.items() if len(entries) > 1]\n",
    "    \n",
    "    print(f\"\\nPotential Duplicates Found (Public Only): {len(dupes)} groups\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, group in enumerate(dupes):\n",
    "        print(f\"Group {i+1} ({len(group)} records):\")\n",
    "        for rec in group:\n",
    "            print(f\"  - OID: {rec['oid']}\")\n",
    "            print(f\"    Title:   {rec['title']}\")\n",
    "            print(f\"    Journal: {rec['journal']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    if not dupes:\n",
    "        print(\"PASS: No internal duplicates found in Public entries based on flexible Title + Journal matching.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error checking JSON uniqueness: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5105f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating dome_review_raw_human_20260202.json with duplicate cross-references...\n",
      "Loaded 354 records.\n",
      "Tagged 19 records with duplicate references.\n",
      "Successfully updated dome_review_raw_human_20260202.json.\n"
     ]
    }
   ],
   "source": [
    "# 14c. Update JSON with Duplicate Info (Version 17)\n",
    "# Action: Update the source JSON file directly.\n",
    "#         Append new field 'Duplicate_shortid' to all entries.\n",
    "#         For Public entries with duplicates, list the conflicting shortids.\n",
    "#         For others, leave empty.\n",
    "\n",
    "import json\n",
    "import collections\n",
    "\n",
    "# Using the 20260202 file as per global notebook instruction (overriding any legacy filenames)\n",
    "json_file = \"dome_review_raw_human_20260202.json\"\n",
    "\n",
    "print(f\"Updating {json_file} with duplicate cross-references...\")\n",
    "\n",
    "try:\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    print(f\"Loaded {len(json_data)} records.\")\n",
    "\n",
    "    # 1. Identify Duplicates (Public Only)\n",
    "    public_entries = [e for e in json_data if e.get('public') is True]\n",
    "    \n",
    "    # Normalization\n",
    "    def normalize_flexible(text):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        return \"\".join(c for c in text if c.isalnum()).lower()\n",
    "\n",
    "    # Grouping\n",
    "    groups = collections.defaultdict(list)\n",
    "    for entry in public_entries:\n",
    "        title = entry.get('publication', {}).get('title', '')\n",
    "        journal = entry.get('publication', {}).get('journal', '')\n",
    "        shortid = entry.get('shortid', '')\n",
    "        \n",
    "        # We use the normalized Title+Journal as the unique fingerprint\n",
    "        norm_title = normalize_flexible(title)\n",
    "        norm_journal = normalize_flexible(journal)\n",
    "        \n",
    "        if norm_title:\n",
    "            key = (norm_title, norm_journal)\n",
    "            groups[key].append({\n",
    "                'shortid': shortid,\n",
    "                'oid': entry.get('_id', {}).get('$oid')\n",
    "            })\n",
    "\n",
    "    # 2. Build Mapping: shortid -> [duplicate_shortids]\n",
    "    # (Only for groups with > 1 entry)\n",
    "    dupe_map = {}\n",
    "    \n",
    "    for key, group in groups.items():\n",
    "        if len(group) > 1:\n",
    "            # Get list of all shortids in this group\n",
    "            # Filter out empty shortids just in case\n",
    "            all_ids = [m['shortid'] for m in group if m['shortid']]\n",
    "            \n",
    "            for member in group:\n",
    "                my_id = member['shortid']\n",
    "                if my_id:\n",
    "                    # Siblings are everyone else in the group\n",
    "                    siblings = [sid for sid in all_ids if sid != my_id]\n",
    "                    # Sort for consistency\n",
    "                    siblings.sort()\n",
    "                    dupe_map[my_id] = siblings\n",
    "\n",
    "    # 3. Apply to All JSON Data\n",
    "    updated_count = 0\n",
    "    for entry in json_data:\n",
    "        my_id = entry.get('shortid')\n",
    "        \n",
    "        # Look up dupes (returns [] if not found or if private)\n",
    "        # Note: If an entry is private, it wasn't in 'groups', so it won't be in 'dupe_map'. Correct.\n",
    "        duplicates = dupe_map.get(my_id, [])\n",
    "        \n",
    "        # Update/Add Field\n",
    "        entry['Duplicate_shortid'] = duplicates\n",
    "        \n",
    "        if duplicates:\n",
    "            updated_count += 1\n",
    "            \n",
    "    print(f\"Tagged {updated_count} records with duplicate references.\")\n",
    "\n",
    "    # 4. Save back to file\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "        \n",
    "    print(f\"Successfully updated {json_file}.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error updating JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b9ef528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering dome_review_raw_human_20260202.json for public entries...\n",
      "Success! Created 'public_dome_review_raw_human_20260202.json' with 281 entries.\n"
     ]
    }
   ],
   "source": [
    "# 14d. Create Public-Only JSON Subset\n",
    "# Filter the source JSON to create a clean public release version.\n",
    "\n",
    "import json\n",
    "\n",
    "input_file = \"dome_review_raw_human_20260202.json\"\n",
    "output_file = \"public_dome_review_raw_human_20260202.json\"\n",
    "\n",
    "print(f\"Filtering {input_file} for public entries...\")\n",
    "\n",
    "try:\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # Filter\n",
    "    public_content = [item for item in data if item.get('public') is True]\n",
    "    \n",
    "    # Save\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(public_content, f, indent=4)\n",
    "        \n",
    "    print(f\"Success! Created '{output_file}' with {len(public_content)} entries.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating public subset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4fdfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing intermediate deduplication on V11 data...\n",
      "------------------------------\n",
      "Original V11 count: 188\n",
      "Dropped duplicates: 12\n",
      "Retained records:   176\n",
      "Saved deduplicated data to v11b_Dome-Recommendations-Deduplicated.tsv\n",
      "Saved dropped duplicates to v11b_Dome-Recommendations-Deduplicated_Dropped.tsv\n"
     ]
    }
   ],
   "source": [
    "# 14e. Intermediate Deduplication (Pre-Validation)\n",
    "# Remove duplicates from V11 based on Title, prioritizing completeness.\n",
    "\n",
    "print(\"Performing intermediate deduplication on V11 data...\")\n",
    "\n",
    "# Normalized Title Helper\n",
    "def normalize_title_dedup(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    return \"\".join(c for c in text if c.isalnum()).lower()\n",
    "\n",
    "# Working on df_repaired from previous step\n",
    "if 'df_repaired' not in locals():\n",
    "    # Load if missing\n",
    "    try:\n",
    "        df_repaired = pd.read_csv(\"v11_Dome-Recommendations-EPMC_Metadata_Repaired.tsv\", sep='\\t')\n",
    "    except:\n",
    "        print(\"Error: df_repaired not found.\")\n",
    "        df_repaired = pd.DataFrame()\n",
    "\n",
    "if not df_repaired.empty:\n",
    "    # 1. Calculate Completeness Score\n",
    "    # Count non-null values in columns (excluding system columns if possible, but general is fine)\n",
    "    df_repaired['temp_completeness_score'] = df_repaired.notna().sum(axis=1)\n",
    "    \n",
    "    # 2. Normalize Title\n",
    "    df_repaired['temp_norm_title'] = df_repaired['publication/title'].apply(normalize_title_dedup)\n",
    "    \n",
    "    # 3. Sort by Score (Complete -> Less Complete)\n",
    "    # We want to keep the MOST complete one, so sort Descending.\n",
    "    # drop_duplicates(keep='first') will then keep the top one (the most complete).\n",
    "    df_repaired.sort_values(by='temp_completeness_score', ascending=False, inplace=True)\n",
    "    \n",
    "    # 4. Separate Duplicates\n",
    "    # identify based on title only\n",
    "    mask_has_title = df_repaired['temp_norm_title'] != ''\n",
    "    \n",
    "    # Rows with titles that appear more than once\n",
    "    # We want to see what is being dropped. \n",
    "    # Let's perform the drop\n",
    "    df_clean = df_repaired.drop_duplicates(subset=['temp_norm_title'], keep='first')\n",
    "    \n",
    "    # Identify dropped rows\n",
    "    dropped_indices = df_repaired.index.difference(df_clean.index)\n",
    "    df_dropped = df_repaired.loc[dropped_indices]\n",
    "    \n",
    "    # 5. Cleanup Helpers\n",
    "    df_clean = df_clean.drop(columns=['temp_completeness_score', 'temp_norm_title'])\n",
    "    df_dropped = df_dropped.drop(columns=['temp_completeness_score', 'temp_norm_title'])\n",
    "    \n",
    "    # Update the main variable for next steps\n",
    "    df_repaired = df_clean.copy()\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Original V11 count: {len(df_clean) + len(df_dropped)}\")\n",
    "    print(f\"Dropped duplicates: {len(df_dropped)}\")\n",
    "    print(f\"Retained records:   {len(df_clean)}\")\n",
    "    \n",
    "    # 6. Save\n",
    "    file_retained = \"v11b_Dome-Recommendations-Deduplicated.tsv\"\n",
    "    file_dropped = \"v11b_Dome-Recommendations-Deduplicated_Dropped.tsv\"\n",
    "    \n",
    "    df_clean.to_csv(file_retained, sep='\\t', index=False)\n",
    "    df_dropped.to_csv(file_dropped, sep='\\t', index=False)\n",
    "    print(f\"Saved deduplicated data to {file_retained}\")\n",
    "    print(f\"Saved dropped duplicates to {file_dropped}\")\n",
    "\n",
    "else:\n",
    "    print(\"No data to deduplicate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a714ab4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ac601aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating records based on Normalized Title matching...\n",
      "Loaded 281 source records from Public JSON.\n",
      "Indexed 271 unique titles from 281 JSON entries.\n",
      "Matching records against JSON titles...\n",
      "Matching Results: 143 Retained | 33 Dropped (No Match)\n",
      "Saved matched records to v12_Dome-Recommendations-Validated_Retained.tsv\n",
      "Saved unmatched records to v12_Dome-Recommendations-Validated_Dropped_Backup.tsv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 15. Validation: Match Records against Original JSON Source (Version 12)\n",
    "# Revised Logic: Title-Based Validation (Normalized)\n",
    "# *Updated*: Uses v11b Deduplicated TSV and Public JSON source\n",
    "\n",
    "print(\"Validating records based on Normalized Title matching...\")\n",
    "\n",
    "# Using the new Public Subset for validation\n",
    "raw_reviews_file = \"public_dome_review_raw_human_20260202.json\"\n",
    "\n",
    "try:\n",
    "    with open(raw_reviews_file, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    print(f\"Loaded {len(json_data)} source records from Public JSON.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {raw_reviews_file} not found.\")\n",
    "    json_data = []\n",
    "\n",
    "def normalize_title(text):\n",
    "    \"\"\"\n",
    "    Normalizes a title string for lenient comparison.\n",
    "    - Lowercase\n",
    "    - Removes all non-alphanumeric characters (punctuation, spaces)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    return \"\".join(c for c in text if c.isalnum()).lower()\n",
    "\n",
    "# Build Set of Normalized Titles from JSON Source\n",
    "json_titles = set()\n",
    "count_titles = 0\n",
    "for entry in json_data:\n",
    "    title = entry.get('publication', {}).get('title', '')\n",
    "    if title:\n",
    "        norm = normalize_title(title)\n",
    "        if norm:\n",
    "            json_titles.add(norm)\n",
    "            count_titles += 1\n",
    "\n",
    "print(f\"Indexed {len(json_titles)} unique titles from {count_titles} JSON entries.\")\n",
    "\n",
    "# Prepare DataFrame Records\n",
    "# Try to load v11b if not present in memory\n",
    "if 'df_repaired' not in locals() or df_repaired.empty: \n",
    "    print(\"Loading v11b from disk...\")\n",
    "    try:\n",
    "        df_to_validate = pd.read_csv(\"v11b_Dome-Recommendations-Deduplicated.tsv\", sep='\\t')\n",
    "    except:\n",
    "        print(\"Error: v11b file not found. Run previous step.\")\n",
    "        df_to_validate = pd.DataFrame()\n",
    "else:\n",
    "    # Use version in memory (which should be the deduped one from 14e)\n",
    "    # Double check by size if possible, or just copy\n",
    "    df_to_validate = df_repaired.copy()\n",
    "\n",
    "matched_rows = []\n",
    "unmatched_rows = []\n",
    "\n",
    "print(\"Matching records against JSON titles...\")\n",
    "\n",
    "if not df_to_validate.empty:\n",
    "    for idx, row in df_to_validate.iterrows():\n",
    "        # Extract Title from DataFrame\n",
    "        d_title = str(row.get('publication/title', ''))\n",
    "        \n",
    "        # Normalize\n",
    "        d_norm = normalize_title(d_title)\n",
    "        \n",
    "        # Check Match: Title must exist in JSON source\n",
    "        if d_norm and d_norm in json_titles:\n",
    "            matched_rows.append(row)\n",
    "        else:\n",
    "            unmatched_rows.append(row)\n",
    "\n",
    "# Create Output DataFrames\n",
    "df_matched = pd.DataFrame(matched_rows)\n",
    "df_unmatched = pd.DataFrame(unmatched_rows)\n",
    "\n",
    "print(f\"Matching Results: {len(df_matched)} Retained | {len(df_unmatched)} Dropped (No Match)\")\n",
    "\n",
    "# Save V12 Retained\n",
    "output_file_v12_retained = \"v12_Dome-Recommendations-Validated_Retained.tsv\"\n",
    "if not df_matched.empty:\n",
    "    df_matched.to_csv(output_file_v12_retained, sep='\\t', index=False)\n",
    "    print(f\"Saved matched records to {output_file_v12_retained}\")\n",
    "else:\n",
    "    print(\"Warning: No records matched!\")\n",
    "    # Save empty structure if dataframe columns exist\n",
    "    if not df_to_validate.empty:\n",
    "         df_to_validate.iloc[0:0].to_csv(output_file_v12_retained, sep='\\t', index=False)\n",
    "\n",
    "# Save Dropped Backup\n",
    "output_file_v12_dropped = \"v12_Dome-Recommendations-Validated_Dropped_Backup.tsv\"\n",
    "if not df_unmatched.empty:\n",
    "    df_unmatched.to_csv(output_file_v12_dropped, sep='\\t', index=False)\n",
    "    print(f\"Saved unmatched records to {output_file_v12_dropped}\")\n",
    "else:\n",
    "    print(\"All records matched.\")\n",
    "    if not df_to_validate.empty:\n",
    "        df_to_validate.iloc[0:0].to_csv(output_file_v12_dropped, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d91e6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending curator emails based on User OID (Version 13)...\n",
      "Loaded 120 user mappings.\n",
      "Processing v12_Dome-Recommendations-Validated_Retained.tsv -> v13_Dome-Recommendations-With_Emails_Retained.tsv...\n",
      "  Saved v13_Dome-Recommendations-With_Emails_Retained.tsv (143 records).\n",
      "Processing v12_Dome-Recommendations-Validated_Dropped_Backup.tsv -> v13_Dome-Recommendations-With_Emails_Dropped.tsv...\n",
      "  Saved v13_Dome-Recommendations-With_Emails_Dropped.tsv (33 records).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 16. Cleanup: Append Curator Emails (Version 13)\n",
    "# Processing both Retained and Dropped/Backup V12 files\n",
    "\n",
    "print(\"Appending curator emails based on User OID (Version 13)...\")\n",
    "\n",
    "users_file = \"dome_users_20260202.json\"\n",
    "\n",
    "# Define the pairs of files to process: (Input V12, Output V13)\n",
    "files_to_process = [\n",
    "    (\"v12_Dome-Recommendations-Validated_Retained.tsv\", \"v13_Dome-Recommendations-With_Emails_Retained.tsv\"),\n",
    "    (\"v12_Dome-Recommendations-Validated_Dropped_Backup.tsv\", \"v13_Dome-Recommendations-With_Emails_Dropped.tsv\")\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Load User Data Once\n",
    "    with open(users_file, 'r', encoding='utf-8') as f:\n",
    "        users_data = json.load(f)\n",
    "        \n",
    "    # Create OID -> Email mapping\n",
    "    oid_to_email = {}\n",
    "    for u in users_data:\n",
    "        email = u.get('email')\n",
    "        oid = u.get('_id', {}).get('$oid')\n",
    "        if email and oid:\n",
    "            oid_to_email[oid.strip()] = email.strip()\n",
    "            \n",
    "    print(f\"Loaded {len(oid_to_email)} user mappings.\")\n",
    "\n",
    "    # Process each file\n",
    "    for input_file, output_file in files_to_process:\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"Skipping {input_file} (File not found)\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing {input_file} -> {output_file}...\")\n",
    "        df_temp = pd.read_csv(input_file, sep='\\t')\n",
    "        \n",
    "        if df_temp.empty:\n",
    "            print(f\"  Warning: {input_file} is empty.\")\n",
    "            \n",
    "        # Get OIDs from user/$oid and map to email\n",
    "        # Handle case where user/$oid might be missing or NaN gracefully\n",
    "        if 'user/$oid' in df_temp.columns:\n",
    "            df_temp['curator_email'] = df_temp['user/$oid'].apply(lambda x: oid_to_email.get(str(x).strip(), '') if pd.notna(x) else '')\n",
    "        else:\n",
    "            print(\"  Column 'user/$oid' not found creating empty column.\")\n",
    "            df_temp['curator_email'] = ''\n",
    "\n",
    "        # Reorder columns: curator_email first\n",
    "        cols = list(df_temp.columns)\n",
    "        if 'curator_email' in cols:\n",
    "            cols.remove('curator_email')\n",
    "            cols.insert(0, 'curator_email')\n",
    "            df_temp = df_temp[cols]\n",
    "        \n",
    "        # Save\n",
    "        df_temp.to_csv(output_file, sep='\\t', index=False)\n",
    "        print(f\"  Saved {output_file} ({len(df_temp)} records).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error mapping emails: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "317b8081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending missing records from Deduplicated Public JSON source to create complete dataset (Version 14)...\n",
      "Loaded 143 retained validated records from v12_Dome-Recommendations-Validated_Retained.tsv\n",
      "Loaded 271 total source records from JSON\n",
      "Index built: 143 titles and 143 DOIs found in v12.\n",
      "Identified 128 entries in JSON that are missing from v12.\n",
      "------------------------------\n",
      "Total Entries in Source JSON: 271\n",
      "Total Entries in Final v14:   271\n",
      "SUCCESS: Final count matches Source JSON count exactly.\n",
      "Saved complete dataset to v14_Dome-Recommendations-Complete_From_Source.tsv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 17. Data Completeness: Append Missing Entries from Source JSON (Version 14)\n",
    "# Logic: Simple Title or DOI match. Appending unique missing JSON entries.\n",
    "# *Updated*: Uses dedup_public_dome_review_raw_human_20260202.json\n",
    "\n",
    "print(\"Appending missing records from Deduplicated Public JSON source to create complete dataset (Version 14)...\")\n",
    "\n",
    "input_file = \"v12_Dome-Recommendations-Validated_Retained.tsv\"\n",
    "output_file_v14 = \"v14_Dome-Recommendations-Complete_From_Source.tsv\"\n",
    "json_file = \"dedup_public_dome_review_raw_human_20260202.json\"\n",
    "\n",
    "try:\n",
    "    # 1. Load v12 Data (Validated)\n",
    "    if os.path.exists(input_file):\n",
    "        df_v12 = pd.read_csv(input_file, sep='\\t')\n",
    "    else:\n",
    "        df_v12 = pd.DataFrame()\n",
    "        \n",
    "    print(f\"Loaded {len(df_v12)} retained validated records from {input_file}\")\n",
    "    \n",
    "    # 2. Load JSON Source\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    print(f\"Loaded {len(json_data)} total source records from JSON\")\n",
    "\n",
    "    # 3. Build sets of Existing Identifiers from v12 (DOI and Title)\n",
    "    def normalize_text(text):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        # Aggressive normalization: alphanumeric only, lowercase\n",
    "        return \"\".join(c for c in text if c.isalnum()).lower()\n",
    "\n",
    "    existing_titles = set()\n",
    "    existing_dois = set()\n",
    "\n",
    "    # Populate lookups from the existing dataframe\n",
    "    for idx, row in df_v12.iterrows():\n",
    "        t = normalize_text(str(row.get('publication/title', '')))\n",
    "        d = normalize_text(str(row.get('publication/doi', '')))\n",
    "        \n",
    "        if t: existing_titles.add(t)\n",
    "        if d: existing_dois.add(d)\n",
    "\n",
    "    print(f\"Index built: {len(existing_titles)} titles and {len(existing_dois)} DOIs found in v12.\")\n",
    "\n",
    "    # 4. Filter JSON for Missing Entries\n",
    "    new_rows = []\n",
    "    \n",
    "    # Get schema from v12 for flattening\n",
    "    # We want the new rows to respect the column structure of v12\n",
    "    if not df_v12.empty:\n",
    "        schema_cols = list(df_v12.columns)\n",
    "    else:\n",
    "        # Fallback if v12 is empty, unlikely but safe\n",
    "        schema_cols = [] \n",
    "\n",
    "    # Identify columns to ignore during flattening (curator_email is removed later anyway, but cleaner to skip)\n",
    "    cols_to_map = [c for c in schema_cols if c != 'curator_email']\n",
    "\n",
    "    def flatten_entry(entry, cols):\n",
    "        row = {}\n",
    "        for col in cols:\n",
    "            # Logic to walk keys: \"publication/title\" -> entry[\"publication\"][\"title\"]\n",
    "            keys = col.split('/')\n",
    "            val = entry\n",
    "            try:\n",
    "                for k in keys:\n",
    "                    val = val[k]\n",
    "                # If we get a complex object (dict/list) instead of a value, treat as None/Empty\n",
    "                if isinstance(val, (dict, list)):\n",
    "                    row[col] = None\n",
    "                else:\n",
    "                    row[col] = val\n",
    "            except (KeyError, TypeError):\n",
    "                # If path doesn't exist\n",
    "                row[col] = None\n",
    "        return row\n",
    "\n",
    "    count_appended = 0\n",
    "    \n",
    "    for entry in json_data:\n",
    "        # Check if this entry exists in v12 based on simple Title OR DOI match\n",
    "        j_title = normalize_text(entry.get('publication', {}).get('title', ''))\n",
    "        j_doi = normalize_text(entry.get('publication', {}).get('doi', ''))\n",
    "        \n",
    "        # Match Logic: match on DOI match OR Title match\n",
    "        # (If either matches, we assume the record is already present in v12)\n",
    "        match_found = False\n",
    "        \n",
    "        if j_doi and j_doi in existing_dois:\n",
    "            match_found = True\n",
    "        elif j_title and j_title in existing_titles:\n",
    "            match_found = True\n",
    "            \n",
    "        if not match_found:\n",
    "            # It is MISSING -> Flatten and Add to queue\n",
    "            new_row = flatten_entry(entry, cols_to_map)\n",
    "            new_rows.append(new_row)\n",
    "            count_appended += 1\n",
    "            \n",
    "    print(f\"Identified {count_appended} entries in JSON that are missing from v12.\")\n",
    "\n",
    "    # 5. Concatenate\n",
    "    if new_rows:\n",
    "        df_new = pd.DataFrame(new_rows)\n",
    "        # Ensure new dataframe matches v12 columns (except those we skipped)\n",
    "        df_final = pd.concat([df_v12, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df_final = df_v12.copy()\n",
    "        \n",
    "    # 6. Final Cleanup\n",
    "    if 'curator_email' in df_final.columns:\n",
    "        df_final.drop(columns=['curator_email'], inplace=True)\n",
    "        print(\"Dropped 'curator_email' column.\")\n",
    "        \n",
    "    # 7. Verification\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total Entries in Source JSON: {len(json_data)}\")\n",
    "    print(f\"Total Entries in Final v14:   {len(df_final)}\")\n",
    "    \n",
    "    # Strict numeric check\n",
    "    if len(df_final) == len(json_data):\n",
    "        print(\"SUCCESS: Final count matches Source JSON count exactly.\")\n",
    "    else:\n",
    "        diff = len(df_final) - len(json_data)\n",
    "        print(f\"WARNING: Mismatch by {diff} records.\")\n",
    "        if diff > 0:\n",
    "            print(\"  (Final has MORE rows than JSON -> Likely duplicates in original v12 TSV)\")\n",
    "        else:\n",
    "            print(\"  (Final has FEWER rows than JSON -> Some JSON entries not appended? Check match logic.)\")\n",
    "\n",
    "    # 8. Save\n",
    "    df_final.to_csv(output_file_v14, sep='\\t', index=False)\n",
    "    print(f\"Saved complete dataset to {output_file_v14}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating v14: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b94f947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicating Public JSON Source...\n",
      "Loaded 281 entries from public_dome_review_raw_human_20260202.json.\n",
      "------------------------------\n",
      "Final Count: 271\n",
      "Dropped Duplicates: 10\n",
      "Saved deduplicated JSON to dedup_public_dome_review_raw_human_20260202.json\n"
     ]
    }
   ],
   "source": [
    "# 16b. Deduplicate Public JSON Source\n",
    "# Creates: dedup_public_dome_review_raw_human_20260202.json\n",
    "# Logic: Group by normalized Title+Journal. Retain only the 'best' entry (highest coverage/length).\n",
    "\n",
    "import json\n",
    "import collections\n",
    "\n",
    "print(\"Deduplicating Public JSON Source...\")\n",
    "\n",
    "input_json = \"public_dome_review_raw_human_20260202.json\"\n",
    "output_json = \"dedup_public_dome_review_raw_human_20260202.json\"\n",
    "\n",
    "try:\n",
    "    with open(input_json, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Loaded {len(data)} entries from {input_json}.\")\n",
    "\n",
    "    # Helper: Calculate 'Coverage Score' for a JSON entry\n",
    "    def calculate_json_score(entry):\n",
    "        # We can count the number of keys in the flattened structure or just total leaves\n",
    "        # Simple heuristic: String length of the JSON string dump of the entry? \n",
    "        # Better: Count non-empty values in the dictionary recursively\n",
    "        \n",
    "        score = 0\n",
    "        def recurse_count(obj):\n",
    "            local_score = 0\n",
    "            if isinstance(obj, dict):\n",
    "                for k, v in obj.items():\n",
    "                    local_score += recurse_count(v)\n",
    "            elif isinstance(obj, list):\n",
    "                for item in obj:\n",
    "                    local_score += recurse_count(item)\n",
    "            elif obj: # Not None, not empty string, not False, not 0\n",
    "                 local_score += 1\n",
    "            return local_score\n",
    "            \n",
    "        return recurse_count(entry)\n",
    "\n",
    "    # Normalization\n",
    "    def normalize_flexible(text):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        return \"\".join(c for c in text if c.isalnum()).lower()\n",
    "\n",
    "    # Grouping\n",
    "    groups = collections.defaultdict(list)\n",
    "    for entry in data:\n",
    "        title = entry.get('publication', {}).get('title', '')\n",
    "        journal = entry.get('publication', {}).get('journal', '')\n",
    "        \n",
    "        norm_title = normalize_flexible(title)\n",
    "        norm_journal = normalize_flexible(journal)\n",
    "        \n",
    "        if norm_title:\n",
    "            key = (norm_title, norm_journal)\n",
    "            groups[key].append(entry)\n",
    "        else:\n",
    "            # No title? Keep it safe as unique with OID as key suffix or separate list\n",
    "            # We'll just add it to a unique bucket or keep unmatched\n",
    "            # Let's say unmatched ones are kept automatically\n",
    "            oid = entry.get('_id', {}).get('$oid')\n",
    "            groups[('__no_title__', oid)].append(entry)\n",
    "\n",
    "    # Selection\n",
    "    final_entries = []\n",
    "    dropped_count = 0\n",
    "    \n",
    "    for key, group in groups.items():\n",
    "        if len(group) == 1:\n",
    "            final_entries.append(group[0])\n",
    "        else:\n",
    "            # Conflict! Pick best.\n",
    "            # Sort by score descending\n",
    "            group.sort(key=calculate_json_score, reverse=True)\n",
    "            best = group[0]\n",
    "            final_entries.append(best)\n",
    "            dropped_count += (len(group) - 1)\n",
    "\n",
    "    # Save\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_entries, f, indent=4)\n",
    "        \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Final Count: {len(final_entries)}\")\n",
    "    print(f\"Dropped Duplicates: {dropped_count}\")\n",
    "    print(f\"Saved deduplicated JSON to {output_json}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error deduplicating JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75f4e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Intelligent Deduplication (Version 15)...\n",
      "Loaded 271 records from v14.\n",
      "------------------------------\n",
      "REPORT: 2 rows involved in duplicates saved to v15_Duplicates_Report_Survivors_and_Dropped.tsv\n",
      "        (This file contains BOTH the retained survivor and the dropped duplicates)\n",
      "------------------------------\n",
      "Original Count: 271\n",
      "Dropped:        1 (Worse copies removed)\n",
      "Final Count:    270\n",
      "Saved optimized dataset to v15_Dome-Recommendations-Best_Candidate_Retained.tsv\n",
      "\n",
      "Source Public Deduplicated JSON entries: 271\n",
      "Note: Count difference is -1.\n"
     ]
    }
   ],
   "source": [
    "# 18. Deduplication: Intelligent Resolution (Version 15)\n",
    "# Strategy: \"Keep Best, Review All Conflicts\"\n",
    "# 1. Score records by Completeness (filled fields) and Recency (date).\n",
    "# 2. Sort data so \"Best\" records are first.\n",
    "# 3. Deduplicate by DOI and Title (keeping the TOP/BEST record).\n",
    "# 4. Generate Clean Dataset (retaining the survivors).\n",
    "# 5. Generate Review Dataset (showing both Survivors and Dropped duplicates for comparison).\n",
    "# *Updated*: Uses dedup_public_dome_review_raw_human_20260202.json for validation\n",
    "\n",
    "print(\"Performing Intelligent Deduplication (Version 15)...\")\n",
    "\n",
    "input_file = \"v14_Dome-Recommendations-Complete_From_Source.tsv\"\n",
    "output_file_v15 = \"v15_Dome-Recommendations-Best_Candidate_Retained.tsv\"\n",
    "review_file_v15 = \"v15_Duplicates_Report_Survivors_and_Dropped.tsv\" \n",
    "json_file = \"dedup_public_dome_review_raw_human_20260202.json\"\n",
    "\n",
    "try:\n",
    "    if os.path.exists(input_file):\n",
    "        df_v15 = pd.read_csv(input_file, sep='\\t')\n",
    "        print(f\"Loaded {len(df_v15)} records from v14.\")\n",
    "    else:\n",
    "        print(f\"Error: {input_file} not found. Please run previous cell.\")\n",
    "        df_v15 = pd.DataFrame()\n",
    "\n",
    "    if not df_v15.empty:\n",
    "        # --- 1. Preparation & Scoring ---\n",
    "        \n",
    "        # Normalization Helpers\n",
    "        def normalize_title_simple(text):\n",
    "            if not isinstance(text, str): return \"\"\n",
    "            return \" \".join(text.split()).lower()\n",
    "\n",
    "        def normalize_doi(text):\n",
    "            if not isinstance(text, str): return \"\"\n",
    "            return text.strip().lower()\n",
    "\n",
    "        df_v15['bs_norm_title'] = df_v15['publication/title'].apply(normalize_title_simple)\n",
    "        df_v15['bs_norm_doi'] = df_v15['publication/doi'].apply(normalize_doi)\n",
    "\n",
    "        # Calculate Scores\n",
    "        # A. Completeness: Count non-null, non-empty values\n",
    "        # (Exclude temp columns from count)\n",
    "        data_cols = [c for c in df_v15.columns if not c.startswith('bs_')]\n",
    "        df_v15['bs_completeness'] = df_v15[data_cols].notna().sum(axis=1)\n",
    "\n",
    "        # B. Recency: Parse 'update' column if exists\n",
    "        if 'update' in df_v15.columns:\n",
    "            df_v15['bs_date'] = pd.to_datetime(df_v15['update'], errors='coerce')\n",
    "        else:\n",
    "            df_v15['bs_date'] = pd.NaT\n",
    "\n",
    "        # --- 2. Sorting to Prioritize Best Records ---\n",
    "        # Sort Order:\n",
    "        # 1. Completeness (Desc) -> More data is better\n",
    "        # 2. Date (Desc) -> Newer is better\n",
    "        # 3. Index (Asc) -> Stability (keep original/top if tile)\n",
    "        \n",
    "        df_v15.sort_values(by=['bs_completeness', 'bs_date'], ascending=[False, False], inplace=True)\n",
    "        # Reset index to ensure sequential processing respects sort\n",
    "        # But keep old index to track origin if needed? No, just rely on sorted order.\n",
    "        \n",
    "        # --- 3. Identification of Conflicts ---\n",
    "        \n",
    "        # We need to identify ALL rows involved in duplicates for the report,\n",
    "        # irrespective of whether they will be kept or dropped.\n",
    "        \n",
    "        title_mask = df_v15['bs_norm_title'] != ''\n",
    "        # doi_mask = df_v15['bs_norm_doi'] != '' # DOI conflicts checked below\n",
    "        \n",
    "        # Identify duplicates (Mark all occurrences)\n",
    "        title_dupes_all = df_v15.duplicated(subset=['bs_norm_title'], keep=False) & title_mask\n",
    "        doi_dupes_all = df_v15.duplicated(subset=['bs_norm_doi'], keep=False) & (df_v15['bs_norm_doi'] != '')\n",
    "        \n",
    "        conflict_mask = title_dupes_all | doi_dupes_all\n",
    "        \n",
    "        # Extract the Conflict Group for Review BEFORE we drop anything\n",
    "        df_conflicts = df_v15[conflict_mask].copy()\n",
    "        \n",
    "        if not df_conflicts.empty:\n",
    "            df_conflicts['Review_Reason'] = ''\n",
    "            df_conflicts.loc[title_dupes_all, 'Review_Reason'] += 'TITLE_MATCH '\n",
    "            df_conflicts.loc[doi_dupes_all, 'Review_Reason'] += 'DOI_MATCH '\n",
    "            \n",
    "            # Sort for Review: Group by Title/DOI to see pairs\n",
    "            df_conflicts.sort_values(by=['bs_norm_title', 'bs_norm_doi'], inplace=True)\n",
    "            \n",
    "            # Reorder columns\n",
    "            cols = list(df_conflicts.columns)\n",
    "            priority = ['Review_Reason', 'bs_completeness', 'update', 'publication/title', 'publication/doi']\n",
    "            # Filter priority to valid columns\n",
    "            priority = [c for c in priority if c in cols]\n",
    "            remaining = [c for c in cols if c not in priority and not c.startswith('bs_')]\n",
    "            \n",
    "            df_review = df_conflicts[priority + remaining]\n",
    "            \n",
    "            df_review.to_csv(review_file_v15, sep='\\t', index=False)\n",
    "            print(\"-\" * 30)\n",
    "            print(f\"REPORT: {len(df_review)} rows involved in duplicates saved to {review_file_v15}\")\n",
    "            print(\"        (This file contains BOTH the retained survivor and the dropped duplicates)\")\n",
    "        \n",
    "        # --- 4. Deduplication (Keep First/Best) ---\n",
    "        \n",
    "        initial_count = len(df_v15)\n",
    "        \n",
    "        # Explicit Strategy:\n",
    "        # Since we sorted by Completeness (Desc) and Date (Desc),\n",
    "        # keep='first' will retain the record with the most data (or newest).\n",
    "        # It drops subsequent (worse/identical) copies.\n",
    "        \n",
    "        # Drop DOI duplicates\n",
    "        df_v15_dedup = df_v15.drop_duplicates(subset=['bs_norm_doi'], keep='first')\n",
    "        \n",
    "        # Now Drop Title duplicates from the result\n",
    "        # Handle empty titles carefully (don't dedup empty strings against each other as one group)\n",
    "        with_title = df_v15_dedup[df_v15_dedup['bs_norm_title'] != '']\n",
    "        no_title = df_v15_dedup[df_v15_dedup['bs_norm_title'] == '']\n",
    "        \n",
    "        with_title_dedup = with_title.drop_duplicates(subset=['bs_norm_title'], keep='first')\n",
    "        \n",
    "        df_clean = pd.concat([with_title_dedup, no_title], ignore_index=True)\n",
    "        \n",
    "        # --- 5. Cleanup and Save ---\n",
    "        \n",
    "        # Remove helper columns\n",
    "        clean_cols = [c for c in df_clean.columns if not c.startswith('bs_')]\n",
    "        df_clean = df_clean[clean_cols]\n",
    "        \n",
    "        final_count = len(df_clean)\n",
    "        dropped_count = initial_count - final_count\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Original Count: {initial_count}\")\n",
    "        print(f\"Dropped:        {dropped_count} (Worse copies removed)\")\n",
    "        print(f\"Final Count:    {final_count}\")\n",
    "        \n",
    "        df_clean.to_csv(output_file_v15, sep='\\t', index=False)\n",
    "        print(f\"Saved optimized dataset to {output_file_v15}\")\n",
    "\n",
    "        # Strict Check\n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            print(f\"\\nSource Public Deduplicated JSON entries: {len(json_data)}\")\n",
    "            if len(df_clean) == len(json_data):\n",
    "                print(\"SUCCESS: Final count matches Source JSON count exactly.\")\n",
    "            else:\n",
    "                 diff = len(df_clean) - len(json_data)\n",
    "                 print(f\"Note: Count difference is {diff}.\")\n",
    "                 \n",
    "        except Exception as e:\n",
    "            print(f\"Error checking JSON: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in deduplication: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e1de7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying final system flags...\n",
      "Loaded 270 records from v15_Dome-Recommendations-Best_Candidate_Retained.tsv\n",
      "Updated columns: 'publication/done' (0.0), 'publication/skip' (0.0), 'public' (1.0)\n",
      "Saved final prepared dataset to v16_Dome-Recommendations-Import_Ready_With_Flags.tsv\n"
     ]
    }
   ],
   "source": [
    "# 18b. Final Formatting: Set System Flags\n",
    "# Objective: Reset workflow flags and ensure public visibility for the final dataset.\n",
    "\n",
    "print(\"Applying final system flags...\")\n",
    "\n",
    "input_file = \"v15_Dome-Recommendations-Best_Candidate_Retained.tsv\"\n",
    "output_file_v16 = \"v16_Dome-Recommendations-Import_Ready_With_Flags.tsv\"\n",
    "\n",
    "try:\n",
    "    if os.path.exists(input_file):\n",
    "        df_flags = pd.read_csv(input_file, sep='\\t')\n",
    "        print(f\"Loaded {len(df_flags)} records from {input_file}\")\n",
    "        \n",
    "        # Apply Flags as requested\n",
    "        # publication/done -> 0.0\n",
    "        # publication/skip -> 0.0\n",
    "        # public -> 1.0\n",
    "        \n",
    "        df_flags['publication/done'] = 0.0\n",
    "        df_flags['publication/skip'] = 0.0\n",
    "        df_flags['public'] = 1.0\n",
    "        \n",
    "        print(\"Updated columns: 'publication/done' (0.0), 'publication/skip' (0.0), 'public' (1.0)\")\n",
    "        \n",
    "        # Save\n",
    "        df_flags.to_csv(output_file_v16, sep='\\t', index=False)\n",
    "        print(f\"Saved final prepared dataset to {output_file_v16}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {input_file} not found. Please run previous cell.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error applying flags: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "824e73ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Metadata Remediation (PMID/PMCID Injection)...\n",
      "Loaded target dataset: 270 records.\n",
      "Loaded source registry: 280 records.\n",
      "Source Columns Identified - DOI: publication_doi, Title: publication_title\n",
      "------------------------------\n",
      "Results of Metadata Remediation:\n",
      "  Processed 270 records.\n",
      "  PMIDs Filled:   27\n",
      "  PMCIDs Filled:  107\n",
      "  Total PMIDs:    262\n",
      "  Total PMCIDs:   237\n",
      "  Conflicts Found: 3\n",
      "Saved remediated dataset to v17_Dome-Recommendations-Remediated_Metadata.tsv\n",
      "Saved conflict details to v17_Metadata_Conflict_Report.tsv\n",
      "Saved 8 records with missing PMIDs to v17_Missing_PMID_Report.tsv\n"
     ]
    }
   ],
   "source": [
    "# 19. Metadata Remediation: Enforce PMCID/PMID from External Registry (Version 17)\n",
    "# Objective: Augment v16 dataset with PMCIDs and PMIDs from 'PMCIDs_DOME_Registry_Contents_2026-01-09.tsv'\n",
    "# Match Logic: DOI (Primary) and Title (Secondary verification)\n",
    "# Action: Fill missing values. Flag conflicts where existing value differs from source.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Starting Metadata Remediation (PMID/PMCID Injection)...\")\n",
    "\n",
    "input_file_v16 = \"v16_Dome-Recommendations-Import_Ready_With_Flags.tsv\"\n",
    "source_registry_file = \"../DOME_Registry_TSV_Files/PMCIDs_DOME_Registry_Contents_2026-01-09.tsv\"\n",
    "output_file_v17 = \"v17_Dome-Recommendations-Remediated_Metadata.tsv\"\n",
    "conflict_report_file = \"v17_Metadata_Conflict_Report.tsv\"\n",
    "missing_pmid_file = \"v17_Missing_PMID_Report.tsv\"\n",
    "\n",
    "try:\n",
    "    # 1. Load Datasets\n",
    "    if os.path.exists(input_file_v16):\n",
    "        df_target = pd.read_csv(input_file_v16, sep='\\t')\n",
    "        print(f\"Loaded target dataset: {len(df_target)} records.\")\n",
    "    else:\n",
    "        print(f\"Error: {input_file_v16} not found.\")\n",
    "        df_target = pd.DataFrame()\n",
    "        \n",
    "    if os.path.exists(source_registry_file):\n",
    "        df_source = pd.read_csv(source_registry_file, sep='\\t')\n",
    "        print(f\"Loaded source registry: {len(df_source)} records.\")\n",
    "    else:\n",
    "        # Try absolute path just in case notebook relative path fails\n",
    "        abs_path = os.path.abspath(os.path.join(os.getcwd(), source_registry_file))\n",
    "        if os.path.exists(abs_path):\n",
    "             df_source = pd.read_csv(abs_path, sep='\\t')\n",
    "             print(f\"Loaded source registry (abs path): {len(df_source)} records.\")\n",
    "        else:\n",
    "            print(f\"Error: Registry file not found at {source_registry_file}\")\n",
    "            df_source = pd.DataFrame()\n",
    "\n",
    "    if not df_target.empty and not df_source.empty:\n",
    "        \n",
    "        # 2. Prepare Source Dictionary for Fast Lookup\n",
    "        # Normalize Keys\n",
    "        def normalize_key(text):\n",
    "            if not isinstance(text, str): return \"\"\n",
    "            return \"\".join(c for c in text if c.isalnum()).lower()\n",
    "\n",
    "        # We will index source by DOI\n",
    "        source_cols = df_source.columns\n",
    "        # Identify correct columns in source\n",
    "        # User said: mapped_pmcid and mapped_pmid\n",
    "        # We need to find the DOI column in source\n",
    "        doi_col_source = next((c for c in source_cols if 'doi' in c.lower()), None)\n",
    "        title_col_source = next((c for c in source_cols if 'title' in c.lower()), None)\n",
    "        \n",
    "        print(f\"Source Columns Identified - DOI: {doi_col_source}, Title: {title_col_source}\")\n",
    "\n",
    "        source_lookup = {}\n",
    "        for idx, row in df_source.iterrows():\n",
    "            if doi_col_source:\n",
    "                doi_norm = normalize_key(str(row[doi_col_source]))\n",
    "                if doi_norm:\n",
    "                    source_lookup[doi_norm] = {\n",
    "                        'pmid': str(row.get('mapped_pmid', '')),\n",
    "                        'pmcid': str(row.get('mapped_pmcid', '')),\n",
    "                        'title': str(row.get(title_col_source, '')) if title_col_source else ''\n",
    "                    }\n",
    "\n",
    "        # 3. Iterate and Update Target\n",
    "        # Counters\n",
    "        count_updated_pmid = 0\n",
    "        count_updated_pmcid = 0\n",
    "        count_conflicts = 0\n",
    "        conflicts = []\n",
    "\n",
    "        # Ensure target columns exist\n",
    "        if 'publication/pmid' not in df_target.columns: df_target['publication/pmid'] = None\n",
    "        if 'publication/pmcid' not in df_target.columns: df_target['publication/pmcid'] = None\n",
    "\n",
    "        for idx, row in df_target.iterrows():\n",
    "            target_doi = normalize_key(str(row.get('publication/doi', '')))\n",
    "            \n",
    "            if target_doi in source_lookup:\n",
    "                src_data = source_lookup[target_doi]\n",
    "                \n",
    "                # --- PMID Logic ---\n",
    "                curr_pmid = str(row.get('publication/pmid', '')).replace('nan', '').replace('.0', '').strip()\n",
    "                new_pmid = src_data['pmid'].replace('nan', '').replace('.0', '').strip()\n",
    "                \n",
    "                if new_pmid:\n",
    "                    if not curr_pmid:\n",
    "                        # Fill missing\n",
    "                        df_target.at[idx, 'publication/pmid'] = new_pmid\n",
    "                        count_updated_pmid += 1\n",
    "                    elif curr_pmid != new_pmid:\n",
    "                        # Conflict\n",
    "                        count_conflicts += 1\n",
    "                        conflicts.append({\n",
    "                            'index': idx,\n",
    "                            'doi': row.get('publication/doi'),\n",
    "                            'field': 'PMID',\n",
    "                            'current_value': curr_pmid,\n",
    "                            'registry_value': new_pmid,\n",
    "                            'source_title_check': src_data['title']\n",
    "                        })\n",
    "\n",
    "                # --- PMCID Logic ---\n",
    "                curr_pmcid = str(row.get('publication/pmcid', '')).replace('nan', '').strip()\n",
    "                new_pmcid = src_data['pmcid'].replace('nan', '').strip()\n",
    "                \n",
    "                if new_pmcid:\n",
    "                    if not curr_pmcid:\n",
    "                        # Fill missing\n",
    "                        df_target.at[idx, 'publication/pmcid'] = new_pmcid\n",
    "                        count_updated_pmcid += 1\n",
    "                    elif curr_pmcid != new_pmcid:\n",
    "                        # Conflict\n",
    "                        count_conflicts += 1\n",
    "                        conflicts.append({\n",
    "                            'index': idx,\n",
    "                            'doi': row.get('publication/doi'),\n",
    "                            'field': 'PMCID',\n",
    "                            'current_value': curr_pmcid,\n",
    "                            'registry_value': new_pmcid,\n",
    "                            'source_title_check': src_data['title']\n",
    "                        })\n",
    "        \n",
    "        # Calculate Totals\n",
    "        def has_value(val):\n",
    "            s = str(val).lower().strip().replace('nan', '').replace('.0', '')\n",
    "            return s != ''\n",
    "\n",
    "        total_pmids = df_target['publication/pmid'].apply(has_value).sum()\n",
    "        total_pmcids = df_target['publication/pmcid'].apply(has_value).sum()\n",
    "\n",
    "        # 4. Save Results\n",
    "        df_target.to_csv(output_file_v17, sep='\\t', index=False)\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Results of Metadata Remediation:\")\n",
    "        print(f\"  Processed {len(df_target)} records.\")\n",
    "        print(f\"  PMIDs Filled:   {count_updated_pmid}\")\n",
    "        print(f\"  PMCIDs Filled:  {count_updated_pmcid}\")\n",
    "        print(f\"  Total PMIDs:    {total_pmids}\")\n",
    "        print(f\"  Total PMCIDs:   {total_pmcids}\")\n",
    "        print(f\"  Conflicts Found: {count_conflicts}\")\n",
    "        print(f\"Saved remediated dataset to {output_file_v17}\")\n",
    "        \n",
    "        # 5. Save Conflicts\n",
    "        if conflicts:\n",
    "            df_conflicts = pd.DataFrame(conflicts)\n",
    "            df_conflicts.to_csv(conflict_report_file, sep='\\t', index=False)\n",
    "            print(f\"Saved conflict details to {conflict_report_file}\")\n",
    "        else:\n",
    "            print(\"No conflicts detected.\")\n",
    "            \n",
    "        # 6. Save Missing PMID Report\n",
    "        # Filter for rows where has_value is False for PMID\n",
    "        missing_pmid_mask = ~df_target['publication/pmid'].apply(has_value)\n",
    "        df_missing_pmid = df_target[missing_pmid_mask].copy()\n",
    "\n",
    "        if not df_missing_pmid.empty:\n",
    "            # Columns to export\n",
    "            export_cols = ['publication/title', 'publication/journal', 'publication/doi']\n",
    "            # Only include columns that actually exist in the dataframe\n",
    "            final_export_cols = [c for c in export_cols if c in df_missing_pmid.columns]\n",
    "            \n",
    "            df_missing_pmid[final_export_cols].to_csv(missing_pmid_file, sep='\\t', index=False)\n",
    "            print(f\"Saved {len(df_missing_pmid)} records with missing PMIDs to {missing_pmid_file}\")\n",
    "        else:\n",
    "            print(\"Great news! No records are missing PMIDs.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in metadata remediation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53da951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7a6d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: 270 records\n",
      "Total items needing remediation: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353595423abc4ce8b1d4203d31c18080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Search DOI:', placeholder='Paste DOI here'), Button(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20. Manual Metadata Remediation Interface (Version 18 Preview)\n",
    "# Objective: Interactive widget to manually resolve missing PMIDs and conflicts identified in Step 19.\n",
    "# Features:\n",
    "# - Loads v17 dataset.\n",
    "# - Targets rows with missing PMIDs or reported conflicts.\n",
    "# - Persists progress to 'v18_Remediation_Log.json' to avoid re-doing work.\n",
    "# - Allows DOI search.\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "input_file = \"v17_Dome-Recommendations-Remediated_Metadata.tsv\"\n",
    "conflict_file = \"v17_Metadata_Conflict_Report.tsv\"\n",
    "progress_log_file = \"v18_Remediation_Log.json\"\n",
    "output_file = \"v18_Dome-Recommendations-Manual_Remediated.tsv\"\n",
    "\n",
    "# --- Load Data ---\n",
    "if os.path.exists(input_file):\n",
    "    df_work = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded dataset: {len(df_work)} records\")\n",
    "else:\n",
    "    print(\"Error: v17 file not found. Run Step 19 first.\")\n",
    "    df_work = pd.DataFrame()\n",
    "\n",
    "# Verify Columns\n",
    "if 'publication/pmid' not in df_work.columns: df_work['publication/pmid'] = \"\"\n",
    "if 'publication/pmcid' not in df_work.columns: df_work['publication/pmcid'] = \"\"\n",
    "\n",
    "# Load Conflicts (to prioritize)\n",
    "conflict_indices = set()\n",
    "if os.path.exists(conflict_file):\n",
    "    try:\n",
    "        df_conflicts = pd.read_csv(conflict_file, sep='\\t')\n",
    "        # Assuming we can key by DOI if index changed, but v17 should align with v17 report if not sorted.\n",
    "        # Best to match by DOI since indices might shift if file reloaded? \n",
    "        # Actually v17 was saved right after v17 report generation in Step 19 with no re-sort.\n",
    "        # We'll use DOI matching to be safe.\n",
    "        conflict_dois = set(df_conflicts['doi'].dropna().astype(str).str.lower().str.strip())\n",
    "    except:\n",
    "        conflict_dois = set()\n",
    "else:\n",
    "    conflict_dois = set()\n",
    "\n",
    "# Load Progress\n",
    "remediation_log = {}\n",
    "if os.path.exists(progress_log_file):\n",
    "    with open(progress_log_file, 'r') as f:\n",
    "        remediation_log = json.load(f)\n",
    "    print(f\"Loaded existing progress: {len(remediation_log)} entries resolved.\")\n",
    "\n",
    "# --- Identify Work Queue ---\n",
    "# Criteria: \n",
    "# 1. DOI is in conflict list OR\n",
    "# 2. PMID is missing (empty or nan)\n",
    "# AND\n",
    "# 3. DOI is NOT in remediation_log\n",
    "\n",
    "def get_doi(row):\n",
    "    return str(row.get('publication/doi', '')).strip()\n",
    "\n",
    "def needs_remediation(row):\n",
    "    doi = get_doi(row)\n",
    "    if not doi: return False # Skip empty DOI rows\n",
    "    if doi in remediation_log: return False # Already done\n",
    "    \n",
    "    # Check conflict\n",
    "    is_conflict = doi.lower() in conflict_dois\n",
    "    \n",
    "    # Check missing PMID\n",
    "    pmid = str(row.get('publication/pmid', ''))\n",
    "    is_missing = pmid.lower() in ['nan', '', 'none', '.0']\n",
    "    \n",
    "    return is_conflict or is_missing\n",
    "\n",
    "# Create a queue of indices\n",
    "df_work['temp_doi_key'] = df_work['publication/doi'].astype(str).str.strip()\n",
    "queue_indices = [i for i, row in df_work.iterrows() if needs_remediation(row)]\n",
    "\n",
    "print(f\"Total items needing remediation: {len(queue_indices)}\")\n",
    "\n",
    "# --- Interface Logic ---\n",
    "\n",
    "current_q_index = 0\n",
    "\n",
    "# Widgets\n",
    "output_area = widgets.Output()\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "w_doi_display = widgets.HTML(value=\"<b>DOI:</b> ...\")\n",
    "w_title_display = widgets.HTML(value=\"<b>Title:</b> ...\")\n",
    "w_journal_display = widgets.HTML(value=\"<b>Journal:</b> ...\")\n",
    "w_status_display = widgets.HTML(value=\"\")\n",
    "\n",
    "w_pmid_input = widgets.Text(description=\"PMID:\", style=style)\n",
    "w_pmcid_input = widgets.Text(description=\"PMCID:\", style=style)\n",
    "\n",
    "w_save_btn = widgets.Button(description=\"Save & Next\", button_style='success')\n",
    "w_skip_btn = widgets.Button(description=\"Skip\", button_style='warning')\n",
    "w_stop_btn = widgets.Button(description=\"Stop & Export\", button_style='danger')\n",
    "\n",
    "w_search_input = widgets.Text(description=\"Search DOI:\", placeholder=\"Paste DOI here\")\n",
    "w_search_btn = widgets.Button(description=\"Find\")\n",
    "\n",
    "# Helper to get current actual dataframe index\n",
    "def get_current_idx():\n",
    "    if 0 <= current_q_index < len(queue_indices):\n",
    "        return queue_indices[current_q_index]\n",
    "    return None\n",
    "\n",
    "def load_entry(idx):\n",
    "    if idx is None:\n",
    "        w_status_display.value = \"<b>Queue Complete!</b>\"\n",
    "        return\n",
    "\n",
    "    row = df_work.loc[idx]\n",
    "    doi = str(row.get('publication/doi', ''))\n",
    "    title = str(row.get('publication/title', ''))\n",
    "    journal = str(row.get('publication/journal', ''))\n",
    "    \n",
    "    curr_pmid = str(row.get('publication/pmid', '')).replace('nan', '')\n",
    "    curr_pmcid = str(row.get('publication/pmcid', '')).replace('nan', '')\n",
    "\n",
    "    w_doi_display.value = f\"<b>DOI:</b> <a href='https://doi.org/{doi}' target='_blank'>{doi}</a> (Index: {idx})\"\n",
    "    w_title_display.value = f\"<b>Title:</b> {title}\"\n",
    "    w_journal_display.value = f\"<b>Journal:</b> {journal}\"\n",
    "    \n",
    "    # Check if conflict\n",
    "    if doi.lower() in conflict_dois:\n",
    "        w_status_display.value = \"<span style='color:red'><b>CONFLICT DETECTED</b> check sources</span>\"\n",
    "    elif curr_pmid == \"\":\n",
    "        w_status_display.value = \"<span style='color:orange'>Missing PMID</span>\"\n",
    "    else:\n",
    "        w_status_display.value = \"Review mode\"\n",
    "\n",
    "    # Pre-fill inputs with current values\n",
    "    w_pmid_input.value = curr_pmid\n",
    "    w_pmcid_input.value = curr_pmcid\n",
    "\n",
    "def save_current(_):\n",
    "    global current_q_index\n",
    "    idx = get_current_idx()\n",
    "    if idx is None: return\n",
    "\n",
    "    row = df_work.loc[idx]\n",
    "    doi = str(row.get('publication/doi', '')).strip()\n",
    "    \n",
    "    # Get values\n",
    "    new_pmid = w_pmid_input.value.strip()\n",
    "    new_pmcid = w_pmcid_input.value.strip()\n",
    "    \n",
    "    # Update DataFrame\n",
    "    df_work.at[idx, 'publication/pmid'] = new_pmid\n",
    "    df_work.at[idx, 'publication/pmcid'] = new_pmcid\n",
    "    \n",
    "    # Log persistence\n",
    "    if doi:\n",
    "        remediation_log[doi] = {\n",
    "            'pmid': new_pmid,\n",
    "            'pmcid': new_pmcid,\n",
    "            'action': 'manual_update'\n",
    "        }\n",
    "        # Save log immediately\n",
    "        with open(progress_log_file, 'w') as f:\n",
    "            json.dump(remediation_log, f, indent=2)\n",
    "    \n",
    "    # Move next\n",
    "    current_q_index += 1\n",
    "    if current_q_index < len(queue_indices):\n",
    "        load_entry(queue_indices[current_q_index])\n",
    "    else:\n",
    "        w_status_display.value = \"Queue Complete! Click Stop & Export.\"\n",
    "\n",
    "def skip_current(_):\n",
    "    global current_q_index\n",
    "    # Just move next without saving to log (so it appears again) or mark as skipped?\n",
    "    # User said \"If raren it will chekc all reolved\". \n",
    "    # If we skip, maybe we should mark it as skipped in log so it doesn't show up again?\n",
    "    # Let's assume 'Skip' means 'I'll do it later', so don't add to log.\n",
    "    \n",
    "    current_q_index += 1\n",
    "    if current_q_index < len(queue_indices):\n",
    "        load_entry(queue_indices[current_q_index])\n",
    "    else:\n",
    "        w_status_display.value = \"Queue Complete!\"\n",
    "\n",
    "def export_data(_):\n",
    "    # Apply all logs to df_work one last time to be sure\n",
    "    print(\"Applying log to dataset...\")\n",
    "    for doi, data in remediation_log.items():\n",
    "        # Find index by DOI\n",
    "        matches = df_work[df_work['temp_doi_key'] == doi].index\n",
    "        for m_idx in matches:\n",
    "            df_work.at[m_idx, 'publication/pmid'] = data.get('pmid', '')\n",
    "            df_work.at[m_idx, 'publication/pmcid'] = data.get('pmcid', '')\n",
    "    \n",
    "    # Drop temp col\n",
    "    if 'temp_doi_key' in df_work.columns:\n",
    "        df_work.drop(columns=['temp_doi_key'], inplace=True)\n",
    "        \n",
    "    df_work.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Exported remediated dataset to {output_file}\")\n",
    "    with output_area:\n",
    "        print(f\"Saved {output_file}\")\n",
    "\n",
    "def search_doi(_):\n",
    "    search_term = w_search_input.value.strip()\n",
    "    if not search_term: return\n",
    "    \n",
    "    # Find in df_work\n",
    "    # Check DOI column string match\n",
    "    matches = df_work[df_work['publication/doi'].astype(str).str.contains(search_term, case=False, na=False)]\n",
    "    \n",
    "    if not matches.empty:\n",
    "        found_idx = matches.index[0]\n",
    "        # Load this entry specifically, bypassing queue logic mainly for display\n",
    "        # But we need to update 'current_q_index' to make 'Save' work.\n",
    "        # If the found item is in our queue, sync to it.\n",
    "        # If not, we might be editing something already resolved or not in queue.\n",
    "        \n",
    "        # Simple approach: Identify if found_idx is in queue_indices\n",
    "        if found_idx in queue_indices:\n",
    "            global current_q_index\n",
    "            current_q_index = queue_indices.index(found_idx)\n",
    "            load_entry(found_idx)\n",
    "            w_status_display.value += \" (Found in Queue)\"\n",
    "        else:\n",
    "            # It's not in the queue, but we want to edit it.\n",
    "            # We can force load it\n",
    "            load_entry(found_idx)\n",
    "            w_status_display.value = \"<b>Manually Loaded (Not in active queue)</b>\"\n",
    "            \n",
    "            # Monkey-patch get_current_idx for this one-off edit\n",
    "            global get_current_idx_override\n",
    "            get_current_idx_override = found_idx\n",
    "            \n",
    "            # We need to handle the Save button logic differently or update state\n",
    "            # For simplicity, we won't fully support \"next\" after a manual search result that isn't in queue.\n",
    "            # But the user asked to \"search by doi\".\n",
    "            \n",
    "    else:\n",
    "        w_status_display.value = f\"DOI '{search_term}' not found.\"\n",
    "\n",
    "# Wire up events\n",
    "w_save_btn.on_click(save_current)\n",
    "w_skip_btn.on_click(skip_current)\n",
    "w_stop_btn.on_click(export_data)\n",
    "w_search_btn.on_click(search_doi)\n",
    "\n",
    "# Layout\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([w_search_input, w_search_btn]),\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    w_doi_display,\n",
    "    w_title_display,\n",
    "    w_journal_display,\n",
    "    w_status_display,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    w_pmid_input,\n",
    "    w_pmcid_input,\n",
    "    widgets.HBox([w_save_btn, w_skip_btn, w_stop_btn]),\n",
    "    output_area\n",
    "])\n",
    "\n",
    "# Initialize\n",
    "if queue_indices:\n",
    "    load_entry(queue_indices[0])\n",
    "    display(ui)\n",
    "else:\n",
    "    print(\"All conflicts and missing PMIDs resolved! Check output.\")\n",
    "    export_data(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "444b63a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating formats in v18_Dome-Recommendations-Manual_Remediated.tsv...\n",
      "------------------------------\n",
      "Validation Results:\n",
      "PMID: 264 -> 263 valid. (Removed 1)\n",
      "PMCID: 238 -> 238 valid. (Removed 0)\n",
      "Saved validated file to v19_Dome-Recommendations-Format_Validated.tsv\n",
      "Saved invalid inputs report to v19_Invalid_IDs_Dropped.tsv\n"
     ]
    }
   ],
   "source": [
    "# 21. Final Format Validation (PMID/PMCID)\n",
    "# Purpose: Ensure strict formatting for ID columns before import.\n",
    "# Rules:\n",
    "# - PMID: Must be numeric digits only.\n",
    "# - PMCID: Must start with 'PMC' followed by digits.\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Determine input file (prioritize Manual output, fall back to Auto output)\n",
    "input_file = \"v18_Dome-Recommendations-Manual_Remediated.tsv\"\n",
    "if not os.path.exists(input_file):\n",
    "    print(f\"{input_file} not found, checking v17...\")\n",
    "    input_file = \"v17_Dome-Recommendations-Remediated_Metadata.tsv\"\n",
    "\n",
    "output_file = \"v19_Dome-Recommendations-Format_Validated.tsv\"\n",
    "dropped_report = \"v19_Invalid_IDs_Dropped.tsv\"\n",
    "\n",
    "print(f\"Validating formats in {input_file}...\")\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    \n",
    "    dropped_log = []\n",
    "\n",
    "    # 1. Validate PMID\n",
    "    def validate_pmid(row, idx):\n",
    "        val = row.get('publication/pmid')\n",
    "        s = str(val).strip()\n",
    "        \n",
    "        # Cleanup float conversions\n",
    "        if s.endswith('.0'): s = s[:-2]\n",
    "        \n",
    "        # Check emptiness\n",
    "        if s.lower() in ['nan', 'none', '', '<na>']: return None\n",
    "        \n",
    "        # Rules: Digits only\n",
    "        if re.match(r'^\\d+$', s):\n",
    "            return s\n",
    "        \n",
    "        # Log Drop\n",
    "        dropped_log.append({\n",
    "            'index': idx,\n",
    "            'doi': row.get('publication/doi'),\n",
    "            'field': 'PMID',\n",
    "            'value': s,\n",
    "            'reason': 'Not numeric'\n",
    "        })\n",
    "        return None\n",
    "\n",
    "    # 2. Validate PMCID\n",
    "    def validate_pmcid(row, idx):\n",
    "        val = row.get('publication/pmcid')\n",
    "        s = str(val).strip()\n",
    "        \n",
    "        if s.lower() in ['nan', 'none', '', '<na>']: return None\n",
    "        \n",
    "        # Rules: Must start with PMC and be followed by digits\n",
    "        # Allow case insensitive input, standardize to uppercase\n",
    "        if re.match(r'^PMC\\d+$', s, re.IGNORECASE):\n",
    "            return s.upper()\n",
    "        \n",
    "        # Log Drop\n",
    "        dropped_log.append({\n",
    "            'index': idx,\n",
    "            'doi': row.get('publication/doi'),\n",
    "            'field': 'PMCID',\n",
    "            'value': s,\n",
    "            'reason': 'Invalid format (Expected PMC#)'\n",
    "        })\n",
    "        return None\n",
    "\n",
    "    # Track counts\n",
    "    pmid_count_start = df['publication/pmid'].notna() & (df['publication/pmid'].astype(str) != 'nan')\n",
    "    pmcid_count_start = df['publication/pmcid'].notna() & (df['publication/pmcid'].astype(str) != 'nan')\n",
    "    \n",
    "    # Apply validations\n",
    "    # Using list comprehensions for cleaner index access in logging\n",
    "    new_pmids = [validate_pmid(row, i) for i, row in df.iterrows()]\n",
    "    new_pmcids = [validate_pmcid(row, i) for i, row in df.iterrows()]\n",
    "    \n",
    "    df['publication/pmid'] = new_pmids\n",
    "    df['publication/pmcid'] = new_pmcids\n",
    "    \n",
    "    # Check results\n",
    "    pmid_count_end = df['publication/pmid'].notna().sum()\n",
    "    pmcid_count_end = df['publication/pmcid'].notna().sum()\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Validation Results:\")\n",
    "    print(f\"PMID: {pmid_count_start.sum()} -> {pmid_count_end} valid. (Removed {len([x for x in dropped_log if x['field']=='PMID'])})\")\n",
    "    print(f\"PMCID: {pmcid_count_start.sum()} -> {pmcid_count_end} valid. (Removed {len([x for x in dropped_log if x['field']=='PMCID'])})\")\n",
    "    \n",
    "    # Save Main File\n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Saved validated file to {output_file}\")\n",
    "    \n",
    "    # Save Drop Log\n",
    "    if dropped_log:\n",
    "        pd.DataFrame(dropped_log).to_csv(dropped_report, sep='\\t', index=False)\n",
    "        print(f\"Saved invalid inputs report to {dropped_report}\")\n",
    "    else:\n",
    "        print(\"No invalid formats found.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Could not find input file {input_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ede2ae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 270 records from v19_Dome-Recommendations-Format_Validated.tsv\n",
      "Found 263 unique PMIDs to query.\n",
      "Querying EPMC API...\n",
      "  Batch 250-263 / 263...\n",
      "API Retrieval Complete. Retrieved metadata for 262 PMIDs.\n",
      "Applying updates to dataframe...\n",
      "------------------------------\n",
      "Overwrite Complete.\n",
      "Updated 262 records with EPMC data.\n",
      "Saved to v20_Dome-Recommendations-EPMC_Metadata.tsv\n",
      "Saved retrieval log to v20_EPMC_Retrieval_Log.tsv\n"
     ]
    }
   ],
   "source": [
    "# 22. EPMC Metadata Overwrite (Version 20)\n",
    "# Objective: Query Europe PMC API using valid PMIDs from v19 to overwrite Title, Journal, Authors, and DOI.\n",
    "# Rationale: Ensure high-quality, consistent metadata from the source of truth (EPMC).\n",
    "# Fix: includes robust handling for float-string conversion (e.g. '12345.0') when reading CSVs.\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "input_file = \"v19_Dome-Recommendations-Format_Validated.tsv\"\n",
    "output_file = \"v20_Dome-Recommendations-EPMC_Metadata.tsv\"\n",
    "epmc_log_file = \"v20_EPMC_Retrieval_Log.tsv\"\n",
    "\n",
    "# EPMC API Endpoint\n",
    "EPMC_API_URL = \"https://www.ebi.ac.uk/europepmc/webservices/rest/search\"\n",
    "\n",
    "def get_epmc_batch_metadata(pmid_list):\n",
    "    if not pmid_list: return {}\n",
    "    \n",
    "    # Construct Query: EXT_ID:123 OR EXT_ID:456 ...\n",
    "    # API limits: URL length. keep batches reasonable (e.g., 20-25)\n",
    "    query_parts = [f\"EXT_ID:{p}\" for p in pmid_list]\n",
    "    query = \" OR \".join(query_parts)\n",
    "    \n",
    "    params = {\n",
    "        'query': query,\n",
    "        'format': 'json',\n",
    "        'resultType': 'core',\n",
    "        'pageSize': len(pmid_list)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(EPMC_API_URL, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        results = {}\n",
    "        if 'resultList' in data and 'result' in data['resultList']:\n",
    "            for item in data['resultList']['result']:\n",
    "                # Key by PMID\n",
    "                p = item.get('pmid')\n",
    "                if p:\n",
    "                    results[str(p)] = {\n",
    "                        'title': item.get('title', ''),\n",
    "                        'journal': item.get('journalInfo', {}).get('journal', {}).get('title', ''),\n",
    "                        'authors': item.get('authorString', ''),\n",
    "                        'doi': item.get('doi', '')\n",
    "                    }\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"API Request failed for batch: {e}\")\n",
    "        return {}\n",
    "\n",
    "def robust_pmid_clean(val):\n",
    "    \"\"\"Clean PMID string, handling floats and NaNs common in CSV reads.\"\"\"\n",
    "    s = str(val).strip()\n",
    "    if s.lower() in ['nan', 'none', '', '<na>']:\n",
    "        return None\n",
    "    # Remove .0 artifact if pandas read it as float\n",
    "    if s.endswith('.0'):\n",
    "        s = s[:-2]\n",
    "    # Verify it is digits\n",
    "    if s.isdigit():\n",
    "        return s\n",
    "    return None\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded {len(df)} records from {input_file}\")\n",
    "    \n",
    "    # Ensure author column exists\n",
    "    if 'publication/authors' not in df.columns:\n",
    "        print(\"Adding 'publication/authors' column...\")\n",
    "        df['publication/authors'] = \"\"\n",
    "\n",
    "    # Robust extraction of unique PMIDs\n",
    "    unique_pmids = set()\n",
    "    if 'publication/pmid' in df.columns:\n",
    "        for val in df['publication/pmid']:\n",
    "            cleaned = robust_pmid_clean(val)\n",
    "            if cleaned:\n",
    "                unique_pmids.add(cleaned)\n",
    "    \n",
    "    valid_pmids = sorted(list(unique_pmids))\n",
    "    \n",
    "    print(f\"Found {len(valid_pmids)} unique PMIDs to query.\")\n",
    "    \n",
    "    if valid_pmids:\n",
    "        # Batch Processing\n",
    "        BATCH_SIZE = 25\n",
    "        epmc_data_map = {}\n",
    "        retrieval_log = []\n",
    "        \n",
    "        print(\"Querying EPMC API...\")\n",
    "        for i in range(0, len(valid_pmids), BATCH_SIZE):\n",
    "            batch = valid_pmids[i:i+BATCH_SIZE]\n",
    "            print(f\"  Batch {i}-{min(i+BATCH_SIZE, len(valid_pmids))} / {len(valid_pmids)}...\", end='\\r')\n",
    "            \n",
    "            results = get_epmc_batch_metadata(batch)\n",
    "            epmc_data_map.update(results)\n",
    "            \n",
    "            time.sleep(0.3) # Politeness delay\n",
    "            \n",
    "        print(f\"\\nAPI Retrieval Complete. Retrieved metadata for {len(epmc_data_map)} PMIDs.\")\n",
    "        \n",
    "        # Apply Updates\n",
    "        updated_count = 0\n",
    "        \n",
    "        print(\"Applying updates to dataframe...\")\n",
    "        for idx, row in df.iterrows():\n",
    "            pmid = robust_pmid_clean(row.get('publication/pmid'))\n",
    "            \n",
    "            if pmid and pmid in epmc_data_map:\n",
    "                meta = epmc_data_map[pmid]\n",
    "                \n",
    "                # Capture old values for logging\n",
    "                old_title = str(row.get('publication/title', ''))\n",
    "                old_doi = str(row.get('publication/doi', ''))\n",
    "                \n",
    "                # Overwrite\n",
    "                df.at[idx, 'publication/title'] = meta['title']\n",
    "                \n",
    "                # Standardize journal name? Keeping raw from EPMC for now\n",
    "                current_j = str(row.get('publication/journal', ''))\n",
    "                # Only update journal if currently missing? Or always?\n",
    "                # \"overwrite the respective tsv fields\" -> implies Always\n",
    "                df.at[idx, 'publication/journal'] = meta['journal']\n",
    "                \n",
    "                df.at[idx, 'publication/authors'] = meta['authors']\n",
    "                \n",
    "                # Update DOI if present in EPMC\n",
    "                current_doi = old_doi\n",
    "                new_doi = current_doi\n",
    "                if meta['doi']:\n",
    "                    df.at[idx, 'publication/doi'] = meta['doi']\n",
    "                    new_doi = meta['doi']\n",
    "\n",
    "                updated_count += 1\n",
    "                \n",
    "                retrieval_log.append({\n",
    "                    'pmid': pmid,\n",
    "                    'old_title': old_title,\n",
    "                    'new_title': meta['title'],\n",
    "                    'old_doi': old_doi,\n",
    "                    'new_doi': new_doi\n",
    "                })\n",
    "                \n",
    "        # Save\n",
    "        df.to_csv(output_file, sep='\\t', index=False)\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Overwrite Complete.\")\n",
    "        print(f\"Updated {updated_count} records with EPMC data.\")\n",
    "        print(f\"Saved to {output_file}\")\n",
    "        \n",
    "        # Save Log\n",
    "        if retrieval_log:\n",
    "            pd.DataFrame(retrieval_log).to_csv(epmc_log_file, sep='\\t', index=False)\n",
    "            print(f\"Saved retrieval log to {epmc_log_file}\")\n",
    "    else:\n",
    "        print(\"No valid PMIDs found to process. Saving copy of input to v20.\")\n",
    "        df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "else:\n",
    "    print(f\"Input file {input_file} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25029815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "461f5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 270 records from v20_Dome-Recommendations-EPMC_Metadata.tsv\n",
      "Setting 'publication/updated' to: 02/02/2026 19:46:52\n",
      "Saved final dataset to v21_Dome-Recommendations-Ready_For_Import.tsv\n"
     ]
    }
   ],
   "source": [
    "# 23. Update Timestamp (Version 21)\n",
    "# Objective: Set 'publication/updated' to the current date and time for all records.\n",
    "# Format: MM/DD/YYYY HH:MM:SS (e.g., 06/23/2022 03:07:23)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "input_file = \"v20_Dome-Recommendations-EPMC_Metadata.tsv\"\n",
    "output_file = \"v21_Dome-Recommendations-Ready_For_Import.tsv\"\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded {len(df)} records from {input_file}\")\n",
    "    \n",
    "    # Generate timestamp\n",
    "    # Format: MM/DD/YYYY HH:MM:SS\n",
    "    now_str = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "    print(f\"Setting 'publication/updated' to: {now_str}\")\n",
    "    \n",
    "    # Overwrite column for all rows\n",
    "    df['publication/updated'] = now_str\n",
    "    \n",
    "    # Save final dataset\n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Saved final dataset to {output_file}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Error: {input_file} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6746c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 270 records from v21_Dome-Recommendations-Ready_For_Import.tsv\n",
      "Setting 'reviewState' to 'undefined' for all entries...\n",
      "Saved dataset with reset reviewState to v22_Dome-Recommendations-ReviewState_Reset.tsv\n"
     ]
    }
   ],
   "source": [
    "# 24. Reset Review State (Version 22)\n",
    "# Objective: Reset 'reviewState' to 'undefined' for all records.\n",
    "# Rationale: Prepare records for fresh import/review cycle.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_file = \"v21_Dome-Recommendations-Ready_For_Import.tsv\"\n",
    "output_file = \"v22_Dome-Recommendations-ReviewState_Reset.tsv\"\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded {len(df)} records from {input_file}\")\n",
    "    \n",
    "    # Overwrite column for all rows\n",
    "    print(\"Setting 'reviewState' to 'undefined' for all entries...\")\n",
    "    df['reviewState'] = 'undefined'\n",
    "    \n",
    "    # Save final dataset\n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Saved dataset with reset reviewState to {output_file}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Error: {input_file} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e7eb0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 270 records from v22_Dome-Recommendations-ReviewState_Reset.tsv\n",
      "Sample existing 'created/$date' values: ['2022-09-01T15:16:05.444Z', '2022-09-01T15:16:05.444Z', '2022-09-01T15:16:05.444Z', '2022-09-01T15:16:05.443Z', '2022-12-21T01:13:22.874Z']\n",
      "Migrated 143 values from 'update' to 'created/$date'.\n",
      "Clearing 'update' column...\n",
      "Saved dataset to v23_Dome-Recommendations-Created_Date_Fixed.tsv\n"
     ]
    }
   ],
   "source": [
    "# 25. Migrate 'update' to 'created/$date' (Version 23)\n",
    "# Objective: Move values from legacy 'update' column to 'created/$date' where the target is empty.\n",
    "# Formatting: Ensure consistency with existing 'created/$date' format.\n",
    "# Cleanup: Clear the 'update' column after migration.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "\n",
    "input_file = \"v22_Dome-Recommendations-ReviewState_Reset.tsv\"\n",
    "output_file = \"v23_Dome-Recommendations-Created_Date_Fixed.tsv\"\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded {len(df)} records from {input_file}\")\n",
    "    \n",
    "    # helper for checking emptiness\n",
    "    def is_empty(val):\n",
    "        return str(val).lower() in ['nan', 'none', '', '<na>', 'nat']\n",
    "\n",
    "    # Ensure columns exist\n",
    "    if 'created/$date' not in df.columns: df['created/$date'] = \"\"\n",
    "    if 'update' not in df.columns:\n",
    "        print(\"Column 'update' not found, skipping migration.\")\n",
    "    else:\n",
    "        migrated_count = 0\n",
    "        \n",
    "        # Determine target format from an existing valid entry in 'created/$date' if possible\n",
    "        # Or assume standard ISO or similar based on user request \"alignment with these existing entries\"\n",
    "        # Let's inspect a sample if possible, otherwise default to a robust format.\n",
    "        # Usually DOME uses something like \"2022-06-23T03:07:23.000Z\" or similar?\n",
    "        # User accepted \"06/23/2022 03:07:23\" for publication/updated earlier.\n",
    "        # But `created/$date` usually implies a specific system format (often ISO 8601).\n",
    "        # Let's try to detect format from non-empty created/$date entries.\n",
    "        \n",
    "        example_dates = df[~df['created/$date'].apply(is_empty)]['created/$date'].head(5).tolist()\n",
    "        print(f\"Sample existing 'created/$date' values: {example_dates}\")\n",
    "        \n",
    "        # Heuristic: If we can't determine, we stick to the string as is, or try to normalize.\n",
    "        # User said \"reformat in alignment with these existing entries formatting\"\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            target_val = row.get('created/$date', '')\n",
    "            source_val = row.get('update', '')\n",
    "            \n",
    "            # Only migrate if target is empty AND source is NOT empty\n",
    "            if is_empty(target_val) and not is_empty(source_val):\n",
    "                \n",
    "                # Attempt reformatting\n",
    "                # We need to guess the format of 'source_val' and convert to format of 'target'\n",
    "                # For now, let's just copy it, assuming relatively compatible, \n",
    "                # but let's try to be smart if the source looks like a date.\n",
    "                \n",
    "                try:\n",
    "                    # Parse source\n",
    "                    dt = parser.parse(str(source_val))\n",
    "                    \n",
    "                    # Format: If we have examples, try to match? \n",
    "                    # If existing examples are ISO (2023-01-01T...), allow that.\n",
    "                    # If simpler, allow that.\n",
    "                    # Without examples, valid ISO string is safest for system dates.\n",
    "                    # Let's use the format derived from the previous step \"06/23/2022 03:07:23\" \n",
    "                    # OR stick to exactly what the user asked for.\n",
    "                    # Since I cannot see the existing format dynamically without running, \n",
    "                    # I will try to detect if it looks like ISO or US style.\n",
    "                    \n",
    "                    # Defaulting to preserving the parsed date string representation usually works,\n",
    "                    # but let's try to format it like: \"2022-06-23T15:30:00.000Z\" (common for $date)\n",
    "                    # OR \"06/23/2022 03:07:23\"\n",
    "                    \n",
    "                    # Let's blindly copy first, relying on parser only if needed?\n",
    "                    # \"reformat in alignment\" -> Implies I should make it look like the others.\n",
    "                    # I'll convert to a standard string.\n",
    "                    \n",
    "                    # Assuming standard format: YYYY-MM-DDTHH:MM:SS.mmmZ is typical for Mongo/JSON systems using $date\n",
    "                    # But the previous TSV steps used \"MM/DD/YYYY HH:MM:SS\".\n",
    "                    \n",
    "                    # Let's check the first non-empty created/$date provided in the print above (mentally).\n",
    "                    # I will assume standard format for now.\n",
    "                    \n",
    "                    new_val = str(source_val) # Fallback\n",
    "                    \n",
    "                    # Logic: If existing entries contain 'T', assume ISO\n",
    "                    # If existing contain '/', assume US\n",
    "                    has_iso = any('T' in str(x) for x in example_dates)\n",
    "                    has_slash = any('/' in str(x) for x in example_dates)\n",
    "                    \n",
    "                    if has_iso:\n",
    "                        new_val = dt.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                    elif has_slash:\n",
    "                         new_val = dt.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "                    else:\n",
    "                        # Fallback to a clean string representation\n",
    "                        new_val = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                    df.at[idx, 'created/$date'] = new_val\n",
    "                    migrated_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # If parsing fails, just copy raw string? Or skip?\n",
    "                    # \"properly filled entries\"... let's copy raw if parse fails.\n",
    "                    df.at[idx, 'created/$date'] = source_val\n",
    "                    migrated_count += 1\n",
    "\n",
    "        print(f\"Migrated {migrated_count} values from 'update' to 'created/$date'.\")\n",
    "\n",
    "        # Clear 'update' column\n",
    "        print(\"Clearing 'update' column...\")\n",
    "        df['update'] = \"\" \n",
    "        \n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Saved dataset to {output_file}\")\n",
    "else:\n",
    "    print(f\"{input_file} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e27884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 270 records.\n",
      "Repairing date formats in 'created/$date'...\n",
      "Entries requiring repair: 143\n",
      "Sample before: 2022-05-20T16:23:02.000000Z\n",
      "Sample after:  2022-05-20T16:23:02.000Z\n",
      "Repair complete.\n",
      "Saved aligned dataset to v24_Dome-Recommendations-Dates_Aligned.tsv\n"
     ]
    }
   ],
   "source": [
    "# 26. Repair Date Formatting (Version 24)\n",
    "# Objective: Align 'created/$date' format to strict ISO with 3 millisecond digits (YYYY-MM-DDTHH:MM:SS.mmmZ).\n",
    "# Fix: Truncate 6-digit microseconds (python default) to 3-digit milliseconds to match existing DOME format.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "input_file = \"v23_Dome-Recommendations-Created_Date_Fixed.tsv\"\n",
    "output_file = \"v24_Dome-Recommendations-Dates_Aligned.tsv\"\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded {len(df)} records.\")\n",
    "    \n",
    "    def align_date_ms(val):\n",
    "        s = str(val).strip()\n",
    "        if s.lower() in ['nan', 'none', '']: return \"\"\n",
    "        \n",
    "        # Regex to find .mu_secondsZ pattern (e.g. .000000Z or .123456Z)\n",
    "        # We want to keep just the first 3 digits of the fraction.\n",
    "        \n",
    "        # 1. Check if it matches the 'Bad' format (6 digits)\n",
    "        # Regex: Ends with .ddddddZ\n",
    "        if re.search(r'\\.\\d{6}Z$', s):\n",
    "            # Truncate to .dddZ\n",
    "            # Split on the decimal point logic is safest\n",
    "            parts = s.split('.')\n",
    "            if len(parts) >= 2:\n",
    "                main_part = parts[0] # YYYY-MM-DDTHH:MM:SS\n",
    "                frac_part = parts[-1] # 000000Z\n",
    "                \n",
    "                # Take first 3 digits of fraction\n",
    "                if len(frac_part) >= 3:\n",
    "                    new_frac = frac_part[:3] + \"Z\"\n",
    "                    return f\"{main_part}.{new_frac}\"\n",
    "        \n",
    "        return s\n",
    "\n",
    "    # Apply to created/$date\n",
    "    if 'created/$date' in df.columns:\n",
    "        print(\"Repairing date formats in 'created/$date'...\")\n",
    "        \n",
    "        # Check counts of bad formats\n",
    "        bad_mask = df['created/$date'].astype(str).str.contains(r'\\.\\d{6}Z', regex=True, na=False)\n",
    "        print(f\"Entries requiring repair: {bad_mask.sum()}\")\n",
    "        \n",
    "        if bad_mask.sum() > 0:\n",
    "            sample = df.loc[bad_mask, 'created/$date'].iloc[0]\n",
    "            print(f\"Sample before: {sample}\")\n",
    "            \n",
    "            # Apply fix\n",
    "            df['created/$date'] = df['created/$date'].apply(align_date_ms)\n",
    "            \n",
    "            # check after\n",
    "            new_sample = align_date_ms(sample)\n",
    "            print(f\"Sample after:  {new_sample}\")\n",
    "        else:\n",
    "            print(\"No 6-digit timestamps found.\")\n",
    "        \n",
    "        # Verify\n",
    "        print(\"Repair complete.\")\n",
    "    \n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Saved aligned dataset to {output_file}\")\n",
    "\n",
    "else:\n",
    "    print(f\"{input_file} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b13bd309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 270 records.\n",
      "Syncing 'publication/updated' -> 'updated/$date' with reformatting...\n",
      "Sample Source: 02/02/2026 19:46:52\n",
      "Sample Target: 2026-02-02T19:46:52.000Z\n",
      "Saved synced dataset to v25_Dome-Recommendations-Sync_Updates.tsv\n"
     ]
    }
   ],
   "source": [
    "# 27. Sync 'publication/updated' to 'updated/$date' (Version 25)\n",
    "# Objective: Copy timestamp from 'publication/updated' to 'updated/$date'.\n",
    "# Transformation: Convert from US Format (MM/DD/YYYY HH:MM:SS) to ISO 8601 (YYYY-MM-DDTHH:MM:SS.mmmZ)\n",
    "# to ensure the columns are synchronized in time but aligned to their respective schema formats.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "input_file = \"v24_Dome-Recommendations-Dates_Aligned.tsv\"\n",
    "output_file = \"v25_Dome-Recommendations-Sync_Updates.tsv\"\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded {len(df)} records.\")\n",
    "    \n",
    "    # helper to convert formats\n",
    "    def convert_date_format(val):\n",
    "        s = str(val).strip()\n",
    "        if s.lower() in ['nan', 'none', '']: return \"\"\n",
    "        \n",
    "        try:\n",
    "            # Parse from US format set in Step 23\n",
    "            # Format: MM/DD/YYYY HH:MM:SS\n",
    "            dt = datetime.strptime(s, \"%m/%d/%Y %H:%M:%S\")\n",
    "            \n",
    "            # Output to ISO format required for $date fields (as per Step 26 standards)\n",
    "            # Format: YYYY-MM-DDTHH:MM:SS.mmmZ\n",
    "            return dt.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "        except ValueError:\n",
    "            # If parsing fails, maybe it's already in ISO or different? \n",
    "            # Log it or just return original?\n",
    "            # User instructions \"copy over\", let's try to maintain data.\n",
    "            print(f\"Warning: Could not parse date '{s}' with expected format. Copying raw.\")\n",
    "            return s\n",
    "\n",
    "    if 'publication/updated' in df.columns:\n",
    "        print(\"Syncing 'publication/updated' -> 'updated/$date' with reformatting...\")\n",
    "        \n",
    "        # Ensure target column exists\n",
    "        if 'updated/$date' not in df.columns:\n",
    "            df['updated/$date'] = \"\"\n",
    "            \n",
    "        # Apply conversion\n",
    "        df['updated/$date'] = df['publication/updated'].apply(convert_date_format)\n",
    "        \n",
    "        # Verify\n",
    "        print(f\"Sample Source: {df['publication/updated'].iloc[0]}\")\n",
    "        print(f\"Sample Target: {df['updated/$date'].iloc[0]}\")\n",
    "        \n",
    "        df.to_csv(output_file, sep='\\t', index=False)\n",
    "        print(f\"Saved synced dataset to {output_file}\")\n",
    "    else:\n",
    "        print(\"Error: 'publication/updated' column missing.\")\n",
    "\n",
    "else:\n",
    "    print(f\"{input_file} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495defe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TSV: 270 records.\n",
      "Loaded JSON: 281 entries.\n",
      "Detecting JSON structure...\n",
      "  Found 'regularization' at path: ['optimization']\n",
      "  Found 'provenance' at path: ['dataset']\n",
      "  Found 'splits' at path: ['dataset']\n",
      "  WARNING: Could not find key 'learning' in sample JSON entries. Matching for this field will fail.\n",
      "Building lookups...\n",
      "  Field 'optimization/regularization': Removing 4 non-unique values.\n",
      "  Field 'dataset/provenance': Removing 2 non-unique values.\n",
      "  Field 'dataset/splits': Removing 4 non-unique values.\n",
      "------------------------------\n",
      "Sync Complete. Recovered IDs for 118 entries.\n",
      "Saved to v26_Dome-Recommendations-ID_Sync_Adaptive.tsv\n"
     ]
    }
   ],
   "source": [
    "# 28. Sync IDs from JSON (Version 29 - Adaptive Structure Discovery)\n",
    "# Objective: Retrieve IDs using direct match on specific fields.\n",
    "# Improvement: Automatically discovers the JSON structure to find where fields like 'regularization' are hiding.\n",
    "# This solves issues where the \"content\" wrapper might be missing or keys might be capitalized differently.\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_file = \"v25_Dome-Recommendations-Sync_Updates.tsv\"\n",
    "json_source = \"public_dome_review_raw_human_20260202.json\"\n",
    "output_file = \"v26_Dome-Recommendations-ID_Sync_Adaptive.tsv\"\n",
    "failure_report = \"v26_ID_Sync_Failures.tsv\"\n",
    "\n",
    "PRIORITY_FIELDS = [\n",
    "    'optimization/regularization', \n",
    "    'dataset/provenance',\n",
    "    'dataset/splits',\n",
    "    'model/learning'\n",
    "]\n",
    "\n",
    "def normalize(val):\n",
    "    if val is None: return \"\"\n",
    "    return str(val).lower().strip().replace('nan', '')\n",
    "\n",
    "# --- Structure Discovery Helper ---\n",
    "def find_keys_recursive(data, target_key, current_path=[]):\n",
    "    \"\"\"\n",
    "    Recursively searches a dictionary for a specific key (case-insensitive).\n",
    "    Returns the path to the parent of that key.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            if k.lower() == target_key.lower():\n",
    "                return current_path # Found it! Return path to parent\n",
    "            \n",
    "            # Recurse\n",
    "            path = find_keys_recursive(v, target_key, current_path + [k])\n",
    "            if path is not None:\n",
    "                return path\n",
    "    return None\n",
    "\n",
    "def get_value_by_path(entry, path, leaf_key):\n",
    "    \"\"\"Retrieves value given a path list and a leaf key.\"\"\"\n",
    "    curr = entry\n",
    "    try:\n",
    "        # Traverse path\n",
    "        for p in path:\n",
    "            curr = curr[p]\n",
    "        \n",
    "        # Find the leaf key (case-insensitive match in the final dict)\n",
    "        if isinstance(curr, dict):\n",
    "            for k, v in curr.items():\n",
    "                if k.lower() == leaf_key.lower():\n",
    "                    return v\n",
    "    except:\n",
    "        return \"\"\n",
    "    return \"\"\n",
    "\n",
    "if os.path.exists(input_file) and os.path.exists(json_source):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    print(f\"Loaded TSV: {len(df)} records.\")\n",
    "    \n",
    "    with open(json_source, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    print(f\"Loaded JSON: {len(json_data)} entries.\")\n",
    "\n",
    "    # 1. Inspect Structure\n",
    "    # Look at the first 10 entries to find where 'regularization' lives\n",
    "    found_paths = {}\n",
    "    \n",
    "    print(\"Detecting JSON structure...\")\n",
    "    for field in PRIORITY_FIELDS:\n",
    "        _, key = field.split('/')\n",
    "        \n",
    "        for entry in json_data[:20]: # Check first 20 entries\n",
    "            path = find_keys_recursive(entry, key, [])\n",
    "            if path is not None:\n",
    "                found_paths[field] = path\n",
    "                print(f\"  Found '{key}' at path: {path}\")\n",
    "                break\n",
    "        \n",
    "        if field not in found_paths:\n",
    "            print(f\"  WARNING: Could not find key '{key}' in sample JSON entries. Matching for this field will fail.\")\n",
    "\n",
    "    # 2. Build Lookups using Discovered Paths\n",
    "    lookups = {field: {} for field in PRIORITY_FIELDS}\n",
    "    collisions = {field: set() for field in PRIORITY_FIELDS}\n",
    "    \n",
    "    print(\"Building lookups...\")\n",
    "    \n",
    "    for entry in json_data:\n",
    "        ids = {\n",
    "            '_id/$oid': entry.get('_id', {}).get('$oid', ''),\n",
    "            'uuid': entry.get('uuid', ''),\n",
    "            'shortid': entry.get('shortid', '')\n",
    "        }\n",
    "        \n",
    "        for field in PRIORITY_FIELDS:\n",
    "            if field in found_paths:\n",
    "                section, key = field.split('/')\n",
    "                path = found_paths[field]\n",
    "                \n",
    "                # Extract value using the dynamic path\n",
    "                raw_val = get_value_by_path(entry, path, key)\n",
    "                val = normalize(raw_val)\n",
    "                \n",
    "                if len(val) > 3:\n",
    "                    if val in lookups[field]:\n",
    "                        collisions[field].add(val)\n",
    "                    else:\n",
    "                        lookups[field][val] = ids\n",
    "\n",
    "    # Clean collisions\n",
    "    for field in PRIORITY_FIELDS:\n",
    "        if collisions[field]:\n",
    "            print(f\"  Field '{field}': Removing {len(collisions[field])} non-unique values.\")\n",
    "            for k in collisions[field]:\n",
    "                if k in lookups[field]:\n",
    "                    del lookups[field][k]\n",
    "\n",
    "    # 3. Match\n",
    "    synced_count = 0\n",
    "    updated_rows = 0\n",
    "    failures = []\n",
    "    \n",
    "    for c in ['_id/$oid', 'uuid', 'shortid']:\n",
    "        if c not in df.columns: df[c] = \"\"\n",
    "        \n",
    "    for i, row in df.iterrows():\n",
    "        # Skip if already fully active\n",
    "        if normalize(row.get('_id/$oid')) and normalize(row.get('uuid')):\n",
    "            continue\n",
    "            \n",
    "        match_found = None\n",
    "        match_source = \"\"\n",
    "        \n",
    "        for field in PRIORITY_FIELDS:\n",
    "            val = normalize(row.get(field, ''))\n",
    "            \n",
    "            if len(val) > 3 and field in lookups and val in lookups[field]:\n",
    "                match_found = lookups[field][val]\n",
    "                match_source = field\n",
    "                break\n",
    "        \n",
    "        if match_found:\n",
    "            updated_any = False\n",
    "            for k, v in match_found.items():\n",
    "                if not normalize(df.at[i, k]):\n",
    "                    df.at[i, k] = v\n",
    "                    updated_any = True\n",
    "            if updated_any:\n",
    "                synced_count += 1\n",
    "                \n",
    "        # Check Final Status for Reporting\n",
    "        # If we still don't have an ID after attempting match\n",
    "        current_oid = normalize(df.at[i, '_id/$oid'])\n",
    "        if not current_oid:\n",
    "             failures.append({\n",
    "                'index': i,\n",
    "                'doi': row.get('publication/doi'),\n",
    "                'title': row.get('publication/title'),\n",
    "                'optimization/regularization': row.get('optimization/regularization'),\n",
    "                'reason': 'No unique match found in priority fields'\n",
    "             })\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Sync Complete. Recovered IDs for {synced_count} entries.\")\n",
    "    print(f\"Saved to {output_file}\")\n",
    "    \n",
    "    # 4. Report Failures\n",
    "    if failures:\n",
    "        print(f\"\\n[ATTENTION] {len(failures)} entries are STILL missing IDs after sync.\")\n",
    "        df_fail = pd.DataFrame(failures)\n",
    "        df_fail.to_csv(failure_report, sep='\\t', index=False)\n",
    "        print(f\"Failure report saved to: {failure_report}\")\n",
    "        print(\"First 5 failures:\")\n",
    "        print(df_fail[['index', 'doi', 'optimization/regularization']].head(5).to_string())\n",
    "    else:\n",
    "        print(\"\\n[SUCCESS] No missing IDs remaining!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Files not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
