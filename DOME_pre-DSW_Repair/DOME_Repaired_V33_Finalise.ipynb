{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83423f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed 270 entries.\n",
      "\n",
      "--- Report ---\n",
      "Original V32 count: 270\n",
      "New JSON count: 270\n",
      "Fields dropped from TSV (not in JSON schema): {'provenance_source'}\n",
      "Fields added to JSON (not in TSV): set()\n",
      "\n",
      "Saved reformatted JSON to v32_Dome-Recommendations-With_Provenance_reformatted.json\n"
     ]
    }
   ],
   "source": [
    "def transform_row_to_json(row, template_keys):\n",
    "    new_entry = {}\n",
    "    \n",
    "    # Helper to clean value\n",
    "    def clean_val(val):\n",
    "        if pd.isna(val):\n",
    "            return \"\" # Default for string fields? Or None? \n",
    "            # JSON example shows empty strings for missing text, e.g. \"dataset\": {\"availability\": \"\", ...}\n",
    "        return val\n",
    "\n",
    "    # Helper to handle numbers that might be floats in DF but ints in JSON\n",
    "    def clean_int(val):\n",
    "        if pd.isna(val):\n",
    "            return 0 # Default to 0? Or skip? JSON has 0, 2, etc.\n",
    "        try:\n",
    "            return int(val)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    # Helper to handle booleans\n",
    "    def clean_bool(val):\n",
    "        if pd.isna(val):\n",
    "            return False\n",
    "        # If 1.0/0.0\n",
    "        if isinstance(val, (int, float)):\n",
    "            return bool(val)\n",
    "        return False\n",
    "    \n",
    "    # Iterate through keys expected in the output JSON\n",
    "    for key in template_keys:\n",
    "        \n",
    "        # 1. _id\n",
    "        if key == '_id':\n",
    "            # TSV has _id/$oid\n",
    "            oid_val = row.get('_id/$oid')\n",
    "            if pd.notna(oid_val):\n",
    "                new_entry['_id'] = {\"$oid\": str(oid_val)}\n",
    "            else:\n",
    "                # Should not happen for ID, but handle graceful\n",
    "                new_entry['_id'] = {\"$oid\": \"\"}\n",
    "        \n",
    "        # 2. user\n",
    "        elif key == 'user':\n",
    "             # TSV has user/$oid\n",
    "            oid_val = row.get('user/$oid')\n",
    "            if pd.notna(oid_val):\n",
    "                new_entry['user'] = {\"$oid\": str(oid_val)}\n",
    "            else:\n",
    "                new_entry['user'] = {\"$oid\": \"\"}\n",
    "\n",
    "        # 3. created / updated (Date objects)\n",
    "        elif key == 'created':\n",
    "            date_val = row.get('created/$date')\n",
    "            if pd.notna(date_val):\n",
    "                 new_entry['created'] = {\"$date\": str(date_val)}\n",
    "            else:\n",
    "                 new_entry['created'] = {\"$date\": \"\"}\n",
    "        \n",
    "        elif key == 'updated':\n",
    "            date_val = row.get('updated/$date')\n",
    "            if pd.notna(date_val):\n",
    "                 new_entry['updated'] = {\"$date\": str(date_val)}\n",
    "            else:\n",
    "                 new_entry['updated'] = {\"$date\": \"\"}\n",
    "\n",
    "        # 4. Nested objects: dataset, evaluation, model, optimization, publication\n",
    "        elif key in ['dataset', 'evaluation', 'model', 'optimization', 'publication']:\n",
    "            new_entry[key] = {}\n",
    "            # Need to know the sub-fields for this key.\n",
    "            # We look at the template item to see what sub-keys exist.\n",
    "            # And map them from TSV columns key/sub_key\n",
    "            \n",
    "            # Get template sub-object\n",
    "            sub_template = template_item.get(key, {})\n",
    "            \n",
    "            # Start collecting sub keys from schema\n",
    "            sub_keys = []\n",
    "            if isinstance(sub_template, dict):\n",
    "                sub_keys = list(sub_template.keys())\n",
    "\n",
    "            # Specific adjustment: Force add pmcid if in publication and not present\n",
    "            if key == 'publication':\n",
    "                 # Check if pmid exists to insert after, or just append\n",
    "                 # Schema doesn't guarantee order in sub_keys list here, but we iterate.\n",
    "                 # Let's rebuild the list carefully.\n",
    "                 ordered_keys = []\n",
    "                 pmcid_added = False\n",
    "                 \n",
    "                 for k in sub_keys:\n",
    "                     ordered_keys.append(k)\n",
    "                     if k == 'pmid':\n",
    "                         # Insert pmcid after pmid\n",
    "                         ordered_keys.append('pmcid')\n",
    "                         pmcid_added = True\n",
    "                 \n",
    "                 if not pmcid_added:\n",
    "                     # If pmid wasn't found (unlikely), append at end or handle if empty\n",
    "                     ordered_keys.append('pmcid')\n",
    "                 \n",
    "                 # Reassign for iteration\n",
    "                 sub_keys = ordered_keys\n",
    "                 # Remove duplicates if pmcid was already in schema (it won't correspond to user request of \"bringing back\" if it was)\n",
    "                 # A set would destroy order. List comprehension with seen set:\n",
    "                 seen = set()\n",
    "                 sub_keys = [x for x in sub_keys if not (x in seen or seen.add(x))]\n",
    "\n",
    "            for sub_key in sub_keys:\n",
    "                tsv_col = f\"{key}/{sub_key}\"\n",
    "                \n",
    "                # Handle specific sub-field types based on known usage or simple heuristics\n",
    "                val = row.get(tsv_col)\n",
    "                \n",
    "                # Special cases for integer fields like 'done', 'skip', 'year', 'update'\n",
    "                if sub_key in ['done', 'skip', 'update', '__v', 'score']:\n",
    "                        new_entry[key][sub_key] = clean_int(val)\n",
    "                elif sub_key == 'publication/year': # just 'year' here\n",
    "                        new_entry[key][sub_key] = str(clean_int(val)) # Year is string in JSON example \"2020\"\n",
    "                elif sub_key == 'tags':\n",
    "                        # In JSON example it is []\n",
    "                        # In TSV valid might be NaN or string?\n",
    "                        if pd.isna(val) or val == \"\":\n",
    "                            new_entry[key][sub_key] = []\n",
    "                        else:\n",
    "                            # If comma separated string?\n",
    "                            new_entry[key][sub_key] = [str(val)] # Or split? Assuming list format needed.\n",
    "                elif sub_key == 'public':\n",
    "                        new_entry[key][sub_key] = clean_bool(val)\n",
    "                else:\n",
    "                    # Default string handling\n",
    "                    # Just in case 'year' is treated as string in publication\n",
    "                    if sub_key == 'year':\n",
    "                            new_entry[key][sub_key] = str(clean_int(val)) if pd.notna(val) else \"\"\n",
    "                    else:\n",
    "                            new_entry[key][sub_key] = clean_val(val)\n",
    "\n",
    "        # 5. Simple fields\n",
    "        else:\n",
    "            # key is something like 'public', 'uuid', 'reviewState', 'shortid', 'update', '__v', 'score'\n",
    "            # Check if it exists in TSV directly\n",
    "            val = row.get(key)\n",
    "            \n",
    "            if key == 'public':\n",
    "                new_entry[key] = clean_bool(val)\n",
    "            elif key in ['update', '__v', 'score']:\n",
    "                # The TSV has 'score' and '__v'\n",
    "                new_entry[key] = clean_int(val)\n",
    "            elif key == 'Duplicate_shortid':\n",
    "                # Not in TSV, add as empty list (based on JSON list type)\n",
    "                new_entry[key] = [] \n",
    "                # (If TSV has a way to construct this, logic goes here. Assuming empty for now as \"field not present add in\")\n",
    "            else:\n",
    "                # String fields: uuid, reviewState, shortid\n",
    "                new_entry[key] = clean_val(val)\n",
    "\n",
    "    return new_entry\n",
    "\n",
    "# Perform transformation\n",
    "new_json_data = []\n",
    "\n",
    "# Since we need to follow the schema strictly, ensure we have the template keys from the JSON\n",
    "# (Already loaded in target_keys)\n",
    "\n",
    "for idx, row in df_v32.iterrows():\n",
    "    entry = transform_row_to_json(row, target_keys)\n",
    "    new_json_data.append(entry)\n",
    "\n",
    "print(f\"Transformed {len(new_json_data)} entries.\")\n",
    "\n",
    "# Reporting\n",
    "tsv_cols = set(df_v32.columns)\n",
    "json_keys_flat = set()\n",
    "\n",
    "# Flatten JSON keys for comparison\n",
    "for k in target_keys:\n",
    "    if k in ['dataset', 'evaluation', 'model', 'optimization', 'publication']:\n",
    "        # Get from first transformed entry instead of template to reflect modifications\n",
    "        if new_json_data and k in new_json_data[0]:\n",
    "             for sub_k in new_json_data[0][k].keys():\n",
    "                json_keys_flat.add(f\"{k}/{sub_k}\")\n",
    "        else:\n",
    "             for sub_k in template_item[k].keys():\n",
    "                json_keys_flat.add(f\"{k}/{sub_k}\")\n",
    "    elif k == '_id':\n",
    "        json_keys_flat.add('_id/$oid')\n",
    "    elif k == 'user':\n",
    "        json_keys_flat.add('user/$oid')\n",
    "    elif k == 'created':\n",
    "        json_keys_flat.add('created/$date')\n",
    "    elif k == 'updated':\n",
    "        json_keys_flat.add('updated/$date')\n",
    "    else:\n",
    "        json_keys_flat.add(k)\n",
    "\n",
    "dropped_cols = tsv_cols - json_keys_flat\n",
    "added_keys = json_keys_flat - tsv_cols\n",
    "\n",
    "print(\"\\n--- Report ---\")\n",
    "print(f\"Original V32 count: {len(df_v32)}\")\n",
    "print(f\"New JSON count: {len(new_json_data)}\")\n",
    "print(f\"Fields dropped from TSV (not in JSON schema): {dropped_cols}\")\n",
    "print(f\"Fields added to JSON (not in TSV): {added_keys}\")\n",
    "\n",
    "# Save the result\n",
    "output_filename = 'v32_Dome-Recommendations-With_Provenance_reformatted.json'\n",
    "with open(output_filename, 'w') as f:\n",
    "    json.dump(new_json_data, f, indent=4)\n",
    "\n",
    "print(f\"\\nSaved reformatted JSON to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c21199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 270 entries from TSV.\n",
      "Loaded 354 entries from JSON template.\n",
      "Target Schema Keys: ['_id', 'dataset', 'evaluation', 'model', 'optimization', 'user', 'publication', 'public', 'created', 'updated', 'uuid', 'reviewState', 'shortid', 'update', '__v', 'score']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load source data\n",
    "v32_path = 'v32_Dome-Recommendations-With_Provenance.tsv'\n",
    "df_v32 = pd.read_csv(v32_path, sep='\\t')\n",
    "\n",
    "# Load template JSON to understand schema\n",
    "json_template_path = 'dome_review_raw_human_20260204.json'\n",
    "with open(json_template_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Use the first entry as a schema template (or analyze all keys if schema varies, but usually consistent)\n",
    "# The user wants to \"use info from ... reformat the v32 file in the same manner\"\n",
    "# We will inspect the keys of the first item to build our target schema structure.\n",
    "template_item = json_data[0]\n",
    "target_keys = list(template_item.keys())\n",
    "\n",
    "print(f\"Loaded {len(df_v32)} entries from TSV.\")\n",
    "print(f\"Loaded {len(json_data)} entries from JSON template.\")\n",
    "print(f\"Target Schema Keys: {target_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dc576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
