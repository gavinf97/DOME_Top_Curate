Review_Reason	bs_completeness	update	publication/title	publication/doi	_id/$oid	dataset/availability	dataset/provenance	dataset/redundancy	dataset/splits	dataset/done	dataset/skip	evaluation/availability	evaluation/comparison	evaluation/confidence	evaluation/measure	evaluation/method	evaluation/done	evaluation/skip	model/availability	model/duration	model/interpretability	model/output	model/done	model/skip	optimization/algorithm	optimization/config	optimization/encoding	optimization/features	optimization/fitting	optimization/meta	optimization/parameters	optimization/regularization	optimization/done	optimization/skip	user/$oid	publication/pmid	publication/pmcid	publication/updated	publication/authors	publication/journal	publication/year	publication/done	publication/skip	publication/tags	public	created/$date	updated/$date	uuid	reviewState	shortid
DOI_MATCH 	45		Imputation method for single-cell RNA-seq data using neural topic model	10.1093/gigascience/giad098	670e3d9261d57eb8bca695d2	Most of the data are in the NCBI Public Dataset.	Human Pancreatic Islet data and Mouse Pancreatic Islet data;Human brain scRNA-seq data.All datasets have been used in other published journals and are available in public dataset repositories	Data does not overlap	No data splitting was done	4.0	0.0	Yes.We will publish it on GitHub	Compare with other algorithms	Not able to use indicator confidence intervals	ARI-Adjusted Rand Index, RI-Rand Index, NMI-Normalized Mutual Information, MI-Mutual Information and so on.	 Independent dataset	5.0	0.0	Links can be provided separately	Transfer learning of models is linearly correlated with the number of genes	Transparent.Neural Topic inherit the advantages of the topic model and is highly interpretable	imputation	4.0	0.0	Adam	Yes.We will publish it on GitHub	Normalization processing	The expression of each gene in a single cell	No	No other data were used as inputs	Around 200	No	6.0	2.0	6465d2d592c76639b8669c75	38000911			Yueyang Qi, Shuangkai Han, Lin Tang, Lin Liu	GigaScience	2023	0.0	0.0		1.0	2024-10-15T10:01:54.363Z	2024-10-15T10:01:54.363Z	a404e9b9-96f0-411a-b390-a893a6c59651	undenfined	aqtrrhz75x
DOI_MATCH 	45		Imputation Methods for Single-Cell RNA-seq Data Using Neural Topic Models	10.1093/gigascience/giad098	64662eaa60bf612a3caabc6b	NCBI Public Dataset. . All data are available at GEO, with human brain data access number: GSE67835; Chung et al. dataset accession code: GSE75688; Hrvatin dataset GEO accession code: GSE59739; Romanov et al. dataset GEO accession code: GSE74672; Deng et al. dataset GEO accession code: GSE45719; mouse pancreatic islet data GEO accession code: GSE84133. Human pancreatic islet data are available at GEO or EMBL-EBI database with accession codes GSE81076, GSE85241, GSE86469, E-MTAB-5061, and GSE84133.	Homo sapiens and Mouse data	Data does not overlap	No	3.0	1.0	Yes.We will publish it on GitHub	Compare with other algorithms	No	ARI-Adjusted Rand Index, RI-Rand Index, NMI-Normalized Mutual Information, MI-Mutual Information	 Independent dataset	4.0	1.0	Links can be provided separately	No	Transparent.Neural Topic inherit the advantages of the topic model and is highly interpretable	No	2.0	2.0	Adam	Yes.We will publish it on GitHub	Normalization processing	The expression of each gene in a single cell	No	No	Around 200	No	5.0	3.0	6465d2d592c76639b8669c75	38000911			Yueyang Qi,Shuangkai Han,Tang Lin,Liu Lin	GigaScience	2023	0.0	0.0		1.0	2023-05-18T13:56:58.509Z	2025-06-10T14:13:31.714Z	0ba2ada5-240f-4c3a-87ad-b1db60315cb9	undenfined	krz8m7iufj
TITLE_MATCH DOI_MATCH 	45		P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure	10.1186/s13321-018-0285-8	65e843f41502715bfe53cd1e	"All the mentioned datasets are selected from previous studies and are publicly available.
Datasets are both mentioned through referencing to other studies and accessible through the URL: https://github.com/rdk/p2rank-datasets"	"Training: CHEN11—a dataset of 251 proteins harboring 476 ligands introduced in LBS prediction benchmarking study.

Optimization and validation: JOINED—consists of structures from several smaller datasets used in previous studies (B48/U48, B210, DT198, ASTEX) joined into one larger dataset. you can find the details below:
B48/U48—Datasets that contain a set of 48 proteins in a bound and unbound state.
B210—a benchmarking dataset of 210 proteins in bound state.
DT198—a dataset of 198 drug-target complexes.
ASTEX—Astex Diverse set is a collection of 85 proteins that was introduced as a benchmarking dataset for molecular docking methods."	"Datasets for training and validation purposes are selected arbitrarily.
Testing dataset is not mentioned.
Only training set is mentioned to be non-redundant without explicit mention on the cutout identity percentage."	"2 data splits were utilized:
Training: CHEN11 dataset composed of 251 data points.
Optimization and validation: JOINED dataset composed of an overall  541 data points.
All the data points are positive examples of protein-ligand complexes."	4.0	0.0	No	The method was compared to other publicly available methods in the 3 mentioned metrics.	"The confidence intervals are only reported for ""Average prediction time per protein"".
While the method is reported to perform best in the first 2 mentioned metrics, which is not the case in terms of prediction time, the difference is not substantial."	"Instead of the conventional performance metrics, 3 reported metrics are as follows:
1. Identification success rate [%] measured by DCCcriterion (distance from pocket center to closest ligand atom) with 4 Å threshold.
2. Average total number of binding sites predicted per protein by on a given dataset.
3. Average time required for prediction on a single protein."	The model was evaluated on two independent datasets. Disjunct with data points present in training and validation set.	4.0	1.0	"The software and the source code is publicly available through the provided link to the GitHub repository of the software.
It is a stand-alone executable software, they currently have a web server, but at the time of publication the web server was under development.
URL: https://github.com/rdk/p2rank
Licence: MIT "	It is mentioned that it requires under 1 s for prediction on one protein.	"The model has 200 trees, each grown with no depth limit using 6 features, this makes it challenging to interpret due to the sheer number of trees and their depth.
However, it is still possible to obtain feature importance scores."	It is a regression model outputting numbers between 0 and 1.	4.0	0.0	"The used algorithm is a Random Forest Regression model.
The model is not novel."	The model is accessible through the URL of the GitHub repository.	The model takes vectors of 35 numerical features as input.	"Every vector is composed of 35 numerical features.
No mention on feature selection."	"The clear number of parameters is not mentioned.
No assessment on over/under fitting was mentioned."	The algorithm is not a meta-predictor.	"Beside the hyper-parameters of Random Forest, the algorithm uses other parameters and ""cut-of's"", ""thresholds"", ""protrusion radius"", are explicitly mentioned.
It is mentioned that only hyper-parameters are optimized on a separate dataset from training set.
The method of optimization is not mentioned."	A validation set was used to optimize the parameters before training on the training set.	8.0	0.0	65e73fdb92c76639b8e309f3	30109435			Radoslav Krivák, David Hoksza	Journal of cheminformatics	2018	6.0	0.0		1.0	2024-03-06T10:22:44.950Z	2024-03-06T10:35:57.616Z	9bd31f10-4479-4940-810c-3e6a4bcfb1e3	undenfined	iblymem5cf
TITLE_MATCH DOI_MATCH 	39		P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure	10.1186/s13321-018-0285-8	6638a2f7b30933003cc215b9	"All the mentioned datasets are selected from previous studies and are publicly available.
Datasets are both mentioned through referencing to other studies and accessible through the URL: https://github.com/rdk/p2rank-datasets"	"Training:  CHEN11—a dataset of 251 proteins harboring 476 ligands introduced in LBS prediction benchmarking study.
Optimization and validation: JOINED—consists of structures from several smaller datasets used in previous studies (B48/U48, B210, DT198, ASTEX) joined into one larger dataset. you can find the details below:
B48/U48—Datasets that contain a set of 48 proteins in a bound and unbound state.
B210—a benchmarking dataset of 210 proteins in bound state.
DT198—a dataset of 198 drug-target complexes.
ASTEX—Astex Diverse set is a collection of 85 proteins that was introduced as a benchmarking dataset for molecular docking methods."	"Datasets for training and validation purposes are selected arbitrarily.
Testing dataset is not mentioned.
Only training set is mentioned to be non-redundant without explicit mention on the cutout identity percentage."	"2 data splits were utilized:
Training: CHEN11 dataset composed of 251 data points.
Optimization and validation: JOINED dataset composed of an overall  541 data points.
All the data points are positive examples of protein-ligand complexes."	4.0	0.0						0.0	5.0	The software and the source code is publicly available through the provided link to the GitHub repository of the software. It is a stand-alone executable software, they currently have a web server, but at the time of publication the web server was under development. URL: https://github.com/rdk/p2rank. Licence: MIT	It is mentioned that it requires under 1 s for prediction on one protein.	The model has 200 trees, each grown with no depth limit using 6 features, this makes it challenging to interpret due to the sheer number of trees and their depth. However, it is still possible to obtain feature importance scores.	It is a regression model outputting numbers between 0 and 1.	4.0	0.0	"The used algorithm is a Random Forest Regression model.
The model is not novel."	URL: https://github.com/rdk/p2rank. Licence: MIT	The model takes vectors of 35 numerical features as input.	"Every vector is composed of 35 numerical features.
No mention on feature selection."	The clear number of parameters is not mentioned. No assessment on over/under fitting was mentioned.	The algorithm is not a meta-predictor.	"Beside the hyper-parameters of Random Forest, the algorithm uses other parameters and ""cut-of's"", thresholds"", ""protrusion radius"", are explicitly mentioned.
It is mentioned that only hyper-parameters are optimized on a separate dataset from training set.
The method of optimization is not mentioned."	A validation set was used to optimize the parameters before training on the training set.	8.0	0.0	65e73fdb92c76639b8e309f3	30109435			Radoslav Krivák, David Hoksza	Journal of cheminformatics	2018		0.0		1.0	2024-05-06T09:29:27.218Z	2024-05-06T09:29:27.218Z	71898e53-9df0-464d-9e78-bb95274221ec	undenfined	toe45v1h7a
TITLE_MATCH DOI_MATCH 	41		SPOT-Disorder2: Improved Protein Intrinsic Disorder Prediction by Ensembled Deep Learning	https://doi.org/10.1016/j.gpb.2019.01.004	6809f90dea60466a7ca5aac2	Details are provided in the paper. 	"They obtained 4229 non-redundant, high-resolution protein sequences from the Protein Data Bank (PDB) and Database of Protein Disorder (DisProt). These include 4157 X-ray crystallography structures (deposited to the PDB prior to August 05, 2003) and 72 fully-disordered proteins from DisProt v5.0. 
For testing, they obtained three independent test datasets (SL250, Mobi9414, and DisProt228) . They removed long proteins (>700 residues) in these sets, and homologous proteins from the training set. "	Data is non redundant. The sequence similarity in the entire dataset is less than 25%. 	"The data is randomly split into a training set (Training) of 2700 chains, a validation set (Validation) of 300 chains, and a testing set (Test) of 1229 chains. Sequence similarity among these proteins is <25% according to BLASTClust . They remove all proteins of length >700 from all datasets. This reduces our training, validation, and test sets to 2615, 293, and 1185 proteins, respectively. For convenience, they will label this test set as Test1185.
For test set, they obtained three independent test datasets (SL250, Mobi9414, and DisProt228) . They removed long proteins (>700 residues) in these sets, and homologous proteins from the training set. "	4.0	0.0	Details are available in the supplementary materials. 	They compare SPOT-Disorder2 to several high-performing protein disorder predictors. These include the local versions of DISOPRED2 and DISOPRED3, MobiDB-lite, AUCpreD, s2D, GlobPlot, DisEMBLE, IUPred, AUCPred, JRONN, MFDp2, PONDR-VSL, SPOT-Disorder,  SPOT-Disorder-Single, ESpritz-D, ESpritz-N, ESpritz-X, and SPINE-D. They also used the webserver of NetSurfP-2.0.	Statistical significance test is done and the results are statistically significant. 	Sensitivity, precision, specifity, AUC ROC, AUC PR, and MCC are used, which are common metrics used in CAID.	They obtained three independent test datasets (SL250, Mobi9414, and DisProt228) . They removed long proteins (>700 residues) in these sets, and homologous proteins from the training set. 	5.0	0.0	SPOT-Disorder2 is available as a web server and as a standalone program at https://sparks-lab.org/server/spot-disorder2/.		The model is a combination of several neural networks, so it could be treated as a black-box. 	The model is regression. It outputs the probability of an amino acid being disordered, so it's a value between 0 and 1.	3.0	1.0	The neural network topology employed in SPOT-Disorder2 consists of various models sequentially combining IncReSeNet, LSTM, and fully-connected (FC) topographical segments.	All the details are available in the supplementary materials. 		"SPOT-Disorder2 employed a similar set of features to SPOT-Disorder. Besides the same evolutionary content consisting of the position-specific substitution matrix (PSSM) profile from PSI-BLAST , SPOT-Disorder2 also includes the hidden Markov model (HMM) profile from HHblits [38]. The PSSM profile is generated by 3 iterations of PSI-BLAST against the UniRef90 sequence database (UniProt release 2018_03), and consists of 20 substitution values of each position for each AA residue type. The HMM profile consists of 30 values generated by using HHblits v3.0.3 with the UniProt sequence profile database from Oct 2017. These 30 values themselves consist of 20 AA substitution probabilities, 10 transition frequencies, and the number of effective homologous sequences of a given protein (Neff). In addition, they utilized the predicted structural properties from SPOT-1D. The features from SPOT-1D consist of 11 secondary structure probabilities (both three- and eight-state predicted secondary structure elements), 4 sine and 4 cosine θ, τ, φ, and ψ backbone angles, 1 relative solvent-accessible surface area (ASA), 1 contact number (CN), and 2 half-sphere exposure (HSE) values based on the carbon-α atoms.

In total there are 73 features in the input. "		They utilized the predicted structural properties from SPOT-1D. The features from SPOT-1D consist of 11 secondary structure probabilities (both three- and eight-state predicted secondary structure elements), 4 sine and 4 cosine θ, τ, φ, and ψ backbone angles, 1 relative solvent-accessible surface area (ASA), 1 contact number (CN), and 2 half-sphere exposure (HSE) values based on the carbon-α atoms.	A large corpus of models with varying hyperparameters are trained and their performance is analyzed on a validation set. These hyperparameters are swept through in a grid search and include the layout of the network, the number of nodes in each layer (one parameter each for LSTM, IncReSeNet, and FC layers), and the number of layers for each layer type. The five top-performing models with hyperparameters are chosen from this validation period and used in the final ensemble for SPOT-Disorder2.	Dropout is used in different layers. 	6.0	2.0	66c495857089c469b477b4ce				Jack Hanson, Kuldip K. Paliwal, Thomas Litfin, Yaoqi Zhou 	Genomics, Proteomics & Bioinformatics	2019	0.0	0.0		1.0	2025-04-24T08:40:45.204Z	2025-04-24T08:40:45.204Z	a7fe5bb8-985a-4fd8-ae1f-9f2ecbf1c06d	undenfined	w55oz05fks
TITLE_MATCH DOI_MATCH 	41		SPOT-Disorder2: Improved Protein Intrinsic Disorder Prediction by Ensembled Deep Learning	https://doi.org/10.1016/j.gpb.2019.01.004	680a4d01ea60466a7ca5ab48	Details are provided in the paper. 	"They obtained 4229 non-redundant, high-resolution protein sequences from the Protein Data Bank (PDB) and Database of Protein Disorder (DisProt). These include 4157 X-ray crystallography structures (deposited to the PDB prior to August 05, 2003) and 72 fully-disordered proteins from DisProt v5.0. 
For testing, they obtained three independent test datasets (SL250, Mobi9414, and DisProt228) . They removed long proteins (>700 residues) in these sets, and homologous proteins from the training set. "	Data is non redundant. The sequence similarity in the entire dataset is less than 25%. 	"The data is randomly split into a training set (Training) of 2700 chains, a validation set (Validation) of 300 chains, and a testing set (Test) of 1229 chains. Sequence similarity among these proteins is <25% according to BLASTClust . They remove all proteins of length >700 from all datasets. This reduces our training, validation, and test sets to 2615, 293, and 1185 proteins, respectively. For convenience, they will label this test set as Test1185.
For test set, they obtained three independent test datasets (SL250, Mobi9414, and DisProt228) . They removed long proteins (>700 residues) in these sets, and homologous proteins from the training set. "	4.0	0.0	Details are available in the supplementary materials. 	They compare SPOT-Disorder2 to several high-performing protein disorder predictors. These include the local versions of DISOPRED2 and DISOPRED3, MobiDB-lite, AUCpreD, s2D, GlobPlot, DisEMBLE, IUPred, AUCPred, JRONN, MFDp2, PONDR-VSL, SPOT-Disorder,  SPOT-Disorder-Single, ESpritz-D, ESpritz-N, ESpritz-X, and SPINE-D. They also used the webserver of NetSurfP-2.0.	Statistical significance test is done and the results are statistically significant. 	Sensitivity, precision, specifity, AUC ROC, AUC PR, and MCC are used, which are common metrics used in CAID.	They obtained three independent test datasets (SL250, Mobi9414, and DisProt228) . They removed long proteins (>700 residues) in these sets, and homologous proteins from the training set. 	5.0	0.0	SPOT-Disorder2 is available as a web server and as a standalone program at https://sparks-lab.org/server/spot-disorder2/.		The model is a combination of several neural networks, so it could be treated as a black-box. 	The model is regression. It outputs the probability of an amino acid being disordered, so it's a value between 0 and 1.	3.0	1.0	The neural network topology employed in SPOT-Disorder2 consists of various models sequentially combining IncReSeNet, LSTM, and fully-connected (FC) topographical segments.	All the details are available in the supplementary materials. 		"SPOT-Disorder2 employed a similar set of features to SPOT-Disorder. Besides the same evolutionary content consisting of the position-specific substitution matrix (PSSM) profile from PSI-BLAST , SPOT-Disorder2 also includes the hidden Markov model (HMM) profile from HHblits [38]. The PSSM profile is generated by 3 iterations of PSI-BLAST against the UniRef90 sequence database (UniProt release 2018_03), and consists of 20 substitution values of each position for each AA residue type. The HMM profile consists of 30 values generated by using HHblits v3.0.3 with the UniProt sequence profile database from Oct 2017. These 30 values themselves consist of 20 AA substitution probabilities, 10 transition frequencies, and the number of effective homologous sequences of a given protein (Neff). In addition, they utilized the predicted structural properties from SPOT-1D. The features from SPOT-1D consist of 11 secondary structure probabilities (both three- and eight-state predicted secondary structure elements), 4 sine and 4 cosine θ, τ, φ, and ψ backbone angles, 1 relative solvent-accessible surface area (ASA), 1 contact number (CN), and 2 half-sphere exposure (HSE) values based on the carbon-α atoms.

In total there are 73 features in the input. "		They utilized the predicted structural properties from SPOT-1D. The features from SPOT-1D consist of 11 secondary structure probabilities (both three- and eight-state predicted secondary structure elements), 4 sine and 4 cosine θ, τ, φ, and ψ backbone angles, 1 relative solvent-accessible surface area (ASA), 1 contact number (CN), and 2 half-sphere exposure (HSE) values based on the carbon-α atoms.	A large corpus of models with varying hyperparameters are trained and their performance is analyzed on a validation set. These hyperparameters are swept through in a grid search and include the layout of the network, the number of nodes in each layer (one parameter each for LSTM, IncReSeNet, and FC layers), and the number of layers for each layer type. The five top-performing models with hyperparameters are chosen from this validation period and used in the final ensemble for SPOT-Disorder2.	Dropout is used in different layers. 	6.0	2.0	66c495857089c469b477b4ce				Jack Hanson, Kuldip K. Paliwal, Thomas Litfin, Yaoqi Zhou 	Genomics, Proteomics & Bioinformatics	2019	0.0	0.0		1.0	2025-04-24T14:38:57.774Z	2025-04-24T14:38:57.774Z	3c79c7ba-adce-4b2e-a00e-0b3df26014cf	undenfined	8mjjeoyqtq
