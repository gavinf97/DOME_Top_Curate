user_email	User_OID	timestamp	PMID	publication/title	publication/authors	publication/journal	publication/year	EPMC_pub_year	publication/doi	publication/tags	dataset/provenance	dataset/splits	dataset/redundancy	dataset/availability	optimization/algorithm	optimization/meta	optimization/encoding	optimization/parameters	optimization/features	optimization/fitting	optimization/regularization	optimization/config	model/interpretability	model/output	model/duration	model/availability	evaluation/method	evaluation/measure	evaluation/comparison	evaluation/confidence	evaluation/availability	Availability of  configuration	Execution time 	Performance measures 	publication/updated	publication/pmid	shortid	update	public	uuid	reviewState
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/23/2022 16:36:18	33465072	Genome-wide prediction of topoisomerase IIŒ≤ binding by architectural factors and chromatin accessibility.	Mart√≠nez-Garc√≠a PM, Garc√≠a-Torres M, Divina F, Terr√≥n-Bautista J, Delgado-Sainz I, G√≥mez-Vela F, Cort√©s-Ledesma F.	PLoS Comput Biol.	2021	2021	10.1371/journal.pcbi.1007814		yes, N_pos: 13128  N_neg: 32766	5-fold cross-validation	Correlation Feature Selection is used.	yes, described at S1 table: https://deposition.proteinensemble.org/job/25e45232-2c53-409f-b734-bbc1710609a2  all models and dataset at https://gitlab.com/mgarciat/genome-wide-prediction-of-topoisomerase-iibeta-binding	Naive Bayes, SVM, Random Forests	no	sliding window on sequence		Fast Correlation Based Filter  and  Scatter Search  were used							yes, GitLab https://gitlab.com/mgarciat/genome-wide-prediction-of-topoisomerase-iibeta-binding	5-fold cross validation					no		ROC  curves and AUC values							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/28/2022 0:44:11	33679869	Construction and Comprehensive Analyses of a METTL5-Associated Prognostic Signature With Immune Implication in Lung Adenocarcinomas.	Sun S, Fei K, Zhang G, Wang J, Yang Y, Guo W, Yang Z, Wang J, Xue Q, Gao Y, He J.	 Front Genet.	2021	2020	10.3389/fgene.2020.617174		public databases: 901 samples from The Cancer Genome Atlas cohort (TCGA-LUAD) and gene expression omnibus (GEO) database	10-fold cross validation		"no, they claim: ""Publicly available datasets were analyzed in this study. This data can be found here: The datasets collected in the current study are available in the TCGA3 and GEO repository."" "	Spathial, Random forest, LASSO	no		"R package randomForestSRC: ""The training was running with ‚Äúimportance = TRUE, block size = 1‚Äù and set with all other parameters set to defaul"""		no	no			regression		no	10-fold cross validation		no	no 	no	no		AUCs for 2-, 3-, and 5-year OS were 0.527, 0.596 and 0.671, respectively							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/28/2022 16:40:10	34419924	Nasopharyngeal metabolomics and machine learning approach for the diagnosis of influenza.	Hogan CA, Rajpurkar P, Sowrirajan H, Phillips NA, Le AT, Wu M, Garamani N, Sahoo MK, Wood ML, Huang C, Ng AY, Mak J, Cowan TM, Pinsky BA.	EBioMedicine.	2021	2021	10.1016/j.ebiom.2021.103546		samples from Stanford Health Care and Stanford Children‚Äôs Health, 1:1 ratio of positive to age and sex-matched negative controls.  Data collection was performed after the reference test (RT-PCR) and before the index test (metabolomics). Discovery cohort (from April 23 2015 to October 13 2019):  118 samples, N_neg 118 samples validation cohort (December 21 2019 to February 18 2020): N_pos 48 samples, N_neg 48 samples	The final analysis included for discovery cohort: training set:  94 positive, 92 negative test set: 24 positive, 26 negative		"Conatact (hoganca@stanford.edu) is provided right the beggining of the ""Methods"" section of the papaer for further information and requests.  The data and code generated during this study were made available at https://github.com/stanfordmlgroup/influenza-qtof."	gradient boosted decision trees and random forests	no		Python version 3.6.8, gradient boosted decision trees: LightGBM v2.2.3 RF: scikit-learn v0.20.2			The models were not retrained using SRM data to avoid overfitting and overestimating test performance. In addition, within the training set, cross-validation was used to develop the models to avoid overfitting to the training set.		Black box	classification		https://github.com/stanfordmlgroup/influenza-qtof	 novel experiments.		costeffective comare to PCR tests and could be performed at the point-of-care comapre to RT-PCR test, no other methods for direct omparisonc		yes, https://github.com/stanfordmlgroup/influenza-qtof/tree/master/data	no	no	AUC, sensitivity, specificity							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/29/2022 23:01:05	34112769	A new molecular classification to drive precision treatment strategies in primary Sj√∂gren's syndrome.	Soret P, Le Dantec C, Desvaux E, Foulquier N, Chassagnol B, Hubert S, Jamin C, Barturen G, Desachy G, Devauchelle-Pensec V, Boudjeniba C, Cornec D, Saraux A, Jousse-Joulin S, Barbarroja N, Rodr√≠guez-Pint√≥ I, De Langhe E, Beretta L, Chizzolini C, Kov√°cs L, Witte T, PRECISESADS Clinical Consortium, PRECISESADS Flow Cytometry Consortium, Bettacchioli E, Buttgereit A, Makowska Z, Lesche R, Borghi MO, Martin J, Courtade-Gaiani S, Xuereb L, Guedj M, Moingeon P, Alarc√≥n-Riquelme ME, Laigle L, Pers JO.	Nat Commun  .	2021	2021	10.1038/s41467-021-23472-7		Clinical data collected by the authors N_neg 330, N_pos 304	N_pos: Discovery 227 and Validation 77		All data included in this study is available upon request at ELIXIR Luxemburg ( https://doi.org/10.17881/th9v-xt85 )	composite model  with several stepp with different classification algorithms (hclust, K-means, mclust, Random Forest)	no	global features (RNA-Seq, Flow cytometry)	Molecular subgroups discovery:  - Step 1: Unsupervised gene selection,  - Step 2: Robust consensus clustering (hclust, K-means, mclust)  - Step 3: Identification of molecular signature (one-way ANOVA and Random Forest),  - Step 4: Robustness classification  - Step 5: Classification of discordant patients -> definition of 4 cluster  Composite model for cluster prediction: #1 xgboost-tree: predict C4 vs all #2 multi-classification:  C1, C2, or C3	features selection by Boruta algorithm ( 10.18637/jss.v036.i11 )	n/a 			Black box	classification		https://lbai-infolab.github.io/SjTree/	independent dataset 		no	no	no	no	no	Accuracy (94.81% for the C4 prediction model, and 96.72% for the multi-classification model.)							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/28/2022 12:23:43	32915751	Contrastive Cross-Site Learning With Redesigned Net for COVID-19 CT Classification.	Wang Z, Liu Q, Dou Q.	 IEEE J Biomed Health Inform.	2020	2020	10.1109/jbhi.2020.3023246		two public COVID-19 CT datasets:   -   https://www.medrxiv.org/content/10.1101/2020.04.24.20078584v3 2482 CT images from 120 patients,  N_pos 1252, N_neg 1230   -   http://arxiv.org/abs/2003.13865 N_pos 349 CT images from 216 patients,  N_neg 397 CT images from 171 patients	no	no	preprocessed data: https://drive.google.com/file/d/1JBp9RH9-yBEdtkNYDi6wWL79o62JD5Td/view     	deep learning, novel approach	no	datasets, all images are first resized to 224 √ó 224 in axial plane,	Batch Normalization   		no	no		color maps using Grad-CAM	regression		https://github.com/med-air/Contrastive-COVIDNet	four-fold cross-validation		firstly comparision to COVID-Net method https://doi.org/10.1038/s41598-020-76550-z (Scientific Reports)  by ROC  AUC  further comparisions by p-value:  - Series-Adapter https://scholar.google.com/scholar?as_q=Learning+multiple+visual+domains+with+residual+adapters&as_occt=title&hl=en&as_sdt=0%2C31   - Parallel-Adapter https://ieeexplore.ieee.org/document/8578945  - MS-Net https://doi.org/10.1038/s41598-020-76550-z	outperforming the original COVID-Net trained on each dataset by 12.16% and 14.23% in AUC respectively,	no	implemented with PyTorch [38] using an Nvidia TITAN Xp GPU.		Accuracy, F1 score, Sensitivity, Precision, AUC							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/28/2022 11:30:10	30853547	Unsupervised classification of multi-omics data during cardiac remodeling using deep learning.	Chung NC, Mirza B, Choi H, Wang J, Wang D, Ping P, Wang W.	 Methods.	2019	2019	10.1016/j.ymeth.2019.03.004		datasets are based on mouse strains generated by the lab itself The aggerated dataset has complete time-series (7 timepoints) data for 3479 proteins and 513 metabolites.	no	no	no	K-means clustering, hierarchal clustering (HC), partitioning around medoids (PAM), LSTM based on variational autoencoder (VAE) deep convolutional embedded clustering (DCEC) 	no		K-means, HC, PAM: K = 6 based on prior biological knowledge  LSTM-VAE:  the input layer of dimension 7 √ó 1 first layer generated 7 √ó n second layer 7 √ó 1  DCEC: used as DOI: 10.1007/978-3-319-70096-0_39	no	no	no		black box	classification		no	no		Comparison only betweeen models created by the authors	no	no	platform: Intel Xeon Processor E5-2643 v4, 128 GB RAM and NVIDIA Quadro M4000 GPU.  K-means and HC: Python scikit-learn  PAM: R ‚Äòcluster‚Äô package LSTM-VAE: https://github.com/bilalmirza8519/LSTM-VAE DCEC: https://github.com/XifengGuo/DCEC		pathway enrichment analysis using Reactome knowledgebase							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/29/2022 0:49:10	30590545	Supervised machine learning for the prediction of infection on admission to hospital: a prospective observational cohort study.	Rawson TM, Hernandez B, Moore LSP, Blandy O, Herrero P, Gilchrist M, Gordon A, Toumazou C, Sriskandan S, Georgiou P, Holmes AH.	J Antimicrob Chemother.	2019	2019	10.1093/jac/dky514		six available blood parameters (C-reactive protein, white cell count, bilirubin, creatinine, ALT and alkaline phosphatase) from 160203 individuals.			Yes,  upon reasonable request from the corresponding author	SVM	no	six blood parameters (C-reactive protein, white cell count, bilirubin, creatinine, ALT and alkaline phosphatase)			Removal of outliers, Synthetic Minority Over-Sampling Technique was used	no		Black box 	classification		no	10-fold cross-validation		no direct comparision	no	no	no		ROC AUC 0.84 92% sensitivity, 94%specificity							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/29/2022 1:42:53	31404081	A modeling and machine learning approach to ECG feature engineering for the detection of ischemia using pseudo-ECG.	Ledezma CA, Zhou X, Rodr√≠guez B, Tan PJ, D√≠az-Zuccarini V.	 PLoS One	2019	2019	10.1371/journal.pone.0220294		 6132 pECG beats was used for training in three class: Control, Mild, Severe	10-fold cross-validation	no	no	neural network	no	pECG signal features: (A) QRS duration,  (B) QT interval,  (C) ST deviation,  (D) T wave duration,  (E) QRS amplitude  (F) T wave amplitude	 multiple setup was tested, selected with : 5 hidden layers and 7 hidden neurons per layer, 			no		Black box	classification		no	10-fold cross-validation		no	n/a 	no	no	no	sensitivity,  PPV, F1-score							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/28/2022 23:57:02	30483279	Artificial Intelligence Understands Peptide Observability and Assists With Absolute Protein Quantification.	Zimmer D, Schneider K, Sommer F, Schroda M, M√ºhlhaus T.	Front Plant Sci.	2018	2018	10.3389/fpls.2018.01559		Yeast data set:  from the PRIDE repository  C. reinhardtii data set:  previous proteome-wide studies each dataset filtered for single occurrence of all proteins  	training datasets consisting of 2,652 yeast and 2,732 C. reinhardtii proteins two validation datasets consisting of 664 yeast and 685 C. reinhardtii proteins	no	at the suplementary files  https://www.frontiersin.org/articles/10.3389/fpls.2018.01559/full#supplementary-material  	neural network	no	BioFSharp framework (available at: https://github.com/CSBiology/BioFSharp) and converted into a feature vector with 45 entries.	five dense layers with 128 nodes each	The networks were trained using a minibatch size of 3 for 10 epoch.		Yes, ‚Äúdropout‚Äù technique 		Black box	classification		webservice: (http://csbweb.bio.uni-kl.de/)	randomly selected 20% of the proteins in each assembly to use them as validation-data-sets,   32 peptides from a QconCAT protein was experimentally validated		ChemScore (Parker, 2002)  PeptideSieve (Mallick et al., 2007), PeptideRank (Qeli et al., 2014), CONSequence (Eyers et al., 2011),  ESPPredictor (Fusaro et al., 2009).	no statistical significance declared.	no			normalized discounted cumulative gain (nDCG) metric							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/28/2022 0:12:23	29133589	Precision Oncology beyond Targeted Therapy: Combining Omics Data with Machine Learning Matches the Majority of Cancer Cells to Effective Therapeutics.	Ding MQ, Chen L, Cooper GF, Young JD, Lu X.	 Mol Cancer Res.	2017	2018	10.1158/1541-7786.mcr-17-0378		source of data:  large pharmacogenomics studies: Genomics of Drug Sensitivity in Cancer Project (GDSC), and the Cancer Cell Line Encyclopedia (CCLE), after filtering, they created a single array of data containing information on 3577 features in 624 cell lines	for training a deep autoencoder: randomly split into training and testing datasets of 520 and 104 samples, respectively  for drug-sensitivity prediction: 25-fold cross-validation		no	Elastic net regression, SVM  and deep autoencoder	no	selected features from the deep learning autoencoder		"selected features from the deep learning autoencoder: ""Matlab code for training a deep autoencoder as described by Hinton and Salakhutdinov was obtained from Hinton's website (http://www.cs.toronto.edu/$hinton/MatlabForSciencePaper.html)"""		Yes, variance-based mixture-fitting feature selection scheme		black box	regression		no	25-fold cross-validation		they mentioned two similar studies:  10.1126/science.1127647 and 10.1038/nature12831 		no	no		lastic net models: average sensitivity 0.75, average specificity 0.78, AUROC 0.81 SVM models: average sensitivity 0.59,  average specificity 0.56, AUROC 0.55 							
andrewhatos@gmail.com	6312169df3794236aa9879e5	3/29/2022 21:41:26	26495028	KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.	Rodr√≠guez-Escobedo JG, Garc√≠a-Sep√∫lveda CA, Cuevas-Tello JC.	 Comput Math Methods Med	2015	2015	10.1155/2015/141363		300 healthy individuals (Mexican Reference Genomic DNA Collection (MGDC-REF),) 43 patients with haematological malignancies (Haematology Department of Hospital Central ‚ÄúDr. Ignacio Morones Prieto‚Äù)	no	no	no	J48 Algorithm, A Priori Algorithm	no	no	no	no	no	no		transparent, the authors provided biological explanation some of scenarios	classification		no	statisctical evaluation		no	no	no	no	"no, the authors only described the machine, ""Weka software using a personal computer with a processor IntelCore i7with 2.3Ghz speed and 3 Gb memory."""	ùëù value, ùúí2							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/21/2022 8:46:51	33464298	Image-based pooled whole-genome CRISPRi screening for subcellular phenotypes.	Kanfer G, Sarraf SA, Maman Y, Baldwin H, Dominguez-Martin E, Johnson KR, Ward ME, Kampmann M, Lippincott-Schwartz J, Youle RJ.	Journal of Cell Biology	2021	2021	10.1083/jcb.202006180		Parking and GFP-TFEB images generated in the same study	Training 80%, validation 15%, 5% Independent test data. N_pos and N_neg unknown for training data. For independent data: N_pos=5401, N_neg=4948.	Not applicable	Yes, https://github.com/ gkanfer/AI-PS/tree/master/facs	SVM and Convolutional Neural Network (ImageNet architecture)	No	150x150 pixel images (CNN). Image descrptors for SVM	Unknown	f=3 (pixel intensities) for CNN. f=3 for SVM (descriptors selected after PCA-based feature selection)	Early stopping used to prevent overfitting (CNN)	No		Black box	Binary classification		Yes https://github.com/gkanfer/AI-PS	Independent testing		No	No confidence reported	Not available	Some hyperparameters specified in the main text	Not availbale	Accuracy, AUPRC							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/1/2022 19:41:49	29720103	Prediction of plant lncRNA by ensemble machine learning classifiers.	Simopoulos CMA, Weretilnyk EA, Golding GB.	BMC Genomics	2018	2018	10.1186/s12864-018-4665-2		Positive data from lncRNAdb v2, lncRNAdisease. Negative data from Ensembl, Araport v11. Npos=436 lncRNA sequences. Nneg=? (total number of negative not known). Not previously used.	Ten different indipendent 10-fold cross-validation performed. N_pos and N_neg for training and testing unknown. 	Not available	Yes, supplementary material.	Stochastic gradient boosting and random forests	No	Eleven features for describing complete lncRNA sequence: mRNA length, ORF length, GC%, Fickett score, hexamer score, alignment identity in SwissProt database, length of alignment in SwissProt database, proportion of alignment length and mRNA length (alignment length:mRNA length), proportion of alignment length and ORF length (alignment length:ORF), presence of transposable element, and sequence percent divergence from transposable element.	Not known	f=11. Feature selection by Recursive feature elimination		No		Transparent. Random forests provide feature importance	Classification		Code not available	Cross-validation. No indipendent datasets		GreeNC method (transcript filtering, no machine-learning), CPAT	No confidence reported	Not available	Configuration and hyper-parameter configuration available in the main text (Table 2)		Sensitivity, Specificity, Accuracy, ROC-AUC							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/9/2022 10:14:51	17374164	Predicting protein function by machine learning on amino acid sequences--a critical evaluation.	Al-Shahib A, Breitling R, Gilbert DR.	BMC Genomics	2007	2007	10.1186/1471-2164-8-78		Los Alamos National Laboratory Bioscience Division STD Sequence Databases. N_pos and N_neg for each functional class are unknown.	Five independent training/testing splits with ratio 4:1. N_pos, N_neg for each training/testing is unknown. No separate validation set.	Redundancy between traiing/testing reduced with PSI-BLAST (e-value threshold set to 0.001)	No	Support Vector Machines	Yes, for computing some feature. No handling of potential dataset redundancy.	Global features encoding frequency and total number of each amino acid, as well as of certain sets of amino acids (e.g. hydrophobic, charged, polar). Protein subdivided into four equally sized fragments and calculated the same feature values for each fragment and combination of fragments. Predicted the secondary structure using Prof, position of putative transmembrane helices using TMHMM and of disordered regions using DisEMBL (predicted features are processed using the above fragmentation strategy). 	Not available	f=2579. Feature selection performed using Wilcoxon signed-rank test	Not available	No		Black box	Multi-class classification		No	Repeated training/testing split (five times). No indipendent datasets		No	No	No	Configuration and hyper-parameter configuration available in the main text	Not available	ROC-AUC							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/9/2022 11:07:20	26834994	Machine learning models identify molecules active against the Ebola virus <i>in vitro</i>.	Ekins S, Freundlich JS, Clark AM, Anantpadma M, Davey RA, Madrid P.	F1000 Research	2017	2015	10.12688/f1000research.7217.3		Dataset from literature (Madrid et al., 2013; Madrid et al., 2015). N_pos=41, N_neg=653	5-Fold Cross-validation split: N_pos_train ~= 33, N_neg_train ~= 522, N_pos_test ~= 8, N_neg_test ~= 131. Leave out 50% √ó 100 fold cross validation: N_pos_train ~= 20, N_neg_train ~= 327, N_pos_test ~= 20, N_neg_test ~= 327	Not applicable	Yes, http://molsync.com/ebola/ (link not working)	Bayesian, Support Vector Machine and Recursive Partitioning Forest	No	Molecular descriptors: molecular function class fingerprints of maximum diameter 6 (FCFP_6), AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area	p_svm=222	f=9	Number of training examples is at least twice p_svm. Reduced risk of over- and under-fitting	No		Black box	Binary classification		No	5-fold Cross-validation and Leave out 50% √ó 100 fold cross validation. No independent test.		No	No confidence reported	Partially available in supplementary material	Configuration avalailble in the supplementary material. models available http://molsync.com/ebola/ (link not working)	Not available	ROC-AUC, Confusion matrix, Sensitivity, Specificty							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/9/2022 11:12:23	18779814	What are decision trees?	Kingsford C, Salzberg SL.	Nature Biotechnology	2008	2008	10.1038/nbt0908-1011		Not applicable	Not applicable	Not applicable	Not applicable	Not applicable	Not applicable	Not applicable	Not applicable	Not applicable	Not applicable	Not applicable		Not applicable	Not applicable		Not applicable	Not applicable		Not applicable	Not applicable	Not applicable	Not applicable	Not applicable	Not applicable							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/15/2022 11:03:41	33328863	Multiplex Networks to Characterize Seizure Development in Traumatic Brain Injury Patients.	La Rocca M, Garner R, Amoroso N, Lutkenhoff ES, Monti MM, Vespa P, Toga AW, Duncan D.	Frontiers in neuroscience	2020	2020	10.3389/fnins.2020.591662		MRI scans of Traumatic Brain Injury (TBI) subjects recruited in EpiBioS4Rx. Npos=16, Nneg=37. Not previously used in literature.	N_pos,train=13, N_neg_train=30, N_pos,test=3, N_neg_test=7. Not separate validation set.	Not applicable	No	Random forest	No	MRI scans parceled into non-overlapping patches of V voxels. Patches represent nodes of a brain network, and the absolute values of Pearson‚Äôs correlation between patch pairs were considered the links between the node. Given N, the number of network nodes, 8N features for each subject	Not known	f=?. Feature selection by Random Forest		No		Black box. Random forest used for feature seleciton	Binary classification		No	Repeated 80%-20% cross-validation. No indipendent datasets		Comparison with a standard baseline method based on Region-Of-Interest (ROI) segmentation	No confidence reported	No	No		Sensitivity, Specificity, Accuracy, ROC-AUC							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/15/2022 15:36:27	32220894	RNA-GPS predicts high-resolution RNA subcellular localization and highlights the role of splicing.	Wu KE, Parker KR, Fazal FM, Chang HY, Zou J.	RNA	2020	2020	10.1261/rna.074161.119		Training data: RNA localization data from  APEX-seq results available in literature (Fazal et al., 2019). Eight localization classes: N_c1=1223,N_c2=768,N_c3=301,N_c4=208,N_c5=1361,N_c6=823,N_c7=159,N_c8=739.  Independent test data: ENCODE Project Consortium 2012, cell line HeLa-S3: N=7641, cell line K562: N=6359. Individual class abundance in independent data is unknown	N_train=80%,N_test=10%,N_val=10%. ENCODE data used for testing	Not handled	Raw APEX-seq data available at Gene Expression Omnibus (GEO) under accession GSE116008	Random forest	No	K-mer featurization (k=3,4,5) scheme for 5'-UTR, CDS and 3'-UTR.	p=sqrt(f)=64, where f is the number of features. 	f=4032.	Risk of underfitting, since p=64 << N_total=2928.	No		Interpretable. Interpretation performed via RF feature importance	Multi-class classification		Yes, GitHub https://github.com/wukevin/rnagps	10-fold cross-validation. Independent dataset		Basset (Kelley et al., 2016), RNATracker (Yan et al.,. 2019). Baselines implemented with other tree-based approaches (e.g XGBoost), neural networks, convolutional networks, recurrent networks (long-short term memory, gated recurrent units). 	No confidence reported	Not available	No	Not availbale	Accuracy, AUROC, AUPRC							
castrense.savojardo2@unibo.it	6603042f92c76639b849e69f	3/21/2022 10:33:58	30615300	Profiling of Gene Expression Biomarkers as a Classifier of Methotrexate Nonresponse in Patients With Rheumatoid Arthritis.	Plant D, Maciejewski M, Smith S, Nair N, Maximising Therapeutic Utility in Rheumatoid Arthritis Consortium, the RAMS Study Group, Hyrich K, Ziemek D, Barton A, Verstappen S.	Arthritis & Rheumatology	2019	2019	10.1002/art.40810		Patient data from the  Rheumatoid Arthritis Medication Study (RAMS). N_pos=42, N_neg=43. Not previuolsy used. 	Nested cross-validation split. N_pos, N_neg not available	Not applicable	No	regularized logistic regression and random forest	No	Gene expression data, clinical variables.	Not available	f=10 ?	Not available	No		Black box	Binary classification		No	10-fold nested cross-validation. No independent validation data		No	No confidence reported	No	No	Not availbale	Balanced accuracy and ROC-AUC							
emidio.capriotti@gmail.com	6312169df3794236aa9879e1	4/6/2022 17:27:29	34603483	Identification of Novel COVID-19 Biomarkers by Multiple Feature Selection Strategies.	Zhang S, Qu R, Wang P, Wang S.	Computational and Mathematical Methods in Medicine (Hindawi)	2021	2021	10.1155/2021/2203636		Data source:  Gene expression profiles from NCBI/GEO GSE152075.  Data points: 484 individuals.  N_pos (swabs Covid positive)= 430, N_neg (swabs Covid negative)= 34.  Used by at least one previous paper (PMID: 32898168).   	Due to sample imbalance, the python package imblearn was used to amplify the number of small samples to the same as that of large samples.  	Not reported	Yes (GEO: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE152075)	Support vector machine (SVM) 	No	Global features. Gene Expression Profile	Not reported	The optimized method uses expression from 66 selected genes. The expression profile genes (genes nr = 16032) were first ranked by feature importance (gene expression) via the minimum redundancy maximum relevancy (mRMR) method, getting down to 500 genes. Subsequently, a SVM classifier was used to screen the optimal feature genes by the incremental feature selection (IFS) method. Optimal genes were selected maximizing the the MCC obtained with a Leave-One-Out Cross-Validation procedure on training set.	Not reported.   The number of features were reduced to 66 by the feature selection algorithms, which however could have induce over-fitting by themselves.	No. Not reported how the regularization parameter in SVM was tuned.		Black box. PCA and GO-Term enrichment analysis on 66 selected genes shows an association with ribosomal protein-encoding, viral protein translation, and protein-membrane location.	Classification (Covid swab positive or negative)		No	Leave-One-Out Cross-validation		No	Not assessed	No	No	Not reported	MCC							
emidio.capriotti@gmail.com	6312169df3794236aa9879e1	4/6/2022 16:25:21	31161221	Temporal Stability and Prognostic Biomarker Potential of the Prostate Cancer Urine miRNA Transcriptome.	Jeon J, Olkhov-Mitsel E, Xie H, Yao CQ, Zhao F, Jahangiri S, Cuizon C, Scarcello S, Jeyapala R, Watson JD, Fraser M, Ray J, Commisso K, Loblaw A, Fleshner NE, Bristow RG, Downes M, Vesprini D, Liu S, Bapat B, Boutros PC.	Journal of the National Cancer Institute	2020	2020	10.1093/jnci/djz112		miRNA samples were extracted from prostate cancer patients cohorts, and profiling obtained.  The dataset was composed of N_pos = 61, N_neg = 78. Data not used previously.    An additional 'discovery' cohort was composed of 10 patients (all negatives) .  (Positive: high-risk patients, i.e. GS (Gleason grade) > 7. low-risk patients (GS = 6).	Training set: N_pos = 50, N_neg = 49.  Testing set: N_pos = 11, N_neg = 29.	Not reported	Raw data were deposited into the Gene Expression Omnibus (GSE86474, https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE86474).	Random forest	No	Global features	Random forest (mtry and ntree) optimized by grid search using 5-fold cross-validation with 10 randomized replicates. Predictive model built with randomForestSRC (v2.4.2) for R.	Intra-stable miRNAs (fourth quartile of ICCs; Q100) from the discovery cohort were used as a set of input features. Feature selection protocol identified the expression of 7 miRNA which maximize the performance of the method tested in cross-validation on the training set.	Number of features ~ N_pos + N_neg and Number of parameters > N_pos + N_neg	Yes. miRNA normalization with NanoStringNorm (v1.1.20).		Black box. No information about the optimized parameters were reported.	Binary classifier (high- and low-risk groups)		Not available	cross-validation on training set and validation on an independent set		No	Confidence interval shows overlap between the performance on training and validation sets	No	No	Not reported	AUC							
emidio.capriotti@gmail.com	6312169df3794236aa9879e1	4/6/2022 18:58:39	31462106	Interactive alkaptonuria database: investigating clinical data to improve patient care in a rare disease.	Cicaloni V, Spiga O, Dimitri GM, Maiocchi R, Millucci L, Giustarini D, Bernardini G, Bernini A, Marzocchi B, Braconi D, Santucci A.	The FASEB Journal	2019	2019	10.1096/fj.201901529r		Source:  AKU-related dataset, 203 patients in total.  Not used previously.	Training set: 181 patients, Validation set: 22 patients	Not reported	The database, hosting the dataset, is accessible via registration request:    http://www.bio.unisi.it/aku-db/	Multiple Linear Regression (MLR) 	No	Global features	7 MLR parameters:  5 feature parameters, 1 intercept, 1 error term.	The 110 numeric fields included in the platform were considered as the possible predictors with a backward elimination method. From the screening of every model, the authors selected the most significant ones (5 predictors) according to the F statistics of the ChiSquare coefficients.  From the text it appears that the feature elimination procedure was applied on the whole dataset.  	Apparently both over-fitting and under-fitting can be excluded (p<N, f =5).  	Not applicable.		Transparent.  All 5 features are clinical parameters known to be related to the AKU illness.	Regression: prediction of patients PTI (Protein Thiolation Index) values, given the patients clinical information.		Not available	Independent validation set.		Not applicable	Significance of the model by F statistics. 	No	Coefficients Estimates and Standard Errors of the predictors are reported.	Not reported	Adjusted coefficient of determination, Mean Standard Error, Maximum Absolute Difference Predicted vs Experimental							
emidio.capriotti@gmail.com	6312169df3794236aa9879e1	4/6/2022 3:38:12	19667082	PineSAP--sequence alignment and SNP identification pipeline.	Wegrzyn JL, Lee JM, Liechty J, Neale DB.	Bioinformatics . 	2009	2009	10.1093/bioinformatics/btp477		Source: Pinus taeda resequencing data, not further specified.  Training set is composed of a total of 300 validated sequences.  Test set is composed of 120 independent sequences, with 563 manually validated SNPs.	 Testing: 120 Sequences 563 manually validated SNPs 	Not reported	No	J48 Algorithm For Decision Tree (WEKA)   Decision tree J48 is the implementation of algorithm ID3 (Iterative Dichotomiser 3) developed by the WEKA project team. 	No	Global features	Not reported	Sequence-based statistics were derived through a customized feature extraction program and fed as a vector for each polymorphism to the J48 classification tree available in the WEKA classifier package.  9 features were used to enhance polymorphism prediction accuracy (as reported in https://nealelab.ucdavis.edu/adept2-overview/pinesap/).	Not reported	No		Input features are transparent (Sequence Depth, Local Average Quality, Alignment Quality) while their combination is not interpretable (Black box).	Binary classifier (SNP predictions accepted or rejected).		Broken link (http://dendrome.ucdavis.edu/adept2/ resequencing.html). The customized pipeline for feature extraction is reported in a new link:   https://nealelab.ucdavis.edu/adept2-overview/pinesap/	Independent dataset of 120 unique sequences with 563 manually validated SNPs. Validation = All SNP calls were identified as based on visual inspection of Polyphred and Polybayes predictions in Consed.		Polyphred, Polybayes. Used for generating the features.	Not reported	No	No	Not reported	Accuracy, sensitivity, specificity							
federico.zambelli@gmail.com	6312169df3794236aa987a0c	1/18/2022 16:56:16	34297718	Machine learning reveals mesenchymal breast carcinoma cell adaptation in response to matrix stiffness.	Rozova VS, Anwer AG, Guller AE, Es HA, Khabir Z, Sokolova AI, Gavrilov MU, Goldys EM, Warkiani ME, Thiery JP, Zvyagin AV.	PLOS Computational Biology 	2021	2021	10.1371/journal.pcbi.1009193		Imaging data produced by the same authors. 826 cells classified in 3 classes (no negative/positive binary classification).	90% training set 10% test set		The features table dataset has not been made available. Authors made available the imaging data at https://www.ebi.ac.uk/biostudies/ with accession number S-BIAD161. Authors also report that features were extracted from images with CellProfiler 3.1.8 and provide the list of morphological and contextual measurements extracted to generate the features table (Table B of http://journals.plos.org/ploscompbiol/article/asset?unique&id=info:doi/10.1371/journal.pcbi.1009193.s002http://journals.plos.org/ploscompbiol/article/asset?unique&id=info:doi/10.1371/journal.pcbi.1009193.s002 )	Random forest	No	global features	Number of parameters not specificed. Hyperparameter tuning was performed using randomised search with K-fold cross-validation to optimise the model parameters 	100. Iterative feature selection removing features with Pearson‚Äôs correlation coefficient > 0.8. Performed on all data.				Black box	Classification			cross-validation				No	No		F1 score of 0.98							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	2/8/2022 0:18:31	34168145	Bioactivity descriptors for uncharacterized chemical compounds.	Bertoni M, Duran-Frigola M, Badia-I-Mompel P, Pauls E, Orozco-Ruiz M, Guitart-Pla O, Alcalde V, Diaz VM, Berenguer-Llergo A, Brun-Heath I, Villegas N, de Herreros AG, Aloy P.	Nature Communications	2021	2021	10.1038/s41467-021-24150-4		Public database	Size not reported. 80:20 train-test split	Not reported	Yes, https://chemicalchecker.org/	Neural network	No	n-dimensional vectors	Not reported	3200	Not reported	Yes, Global orthogonal regularization (alpha = 1)		Black box	Classification		https://gitlabsbnb.irbbarcelona.org/packages/signaturizer	Cross-validation		Not reported	Not applicable	No	No	Not reported	Accuracy							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/16/2022 12:48:49	33995917	Identifying the minimum amplicon sequence depth to adequately predict classes in eDNA-based marine biomonitoring using supervised machine learning.	Dully V, Wilding TA, M√ºhlhaus T, Stoeck T.	Computational and Structural Biotechnology Journal	2021	2021	10.1016/j.csbj.2021.04.005		4 datasets, 3 form previous papers and 1 original. 			Yes. Original dataset: https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJNA417767	Random Forest	No	Amplicon Sequence Variants (ASV) used as features in a relative abundance matrix		Depending on the dataset, from 50 to 5000				Black box	Classification			cross-validation			NAA				custom							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/16/2022 16:16:20	33953203	Regression plane concept for analysing continuous cellular processes with machine learning.	Szkalisity A, Piccinini F, Beleon A, Balassa T, Varga IG, Migh E, Molnar C, Paavolainen L, Timonen S, Banerjee I, Ikonen E, Yamauchi Y, Ando I, Peltonen J, Pieti√§inen V, Honti V, Horvath P.	Nature Communications	2021	2021	10.1038/s41467-021-22866-x		Synthetic dataset + 3 original datasets			Yes, https://data.broadinstitute.org/bbbc/image_sets.html https://doi.org/10.6084/m9.figshare.c.5067638.v1 http://www.mitocheck.org/mitotic_cell_atlas/downloads/v1.0.1/mitotic_cell_atlas_v1.0.1_fulldata.zip https://doi.org/10.6084/m9.figshare.c.5075093.v1	Novel approach (Regression Plane)	No	position and features of each cell to be analyzed			Na	Na			Regression		http://www.cellclassifier.org	cross validation and novel experiments		Multiple			heuristic hyperparameter initialization methods									
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/16/2022 16:40:33	33169030	Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification.	Sani OG, Abbaspourazad H, Wong YT, Pesaran B, Shanechi MM.	Nature Neuroscience	2021	2021	10.1038/s41593-020-00733-0		Two monkeys!			Yes, Upon reasonable request from the corresponding author	Novel approach (Preferential Subspace IDentification)	No							Black box	regression		https://github.com/ShanechiLab/PSID	cross-validation		neural dynamic mod- eling (NDM) e representational modeling  (RM)					cross-validated CC between the true and predicted behavior							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/2/2022 16:10:05	33425719	Intratumoral and Peritumoral Radiomics of Contrast-Enhanced CT for Prediction of Disease-Free Survival and Chemotherapy Response in Stage II/III Gastric Cancer.	Li J, Zhang C, Wei J, Zheng P, Zhang H, Xie Y, Bai J, Zhu Z, Zhou K, Liang X, Xie Y, Qin T.	Frontiers in Oncology	2020	2020	10.3389/fonc.2020.552270		CT images from a total of 739 patients with gastric cancer. 	286 training - 453 validation No info on N_pos and N_neg immediately available 		No	SVM	No			584, SVM-recursive feature elimination used for feature selection on training data only.				Black box	Binary predictions			Independent dataset							sensitivity, specificity, AUC-ROC curve							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/2/2022 16:41:47	30877925	Metabolome-based signature of disease pathology in MS.	Andersen SL, Briggs FBS, Winnike JH, Natanzon Y, Maichle S, Knagge KJ, Newby LK, Gregory SG.	Multiple Sclerosis and Related Disorders	2019	2019	10.1016/j.msard.2019.03.006		Untargeted two-dimensional gas chromatography and time-of-flight mass spectrometry. 12_pos and 13_neg				Random forest	No			325				Transparent. 12 metabolites were determined to be informative for MS status	Binary			Other experiments and literature.							AUC							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/2/2022 17:27:58	29219069	A boosting approach for prediction of protein-RNA binding residues.	Tang Y, Liu D, Wang Z, Wen T, Deng L.	BMC Bioinformatics	2017	2017	10.1186/s12859-017-1879-2		Used by previous papers		 eliminating sequences more similar than 40%	http://dlab.org.cn/PredRBR/ (not working now)	Gradient tree boosting	No	global features		63 + 63, Incremental Feature Selection				Black box	Binary predictions		http://dlab.org.cn/PredRBR/ (not working)	Independent dataset		BindN, PPRint, BindN+, RNABindR2.0, RNABindRPlus, SNBRFinder					sensitivity, specificity, accuracy, precision, F-measure, MCC score							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/3/2022 17:42:56	33354569	PmDNE: Prediction of miRNA-Disease Association Based on Network Embedding and Network Similarity Analysis.	Li J, Liu Y, Zhang Z, Liu B, Wang Y.	BioMed Research International	2020	2020	10.1155/2020/6248686		Database HMDD3.0 (http://www.cuilab.cn/hmdde)			http://www.cuilab.cn/hmdd	Random Forest + Network Embedding  + Network Similarity	No		3, Random Forest	128				Black box	Binary			Cross validation		DeepWalk, Line, Node2Vec, GraRep, GF, Lap, lle (all Network Embedding  methods)				Minutes	ROC-AUC, PR_AUC, Precision, Accuracy, F1, Recall							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/4/2022 17:00:53	32753502	Genome-Wide Analysis of RNA Decay in the Cyanobacterium <i>Synechococcus</i> sp. Strain PCC 7002.	Gordon GC, Cameron JC, Gupta STP, Engstrom MD, Reed JL, Pfleger BF.	mSystems	2020	2020	10.1128/msystems.00224-20		Experimental			Yes, https://www.ncbi.nlm.nih.gov/sra/SRP130967 (Sequences) https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE109174 (transcripts half-life)	Variant of random forest regression	No	Counts of all possible 3- to 8-letter-long sequence motifs present in the 5= and 3= UTRs		200,000 features for UTR sequence motif analysis / using a random subset of features to identify the best candidate feature for splitting at each node				Transparent, T rich UTRs provide stability	Regression			Cross-validation					Hyperparameters reported in the paper		R2							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/4/2022 17:32:12	30970017	Estimation of the breadth of CD4bs targeting HIV antibodies by molecular modeling and machine learning.	Conti S, Karplus M.	Plos Computational Biology	2019	2019	10.1371/journal.pcbi.1006954		Database CATNAP http://hiv.lanl.gov/catnap	3864 exact IC50 values are split randomly in half into a training set and a validation set.		Support information files.	Multi-Layer Perceptron 	No		200	6179		No, high ratio between the number of experimental values in the training and number of parameters in the model 		Black Box	Both		Supplementary information	Cross-validation		Neural Network with two hidden layers, k-nearest neighbors, Random Forest, SVM	Confidence intervals			about 13 minutes	Confusion matrix							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/16/2022 15:35:06	32858131	Interplay between oxidative damage, the redox status, and metabolic biomarkers during long-term fasting.	Grundler F, Mesnage R, Goutzourelas N, Tekos F, Makri S, Brack M, Kouretas D, Wilhelmi de Toledo F.	Food and Chemical Ttoxicology	2020	2020	10.1016/j.fct.2020.111701		109 patients	60% training 40% validation			Classification and Regression Tree	No			12 markers				Transparent - Lipid peroxidation was the most important predictor of the changes in LDL levels	Regression			Cross-validation														
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/17/2022 23:25:21	28881974	Large-scale structure prediction by improved contact predictions and model quality assessment.	Michel M, Men√©ndez Hurtado D, Uziela K, Elofsson A.	Bioinformatics	2017	2017	10.1093/bioinformatics/btx239		PFAM			http://c3.pcons.net/		Yes. Protein structures/Protein sequences							Black box	Regression		http://c3.pcons.net/	Independent dataset							ROC Curve							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/17/2022 23:10:43	26746583	High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning.	Kandaswamy C, Silva LM, Alexandre LA, Santos JM.	Journal of Biomolecular Screening	2016	2016	10.1177/1087057115623451		Public	148649 cells. 1/2 source and 1/2 target		https://bbbc.broadinstitute.org/ accession BBBC021	Deep Transfer Learning (type of Deep Neural Network)	No	Autoencoder		453		leave-one-compound-out cross-validation (LOOCV)		Black box	Classification		http://www.deepnets.ineb.up.pt/files/software/DTL_frontend.html	cross-validation						500 min	Accuracy, confusion matrices							
federico.zambelli@unimi.it	6312169df3794236aa9879f6	3/16/2022 17:02:02	27222432	Cox process representation and inference for stochastic reaction-diffusion processes.	Schnoerr D, Grima R, Sanguinetti G.	Nature Communications	2015	2016	10.1038/ncomms11729		syntetic data and one public dataset			Yes, the Drosophila Bicoid data used in this study is available from the FlyEx database, http://urchin.spbcas.ru/flyex/ 	Novel approach	No							Black box	Regression		Supplementary data of the article			stochastic simulations												
franco.pradelli94@gmai.com	Unknown	3/8/2022 16:07:15	33181068	The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation.	Whittington JCR, Muller TH, Mark S, Chen G, Barry C, Burgess N, Behrens TEJ.	Cell	2020	2020	10.1016/j.cell.2020.10.024																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/17/2022 9:36:07	34388102	COVID-19 Screening in Chest X-Ray Images Using Lung Region Priors.	An J, Cai Q, Qu Z, Gao Z.	IEEE Journal of Biomedical and Health Informatics	2021	2021	10.1109/jbhi.2021.3104629		"Public dataset of Chest X Rays scans labeled for ""normal"", ""viral pneumonia"", and ""COVID-19"". N_normal = 1341; N_viral_pneumonia = 1345; N_covid19 = 219. Used in previous papers."	No test or validation set used. They used 5-fold cross-validation on the dataset for evaluation. Distribution of the classes in the splits not stated.	Only one dataset is used. They used 5-fold cross-validation on the dataset for evaluation.	Yes. They used a public dataset published in a previous paper. Paper doi: 10.1109/ACCESS.2020.3010287	Combination of three DenseNet-121, the output of which was combined in a final fully connected layer. 	"Yes. The classifier input data are generated using an unsupervised ML algorithm extracting three image features from Chest X Rays scans. Such unsupervised ML algorithm is a convolutional adversarial network (they call that ""MS-AdaNet"").  They train and test MS-AdaNet on a independent dataset to prove its ability in extrating features. However they trained this algorithm also on the dataset use for classification when the MS-AdaNet is used as input for the classifier."	The classifier input data are generated by an unsupervised ML algorithm (MS-AdaNet). No transformation is stated for the input data of MS-AdaNet.	Not stated.	The inputs of the algorithm are three images. The definition of the images is not stated.	Not stated	No overfitting prevention strategy is mentioned.		Black box.	Classification		No	5-fold cross-validation 		Compared with other methods presented in literature. 	No confidence intervals or statistical significance provided.	No	No.	Not stated	Accuracy, F1 score, Recall, and Precision							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/18/2022 8:57:44	33810341	The Budapest Amyloid Predictor and Its Applications.	Keresztes L, Sz√∂gi E, Varga B, Farkas V, Perczel A, Grolmusz V.	Biomolecules	2021	2021	10.3390/biom11040500		Waltz database of hexapeptides, classified in amyloidogenic (pos) and nonamyloidogenic (neg). N_pos = 541; N_neg = 901. Dataset used in other papers. Dataset enriched with physicochemical proprieties of amino-acids derived from AAindex. 	Dataset splitted in test set (N_pos = 158; N_neg = 309) and training set (N_pos = 383; N_neg = 592)	The two dataset have no overlaps.	Yes. URL for waltz database: http://waltzdb.switchlab.org/	SVM	No	Aminoacid sequences enriched with physicochemical proprieties from AAindex (for each amino-acid)	3319	3318. No feature selection strategy.	The number of features is huge, but no strategy for overfitting prevention was adopted.	No.		Transparent. The support vector machine linearly separates samples based on the physicochemical features of the aminoacids.	Classification (amyloidogenic or nonamyloidogenic)		The classiffier is available at: https://pitgroup.org/bap/; the source code is not available.	Prediction on the test set.		Compared with another algorithm, but the comparison is only based on the accuracy.	No confidence intervals or statistical significance stated.	No.	No.	Not stated	Accuracy, ROC curve, Area Under Curve (AUC)							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/18/2022 9:58:28	32991297	Identification of lncRNA Signature Associated With Pan-Cancer Prognosis.	Bao G, Xu R, Wang X, Ji J, Wang L, Li W, Zhang Q, Huang B, Chen A, Zhang D, Kong B, Yang Q, Yuan C, Wang X, Wang J, Li X.	IEEE Journal of Biomedical and Health Informatics	2021	2021	10.1109/jbhi.2020.3027680		"Dataset 1: RNA-seq data from The Cancer Genome Atlas for different patients affected by different types of cancer. To the end of ML classification, patients where classified as ""High risk"" or ""Low risk"" based on the Overall Survival time. N = 2210; distribution of High risk and Low risk patients not stated. Used in other papers.  Dataset 2: RNA-seq data from Therapeutically Applicable Research to Generate Effective Treatments (TARGET) dataset (N = 1122). Used in other papers.  Dataset 3: RNA-seq data from Clinical Proteomic Tumor Analysis Consortium (CPTAC) dataset (N=391). Used in other papers."	Dataset 1 divided in training set (N = 1878) and test set (N = 332). Distribution of High and Low risk patients not stated.  Datasets 2 and 3 used as independent test set. Distribution of High and Low risk patients not stated.	Dataset splits for Dataset 1 do not overlap.   Dataset 1, 2 and 3 are independent from each other.	Dataset 1: URL: https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga  Dataset 2: URL: https://ocg.cancer.gov/programs/target  Dataset 3: URL: https://proteomics.cancer.gov/programs/cptac	Random Forest	Yes. Feature selection operated using ML. The set used for feature selection is the same used for the training of the classifier, but the validation for the classifier is operated on independent dataset (Dataset 2 and 3).	No tranformation.	Not stated.	5 lncRNA sequences selected from 731. A ML algorithm based on random forest was used for feature selection. Feature selection was operated on training data only.		No		Black box.	Classification		Yes, code available at: https://github.com/guoqingbao/PanCancerLncRNA	Test set derived from Dataset 1; Independent Datasets 2 and 3.		The model is not compared with others.	Not stated	Yes, the evaluation procedure and code is available at: https://github.com/guoqingbao/PanCancerLncRNA	No, but full code is available.	Not stated.	Area Under Curve (AUC)							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/28/2022 14:25:46	34573923	Mortality Prediction Utilizing Blood Biomarkers to Predict the Severity of COVID-19 Using Machine Learning Technique.	Rahman T, Al-Ishaq FA, Al-Mohannadi FS, Mubarak RS, Al-Hitmi MH, Islam KR, Khandakar A, Hssain AA, Al-Madeed S, Zughaier SM, Chowdhury MEH.	diagnostics	2021	2021	10.3390/diagnostics11091582		"Dataset 1: 387 patients labeled as ""survived"" (pos) (N_pos = 335) and ""dead"" (neg) (N_neg = 49).  Dataset 2: 375 patients labeled as ""survived"" (pos) (N_pos = 201) and ""dead"" (neg) (N_neg = 174).  Both datasets used in previous publications."	Dataset 1 was splitted in two subsets. 80% of the data used for training and validation; 20% of the data used for testing.  Dataset 2 was entirely used for testing	No redundancy between the subsets.	Dataset 1: publicy available with the publication at doi: https://doi.org/10.1016/j.imu.2019.100275. Dataset splits not provided.  Dataset 2: publicy available with the publication at doi: https://doi.org/10.1101/2020.11.02.365536	Logistic Regression	No	Feature selection (operated on the training set finding the top 5 significant features) Imputation of missing data points through MICE Balancing on the dataset (regarding pos and neg cases) through SMOTE	6 (inferred from the context)	"5 selected out of 18. The 5 more relevant feature were selected using chi-square test to identify the feature which significantly differ between the ""pos"" cases and the ""neg"" cases.  It is not clear whether the feature selection was performed just on training data. "		No		Black box	Regression (survival probability)		Yes, the code is available at: https://github.com/tawsifur/Mortality-severity-prediction-using-blood-biomarkers	Predictor evaluated on independent datasets		Compared with Random Forest, Support Vector machine, K-nearest neighbor, XGBoost, and Extra-tree	The performance metrics have confidence intervals. No statistical significance is claimed.	Yes, it is available at: https://github.com/tawsifur/Mortality-severity-prediction-using-blood-biomarkers	Yes, the 6 parameters resulted from training are reported on the paper	Not stated	Accuracy, Precision, Sensitivity, F1-Score, Specificity, AUC							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/15/2022 9:26:07	32905495	Digital solutions for shaping mood and behavior among individuals with mood disorders.	Victory A, Letkiewicz A, Cochran AL.	Current Opinion in Systems Biology	2020	2020	10.1016/j.coisb.2020.07.008																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/16/2022 9:43:09	33329703	Identifying 8-mRNAsi Based Signature for Predicting Survival in Patients With Head and Neck Squamous Cell Carcinoma via Machine Learning.	Tian Y, Wang J, Qin C, Zhu G, Chen X, Chen Z, Qin Y, Wei M, Li Z, Zhang X, Lv Y, Cai G.	Frontiers in Genetics	2020	2020	10.3389/fgene.2020.566159		Dataset 1: RNA-Seq data from The Cancer Genome Atlas for Head and Neck Squamous Cell Carcinoma (TGCA-HNSCC). N = 544; N_pos (survived patients) = 211, N_neg (not survived patients) = 280. Used in the community.  Dataset 2: GSE41613 from the Gene Expression Omnibus (GEO). N = 97; N_pos (survived patients) = 46, N_neg (not survived patients) = 50. Used in the community.	Dataset 1: splitted in 50% for training and 50% for test. Split was conducted randomly. N_pos and N_neg for each subset not stated.  Dataset 2: entirely used for test.	Dataset 1 and Dataset 2 are independent	Dataset 1: Yes. URL: https://portal.gdc.cancer.gov/projects/TCGA-HNSC  Dataset 2: Yes. URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE41613 	One class logistic regression. 	No.	Cox regression analysis, least absolute shrinkage and selection operator (lasso), and Akaike information criterion (AIC) were used to identify the relevant genes to train the logistic regression model.	Not clearly stated, could be inferred from the text.	8 input features selected using Cox regression analysis, least absolute shrinkage and selection operator (lasso), and Akaike information criterion (AIC)	Not clearly stated, but could be inferred from the text that p is smaller than N. 	Not stated.		Transparent. The model generates a risk score according to the expression of the 8 selected genes.	Regression		No	Independent dataset (using Dataset 2)		The method was not compared to others.	Not provided.	No.	No.	Not stated.	area under curve (AUC)							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	3/8/2022 15:42:05	32324731	BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale.	Chen Q, Lee K, Yan S, Kim S, Wei CH, Lu Z.	PLoS Computational Biology	2020	2020	10.1371/journal.pcbi.1007617		Only one dataset employed, created using all PubMed abastracts 			Yes. Dataset available at URL: https://github.com/ncbi/BioConceptVec	Novel approach called BioConceptVec. The paper explains why they used a novel approach	No.		Not stated					Black box	Embeddings		Yes, available at URL: https://github.com/ncbi/BioConceptVec	Intrinsic and Extrinsic evaluation from 9 independent datasets		"Compared with other methods (BioAgvWord and ""Yu et al."")"	No confidence interval	No	Yes, available at URL: https://github.com/ncbi/BioConceptVec	Not stated	Precision, Recall, F1-score, Area Under Curve (AUC)							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	1/28/2022 21:38:37	31466478	EpiSmokEr: a robust classifier to determine smoking status from DNA methylation data.	Bollepalli S, Korhonen T, Kaprio J, Anders S, Ollikainen M.	Epigenomics	2019	2019	10.2217/epi-2019-0206		For each dataset 3 categories are considered: Smokers (S), Former Smokers (FS), and Never Smokers (NS). For each dataset N_S, N_FS, and N_NS will be used for the number of Smokers, Former Smokers, and Never Smokers respectively. For each dataset only data related to DNA methilation.  Dataset 1: data from 474 individuals from the Dietary, Lifestyle and Genetic determinants of Obesity and Metabolic syndrome (DILGOM). N_S = 113, N_FS = 118, N_NS = 243. Used in other papers.  Dstaset 2: data from 408 individuals from the Finnish Twin Cohort (FTC). N_S = 67; N_FS = 141; N_NS = 200. Used in other papers.  Dataset 3: data from 687 individuals from the GSE42861 in Gene Expression Omnibus (GEO). N_S = 266; N_FS = 228; N_NS = 193. Used in other papers.  Dataset 4: data from 464 individuals from the GSE50660 in Gene Expression Omnibus (GEO). N_S = 22; N_FS = 263, N_NS = 179.	Dataset 1: Used as training test. Used for cross-validation randomly subdividing data in 90% training and 10% test data. Distribution of S, FS, and NS after random subdivisions is not stated.  Dataset 2: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.  Dataset 3: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.  Dataset 4: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.	Dataset 1, 2, 3 and 4 are independent from each other.	Dataset 1: yes. Dataset ID: EGAD00001000200; URL: https://ega-archive.org/datasets/EGAD00001000200; license: stated with specific Data Use Ontology (DUO) codes: DUO:0000005, DUO:0000026, DUO:0000027, DUO:0000029, DUO:0000019, DUO:0000028.  Dataset 2: no (available upon request at: https://thl.fi/en/web/thl-biobank/for-researchers/sample-collections/twin-study)  Dataset 3: yes. Dataset id: GSE42861; URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=gse42861; license: not stated.  Dataset 4: yes. Dataset id: GSE50660; URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE50660; license: not stated.	Least absolute shrinkage and selection operator (LASSO).	No.	Training dataset are quantile-normalized before training.	Number of p not stated, but could be inferred from the context.	Number of f = 122.	N/A.	"Introduction of a parameter ""lambda"" in the penalized log likelihood procedure for selecting the ""trainable"" parameter. Selection of the ""lambda"" parameter through cross-validation."		Black box.	Regression (probability scores of being Smoker, Former Smoker or Never Smoker)		Code is available at: https://github.com/sailalithabollepalli/EpiSmokEr. No License provided.	Using independent dataset.		Comparison with non-ML methods provided. An extensive comparison was not performed due to differences in the methods.	Not stated.	No.	The code and the parameters used are available at: https://github.com/sailalithabollepalli/EpiSmokEr. No license specified.	Not stated.	Sensitivity and Specificity							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	1/28/2022 14:49:16	31534955	Predicting Drug-Disease Associations via Using Gaussian Interaction Profile and Kernel-Based Autoencoder.	Jiang HJ, Huang YA, You ZH, You ZH.	BioMed Research International	2019	2019	10.1155/2019/2426958		Dataset 1: Cdataset (N_pos = 2532; N_neg = 2532); Used in previous papers.  Dataset 2: Fdataset (N_pos: 1933; N_neg = 1933); Used in previous papers.  Both databases contain established drug-disease interactions, that they used as positive cases. Negative cases generated randomly pairing diseases and drugs available in the databases. The number of negative cases generated is always equal to the number of positive cases. Both the dataset are integrated with information coming from other databases (PubChem, MeSH).	Both databases used as training and validation set using 10-fold cross-validation.	Dataset 1 and 2 are independent. No redundancies stated in 10-fold cross validation.	Yes. Made available by the authors at: https://github.com/HanJingJiang/GIPAE. No License stated.	Algorithm 1: they use a novel machine learning method for feature extraction, called Gaussian interaction profile kernel and autoencoder (GIPAE).   Algorithm 2: they use Random Forest for classification.	No.	Input information is transformed by GIPAE, in order to extract new features from data. The transformed data are then used for training a Random Forest algorithm.	Not stated.	Not stated. 		Not stated		Algorithm 1: Transparent. Input features regarding diseases and drugs are transform to provide a sort of similarity measure between different drugs and different diseases. These information are then used to train Algorithm 2.  Algorithm 2: black box.	Classification		The repository of the code exists at https://github.com/HanJingJiang/GIPAE but the actual code has been removed.	10-fold cross vaildation		Compared with other predictors of drug-disease association: DrugNet, HGBI, KBMF, MBiRW, DRRS. 	No confidence intervals or statistical significance stated.	No.	No.	Not stated	Sensitivity, Specificity, F1-score, and accuracy.							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/10/2022 16:35:16	31407406	Ensembling multiple raw coevolutionary features with deep residual neural networks for contact-map prediction in CASP13.	Li Y, Zhang C, Bell EW, Yu DJ, Zhang Y.	Proteins: Structure, Function and Bioinformatics	2019	2019	10.1002/prot.25798		Dataset 1: Protein sequences retrived from SCOPe 2.07 database. N = 7,671. Used in other papers. Dataset used for training.  Dataset 2: CASP13. Used in other papers. Dataset used for test. N = 122.  The paper is about the prediction of contact maps in the protein sequence, so data are not in classes and N_pos and N_neg do not apply (N/A from now on)		Dataset 1 (used for training) and Dataset 2 (used for test) are independent.	Yes.   Dataset 1: URL: http://scop.berkeley.edu/  Dataset 2: URL: https://predictioncenter.org/casp13/	Algorithm 1 (TripletRes): neural network  Algorithm 2 (ResTriplet): neural network	Algorithm 1: No.  Algorithm 2: Yes. The network is actually composed of two subnetworks (called Stage 1 and Stage 2 in the paper), the first giving the inputs to the second. 	For each sequence a multiple sequence alignment (MSA) was performed.	Not stated	For each sequence three matrix features are generated: Covariance matrix, Precision Matrix, coupling parameters of the Potts model.		No.		Black box.	The model produces a prediction of the contact map for each residue pair in the sequence alignment.		Not available.	Indipendent dataset (Dataset 2, i.e. CASP13)		Not clear. They compare Algorithm 1 and Algorithm 2. 	They claim statistical significance in the different performances of Algorithm 1 and Algorithm 2.	No.	No.	Not stated.	Prediction accuracy (performed by CASP13 assesors)							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/11/2022 10:17:27	30933970	Adaptive multi-view multi-label learning for identifying disease-associated candidate miRNAs.	Liang C, Yu S, Luo J.	PLOS Computational Biology	2019	2019	10.1371/journal.pcbi.1006931		They use different datasets in the paper.  Dataset 1: obtained composing data from different databases. miRNA-disease association data were retrived from the database HMDD v2.0. They added miRNA information using data from the miRBase database and added disease information using MeSH descriptors. The final dataset was used to compose a matrix where miRNA associated to a disease was labeled 1 and 0 otherwise. N, N_pos, and N_neg not stated, but could be inferred from the text.   Dataset 2: miRNA-disease association data from HMDD v1.0  Dataset3: miRNA expression data associated with Tyroid cancer, retrived from The Cancer Genome Atlas (Project TCGA-THCA).  Dataset 1 not used in previous papers. Datasets 2 and 3 used in the community.	Not stated, but could be inferred from the text.	Not stated.	Dataset 1: No.  Dataset 2: No.  Dataset 3. Yes. URL: https://portal.gdc.cancer.gov/projects/TCGA-THCA	Novel semi-supervised algorthm called AMVML (Adaptive Multi-View Multi-Label). No reason stated for not having published it before.	No.	Not transformed	Not stated, maybe could be inferred from the paper.	Not stated, but could be inferred from the text.		Not stated		Trasparent. Prediction based on similarity between different miRNAs and different diseases. If a given miRNA is associated to a given disease D, it might be associated only with diseases similar to D	Regression (association probability with a disease)		Yes for one specific case: https://github.com/alcs417/AMVML	Leave-one-out validation and 5-fold cross-validation on Dataset 1  5-fold cross validation on Dataset 3 		Compared with other 4 methods for predicting miRNA-disease association. Statistical significance is given as proof for performance.	The performarce difference is statistically significant compared to other 4 algorithms	No.	No	Not stated	Area Under Curve (AUC)							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/15/2022 9:29:17	31120879	Wisdom of crowds in computational biology.	Papin JA, Mac Gabhann F.	PLoS Computational Biology	2019	2019	10.1371/journal.pcbi.1007032																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/15/2022 9:35:20	29614729	Imaging, Tracking and Computational Analyses of Virus Entry and Egress with the Cytoskeleton.	Wang IH, Burckhardt CJ, Yakimovich A, Greber UF.	Viruses	2018	2018	10.3390/v10040166																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	3/8/2022 14:37:33	30388122	LogLoss-BERAF: An ensemble-based machine learning model for constructing highly accurate diagnostic sets of methylation sites accounting for heterogeneity in prostate cancer.	Babalyan K, Sultanov R, Generozov E, Sharova E, Kostryukova E, Larin A, Kanygina A, Govorun V, Arapidi G.	PLoS ONE	2018	2018	10.1371/journal.pone.0204371		All the datasets are public. For all datasetes, pos refer to tumor sample, neg to non-tumor sample.  -- Datasets for prostate cancer -- Dataset 1: GEO dataset GSE74013 (N_pos = 21; N_neg = 27) Dataset 2: TCGA-PRAD (N_pos = 293; N_neg = 23) Dataset 3: GEO dataset GSE55479 (N_pos = 143; N_neg = 0) Dataset 4: GEO dataset GSE38240 (N_pos = 8; N_neg = 4) Dataset 5: GEO dataset GSE73549 (N_pos = 77; N_neg = 15)  -- Datasets for bladder cancer -- Dataset 6: TCGA-BLCA (N_pos = 335; N_neg = 23)  -- Datasets for colorectal cancer -- Dataset 7: TCGA-COAD (N_pos = 333; N_neg = 37) Dataset 8: GEO dataset GSE74013 (N_pos = 14; N_neg = 20)  -- Datasets for renal clear cells cancer -- Dataset 9: TGCA-KIRC (N_pos = 290; N_neg = 130)  -- Datasets for renal papillary cell carcinoma -- Dataset 10: TGCA-KIRP (N_pos = 252; N_neg = 167)	In all cases, the training dataset is used also for validation.  -- Datasets for prostate cancer -- Dataset 1: Splitted in Training (N_pos = 8; N_neg = 11) and Test set (N_pos = 13; N_neg = 16) Dataset 2: Splitted in Training (N_pos = 117; N_neg = 15) and Test set (N_pos = 176; N_neg = 23) Dataset 3: Used as test set (N_pos = 143; N_neg = 0) Dataset 4: Used as test set (N_pos = 8; N_neg = 4) Dataset 5: Used as test set (N_pos = 77; N_neg = 15)  -- Datasets for bladder cancer -- Dataset 6: Splitted in training (N_pos = 134; N_neg = 9) and test set (N_pos = 201; N_neg = 14)  -- Datasets for colorectal cancer -- Dataset 7: Splitted in training (N_pos = 133; N_neg = 15) and test set (N_pos = 200; N_neg = 22) Dataset 8: Splitted in training (N_pos = 6; N_neg = 9) and test set (N_pos = 8; N_neg = 11)  -- Datasets for renal clear cells cancer -- Dataset 9: Splitted in training (N_pos = 116; N_neg = 52) and test set (N_pos = 174; N_neg = 78)  -- Datasets for renal papillary cell carcinoma -- Dataset 10: Splitted in training (N_pos = 101; N_neg = 63) and test set (N_pos = 151; N_neg = 104)	No redundancy stated for dataset splits. All the datasets are independent from each other	Yes.   -- Datasets for prostate cancer -- Dataset 1 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE74013 Dataset 2 URL: https://portal.gdc.cancer.gov/projects/TCGA-PRAD Dataset 3 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE55479 Dataset 4 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE38240 Dataset 5 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE73549  -- Datasets for bladder cancer -- Dataset 6 URL: https://portal.gdc.cancer.gov/projects/TCGA-BLCA  -- Datasets for colorectal cancer -- Dataset 7 URL: https://portal.gdc.cancer.gov/projects/TCGA-COAD Dataset 8 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE74013  -- Datasets for renal clear cells cancer -- Dataset 9 URL: https://wiki.cancerimagingarchive.net/display/Public/TCGA-KIRC  -- Datasets for renal papillary cell carcinoma -- Dataset 10 URL: https://www.google.com/search?channel=trow5&client=firefox-b-d&q=TCGA+KIRP	Random Forest 	No.		Not stated.	Number of features not stated.  The feature selection was actually the main topic of the paper. The feature selection method is carefully described. In brief, features were selected passing through different steps: 1. initial filtering 2. Random Logistic Regression 3. Feature importance of Random Forest 4. evaluating the LogLoss of the prediction performed using different combination of the selected features.	No	No.		Black box	Classification		Yes, the code is available at URL: https://github.com/bioinformatics-IBCH/logloss-beraf	Independent Datasets (test sets)		Compared with other classification models, all based on logistic regression. 	No confidence intervals. No static significance claimed	No.	No.	Not stated	Precision, Recall, F1-score, Area Under Curve (AUC)							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	3/8/2022 16:13:28	29614729	Imaging, Tracking and Computational Analyses of Virus Entry and Egress with the Cytoskeleton.	Wang IH, Burckhardt CJ, Yakimovich A, Greber UF.	Viruses	2018	2018	10.3390/v10040166																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	3/8/2022 15:57:30	28854371	Mass Cytometry and Topological Data Analysis Reveal Immune Parameters Associated with Complications after Allogeneic Stem Cell Transplantation.	Lakshmikanth T, Olin A, Chen Y, Mikes J, Fredlund E, Remberger M, Omazic B, Brodin P.	Cell Reports	2017	2017	10.1016/j.celrep.2017.08.021																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/9/2022 10:22:18	27488918	Molecular Properties of Drugs Interacting with SLC22 Transporters OAT1, OAT3, OCT1, and OCT2: A Machine-Learning Approach.	Liu HC, Goldenberg A, Chen Y, Lun C, Wu W, Bush KT, Balac N, Rodriguez P, Abagyan R, Nigam SK.	Journal of Pharmacology and Experimental Therapeutics	2016	2016	10.1124/jpet.116.232660		"Dataset generated by the authors. Total number of instances not clearly stated (they state ""around 250""), but could be inferred from Supplementary Informations. N_pos or N_neg not stated. Dataset not used in previous papers."	Not stated	Not stated	No	Many algorithms compared: Decision Trees, Support Vector Machine, Neural Network (multilayer perceptron), Naive Bayes, Decision Rule	No	Not clearly stated. They just mention the elimination of non valid attributes (e.g. missing or NaN value for some features) and the selection of attributes through Chi Square Evaluation.	Not stated 	"Not clearly stated (they say ""around 100"")"		No.		Both transparent (e.g. Decision Trees) and black box algorithms (e.g. Neural Networks) were used.	Classification		Not available.	Experimental Validation		Comparison was made among the methods used, based on the ROC Area	Not stated	No	No.	Not stated.	ROC Area							
franco.pradelli94@gmail.com	6312169df3794236aa987a01	3/8/2022 16:01:30	26101544	From Heuristic to Mathematical Modeling of Drugs Dissolution Profiles: Application of Artificial Neural Networks and Genetic Programming.	Mendyk A, G√ºres S, Jachowicz R, Szlƒôk J, Polak S, Wi≈õniowska B, Kleinebudde P.	Computational and Mathematical Methods in Medicine	2015	2015	10.1155/2015/863874																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	3/8/2022 15:46:06	32324731	BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale.	Chen Q, Lee K, Yan S, Kim S, Wei CH, Lu Z.	PLoS Computational Biology	2014	2020	10.1371/journal.pcbi.1007617																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	2/15/2022 9:31:53	20007729	Bioinformatical approaches to characterize intrinsically disordered/unstructured proteins.	Doszt√°nyi Z, M√©sz√°ros B, Simon I.	Briefings in Bioinformatics	2009	2010	10.1093/bib/bbp061																																
franco.pradelli94@gmail.com	6312169df3794236aa987a01	3/8/2022 16:11:07	20007729	Bioinformatical approaches to characterize intrinsically disordered/unstructured proteins.	Doszt√°nyi Z, M√©sz√°ros B, Simon I.	Briefings in Bioinformatics	2009	2010	10.1093/bib/bbp061																																
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	2/7/2022 18:57:16	20122221	Computational prediction of type III secreted proteins from gram-negative bacteria.	Yang Y, Zhao J, Morgan RL, Ma W, Jiang T.	BMC Bioinformatics	2010	2010	10.1186/1471-2105-11-s1-s47		Redundant dataset of type III effectors. Positive cases were identified type III effector (T3SE) proteins from Pseudomonas syringae (P. syringae) pv. tomato strain DC3000, P. syringae pv. syringae strain B728a and P. syringae pv. phaseolicola strain 1448A. Negative cases were all the proteins extracted from the genome of P. syringae pv. tomato strain DC3000, excluding proteins related to type III secretion system (T3SS) and hypothetical proteins. 4,062 proteins total. Npos = 283 protein sequences. Nneg = 3,779 protein sequences.  Non-redundant dataset of type III effectors. Removal of all homologous proteins (redundant), with sequence similarity greater than 60% from redundant dataset of type III effectors. 3,532 proteins total. Npos = 108 protein sequences. Nneg = 3,424 protein sequences. Only the first 100 N-terminal residues were used in both datasets. They were not previously used.	5-fold cross validation was performed. No information about the sizes of training and testing data sets.	Homology present within positive cases. Possibility of overestimating negative cases due to the presence of uncharacterized T3SE proteins within them.	Method and data are available to the public upon request.	Support Vector Machine (SVM) classification with RBF kernel	No	Calculated amino acid composition in terms of different secondary structures strand (E), helix (H) and coil (C), and solvent accessibility states (buried (B) and exposed (E)), with a method called SSE-ACC. The value of each dimension is calculated by  f_i^j=  (N_i^j)/L  where j = {H, E, C}, N_i^j is the frequency of amino acid i in secondary structure element j, and L is the length of the sequence. The value is calculated similarly for solvent accessibility states. 	The parameters used for the redundant data set are g = 0.25, C = 4. The parameters used for the non-redundant data set are g =0.5, C = 4. Grid search was used for parameter optimization.	100 features. The first 60 features are used to describe the frequency of each amino acid in each of the three possible secondary structure elements. The last 40 dimensions represent the frequency of each amino acid having each of the two possible solvent accessibility states.	Single input for SVM method. Optimization through grid search.	Yes, by setting the regularization parameter C=4. L2 regularization adds an L2 penalty equal to the square of the magnitude of coefficients.		Black box. Not investigating feature importance.	Classification, i.e. binary predictions based on the probability of a predicted positive case being p > 0.01.		Method and data are available to the public upon request.	5-fold cross-validation. Independent dataset. A single predicted positive case of the independent dataset was validated through wet-lab experiments.		EffectiveT3, T3SS prediction. Known classifiers for T3SS effector prediction. SVC with cross-validation but with different data encoding. 	Only the non-redundant data were used for the comparisons. Very low precision from EffectiveT3 (recall of 72.2% and precision of 17.9%) and T3SS prediction (recall of 83.3% and precision of 24%) due to being developed in less imbalanced and non-realistic training sets. For different data encoding methods, the recall and precision of effectors were 55.6% and 84.5%, respectively, which were over 5% lower than those of the proposed SSE-ACC method. 	Method and data are available to the public upon request.	Method and data are available to the public upon request.	The whole computation process took several ten hours. All computation tasks were conducted on a Pentium IV desktop PC with dual CPU (2.8 GHz) and 2 GB RAM.	Accuracy, Recall, Precision.							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	2/8/2022 23:45:07	28600868	DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning.	Sundaram L, Bhat RR, Viswanath V, Li X.	Human mutation	2017	2017	10.1002/humu.23272		Exome sequencing data for 1000 samples. Npos = 500 (control group). Nneg = 500 (disease group). Ntrain = 500. Ntest = 500. Data were provided from the Regents of the University of California under the challenge ‚ÄúBipolar Exomes‚Äù.	Npos,train = 200. Nneg,train = 200. Validation set present. Npos,validation = 50. Nneg,validation = 50. Npos,test = 249. Nneg,test = 251.	Random sampling from the pool of 1000 samples and balanced datasets between train, validation, and test datasets.	No	Deep convolutional neural network trained using gradient descent by standard backpropagation algorithm.	No	Moving window length across the input sequences by the convolutional kernels and formation of feature maps. One-hot-encoding was used to create vectors for all the types of genotypes available, to ensure that all the categories are equidistant from each other.	The deep convolutional network takes in a 23-channel input, with each input being the one-hot encoded variants of a chromosome. Initializing weights to reduce the loss function at each epoch.	Featured maps formed from filtered exonic variants, one-hot encoded per chromosome.	Application of a batch normalization layer after the max-pooling layer contributes to avoiding overfitting the data. Additionally, balanced training, validation and testing datasets were used.	Yes. Reduction of feature dimension using L1 regularization with penalty parameter C = 0.85. Less than 1% of the total features remain.		Black box. Reduced performance due to repeated feature subsampling supports the importance of all features in model performance and the absence of sequencing method artifacts.	Classification with binary predictions.		Not available	Cross-validation		Decision trees and random forests.	Higher performance metrics of the convolutional neural network (e.g., accuracy = 0.65) than those of the comparing algorithms (accuracy = 0.55). Confidence intervals were not calculated, and statistical testing was not applied.	No	No.	Training the model end-to-end takes close to 6 hours on Nvidia Tesla M40 servers.	Accuracy, Precision, Recall, F1-Score, AUC score, ROC curve.							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/26/2022 18:39:06	34070374	Identification of Circulating Diagnostic Biomarkers for Coronary Microvascular Disease in Postmenopausal Women Using Machine-Learning Techniques.	Arredondo Eve A, Tunc E, Liu YJ, Agrawal S, Erbak Yilmaz H, Emren SV, Akyƒ±ldƒ±z Ak√ßay F, Mainzer L, ≈Ωurauskienƒó J, Madak Erdogan Z.	Metabolites	2021	2021	10.3390/metabo11060339		Profiles of 150 metabolites based on gas chromatography mass spectrometry (GC/MS) analysis of plasma samples from 70 postmenopausal women.	Npos=23 patients with coronary microvascular disease (CMD). Nneg=47 participants, including 21 patients with coronary artery disease (CAD) and 26 healthy participants as control group.	During GC/MS analysis tentative substances were not reported. All known artificial peaks were identified and removed before data mining. The metabolic feature columns, which had more than 40% of data missing, were eliminated.	Data is available from authors upon request.	Recursive feature elimination with cross-validation (RFECV) from sklearn. Random forest was used as the estimator.	No	1) To allow comparison between samples, all data were normalized to the internal standard in each chromatogram. The raw data consisting of 175 metabolites measured across 70 participants was normalized using min/max scaling.  2) Data imputation with IterativeImputer of sklearn was utilized to handle missing data. The trained imputer was tested by removing the data of one metabolite feature column and imputing the data afterward. The performance of the imputer was measured for each of the metabolites using R^2 metric. Metabolite columns with R^2 < 0.3 and more than 5% of missing values across all patients were removed. 3) Data standardization to zero mean and unit variance for each metabolite feature column.  Data pre-processing step reduced the feature columns to 75 metabolites.  	Not specified	Metabolic profiles of 45 metabolites following data preprocessing. Recursive feature elimination with cross-validation (RFECV), using random forest, reduced the number of features to 15 metabolites.	Not specified	Not specified		Transparent. 15 selected metabolites following feature elimination, including stearic acid and ornithine, leading to best model performance. Unpaired t-test to identify metabolites with differences between CMD and non-CMD.	The binary predictions of ‚ÄúCMD‚Äù and ‚Äúnon-CMD‚Äù, with the latter combining both CAD and control group samples.		Data is available from authors upon request.	5-fold cross-validation		1) One-way-ANOVA model and chi-squared analysis were fitted to test the statistical significance of clinical differences between different participant groups, followed by Tukey‚Äôs post hoc test. p < 0.05 was considered significant. 2) Z-scores were calculated for each metabolite. An unpaired t-test was performed to identify metabolites that are different between each participant group. 	Not specified	Data is available from authors upon request.	Data is available from authors upon request.	Not specified	Receiver operating curves (ROC), precision‚Äìrecall (PR) curves, AUC score, F1 score							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	2/21/2022 23:04:51	27832081	Machine Learning for Characterization of Insect Vector Feeding.	Willett DS, George J, Willett NS, Stelinski LL, Lapointe SL.	PLOS Computational Biology	2016	2016	10.1371/journal.pcbi.1005158		27 electrical penetration graph (EPG) waveform recordings  totaling 470 hours on nine different citrus varieties. Not previously used.	1) Data split for each EPG recording. Ntrain = 5%. Ntest = 95%. 3 splits. 2) Ntrain = 5% from each of 26 EPG recordings. Ntest = 100% from 1 EPG recording (27th). 	1) A classification model was trained and used for predictions on each EPG recording independently.  2) Random selection of 5% of 26 EPG recordings used as training and 1 EPG recording as testing. 27 repeats (Leave-one-out cross-validation). 	No	Random Forests Classification	No	EPG waveform recordings were manually classified into 6 feeding states: C, D, E1, E2, G, NP. Fast Fourier transform of EPG recordings. The 6 frequencies with the highest magnitudes, often harmonics, were extracted and used for further analysis.	Not applicable	Main periodic components of the time series	No	No		Not reported	Multi-label predictions on 6 different feeding states. Binary predictions between phloem (E1 and E2) and non-phloem (C, D, NP, and G) feeding states.		Not available	1) 3 repeats of 10-fold cross validation for each EPG recording. 2) Leave-one-out cross-validation. 3 repeats of 10-fold cross validation for 5% of 26 EPG recordings (train). 1 EPG recording for testing. 		Not applicable	95% confidence intervals. Confusion matrices.	No	No	Not available	Average of: Accuracy, Sensitivity, Specificity, Positive Predictive value, Negative Predictive value, Prevalence, Detection Rate, Detection Prevalence, Balanced Accuracy.							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	2/23/2022 23:30:01	19154573	Identification of novel DNA repair proteins via primary sequence, secondary structure, and homology.	Brown JB, Akutsu T.	BMC Bioinformatics	2009	2009	10.1186/1471-2105-10-25		1) First dataset of protein sequences for identification experiments of DNA repair proteins. Gene Ontology (GO) annotated proteins from PDB. Npos=557 and Nneg=1443 total protein sequences. Npos=114 and Nneg=353 protein sequences with 90% sequence similarity. Npos=76 and Nneg=215 protein sequences with 50% sequence similarity. 2) Second dataset of protein sequences for identification experiments of DNA repair proteins. Gene Ontology (GO) annotated proteins from Uniprot: - Protein sequences of ‚ÄúBase Excision Repair‚Äù, Npos=2624 and Nneg=4723 for total protein sequences, Npos=1721 and Nneg=2924 protein sequences with 90% sequence similarity, and Npos=630 and Nneg=1200 protein sequences with 50% sequence similarity. - Protein sequences of ‚ÄúDNA Dealyklation‚Äù, Npos=25 and Nneg=7322 for total protein sequences. - Protein sequences of ‚ÄúDNA synthesis during DNA repair‚Äù, Npos=28 and Nneg=7319 for total protein sequences. - Protein sequences of ‚ÄúDouble Strand Break repair‚Äù, Npos=364 and Nneg=6983 for total protein sequences, Npos=266 and Nneg=4379 protein sequences with 90% sequence similarity and Npos=174 and Nneg=1656 protein sequences with 50% sequence similarity. - Protein sequences of ‚ÄúError-prone DNA repair‚Äù, Npos=46 and Nneg=7301 for total protein sequences, Npos=36 and Nneg=4609 protein sequences with 90% sequence similarity. - Protein sequences of ‚ÄúMismatch repair‚Äù, Npos=1777 and Nneg=5570 for total protein sequences, Npos=1020 and Nneg=3625 protein sequences with 90% sequence similarity and Npos=468 and Nneg=1362 protein sequences with 50% sequence similarity. - Protein sequences of ‚ÄúNucleotide Excision Repair‚Äù, Npos=2106 and Nneg=5241 for total protein sequences, Npos=1325 and Nneg=3320 protein sequences with 90% sequence similarity and Npos=363 and Nneg=1467 protein sequences with 50% sequence similarity. - Protein sequences of ‚ÄúPostreplication repair‚Äù, Npos=28 and Nneg=7319 for total protein sequences. - Protein sequences of GO ‚ÄúRegulation of DNA repair‚Äù, Npos=264 and Nneg=7083 for total protein sequences, Npos=174 and Nneg=4471 protein sequences with 90% sequence similarity, and Npos=114 and Nneg=1716 protein sequences with 50% sequence similarity. - Protein sequences of GO ‚ÄúSingle Strand Break repair‚Äù, Npos=40 and Nneg=4605 for total protein sequences, and Npos=25 and Nneg=1805 protein sequences with 90% sequence similarity. 3) 31 vertebrate genomes from ENSEMBL for identification of novel, DNA repair-related proteins. 	5-fold and one-versus-one-versus-rest cross-validation. Not specified further.	Overlaps between protein sequence datasets of 0%(unfiltered), 50% and 90% sequence similarity. Only DNA repair pathways which were consisted of at least 25 proteins, were considered. Removed redundancy of protein sequences which belong to more than one pathway. Removed proteins which contain the following keywords in their GO descriptions: putative, similar, possible/possibly, probable/probably, theoretical, and hypothetical.	Yes. Additional information.	Support Vector Machine (SVM)	Yes. Utilization of BLAST in protein sequences data encoding for homology features.	Different data processing methods for transforming input protein sequences: 1) Tripeptide (k=3) frequency in protein sequence: Considering all possible subsequences of length k in the query protein sequence and dividing the number of occurrences of each k-mer by the total number of possible k-mers. 2) Secondary structure: For each protein in each dataset SSPro was used to obtain a secondary structure role for each amino acid in the protein in question. 3) Frequency Priors: Scanning database of known DNA repair proteins for the frequencies of each type of amino acid, and using this information to determine if a query protein not belonging to the known database has a similar percentage of each type of amino acid (vf+) or not (vf-). 4) BLAST homology: Homology positive or negative assessment and return of value, vb+ or vb-, if BLAST e-value is lower or higher than a 0.001 threshold, respectively. 	Not available	1) Primary Sequence 2) Primary Sequence and Secondary Structure 3) Primary Sequence and Frequency Priors 4) Primary Sequence and Homology 5) Primary Structure, Secondary Structure, Homology 6) BLAST Homology 	Not available	Yes, manually setting the gamma value of the radial basis function (RBF) similarity-metric.		Comparing model performance following training on datasets with different features.	Binary predictions. SVM scores or BLAST e-value as outputs, and comparisons with thresholds to determine the prediction (DNA repair protein or Not)		Yes. Web server: https://sunflower.kuicr.kyoto-u.ac.jp/~jbbrown/dnaRepairPrediction/v2/index.py	1) 5-fold cross-validation 2) One-versus-one-versus-rest cross-validation. This technique differs in that for k-fold validation, one portion is still set aside for evaluation, but instead of k - 1 portions of data for training, only a single portion is used for training, and the k - 2 remaining portions are used as a reference homology database for querying training and test data. The end goal this technique is to combine homology and sequence data in an unbiased way and obtain a realistic estimate of method performance. 		The transformation based SVM experimental results were compared with independent BLAST trials. A continuum of thresholds was used in order to obtain ROC curves and compare different techniques. 	Pairwise comparisons of classifiers using both the parametric t-test and non-parametric Wilcoxon Signed-Rank Test.	Yes. Additional information.	Not available	Yes. Available report in Additional information.	ROC curves, AUC scores							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	2/28/2022 13:11:53	25783485	Performance of case-control rare copy number variation annotation in classification of autism.	Engchuan W, Dhindsa K, Lionel AC, Scherer SW, Chan JH, Merico D.	BMC Medical Genomics	2015	2015	10.1186/1755-8794-8-s1-s7		Rare Copy Number Variation (CNV) data and comprehensive gene annotations from Npos=1892 Autism Spectrum Disorder ASD subjects (1623 males and 270 females), and Nneg=2342 platform-matched controls (1093 males and 1250 females) with at least one rare CNV (frequency 1% or less). All subjects (Npos) are of European ancestry and Caucasian ethnicity. Data were collected from previous studies: Autism Genome Project (AGP), SAGE (Study of Addiction Genetics and Environment), Ontario Colorectal Cancer study, HABC (Health Aging and Body Composition). 	Only subjects harboring at least one rare genic CNV were used for classification, as features would be constantly zero for the other subjects, but all subjects were considered when reporting percentage ‚Äúexplained‚Äù statistics. This resulted in a subset of Npos=1570 ASD subjects (80.8%) and Nneg=1916 controls (81.8%). Random division into 3 equal and stratified subsets. Ntrain = 2 subsets. Ntest=1 subset. This process was repeated 3 times without re-dividing the dataset. 	Subjects with karyotypic abnormalities, Fragile X syndrome or other genetic syndromes causing congenital malformations were excluded from the analysis. Only samples meeting quality thresholds were used for CNV analysis. CNVs (of size 30 kb or greater) were detected using an analytical pipeline optimized for Illumina 1M arrays. All de novo CNVs were experimentally validated. Samples with copy number variation greater than 7.5 MB were excluded. 	Yes. Stage-1 CNV calls are available in dbGAP as phs000267.v3.p2. Stage-2 CNV calls are available in dbGAP as phs000267.v4.p2. Supplementary files for rare variants of ASD subjects and controls.	Random Forest (RF), Conditional Inference Forest (CF), SVM with Linear kernel, Neural network.	No	Clinical categorization of de novo and inherited CNVs as pathogenic, uncertain or benign following clinical annotation guidelines. Large and very rare CNVs were also classified as pathogenic.  Gene annotations based on CNVs. Gene-set construction, based on CNV gene annotations.	For RF and CF default settings were used unless otherwise specified. For Linear SVM the cost parameter was kept at default as 1 and class weights were kept even. Each feature was independently normalized and rescaled to a 0-1 interval prior to being input into the classifier. The Neural Network was built with two middle layers of 100 and 50 nodes each, a learning rate of 0.005 with a 0.9 momentum. The network was trained through back-propagation, and without feature normalization or scaling. 	Clinically categorized CNVs. CNV annotated genes. 20 curated gene-sets of neurobiological relevance. Total gene count.	Stratified 3-fold cross-validation was used to avoid overfitting.  The absence of overfitting was further assessed by replacing real classification features with randomized features based on gene identity permutation.  Feature selection was based on the feature relevance metrics calculated on the data subset used for training, and performed independently for every training set, to avoid any overfitting issues. Additionally, all subsets presented a gender composition similar to the full dataset. 	Not specified.		Feature selection for RF based on Mean Decrease Accuracy (MDA) and Mean Decrease Gini. Feature selection for CF based on MDA was performed with and without step-wise decorrelation, and on MRMR (Minimum Redundancy Maximum Relevance Feature Selection). Reported in Additional information. Black box for SVM with Linear kernel and Neural network. 	Prediction probabilities. Binary predictions.		Not available.	Stratified 3-fold cross-validation.		Comparison and evaluation of algorithms‚Äô performance by splitting data into:  1) all subjects,  2) subjects with de novo CNVs, and  3) subjects with pathogenic CNVs Moreover, evaluating algorithms‚Äô performance by splitting observations (CNVs) into: 1) Total CNVs,  2) gain CNVs, and  3) loss CNVs Additionally, evaluating algorithms‚Äô performance by separating features, following feature selection, into: 1) top 20 ranking features 2) top 15% ranking features 1) top 40% ranking features CF reported as an optimal classification approach based on comparisons with different algorithms and the respective AUC scores. 	Not reported.	Not available.	Not available.	Not reported.	AUC score. Percentage of correctly classified ASD subjects, which was calculated as the number of ASD subjects correctly predicted in at least 15 out of 20 iterations divided by the study total (Npos=1892). 							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/1/2022 14:21:27	33324147	Functional Connectivity Combined With a Machine Learning Algorithm Can Classify High-Risk First-Degree Relatives of Patients With Schizophrenia and Identify Correlates of Cognitive Impairments.	Liu W, Zhang X, Qiao Y, Cai Y, Yin H, Zheng M, Zhu Y, Wang H.	Frontiers in neuroscience	2020	2020	10.3389/fnins.2020.577568		Functional connectivity (FC) patterns obtained from resting-state functional magnetic resonance imaging (RS-fMRI). 1) Npos=38 Schizophrenia (SCZ) patients and Nneg=38 healthy controls (HC) 2) The produced classifier was applied to Ntest=38 high-risk first-degree relatives (FDRs) to predict their cognitive performance. 	Leave one- out cross-validation, with Ntrain=37 and Ntest=1 for each iteration.	Not specified	Declared availability upon request.	Support Vector Machine with Linear kernel (Linear SVM)	No	The subjects‚Äô brains were parcellated into 200 regions of interest (ROIs) using the Craddock atlas. Œ§he RS-fMRI data were preprocessed to calculate FC measures between each pair of ROIs.  Friston-24 parameters were used to regress out the effects of head motion. To further reduce the effects of nuisance factors, signals from cerebrospinal fluid and white matter were also regressed out.  DARTEL toolbox was used to normalize the data and the resulting images were finally smoothed with a 6-mm full width at half maximum (FWHM) Gaussian kernel. The time series within each ROI were first band-pass filtered (0.01‚Äì0.08 Hz) and then averaged. For each participant, FC was calculated between each ROI using Pearson‚Äôs correlation coefficients, resulting in 19900-dimensional FC feature vectors for each subject. Patients with SCZ were labeled as 1, and HCs were labeled as -1. 	Linear SVM was implemented using the LIBSVM toolbox with the parameter C set to the default value of 1.	FC measurements between each pair of the 200 brain ROIs were used as classification features. Feature selection was performed for data dimension reduction using F-score for feature ranking. The 644 highest-ranked FC features were used to build the classifier.	Not specified	Yes. Linear SVM with C=1 and feature selection for data dimension reduction were selected to avoid overfitting.		Feature weight extraction from the Linear SVM model and feature selection for data dimension reduction, using F-score for feature ranking, were performed to interpret feature importance. This allowed for the identification of the 18 ROIs having weights that were at least 1 standard deviation greater than the average of the weights of all regions, thus making the greatest contribution to the model.	1) Binary predictions. 2) Classification score, which is the average of the 76 prediction labels. From a range of -1 to 1, a positive score indicates a SCZ pattern, and a negative score indicates a HC pattern. Binary predictions. 		Not available	Leave one-out cross-validation (LOOCV). Independent dataset of 142 features obtained by masking DMN, FP, auditory, and sensorimotor brain networks. Similar training of a Linear SVM classifier and evaluation of the resulting metrics. 		Not applicable	1) Permutation statistical testing. 2) Semantic fluency test (animal version) was administered to evaluate the executive function and the semantic memory, which are severely affected in SCZ. The performance was analyzed using the number of correct words within 1 min. Statistical testing of the correlation between classification score and semantic fluency scores of FDR participants. 	Not available	No	Not specified	Accuracy, sensitivity, specificity, ROC curve, AUC score.							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/2/2022 11:14:34	32218835	Gene expression profiling identified TP53<sup>Mut</sup>PIK3CA<sup>Wild</sup> as a potential biomarker for patients with triple-negative breast cancer treated with immune checkpoint inhibitors.	Cheng J, Ding X, Xu S, Zhu B, Jia Q.	Oncology letters	2020	2020	10.3892/ol.2020.11381		RNA-Seq expression values of immune regulatory molecules, including CTLA‚Äë4, IDO1, LAG3, PDCD1, PDL1 and TIM3 across four types of breast cancer (HER2, luminal A, luminal B and TNBC) from The Cancer Genome Atlas (TCGA) database. Data for tumor mutation burden (TMB) from TCGA database. 	Not specified	Not specified	The datasets generated and/or analyzed during the present study are available in the TCGA database.	Random Forests	No	RNA-Seq expression values in transcripts per million (TPM) were log2-transformed and normalized.  Estimation of relative immune cell relative infiltration and abundance  by using the method single‚Äësample gene set enrichment analysis (ssGSEA) which identified gene sets from the Molecular Signatures Database that were enriched in TNBC RNA-Seq data. 28 heterogeneous immune cells were classified according to gene sets. The degree of immune cell infiltration was determined by the ssGSEA scores. The immune signature was clustered into 3 populations, namely high‚Äë, medium‚Äë and low‚Äëinfiltration.	Not specified.	Hundreds of variants, TMB data, were employed as input parameters, including the relative infiltration of the 28 types of heterogenous immune cells, somatic mutation counts, 78 immune‚Äërelated molecules, and 50 signaling pathways from the HALLMARK collection. In total 782 features were used to assess cytolytic activity (CYT).	Not specified	Not specified		Feature importance score, relative contribution of each factor to the resulting immune response, for determining the most important features for CYT.	Multi-label predictions		Not available	Not specified		Factors that were associated with immune response in this analysis were consistent with established knowledge on antitumor immunity.	OOB samples providing estimates of model error rate for the decision trees.	Not available	Not available	Not specified	Out of bag (OOB) scores							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/3/2022 14:47:08	25646976	Exploring bacterial organelle interactomes: a model of the protein-protein interaction network in the Pdu microcompartment.	Jorda J, Liu Y, Bobik TA, Yeates TO.	PLOS Computational Biology	2015	2015	10.1371/journal.pcbi.1004067		Training dataset of 40 pairs of Pdu protein sequences whose presence or absence of physical, protein-protein interactions (PPIs) could be experimentally validated via binding assays, complementation and expression studies or crystallographic data.  Testing dataset of protein orthologs collected from 34 bacterial genomes in the KEGG database and collapsed among 22 orthologous protein groups, which represent types of bacterial microcompartment (MCP) proteins known to be associated with the propanediol utilizing (Pdu) system. 	For the training set, Npos=16 interacting and Nneg=24 non-interacting protein pairs. For the testing set, pairwise combinations of the 22 orthologous protein groups resulted in 231 unique protein pairs that needed to be classified. 	Incomplete or erroneous annotations of the Pdu gene products were corrected after sequence comparison with the Pdu operon from Salmonella enterica LT2, the best-characterized strain in terms of Pdu MCP.	Yes. Supporting information.	Random Forest classifier	No	For each ortholog group, its corresponding protein sequences were aligned with MUSCLE. The multiple sequence alignments were subsequently input in PhyML for the construction of phylogenetic trees using the Maximum Likelihood method. For amino acid and nucleotide-based tree construction in PhyML, the LG and HKY85 substitution matrices were used, respectively. Additionally, distance matrices were calculated for each tree, where the distance between two leaves corresponds to the sum of the branch lengths separating them.   Comparing two trees can be subject to artefacts and lead in some cases to spurious correlations if speciation events are not taken in account. For this reason, some of the co-evolution features also involve the Tree of Life (ToL) of the 34 genomes studied, which originated from submitting sequences of their respective 16S ribosomal RNA to similar treatment. Since distances in the ToL are computed from a nucleotide-based substitution matrix, the distances in the ToL matrix were rescaled for proper comparison with the protein-based distance matrices. 	Not specified	For each protein pair, 7 coevolution features measuring the pairwise tree similarities have been defined.  Of these, 4 features are based on pairwise comparison of the distance matrices, as defined in the mirrortree approach, and whose metrics correspond to the linear correlation coefficient between the two matrices in consideration. Let A and B be the two MCP ortholog groups, mA and mB their respective matrices, tA and tB their trees. The parameter mirrorAB is the correlation between mA and mB, mirrorA is between mA and ToL, and mirrorB is between mB and ToL. The fourth descriptor, mirrorAB-ToL, involves an adaptation of the mirror tree, also known as tol-mirror, which measures the correlation between mA and mB after removing the background similarity inherent to speciation events in the ToL. The remaining 3 topological features are derived from the Icong index, defined as the probability that the Maximum Agreement Subtree (MAST) between two trees is arising by chance. Along the same idea, topological similarities were computed between tree A and ToL, tree B and ToL, and finally A and B (topA, topB, topAB). 	Not specified	Not specified		Not explicitly interpreted. Comparison of classification performance for fewer features and evaluation of their discriminatory power individually by ranking their accuracies in the context of an unsupervised analysis. Results support the importance of all features for optimal model performance.	Binary predictions of pos for an interacting protein group pair and neg for those not interacting. For prediction probability is less than 0.7 then the result is neg, and for equal or greater than 0.7 the result is pos (increased specificity).		Not available	10-fold cross-validation. Experimental confirmation of a predicted positive PPI from the testing dataset.		Not applicable.	High training accuracy for experimentally characterized PPIs, 15 of 16 correctly predicted as pos. Claiming support for the high specificity criterion.	Yes. Supporting information.	Not available	Not specified	ROC curve, AUC score							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/4/2022 12:54:32	29849042	Distinct epigenomic patterns are associated with haploinsufficiency and predict risk genes of developmental disorders.	Han X, Chen S, Flynn E, Wu S, Wintner D, Shen Y.	Nature Communications	2018	2018	10.1038/s41467-018-04552-7		ChIP-seq data, including uniformly processed peak calling results and peak width of promoter histone modifications from Roadmap and ENCODE projects for active (H3K4me3, H3K9ac, and H2A.Z) and repressive (H3K27me3) promoter modifications, and marks associated with enhancers (H3K4me1, H3K27ac, DNase I hypersensitivity sites).   Curated haploinsufficient (HIS) genes, positive (Npos) training observations, were collected from haploinsufficient training genes used in previous studies and genes with haploinsufficient score of 3 in ClinGen Dosage Sensitivity Map.  Curated haplosufficient (HS) genes, negative (Nneg) training observations, included genes deleted in two or more healthy people, based on CNVs detected in 2026 normal individuals.  All data were used in previous studies. 	Following pruning for the training set, Npos=287 curated haploinsufficient genes and Nneg=574 curated haplosufficient genes were considered for further analysis. 1) Ntrain=90%. Ntest=10%. 10-fold cross validation for training. 100 randomized runs. 2) Final training with all training data and estimation of probabilities. 	Only genes with half or more of its length covered by any deletion were considered ‚Äúdeleted‚Äù (HS genes) in an individual.  The initial raw training may have included some false positive and false negative genes, as it contained results from automated literature mining that is known to give noisy output. To optimize the performance, the following pruning of the raw training set was performed:   1) Only protein-coding genes in autosomes were kept, as non-protein coding genes or genes on sex chromosomes may be under different mechanism of epigenomic regulation. 2) From the positive training set, genes with sufficient contradictory evidence were removed (ExAC pLI ‚â§ 0.1 and expected loss-of-function variants >1011). 3) From the negative training set, genes with sufficient contradictory evidence (pLI ‚â• 0.2 and expected loss-of-function variants>10) were removed. 	Yes. Supplementary Data.	Random forest, Support Vector Machine (SVM), and SVM with LASSO feature selection.	No	For promoter features (H2A.Z, H3K27me3, H3K4me3, and H3K9ac), GappedPeaks were used to allow for broad domains of ChIP-seq signal. The assignment of a GapppedPeak to a gene followed these steps in order:  1) For each gene, only TSS of Ensembl canonical transcripts were used. 2) A GappedPeak was assigned to a TSS if the GappedPeak overlaps with the upstream 5 kb to downstream 1 kb region around the TSS. This definition of basal cis-regulatory region around promoter was according to GREAT tool. Assigning one GappedPeak to multiple TSS was allowed. 3) For TSS having more than 1 GappedPeak assigned, only the closest one was kept. 4) For genes with multiple TSS and hence multiple assigned GappedPeaks, only the longest GappedPeak was kept. After these four steps, if one gene had been associated with a GappedPeak, then the width of the peak was used as an epigenomic feature in the following machine learning models. If a gene had no associated GappedPeak, then the peak width is 0.  Coverage of H3K27ac, H3K27me3, H3K36me3, H3K4me1, H3K4me3, H3K9me3, DNase I, and RNA-seq data was used as input for EpiTensor to infer interacting enhancers across distant genomic regions. This was done as balance between more input data types and more cell types included, as not every cell type has all these histone modifications characterized. 	Alpha parameter equal to 1 for Lasso regularization. No further parameters were specified.	The widths of called ChIP-seq peaks was used as promoter features. The counts of the interacting number of promoters and enhancers within pre-defined topologically associated domains (TADs) as enhancer features. Specifically, the results of peak width and number of interacting enhancers were consolidated into a matrix, with each row being a gene and each column representing a combination of a tissue and a data type, e.g. ‚ÄúH3K4me3 peak width in fetal heart‚Äù. One combination of a tissue and a data type was referred to as one epigenomic feature. This matrix was used as input for the machine learning models. 	Not specified	Yes. LASSO regularization was used with SVM for overfitting prevention.		Epigenomic features critical for the prediction were determined by calculating a Spearman correlation coefficient between each epigenomic feature and Episcore (random forest model) prediction.   One epigenomic feature corresponds to a data type per certain tissue/cell type. To examine which data types are more important, these Spearman correlation coefficients were plotted by data type.  To examine what tissue/cell types are more important, the averaged z-score for each tissue/cell type was calculated by: 1) Converting every Spearman correlation coefficient to a Z-score using mean and standard deviation specific to each data type and 2) Average Z-scores from various data types for each tissue/cell type.  This analysis indicated that epigenomic features in stem cells, brain tissues, and fetal tissues contribute more to Episcore prediction than other features. 	Binary predictions. All training genes used to train the best performing Random Forest model, and then estimate the probabilities of being positive (HIS) for all genes. The whole process was repeated 30 times and the arithmetic mean of the 30 sets of probabilities was used as result.		Yes. GitHub website. https://github.com/ShenLab/episcore	1) 100 randomized runs with Ntrain=90% and Ntest=10% for each run. 10-fold cross validation was applied. 2) For the best performing model (Random Forest) all training data were used to train the final model. 		Random Forest model performed better than SVM and SVM with Lasso, and it was chosen for training the final model (Episcore). Comparison of Episcore with pLI scores from ExAC, Shet values, and ranks of mouse heart expression level, using de novo likely-gene-disrupting (LGD) variants identified in: 1)  A previously published whole exome sequencing study DDD (Deciphering Developmental Disorders consortium) of 1365 trio families with congenital heart disease (CHD). 2) A second CHD WES cohort of 2645 parent‚àíoffspring trios from the Pediatric Cardiac Genomics Consortium (PCGC). LGD variants include frameshift, nonsense and canonical splice site mutations. Episcore achieved better performance in prioritizing LGD de novo variants than the other methods. 	Permutation testing.	Yes. Supplementary Data.	Yes. GitHub website. https://github.com/ShenLab/episcore	Not specified	ROC curve, AUC score, sensitivity, specificity							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/27/2022 23:10:49	33039708	MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.	Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS.	EBioMedicine	2020	2020	10.1016/j.ebiom.2020.103042		Breast magnetic resonance imaging (MRI) and clinical data from 311 HER2 overexpressing breast cancer patients.  1)        Patients were classified into two groups based on HER2 expression level. Npos=279 patients with tumours that showed HER2 protein overexpression on immunohistochemistry (IHC 3+; IHC group). Nneg=32 patients with tumours that showed HER2 gene amplification detected by FISH in the absence of protein overexpression on IHC (IHC 2+ or 1+ to 2+; FISH group). 2)        Npos=188 patients with pathologic complete response (pCR), which was defined as no residual invasive carcinoma in the breast or axillary lymph nodes (ypT0/isN0) at surgical resection. Nneg=123 patients that are non-pCR. 	For the prediction of pathological complete response, the data was split into training and test sets at a ratio of 4:1 (80% training and 20% test), with feature selection performed purely on the training set. Npos,train=150 patients with pCR. Npos,test=38 patients with pCR. Nneg,train=99 patients with non-pCR. Nneg,test=24 patients with non-pCR.  Due to the low number of cases in the minority class, this was not feasible for the comparison between the IHC and FISH groups.	Inclusion criteria for this study were HER2 overexpressing breast cancer patients who underwent NAC and pretreatment state-of-the-art contrast-enhanced breast MRI. 70 were excluded because they did not have pretreatment breast MRI and 64 patients with outside images were excluded because of poor image quality.	Not available	Coarse decision trees	No	Following ROC and correlation analysis, Breast MRIs were assessed according to the American College of Radiology (ACR) Breast Imaging Reporting and Data System (BI-RADS) lexicon.  Manual, expert review on the MRI exams and performed 3D segmentations of the whole tumour in the first post-contrast non-subtracted sequence using ITK-SNAP software.  Susceptibility artefacts related to post-biopsy changes, when present, were excluded from segmentation and only the largest lesion was segmented in multifocal tumours.   Enhancement maps were calculated as the percentage increase in signal from the pre-contrast image to the first post-contrast image. Radiomics and statistical analysis were performed using MATLAB and publicly available CERR (Computational Environment for Radiological Research) software.  Furthermore, data was reduced to a fixed bin number of 16 grey levels and only an interpixel distance of one was considered. CERR analysis resulted in 102 texture parameters sub-divided into six categories - 22 first order statistics, 26 statistics based on grey level cooccurrence matrices, 16 statistics based on run length matrices, 16 statistics based on size zone matrices, 17 statistics based on neighborhood grey level dependence matrices, and finally five statistics based on neighborhood grey tone difference matrices.  Features were computed for each 2D directional matrix and averaged over 2D directions and slices, since data was not isotropic. As patients were scanned at different sites, Combat harmonisation was performed to remove the centre effect (local vs. foreign scans) while retaining the pathophysiologic information (either HER2 expression or pathologic response). The harmonisation employed Bayes estimates to account for both additive and multiplicative scanner effects.  Univariate analysis was performed to identify significant parameters. Continuous variables were described as mean, standard deviation (SD), and range. The two-tailed Mann-Whitney U test for two independent samples was used to determine significant differences between groups. Correlation analysis was then employed to remove redundant parameters from advancement to model development. If a highly positive (> 0.9) or highly negative (< -0.9) correlation was noted, the parameter with the lowest area under the receiver operating curve (AUROC) was removed. 	Coarse decision tree modelling was implemented in MATLAB, with the maximum number of splits set at four and utilizing Gini‚Äôs diversity index as the splitting criterion.	1) The final model to predict HER2 intratumour expression levels (IHC vs. FISH) utilized three MRI features. Lesion type and multifocality (clinical features) and large zone emphasis (radiomic feature). 2) The model to predict pCR status included six MRI parameters. Lesion type and size (clinical parameters) and variance, first order entropy, 90th percentile and zone length variance (radiomic parameters). 	Not specified	Not specified		Transparent. Assessing the presence of statistically significant differences, using Mann-Whitney U-test and Chi-squared test, across clinical and MRI features of 1) IHC vs FISH and 2) pCR vs non-pCR groups, before including them to the final model.	1) Binary predictions of IHC (positive) or FISH (negative) samples. 2) Binary predictions of pCR (positive) or non-pCR (negative) samples. 		Not available	5-fold cross validation		Not specified	Not specified	Not available	Not available	Not specified	Sensitivity, specificity, diagnostic accuracy							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/27/2022 14:51:24	31058230	Intermittent Hypoxia and Hypercapnia Reproducibly Change the Gut Microbiome and Metabolome across Rodent Model Systems.	Tripathi A, Xu ZZ, Xue J, Poulsen O, Gonzalez A, Humphrey G, Meehan MJ, Melnik AV, Ackermann G, Zhou D, Malhotra A, Haddad GG, Dorrestein PC, Knight R.	mSystems	2019	2019	10.1128/msystems.00058-19		16S rRNA sequencing and untargeted liquid chromatography-tandem mass spectrometry (LC-MS/MS) data from fecal samples of atherosclerosis-prone, 10-week-old, male mice on a C57BL/6J background. 24 knockout mice for ApoE (ApoE-/-) and 16 knockout mice for Ldlr (Ldlr-/-). Fecal samples were collected at baseline and twice each week. 6 weeks, 12 time points and 192 samples, for Ldlr-/- mice. 10 weeks, 20 time points and 480 samples, for ApoE-/- mice. 	1) Npos=96 samples for 8 Ldlr-/- mice exposed to intermittent hypoxia and hypercapnia (IHH). Nneg=96 samples for 8 Ldlr-/- mice exposed to air. Ntrain=192 for Ldlr-/- mice. Ntest=480 for ApoE-/- mice. 2) Npos=12 ApoE-/- mice exposed to intermittent hypoxia and hypercapnia (IHH). Nneg=12 ApoE-/- mice exposed to air. Ntrain=480 for ApoE-/- mice. Ntest=192 for Ldlr-/- mice. 	Analytical standards for bile acids of interest were used with the same LC-MS/MS to ensure feature annotation. Data set stratification by genotypes and effect size calculation of each of the covariates within each mouse model to untangle the effect of genotype. 	Yes, online under the following accession numbers: for metabolomics data, MSV000081482 (Ldlr knockout animal) at ftp://massive.ucsd.edu/MSV000081482, MSV000082813 (ApoE knockout animal) at ftp://massive.ucsd.edu/MSV000082813, and MSV000081853 (commercial standards) at ftp://massive.ucsd.edu/MSV000081853, and for microbiome data, ERP106495 (Ldlr knockout animals; EBI database) and ERP110592 (ApoE knockout animals).	Random forest	No	1) 16S rRNA raw amplicon sequencing data were processed and converted to sub-operational taxonomic unit (sOTU) abundance per sample (BIOM format) using the Deblur workflow. Taxonomies for sOTUs were assigned using the sklearn-based taxonomy classifier trained on the Greengenes 13_8 99% OTUs in QIIME 2. The sOTU table was rarefied to a depth of 2,000 sequences/sample to control for sequencing effort. A phylogeny was inferred using SAT√©-enabled phylogenetic placement, which was used to insert 16S Deblur sOTUs into Greengenes 13_8 at a 99% phylogeny. 2) Raw LC-MS/MS data sets were converted to m/z extensible markup language (mzXML) in centroid mode using MSConvert. All mzXML files were cropped with an m/z range of 75.00 to 1,000.00 Da. Feature extraction was performed in MZmine2 with a signal intensity threshold of 2.0e5 and minimum peak width of 0.3 s. The maximum allowed mass and retention time tolerances were 10 ppm and 10 s, respectively. A local minimum search algorithm with a minimum relative peak height of 1% was used for chromatographic deconvolution; the maximum peak width was set to 1 min. The detected peaks were aligned across all samples using the above-mentioned retention time and mass tolerances, producing the final feature table used in these analyses.  Molecular networking in GNPS was performed to putatively identify molecular features using MS/MS-based spectral library matches. 	Not specified	1) First data layer.16S rRNA amplicon sequencing-derived abundances of microbial taxonomies. 2) Second data layer. Quantified LC-MS/MS peaks of detected metabolites following preprocessing. 	Cross-validation with all the samples from the same mouse appearing only in either training or validation data but not both, to avoid overoptimistic cross-validation accuracy scores because of the classifier learning idiosyncrasies of the individual itself rather than the treatment.	Not specified		Transparent. The abundance of each feature, 16S sequence and metabolite, was used as the score to plot the ROC curve and compute the AUC score. Features that can single-handedly distinguish IHH-exposed samples on ROC plots were highlighted.	1) Binary predictions of IHH-exposed samples (positive) or air-exposed samples (negative) using total Ldlr-/- and ApoE-/- data as training and testing dataset, and vice versa. 2) For longitudinal binary predictions of IHH-exposed samples (positive) or air-exposed samples (negative), using Ldlr-/- or ApoE-/- data per time point as training and testing dataset, and vice versa. 		Yes, in Jupyter notebooks available on GitHub (https://github.com/knightlab-analyses/crossmodel_prediction).	Cross-validation. Details not specified.		Not specified	Not specified	Yes. Supplementary information.	Yes, in Jupyter notebooks available on GitHub (https://github.com/knightlab-analyses/crossmodel_prediction).	Not specified	ROC curves, AUC score.							
konstantinoskyritsis@certh.gr	6312169df3794236aa9879ed	3/25/2022 13:35:02	19091017	Semi-automatic conversion of BioProp semantic annotation to PASBio annotation.	Tsai RT, Dai HJ, Huang CH, Hsu WL.	BMC Bioinformatics	2008	2008	10.1186/1471-2105-9-s12-s18		Manually re-annotated 313 sentences, containing 2304 predicate-argument structures (PAS) annotated for 49 biomedical verbs.	Separation of dataset into 3 subsets. Ntrain = 2 subsets. Ntest = 1 subset. The process is repeated three times, with each of the test sets being used exactly once (3-fold cross-validation).	Not specified	Not available	The semantic role labeling (SRL) system BIOSMILE, which is based on Maximum entropy.   Novel rule-based converter based on verb-by-verb conversion rules which describe under which conditions each mapping is valid.The algorithm used by the rule-generator compares corresponding framesets for a given verb sense, checks each argument in its PASBio frameset, and tries to find an argument in its BioProp frameset that has the same semantic role under a set of conditions. When a match is found, the algorithm maps a link between the two frameset arguments, which includes a description of required conditions, named entities (NEs) and keywords. 	Yes. Combination of BIOSMILE SRL system output with novel rule-based converter. Independency not specified.	1) Tagging of 5 names entities (NEs), protein, DNA, RNA, cell line, and cell type, with NERBio recognition software. A dictionary was used to find other NE types, such as exon and intron. 2) Identification of the PAS objects of each sentence followed by classification of the semantic roles of the arguments according to BioProp format, using BIOSMILE SRL system. 3) Rule-based conversion from BioProp to PASBio annotation, using the novel rule-based converter. 	Not specified	Semantic roles of PAS objects following PASBio annotation	Not specified	Not specified		Not specified	Multi-label predictions		Not available	3-fold cross-validation		Comparison with ML-based SRL systems of other specific domains based on F-score performance	Not specified	Not available	Not available	Not specified	Precision, recall, F-score							
ljgarcia@zbmed.de	6312169df3794236aa987a13	1/28/2022 12:34:45	29263361	Supervised learning in spiking neural networks with FORCE training.	Nicola W, Clopath C.	Nature Communications	2017	2017	10.1038/s41467-017-01827-3		Multiple ML pipelines are discussed. Data source is mentioned only for 1 of them (zebra finch singing) via an article reference (so it seems to have been used by a previous paper). I did not find any mention of data points.	I did not find any of this in the text	I did not find it in the text	Availability of data is not stated. There is availability of the code (mentioned as data availability). If the data is part of the code repo, I did not see it. Only *.m files for MatLab	FORCE method using Izhikevich, Theta and LIF neuron models. It does not seem to be a novel approach as they mention building upon others.	I did not see it in the text	I did not see it in the text	There is a box listing parameters and their values. They mention previous works for tuning the parameters (not sure if they cover all of the parameters though)	I did not see it in the text	I did not see it in the text	I did not see it in the text		It did not look very transparent to me	It produces a reproduction, e.g. given a song, the neural network is trained to reproduce it.		Yes, see https://senselab.med.yale.edu/ModelDB/ShowModel?model=190565 (also in GitHub at https://github.com/ModelDBRepository/190565) I did not see a license	For the songs, it looks like they compared the waves but I did not see a clear mention on how the method was evaluated		Izhikevich, Theta and LIF models are used	I did not see it in the text	I did not see it in the text but it could be part of the available code	Not sure. MatLab code is available so I guess it is possible to change the hyper-parameter configuration there. See https://senselab.med.yale.edu/ModelDB/ShowModel?model=190565	I did not see it in the text	Accuracy is mentioned in the text.							
ljgarcia@zbmed.de	6312169df3794236aa987a13	4/18/2022 16:33:16	33039708	MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.	Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS.	EBioMedicine	2020	2020	10.1016/j.ebiom.2020.103042		311 patients chosen out of 445 available records. 	Split 80:20. Random splitting of the data resulted in 249 cases (150 pCR, 99 no pCR) in the training set and 62 cases (38 pCR, 24 no pCR) in the test set.	Not explicitly stated	Not explicitly stated	Coarse decision trees and five-fold cross-validation.	Not explicitly stated	3D segmentation on MRI exams, enhancement maps calculated. Data reduced to fixed bin number of 16 greys levels. Combat harmonisation to reduce centre effect	102 texture parameters in 6 categories	Features computed from 2D directional matrix and average over 2D directions and slices. 	Not explicitly stated	Not explicitly stated		Not explicitly stated	Classification (pCR or no pCR). HER2 expression levels wrt IHC and FISH		Not explicitly stated	AUROC		Comparison of different configurations. Spearman correlation	p-value	Not explicitly stated	Not explicitly stated	Not explicitly stated	Percentile, specificity, sensitivity, positive predict value, negative predict value, accuracy							
ljgarcia@zbmed.de	6312169df3794236aa987a13	4/18/2022 16:44:10	32620137	Single-cell ATAC-seq signal extraction and enhancement with SCATE.	Ji Z, Zhou W, Hou W, Ji H.	Genome  Biology	2020	2020	10.1186/s13059-020-02075-3		Provenance stated via references	Not applicable (it is a cluster approach)	Not applicable (it is a cluster approach)	Not explicitly stated	Statistical analysis and clustering (K-means)	Not applicable	Trimming and segmentation over sequences	Clusters number treated as a tuning parameter. Cross-validation approach to choose optimal K (looks like it was 5000 clusters)	Not applicable	Not applicable	Not applicable		Not explicitly stated	Clustering		https://github.com/zji90/SCATE and release used at https://doi.org/10.5281/zenodo.3711558	Benchmarking over 3 datasets with scATAC-seq data		Across benchmarking datasets	p and q values	Not explicitly stated	Not explicitly stated	1-2 days. running SCATE to reconstruct regulome approximately takes 5 minutes per cell cluster on a computer with 10 computing cores (2.5 GHz CPU/core) and a total of 20GB RAM.	Variance							
ljgarcia@zbmed.de	6312169df3794236aa987a13	4/18/2022 16:39:51	24348896	March of the titans: the locomotor capabilities of sauropod dinosaurs.	Sellers WI, Margetts L, Coria RA, Manning PL.	PLOS One	2013	2013	10.1371/journal.pone.0078733		Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size		Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size		Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size		Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size	Not suitable, it is a simulation on how the Argentinosaurus huinculensis may have moved despite its big size							
ljgarcia@zbmed.de	6312169df3794236aa987a13	4/18/2022 16:37:38	18586734	Modeling peptide fragmentation with dynamic Bayesian networks for peptide identification.	Klammer AA, Reynolds SM, Bilmes JA, MacCoss MJ, Noble WS.	Bioinformatics	2008	2008	10.1093/bioinformatics/btn189		1208 peptide spectrum matches (PSMs) and 18149 mass spectra for validation	Positive and negative points for the Bayesian network are mentioned but no further info provided	Not explicitly stated	PSMs at http://noble.gs.washington.edu/proj/intense (also stated that availability is upon request but the URL indeed has links to the data)	Hybrid dynamic Bayesian network (DBN) / support vector machine (SVM)	Not explicitly stated	Pre-processing: Input data obtained from MS/MS data, an aqueous soluble protein sample from E.coli lysate was reduced, carbamidomethylated and digested with trypsin.	For the SVM, we use a Gaussian kernel, and hyperparameters C (soft margin penalty) and sigma (low case, width of the Gaussian). Hyperparameters are selected using five-fold nested cross-validation, where the parameter with the largest area under the ROC curve is selected.	99-dimensional feature vectors generated by Riptide (Bayesian part)	Not explicitly stated	Not explicitly stated		Not explicitly stated	Classification		Upon request (but did not try to get it, there is a link to a tar file with, it says, C++ and Python for the Riptide part, I did not examine the files)	Comparison against SEQUEST (Riptide with the static SVM outperforms SEQUEST by 10.8% at a 1% false discovery rate) and Percolator		SEQUEST, Percolator	q value, which is defined as the minimal false discovery rate threshold at which the PSM is deemed significant	Not explicitly stated	Not explicitly stated	Not explicitly stated	Kind of discussed but did not see values							
ljgarcia@zbmed.de	6312169df3794236aa987a13	4/18/2022 16:46:33	18834494	Overview of BioCreative II gene normalization.	Morgan AA, Lu Z, Wang X, Cohen AM, Fluck J, Ruch P, Divoli A, Fundel K, Leaman R, Hakenberg J, Sun C, Liu HH, Torres R, Krauthammer M, Lau WW, Liu H, Hsu CN, Schuemie M, Cohen KB, Hirschman L.	Genome Biology	2008	2008	10.1186/gb-2008-9-s2-s3		Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report		Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report		Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report		Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report	Not suitable. It is a BioCreative challenge report							
martina.bevilacqua1991@gmail.com	6312169df3794236aa9879df	2/23/2022 16:01:54	26957000	OH-PRED: prediction of protein hydroxylation sites by incorporating adapted normal distribution bi-profile Bayes feature extraction and physicochemical properties of amino acids.	Jia CZ, He WY, Yao YH.	Journal of Biomolecular Structure and Dynamics	26957000	2017	10.1080/07391102.2016.1163294		265 candidate proteins containing hydroxylated prolines and 34 candidate proteins containing hydroxylated lysines were collected from the UniProtKB/Swiss-Prot database (version 2014_1, www.uniprot.org). Sequence segments around the hydroxylation sites and non-hydroxylation sites were extracted as positive and negative training datasets, respectively. 	After removing the identical sequence, the original datasets contain 659 positive sites and 3855 negative sites for hydroxyproline from 112 proteins, and 97 positive sites and 855 negative sites for hydroxylysine from 25 proteins. The size of the negative datasets is much larger (approximate ratio of 1:6) than that of the positive training datasets. After addressing this problem, ratios of 1:1 and 1:3 of the number of positive samples and the number of negative samples were used to construct the negative training set. (Reduction of the negative set).  Test set is not described. Validation set:  randomly split 10% of the samples from the dataset as an independent test dataset, and the remaining 90% of the samples as a training dataset.	Not stated.	no.	SVM classification method.	no.	The feature vectors are encoded in a bi-profile manner. This approach is explained in the paper (2.2.2. Adapted normal distribution bi-profile Bayes (ANBPB)).	2 parameters ( c = 4, Œ≥ = 0.25 for the hydroxyproline prediction and c = 4, Œ≥ = 0.125 for the hydroxylysine prediction). Parameters were downloaded from http://www.matlabsky.com and optimized by the SVMcgForClass program. 	For feature extraction a modified version of classical bi-profile Bayes was used. Thirteen physicochemical features were selected. They used the jackknife test to select important features and optimize all parameters.	Not stated.	no.		black box.	Classification.		The MATLAB package of OH-PRED is available as Supplementary files.	Independent test dataset.		iHyd-PseAAC (Xu, 2014) and PredHydroxy (Shi, 2015). Performance measures are compared.	Not stated.	no.	no.	Not stated.	Sensitivity, specificity, accuracy.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/20/2022 15:22:27	31132080	Aneugen Molecular Mechanism Assay: Proof-of-Concept With 27 Reference Chemicals.	Bernacki DT, Bryce SM, Bemis JC, Dertinger SD.	TOXICOLOGICAL SCIENCES	2019	2019	10.1093/toxsci/kfz123		Data from previous publication and direct experiments. N= 26.	training set n = 26, divided in 4 classes. Class 1 = 10 elements, class 2 = 12, class 3 = 3, class 4 = 1.		Available upon request to the authors.	ML prediction algorithm was developed based on an artificial neural network (ANN; JMP software, v12.0.1).	no.	Data were comprised of AUC values from each of the 26 cases.	3 hidden nodes.	2 factors.	Not stated.	Not stated.		Transparent: classifies chemicals based on AUC parameters. Small dataset, few features and parameters considered.	Classification (4 classes).		Model developed based on an artificial neural network (ANN; JMP software, v12.0.1). There is no executable file available.	Cross-validation, using a leave-one-out approach.		No comparison.	25 of 26 cases correctly assigned. There is a table with the probability of each case to be correctly classified.	no	no.	Not stated.	Not stated.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/20/2022 16:11:17	31058383	A roadmap to integrate astrocytes into Systems Neuroscience.	Kastanenka KV, Moreno-Bote R, De Pitt√† M, Perea G, Eraso-Pichot A, Masgrau R, Poskanzer KE, Galea E.	Glia	2020	2020	10.1002/glia.23632		The paper is a review and does not have a dataset.																														
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/26/2022 17:25:36	30448611	Brain age from the electroencephalogram of sleep.	Sun H, Paixao L, Oliva JT, Goparaju B, Carvalho DZ, van Leeuwen KG, Akeju O, Thomas RJ, Cash SS, Bianchi MT, Westover MB.	Neurobiology of Aging	2019	2019	10.1016/j.neurobiolaging.2018.10.016		2 large sleep EEG data sets: the Massachusetts General Hospital (MGH) sleep lab data set (N = 2532; ages 18-80); and the Sleep Heart Health Study (SHHS, N =1974; ages 40-80)	The MGH data set (N =2532) was partitioned into a healthy training set (N = 1343) used to train the model, and a testing set (N =1189) to evaluate model performance.  As validation, they used a subset of the SHHS data set where each participant underwent 2 study visits, referred as SHHS1 and SHHS2. The data set contains 987 adults for a total of 1974 nights of EEG recorded. They trained the model in 2 ways. First, they trained the model on 752 participants with paired EEGs (1504 EEGs) from both visits and tested on the held out 235 participants with paired EEGs (470 EEGs) in both visits. They trained the model on the 2365 EEGs from healthy participants in MGH data set. We then predicted BA on the 1974 paired EEGs in SHHS as the testing set.	They maintain strict separation of training and testing participants.	no.	Novel approach: They develop a machine learning model to predict BA based on 2 large sleep EEG data sets. The model is described in the paper.	no.	EEG signals are notch-filtered at 60 Hz to reduce line noise, and bandpass filtered from 0.5 Hz to 20 Hz to reduce myogenic artifacts. For 30s-epochs, those with absolute amplitude larger than 500 m V are removed to minimize movement artifacts. Epochs containing flat EEG for more than 2 seconds are also removed. We also exclude EEGs contaminated by electrocardiogram, indicated by 1 Hz harmonic in the EEG spectrogram. To reduce interparticipant variance, the amplitude of each EEG channel is normalized to have zero median and unit interquartile range across the whole night. The total amount of data removed by these preprocessing procedures is 7% in the MGH data set and 9% in the SHHS data set.	one. To determine the optimal hyperparameter, they randomly select 300 EEGs from the training set to serve as internal validation data.	They extract 102 features from each 30-second epoch covering both time and frequency domains. For each EEG recording, they average the features in each of the 5 sleep stages overtime, yielding 102 x 5 = 510 features per EEG.	One strength of the study is the use of large data sets. The number of EEGs involved in this study is large among relevant ‚ÄúBA‚Äù studies. The large size of the data sets helps to ensure the statistical power as well and to minimize selection bias. A large training set helps ensure that the trained model does not overfit to a particular data set, improving the ability togeneralize when applied beyond the training set. A large testing set allows accurate statistical measurement of how accurately the model performs.			Transparent. The use of a parametric model, improves model interpretation by inspecting each EEG feature and comparing to the age norm for each feature explicitly. An example is provided in Figure 5 of the paper.	Regression.		no.	The model is validated on a longitudinal cohort from a subset of the SHHS data set without neurological or cardiovascular disease.		no.	The method reports statistical significant results.	no.	yes, included in the paper.									
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/21/2022 15:23:13	34345532	CanImmunother: a manually curated database for identification of cancer immunotherapies associating with biomarkers, targets, and clinical effects.	Zhang W, Zeng B, Lin H, Guan W, Mo J, Wu S, Wei Y, Zhang Q, Yu D, Li W, Chan GC.	Oncoimmunology	2021	2021	10.1080/2162402x.2021.1944553		n/a. The paper is a database description.	n/a. 	n/a. 	n/a. 	n/a. 	n/a. 	n/a. 	n/a. 	n/a. 	n/a. 	n/a. 		n/a. 	n/a. 		n/a. 	n/a. 		n/a. 	n/a. 	n/a. 	n/a. 	n/a. 	n/a. 							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/21/2022 17:00:14	25878156	Classification of pallidal oscillations with increasing parkinsonian severity.	Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD.	Journal of Neurophysiology	2015	2015	10.1152/jn.00840.2014		669 paired recordings were made across 3 subjects. Data are divided in 4 classes of (276, 149, 157, 87 points each). Data source: experiment.	90% of the data was used for training and the remaining 10% was used for testing.	Not stated.	no.	support vector machine (SVM)	no.	Each 30- to 120-s paired recording was converted into a single bipolar LFP. The multitaper method was used to calculate a spectrogram of the LFP. using a 2-s window with 10% window steps, resulting in a 1-Hz frequency resolution. Time windows containing movement artifacts were visually identified and removed. The spectrogram was averaged over the remaining windows to produce a single power spectral density (PSD) for each paired recording. An additional feature set was created with phase-amplitude coupling (PAC).	Not stated.	The entire feature set including both spectral and PAC components contained 206 features.  Feature selection was performed. The lasso regularization technique with 10-fold cross-vali- dation was used to perform feature selection through least-squares regression with a penalty on the size of the estimated coefficients. This procedure finds the combination of features that produces the minimum mean-square error (MSE). Lasso regularization was performed separately for the spectral and PAC feature sets.	Large number of features. Feature selection was performed to reduce the number of features used for the classificationto avoid overfitting.	yes: The lasso regularization technique with 10-fold cross-validation was used to perform feature selection through least-squares regression with a penalty on the size of the estimated coefficients		black box.	Classification.		no.	10-fold cross-validation		no.	Not stated.	no.	no.	Not stated.	Sensitivity/specificity measures for each subject/class.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/24/2022 17:28:42	25878156	Classification of pallidal oscillations with increasing parkinsonian severity.	Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD.	Computers and Electronics in Agriculture	2020	2015	10.1152/jn.00840.2014		Data collection was conducted through samples aggregated from mango plants. Data is composed of images.  They perform 3 experimental scenarios: Dataset size (510, 46.500, 62.047).	The overall original dataset has been divided into three subsets namely (i) training; (ii) validation and (iii) testing with 60%, 20% and 20% respectively.	Not stated.	no.	The VGG-16 network architecture (Simonyan & Zisserman, 2014) has been updated to replace the last block containing the softmax classification with a fully-connected layer (FCL).	no.	Data augmentation: blur (+ affine transform), contrast (+ affine transform), noise (+ affine transform). In total, for every image in the original dataset, additional 150 images have been generated through the presented augmentation process.	The weights of the VGG-16 network have been preserved from the pre-trained model. FCL layer network which consists of 2-layers. The first layer is activated by the ReLU function and consists of 256 nodes, followed by the second layer consisting of 16 nodes activated by softmax.	The extracted features are flattened: input feature vector [7*7*512].	They report overfitting and state that they will evaluate the performance of the network training against the overfitting in future research activity.	no.		Black box.	Classification.		no.	Not stated.		Not stated.	Not stated.	no.	no.	The cloud-based deployment of the CPU-only Tensorflow with Keras library has resulted in the computational time between 2 s to 2.99 s for the classification of the input image and provide a response to the mobile application.	Accuracy.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/25/2022 10:53:26	26541179	High-throughput long noncoding RNA profiling for diagnostic and prognostic markers in cancer: opportunities and challenges.	Sun Z.	Epigenomics	2015	2015	10.2217/epi.15.69		The paper is an editorial and does not contain a ML approach.																														
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/25/2022 14:56:54	31871774	Integrative analysis of DNA methylation and gene expression identified cervical cancer-specific diagnostic biomarkers.	Xu W, Xu M, Wang L, Zhou W, Xiang R, Shi Y, Zhang Y, Piao Y.	Signal Transduction and Targeted Therapy	2019	2019	10.1038/s41392-019-0081-6		307 cervical tumor samples from The Cancer Genome Atlas, 113 normal.	The data were randomly divided into ten different sets. Nine sets were used for training, and the remaining set was used for validation.	Not stated.	Yes. Supplementary material of the paper.	Logistic regression model.	no.	Feature selection.	Not stated.	Hybrid feature selection schema based on information gain and sequential backward feature selection (SBFS).	Not stated.	no.		Black box.	Classification.		no.	tenfold cross-validation		no.	no.	no	no.	Not stated.	96.2% sensitivity and 95.2% specificity							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/25/2022 16:07:48	29790392	Interleukin 1 receptor (IL-1R1) activation exacerbates toxin-induced acute kidney injury.	Privratsky JR, Zhang J, Lu X, Rudemiller N, Wei Q, Yu YR, Gunn MD, Crowley SD.	The American Journal of Physiology - Renal Physiology	2018	2018	10.1152/ajprenal.00104.2018		Data from experiments.	Not stated.	Not stated.	no.	T-distributed stochastic neighbor embedding (t-SNE).	no.	Not stated.	Not stated.	Not stated.	Not stated.	Not stated.		black box.	Regression.		no.	Not stated.		Not stated.	Not stated.	no.	no.	Not stated.	Not stated.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	1/26/2022 11:41:26	32826857	Machine learning for effectively avoiding overfitting is a crucial strategy for the genetic prediction of polygenic psychiatric phenotypes.	Takahashi Y, Ueki M, Tamiya G, Ogishima S, Kinoshita K, Hozawa A, Minegishi N, Nagami F, Fukumoto K, Otsuka K, Tanno K, Sakata K, Shimizu A, Sasaki M, Sobue K, Kure S, Yamamoto M, Tomita H.	Translational Psychiatry	2020	2020	10.1038/s41398-020-00957-5		SNP data for a total of 9966 subjects: 4974 training cohort subjects living in Miyagi prefecture recruited by Tohoku University and 4992 validation cohort subjects living in Iwate prefecture recruited by Iwate Medical University. 	After filtering, 3685 subjects in the training cohort and 3048 subjects in the validation cohort with 615,386 variants were subjected to prediction analyses.	Training and test sets are independent. Subjects with a low call rate (<0.98, n = 2 in the training cohort and n = 3 in the validation cohort) were excluded. They detected 2156 close-relationship pairs (620 in the training cohort and 1536 in the validation cohort) using the identity-by-descent method in PLINK software among the training cohort, the validation cohort, or between these cohorts. Then, in each of these pairs, a subject with lower call rates was excluded. Variants with low call rates, low Hardy‚ÄìWeinberg equilibrium exact-test P values, or low minor-allele frequencies were filtered out. Subjects without outcome or covariate information (n = 669 in the training cohort and n = 408 in the validation cohort) were excluded. Finally, 3685 subjects in the training cohort and 3048 subjects in the validation cohort with 615,386 variants were subjected to prediction analyses.	no.	Novel prediction algorithm: Smooth-Threshold Multivariate Genetic Prediction (STMGP)	no.	Not stated.	2 tuning parameters.	They prepared SNP data, phenotype data, and covariate data for both the training and test datasets for the input of the function (3 features).	Not stated.	Strategy to reduce overfitting: screening and building penalized regression models.		Black box.	Regression.		The program code for STMGP (STMGP v1.0), including the function used in the study, is available via CRAN, the official R package archive.	The performance of STMGP was evaluated in terms of prediction accuracy and the degree of overfitting.		The performance of STMGP was evaluated in terms of prediction accuracy and the degree of overfitting, and compared with that of other state-of-the-art methods, which included, in addition to PRS and GBLUP, summary-data-based best linear-unbiased prediction (SBLUP) , BayesR (a Bayesian hierarchical model for complex trait analysis) , and ridge regression (penalized regression model). 	STMGP showed the highest prediction accuracy with the lowest degree of overfitting, although there was no significant difference in prediction accuracy.	no.	no.	Not stated.	Accuracy.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	2/11/2022 16:40:03	22913485	NetiNeti: discovery of scientific names from text using machine learning methods.	Akella LM, Norton CN, Miller H.	BMC Bioinformatics	2012	2012	10.1186/1471-2105-13-211		Data source are databases.	A total of about 40,000 positive examples together with another set of about 43,000 negative examples were used to generate a training set of 83,000 examples for the two class labels.	Not stated.	The American Seashell book and a list of PubMed Central ids used for evaluation of NetiNeti can be found at http://ubio.org/netinetifiles	Probabilistic machine learning algorithms like Na√Øve Bayes and Maximum Entropy.	no.	Strings of text are tokenized and pre-filtered to select candidates.	The parameters are estimated via hill climbing approaches (Improved Iterative Scaling (IIS), Generalized Iterative Scaling (GIS)) and Limited-Memory Variable Metric optimization (L-BFGS). The number of parameters is not stated.	4-5 features are indicated.	Not stated.	no.		black box.	Classification.		The software system implementing NetiNeti can be accessed at http://namefinding.ubio.org.	PubMed Central ids used for evaluation of NetiNeti.		TaxonFinder and FAT tool.	The recall for TaxonFinder is significantly lower compared to NetiNeti, while the precisions are comparable. . The FAT approach has lower precision and recall values compared to NetiNeti and TaxonFinder.	no.	no.	Not stated.	Precision and recall values.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	2/15/2022 17:17:01	28065610	Neural Circuit Inference from Function to Structure.	Real E, Asari H, Gollisch T, Meister M.	Current Biology	2017	2017	10.1016/j.cub.2016.11.040		The data comes from a direct experiment. They consider firing rates of ~200 ganglion cells.	Training set: ~80% of the data. Test set: ~20% of the data.	Not stated.	no.	Single linear-nonlinear cascade models (LN), linear-nonlinear-sum-nonlinear (LNSN), linear-nonlinear-sum-nonlinear-feedback (LNSNF), linear-nonlinear-feedback-sum- nonlinear-feedback (LNFSNF) and LNFDSNF models. (to predict firing rates of ganglion cells)	no.	Not stated.	~100-150 parameters	Not stated.	Fitting is performed but the fitting algorithm is not explained.	"yes. A ""fitting algorithm"" is mentioned but the technique is not explained."		black box.	The model gives as output the neuron's spike rate (time course of the firing rate).		no.	Not stated.		Comparison between models used in the paper.	Median and variance of cells across models.	no.	no.	Not stated.	Not stated.							
martina.bevilacqua1992@gmail.com	6312169df3794236aa987a03	2/23/2022 14:26:24	33510068	Predictive models for mild cognitive impairment to Alzheimer's disease conversion.	Skolariki K, Terrera GM, Danso SO.	Perspective	2021	2021	10.4103/1673-5374.306071		Alzheimer ‚Äôs Disease Neuroimaging Initiative (ADNI), online database. Dataset size: 994. Split into 2 dataset: CTH, n= 650 and HCV, n= 299.	CTH test set, n=167, training set n=483. HCV test set n=120, training set n=179.	Not stated.	Alzheimer ‚Äôs Disease Neuroimaging Initiative (ADNI) (http://www.adni-info.org)	support vector machine (SVM) for which a linear C-SVM algorithm was applied, ii) decision trees, for which a Java open source implementation of the C4.5 algorithm (the J48 algorithm) was used and iii) the Naive Bayes (NB) classifier.	no.	Not stated.	Not stated.	Features based on cortical thickness (CTH) and hippocampal volumes (HCV) extracted from brain scans were used to train the learning algorithms.	Not stated.	Not stated.		Black box.	Classification.		no.	Not stated.		Direct, Direct VOI, STAND-score, Atlas, COMPARE, CTH-SVM, CTH-J48,  CTH-NB, NTI, ROI, Feature Vector, HCV-SVM, HCV-J48, HCV-NB, Volume- SPM5, Volume-FreeSurfer, Shape. These are machine learning techniques used for mild cognitive impairment patients classification. Accuracy is compared in Table 1 of the paper.	Not stated.	no.	no.	Not stated.	Accuracy.							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	2/23/2022 8:54:37	33126877	A new efficient method to detect genetic interactions for lung cancer GWAS.	Luyapan J, Ji X, Li S, Xiao X, Zhu D, Duell EJ, Christiani DC, Schabath MB, Arnold SM, Zienolddiny S, Brunnstr√∂m H, Melander O, Thornquist MD, MacKenzie TA, Amos CI, Gui J.	BMC Medical Genomics	2020	2020	10.1186/s12920-020-00807-9		Originally, there were 533,631 SNPs from 57,775 individuals in the OncoArray-TRICL Consortium population-based study. The filtered data had 27722 individuals (14935 positive and 12787 negative cases). Two simulated datasets were also used to evaluate the type I error rate and power. 	random sampling: 2/3 into a training set and 1/3 into the testing set; 2-fold cross-validation	None between the splits, but participants who were close relatives (second degree relatives or closer) and duplicate individuals were filtered out from the beginning.	Only unfiltered data: NCBI dbGaP repository phs001273.v3.p2, https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001273.v3.p2.	a version of Lasso-penalized Cox regression	No	filtering of data points and features (SNPs)	Not stated explicitly; should be at least n+n^2 for n=108 254	f = 533 000 SNPs; SNPs in linkage disequilibrium were removed, using a correlation threshold of 0.1 and resulting in 108 254 features (not clear if this was done only based on the training data). 		Yes: lasso + selecting only the SNPs involved in the top 1000 one-way and all the SNPs from the top 1000 two-way interactions models based on 2-fold CV.		transparent: identification of genes 	binary		https://github.com/jluyapan/ESMDR	2-fold cross validation + independent test set.		Only comparison against previous state-of-the-art method, Survival MDR (Surv-MDR)	None for the model for the real data; two simulation studies were created to estimate the 5% type I error and power; the significance of the selected models (intermediate step) was evaluated by a 10000-fold permutation test.	No	No	unknown	time-dependent ROC and its AUC							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	2/23/2022 14:14:06	31874628	scReClassify: post hoc cell type classification of single-cell rNA-seq data.	Kim T, Lo K, Geddes TA, Kim HJ, Yang JYH, Yang P.	BMC Genomics	2019	2019	10.1186/s12864-019-6305-x		Simulated and real-world experimental scRNA-seq datasets: the simulated sets had 100 points for each of 3, 5, 7, or 9 classes. The real-world sets were 4 from literature (1059 points with 3 classes, 367 points with 6 classes, 3005 points with 7 classes and 705 points for 10 classes). Some of the labels of all the datasets were artificially corrupted.	multiple AdaSampling (self-supervision) 		yes for real-world data: https://www.ebi.ac.uk/arrayexpress/help/GEO_data.html (ids E-MTAB-3929, GSE87795, GSE60361, GSE82187)	SVM, random forest, ensemble learning	No	Global features	Forced to be in the range of 10-20 + 4 (for SVM) by PCA to capture at least 70%	PCA to capture at least 70%, projected to the range of 10-20 features 				Black box	multi-class reclassification (error correction)		https://github.com/SydneyBioX/scReClassify; https://bioconductor.org/packages/release/bioc/html/scReClassify.html; GPL-3 license	Training data only				No	Some hyperparameters are given in the text.	Not provided	mean classification accuracy; adjusted Rand index							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	2/23/2022 17:15:55	27855170	Identification of an Efficient Gene Expression Panel for Glioblastoma Classification.	Crisman TJ, Zelaya I, Laks DR, Zhao Y, Kawaguchi R, Gao F, Kornblum HI, Coppola G.	PLoS One	2016	2016	10.1371/journal.pone.0164649		6 experimental datasets from the literature (803 = 171+296+46+27+35+228) and 4 classes. The raw data is not provided to evaluate the imbalances	575 data points in the training and validation sets; 228 in the test set; the raw data is not provided to evaluate the imbalances	Not studied	No	random forest	No	global features		All datasets were combined and normalized using the R package limma, and batch effects were adjusted using ComBat. Then the optimal number of features (48 out of presumably 753) was selected using all datasets, potentially leading to contamination. Then subsets of 48 features were used to train models (based on dataset 1), and the best model was chosen (based on datasets 2-5 + genetic algorithm) and evaluated (based on dataset 6).				Partially transparent: the features (genes) selected in the final model were scrutinized for other associations.	4-class classification		https://www.semel.ucla.edu/coppola-lab/simple-glioblastoma-subclassifier	Cross-validation, independent dataset		Baselines: VarSelRF and simple RFE as an alternative to their feature selection; benchmarking: ClaNC by Verhaak et al. (claimed to be the standard in the field).	Only standard deviations for the accuracy values are provided	Only final accuracy values for training, test, and combined datasets in the supporting information.	Partially yes: in the text	Not provided	accuracy							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/7/2022 10:25:36	33133228	A Method for Identifying Vesicle Transport Proteins Based on LibSVM and MRMD.	Tao Z, Li Y, Teng Z, Zhao Y.	Computational and Mathematical Methods in Medicine	2020	2020	10.1155/2020/8926750		based on UniProt search; dataset published in 2019; 2533 pos and 9086 neg	Train: 2214 (pos) and 2214 (neg) -> 5-fold CV; test 319 (pos) 1513 (neg);	The original data was processed by BLAST to get the sequence similarity to less than 30%; the test set was used before.	yes, https://github.com/taozhy/identifying-vesicle-transport-proteins	SVM with RBF kernel	No	global features	39 or 21 (after dimension reduction using max-relevance-max-distance)	"originally over 433; 39 after ""parameter optimisation""; further reduced to 21 by max-relevance-max-distance algorithm"	none	yes, L2 regularisation		black box	binary classification		not provided	5-fold CV; independent test set		none	none	no raw evaluation files; confusion matrix is in the text	partially - only some hyper-parameters are given in the text	not given but should be instant	Recall, Precision, Accuracy, MCC							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/7/2022 10:49:51	27191382	Deep biomarkers of human aging: Application of deep neural networks to biomarker development.	Putin E, Mamoshina P, Aliper A, Korzinkin M, Moskalev A, Kolosov A, Ostrovskiy A, Cantor C, Vijg J, Zhavoronkov A.	Aging	2016	2016	10.18632/aging.100968		62419 anonymized blood biochemistry records from Invitro Laboratory, Ltd.; continuous labels; dataset not used before	random 90/10 train-test split; 10-fold CV mentioned only in a figure	none	not provided	21 DNNs + Elastic net as stacking model; GBoost; RF; DT; LR; kNN; Elastic net; SVM	No	global features	around 5M	6	DNNs outperform baseline ML approaches	Yes: dropout (p=0.2) after each layer, and L2 weight decay		transparent: marker importance based on Permutation Feature Importance; discussion of top 10 features	continuous labels		http://www.aging.ai/ - looks proprietary 	seemingly independent test set		only a set of baseline models, based on R2 and accuracy			Only the summary for the DNNs architectures 	not provided	epsilon-prediction accuracy (epsilon=10); R2; Pearson correlation (not reported); MAE (not reported)							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/7/2022 11:16:44	34093642	Machine Learning Assisted Prediction of Prognostic Biomarkers Associated With COVID-19, Using Clinical and Proteomics Data.	Sardar R, Sharma A, Gupta D.	Frontiers in Genetics	2021	2021	10.3389/fgene.2021.636441		clinical and normalized protein expression profile data for 306 COVID-19 patients and 78 other patients (control) from the Olink website; 42 pos and 264 neg	only LOOCV was used	Not commented	yes: https://www.olink.com/application/mgh-covid-19-study/ upon request	44 different types of ML classification algorithms available in WEKA (v3.8.2)	No	global features	no details provided, but p varies based on the models	1463	none	no details provided		transparent: identification of proteins associated with labels based on feature selection methods in WEKA	possibly both depending on the model		only on the web: http://14.139.62.220/covidprognosis/	LOOCV		None, only the 44 different models used in the study were compared		Confusion matrices in the supplement: http://14.139.62.220/covidprognosis/supple.php	Partially in the supplement: http://14.139.62.220/covidprognosis/supple.php	not given	MCC, Accuracy, Sensitivity, Specificity, area under ROC							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/8/2022 12:38:13	32300371	HMMPred: Accurate Prediction of DNA-Binding Proteins Based on HMM Profiles and XGBoost Feature Selection.	Sang X, Xiao W, Zheng H, Yang Y, Liu T.	Computational and Mathematical Methods in Medicine	2020	2020	10.1155/2020/1384749		Two published datasets from literature: PDB1075 (525 pos and 550 neg) and PDB186 (93 pos and 93 neg)	training: 525 pos / 550 neg; validation: 10-fold CV and jackknife CV; testing: 93 pos / 93 neg	sequences with more than 25% sequence similarity were removed	yes, https://github.com/taigangliu/HMMPred	 SVM, RF, XGBoost for feature ranking	no	global features were derived from sequece-based features by averaging over protein length	p = f+3 for SVM,  	a range from 420 to 4020 was tested; 2000 in the final model	a range of feature numbers was tested based on CVs; XGBoost feature ranking	included in SVM (margin maximisation)		Black box	binary classification 		https://github.com/taigangliu/HMMPred	Cross-validation, independent dataset		comparisons with some existing predictors on the same datasets: DNAbinder, DNA-Prot, iDNA-Prot, iDNA-Prot|dis, Kmer1+ACC, iDNAPro-PseAAC, PseDNA-Pro, Local-DPP, HMMBinder  	not given	no raw evaluation files 	yes: https://github.com/taigangliu/HMMPred	not provided	Accuracy, sensitivity, specificity, MCC, AUC							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/8/2022 13:05:23	24675637	An integrated model of multiple-condition ChIP-Seq data reveals predeterminants of Cdx2 binding.	Mahony S, Edwards MD, Mazzoni EO, Sherwood RI, Kakumanu A, Morrison CA, Wichterle H, Gifford DK.	PLOS Computational Biology	2014	2014	10.1371/journal.pcbi.1003501		55 mouse ES ChIP-seq and DNaseI-seq experiments from a variety of sources, each with up to 4000 pos and 10000 negs.	20 repetitions of random selection of 100 data points for testing	mot checked	No	SVM	No	global features (k-mers)	p = f	not clear: in one place they mention 55-dimensional vectors, but also 4-mer frequencies (256) and 3 additional features.	None provided	Not mentioned		transparent: discriminative motif discovery touched upon	binary classification		Not available for SVM, but the focus of the study was a non ML-based tool: https://github.com/seqcode/multigps	20 random replicates of train/test splits			Not explicitly given but 20 replicates are shown in the ROC graphs	No	No	not given	ROC-AUC							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/8/2022 13:39:24	28807860	Hidden Markov modeling of frequency-following responses to Mandarin lexical tones.	Llanos F, Xie Z, Chandrasekaran B.	Journal of Neuroscience Methods	2017	2017	10.1016/j.jneumeth.2017.08.010		Recorded FFRs to 4 Mandarin tones from 28 people	K-fold CV of varying K for each tone separately (a version of unsupervised learning)	To avoid stimulus artifact bias, training and testing subsets alternated the same number of trials with opposite stimulus polarity	No	hidden Markov models were trained for each class	No	moving average window	not clear	22 discrete intervals	testing various sizes of the moving average window			Black box	probability scores		partially in the supplement	Cross-validation			Yes: SDs are given for each accuracy estimates	No	No	not given	Accuracy							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/8/2022 14:15:46	31856830	Identification of lung cancer gene markers through kernel maximum mean discrepancy and information entropy.	Zhao Z, Peng H, Zhang X, Zheng Y, Chen F, Fang L, Li J.	BMC Medical Genomics	2019	2019	10.1186/s12920-019-0630-4		Three classes are three gene expression datasets collected before: 373 normal, 59 normal adjacent to tumour, and 541 tumour patients	10-fold CV	None checked	NCBI Gene Expression Om-nibus (https://www.ncbi.nlm.nih.gov/geo/): GSE86354 and GSE62944	Kernel maximum mean discrepancy to select features + RF	No	global features	non-parametric method (it seems)	 expression data of 23368 genes	Not provided	None mentioned		transparent: identification of marker genes for lung cancer	scores		Barely: https://github.com/Zhixun-Zhao/GeneMarker	10-fold CV		comparison with conventional t-test and fold change methods	None provided	yes: supporting information	No	not given	Recall, F1, Accuracy, MCC							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/8/2022 14:59:55	23102953	The gradient boosting algorithm and random boosting for genome-assisted evaluation in large data sets.	Gonz√°lez-Recio O, Jim√©nez-Montero JA, Alenda R.	Journal of Dairy Science	2013	2013	10.3168/jds.2012-5630		1859 data points from another publication, continuous lables	train/test: 1601/258 or 1574/235 (depending on the label type); 10-fold CV	data were split by the year of birth (before 2005 -> train, after -> test)	No	gradient boosting algorithm using 2 different weak learner models: OLS and RKHS regression; modification -> random boosting	No	global features	not given	only 39714 SNPs mentioned	Not provided	No		transparent: gene identification	regression		no	independent test set				No	No	not given	"Pearson correlation, Estimated prediction bias (=""average difference between predicted and observed responses in standard deviation units"")"							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/8/2022 17:16:35	30857591	Learning protein constitutive motifs from sequence data.	Tubiana J, Cocco S, Monasson R.	eLife	2019	2019	10.7554/elife.39397		supervised (contact prediction): 18 sets of multiple sequence alignments from pfam database + contact maps based on pdbs; 	train/test: 80%/20% at random 	Reweighting procedure is applied: each sequence is assigned a weight equal to the inverse of the number of sequences with more than 90% identity	yes: https://github.com/jertubiana/ProteinMotifRBM	Restricted Boltzmann Machines	No	aligned sequences	not given explicitly, a different number of hidden units (1-400) were tested	MxNx21 where M is length and N is width of an MSA	regularisation and model selection used	L2 and L2/L1		yes: weights are interrelated for various case studies	probability score		yes: https://github.com/jertubiana/ProteinMotifRBM	independent test (20% of initial data)		performance was compared to direct coupling-based methods, namely the Pseudo-Likelihood Method (plmDCA) and Boltzmann Machine (BM)	not provided	No	yes: https://github.com/jertubiana/ProteinMotifRBM	in the order of 1‚Äì2 days on an Intel Xeon Phi processor with 2¬†√ó¬†28 cores	PPV, accuracy (contact prediction task)							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/8/2022 18:05:03	28747397	Changes and classification in myocardial contractile function in the left ventricle following acute myocardial infarction.	Gao H, Aderhold A, Mangion K, Luo X, Husmeier D, Berry C.	Journal of The Royal Society Interface	2017	2017	10.1098/rsif.2017.0203		clinical trials, 11 pos and 27 neg	LOOCV for testing and internal LOOCV or 5-fold CV for validation	not reported	No, only ClinicalTrials.gov identifier: NCT01717573	Logistic regression, KNN, LDA, DT, RF, Gaussian processes (GP-ARD)	no	global features	various but equal to f in most cases	6	a range of different model types was tested	for some predictors, e.g. Lasso for logistic regression		transparent: identification of the main biomarkers	both, depending on the model used		not provided	LOOCV		only among the models in the paper	Not given	no	partially: supplement 	not provided	sensitivity, specificity, accuracy, AUROC							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/9/2022 9:50:58	30769139	Identifying mutation positions in all segments of influenza genome enables better differentiation between pandemic and seasonal strains.	Kargarfard F, Sami A, Hemmatzadeh F, Ebrahimie E.	Gene	2019	2019	10.1016/j.gene.2019.01.014		new database search in Influenza Research Database; 10 protein datasets with 4240-5373 data points (around 2/3 are pos and 1/3 are neg in each dataset) 	"There is a mysterious ""test data"" set mentioned only once without any additional information."	none reported	yes: supporting information	DT, CBA, Ripper	No	global features (multiple sequence alignment)		f = protein sequence length (200-900)	None provided			transparent: biological interpretation of identified rules (mutations)	probability score		No	"mysterious ""test set"" mentioned only once"			None for evaluation	No	No	Not provided	accuracy							
mazurenko@mail.muni.cz	6312169df3794236aa9879fc	3/9/2022 10:11:09	26422234	PATBox: A Toolbox for Classification and Analysis of P-Type ATPases.	S√∏ndergaard D, Pedersen CN.	PLOS ONE	2015	2015	10.1371/journal.pone.0139571		a dataset of 515 sequences annotated with experimentally verified subtypes; 11 classes	20 runs of non-stratified 5-fold CVs and 2-fold CVs	the dataset was also clustered at similarity thresholds of 30%, 50%, 75%, and 90%	yes	KNN	No	global features: distances are calculated by BLAST		variable sequence lengths of around 1000 AAs	a range of K values tested (1-50), 2 different CV protocols, weighted KNN			transparent: k=1 was selected, which is basically the sequence similarity method	binary predictions		https://services.birc.au.dk/patbox/ - not available as of 09/03/2022	5-fold and 2-fold CV		one other method based on ANN is mentioned in the text 	standard deviation is reported in a figure based on 20*5 values	No	Yes: text	not provided	accuracy							
nils.hoffmann@cebitec.uni-bielefeld.de	6312169df3794236aa9879e9	3/28/2022 20:30:14	33535965	Authoritative subspecies diagnosis tool for European honey bees based on ancestry informative SNPs.	Momeni J, Parejo M, Nielsen RO, Langa J, Montes I, Papoutsis L, Farajzadeh L, Bendixen C, CƒÉuia E, Charri√®re JD, Coffey MF, Costa C, Dall'Olio R, De la R√∫a P, Drazic MM, Filipi J, Galea T, Golubovski M, Gregorc A, Grigoryan K, Hatjina F, Ilyasov R, Ivanova E, Janashia I, Kandemir I, Karatasou A, Kekecoglu M, Kezic N, Matray ES, Mifsud D, Moosbeckhofer R, Nikolenko AG, Papachristoforou A, Petrov P, Pinto MA, Poskryakov AV, Sharipov AY, Siceanu A, Soysal MI, Uzunov A, Zammit-Mangion M, Vingborg R, Bouga M, Kryger P, Meixner MD, Estonba A.	BMC Genomics	2021	2021	10.1186/s12864-021-07379-7		Custom sampling of 22 populations of honey bee in Europe and adjacent regions, total 2145 samples leading to 1.6 billion paired-end fragments. 1998 remained after removal of 62 outliers.	Training: 1391 samples (70% of 1998),  597 (30% of 1998) and 2505 independent samples (out-of-sample with known bee subspecies classification) for validation.	Selection of SNPs (Single Nucleotide Polymorphisms), originally 4400 selected, 4165 after QC check. 4094 SNPs were genotyped (71 failed base calling).	Additional file 1, https://www.ncbi.nlm.nih.gov/sra/?term=PRJNA666033	Linear Support Vector Classification	No	One-hot encoding as vectors	NA, multiple supervised ML methods were used with scikit-learn	Not defined, 1396 * number of genotypes					Classification		https://github.com/jlanga/smsk_popoolation, MIT License	CV		Multiple supervised methods were compared, best method selection based on average accuracy.		Supporting information	Supplementary Information		Accuracy							
nils.hoffmann@cebitec.uni-bielefeld.de	6312169df3794236aa9879e9	3/29/2022 9:10:15	32878308	Targeted Metabolic Profiling of Urine Highlights a Potential Biomarker Panel for the Diagnosis of Alzheimer's Disease and Mild Cognitive Impairment: A Pilot Study.	Yilmaz A, Ugur Z, Bisgin H, Akyol S, Bahado-Singh R, Wilson G, Imam K, Maddens ME, Graham SF.	MDPI Metabolites	2020	2020	10.3390/metabo10090357		20 Alzheimer's Disease patients (AD), 10 Mild cognitive impairment (MCI) and 29 control patients. Metabolomics samples measured with HNMR and DI LC-MS/MS, identification of 142 metabolites with HNMR and 51 with DI LC-MS/MS, demographic information (age and gender)	20, 10, 29 (see provenance) * 142 metabolites, 	Average of concentrations of overlapping metabolites between HNMR and DI LC-MS/MS. PCA to screen for and remove subjects outside of 95% percentile. Student‚Äôs t-test was performed to determine if there were any significantly different metabolites between AD, MCI, and age-matched controls (p < 0.05) when compared pairwise. Non-normally distributed data were analyzed using a Mann‚àíWhitney U test and a Bonferroni correction was applied to account for multiple comparisons. To determine if sample demographics were statistically significantly different, a one-way analysis of variance analysis (ANOVA) was conducted using the IBM SPSS Statistics toolbox (v. 24.0).	MTBLS1695, study still private	SVM (RBF kernel), Logistic regression	No	Log-transform, auto-scaling		Correlation-based feature selection, LASSO, step-wise variable selection				NA (missing or inaccessible model data and source code)	Classification		NA (MetaboLights accession is private)	10-fold Cross-validation		SVM, logistic regression	p-values, CI (95%) for AUCs	Supporting information, potentially in MetaboLights repository under private accession MTBLS1695			AUC, sensitivity, specificity							
nils.hoffmann@cebitec.uni-bielefeld.de	6312169df3794236aa9879e9	3/27/2022 20:48:59	30950198	A directed learning strategy integrating multiple omic data improves genomic prediction.	Hu X, Xie W, Wu C, Xu S.	Plant Biotechnology Journal	2019	2019	10.1111/pbi.13117		Previously reported data, 210 lines, 1619 bins (synthetic markers), 24994 genes transcripts, 1000 metabolites and four agronomic traits	10-fold Cross-Validation	Random choice from Cross-Validation	Stated to use previously reported data, but no explicit reference provided. 	Lasso regression	No		Modified lasso regression, alpha (first layer), beta (second layer), gamma (third layer), 10-fold CV for all parameters, successively	24994 genomic transcripts, 1000 metabolites, four agronomic traits, CV on transcripts > 0.2 and PD > 1 (90th% - 10th%), 5467 genomic transcripts after CV filter		10-fold CV		Model is not available for evaluation	"Regression, outputs ""predictability"""			Cross-validation		Lasso regression		"Yes (not all parameters, evaluation based on ""Predictability""), Supporting information"	Only values for alpha are provided		Predictability							
nils.hoffmann@cebitec.uni-bielefeld.de	6312169df3794236aa9879e9	3/28/2022 20:10:36	31308377	Patient-specific cancer genes contribute to recurrently perturbed pathways and establish therapeutic vulnerabilities in esophageal adenocarcinoma.	Mourikis TP, Benedetti L, Foxall E, Temelkovski D, Nulsen J, Perner J, Cereda M, Lagergren J, Howell M, Yau C, Fitzgerald RC, Scaffidi P, Oesophageal Cancer Clinical and Molecular Stratification (OCCAMS) Consortium, Ciccarelli FD.	Nature Communications	2019	2019	10.1038/s41467-019-10898-3		Data are EAC (esophageal adenocarcinoma) genes from 1) ICGC (261), TCGA (86), Other Study (21)	Training and validation data were completely independent (ICGC/Occam data for training, TCGA and additionaly study data for testing of robustness and validation)	Training and validation are completely separate. Parameter optimization was based on training data with grid search using 10,000 iterations and three fold cross-validation on four different SVM classifiers using a linear, radial, sigmoid and polynomial kernel.	Yes, supporting information, https://ega-archive.org/datasets/EGAD00001004775, https://ega-archive.org/datasets/EGAD00001004776, esophageal adenocarcinoma samples from OCCAM consortium / part of ICGC	SVM	No		nu (all kernels), gamma (radial, sigmoid, polynomial kernels), degree (polynomial kernel). 10000 iterations of three-fold cross validation, random split of training set into 2/3 train, 1/3 test set. Sensitivity is used to select the least varying model from top 5 models for each kernel. (more details in Supplementary Material 1)	34 featuress mapped to genes altered in sample cohort (one of the three datasets). See Supplementary Material 1for details.		best model selection takes into account all previous cross-validation iterations every n (100) cross validations, random reordering of cross validation iterations (5x)		Transparent	Classification		https://github.com/ciccalab/sysSVM, License not defined	Cross validation & independent datasets		No comparison to other methods. Identified helper genes show similar properties to known  cancer genes. Estimation based on pathway enrichment of identified novel genes (helpers) vs known cancer genes (drivers) based on functional association		Supporting information and GitHub / R Project https://github.com/ciccalab/sysSVM	Yes, Supporting information 		Sensitivity							
nils.hoffmann@cebitec.uni-bielefeld.de	6312169df3794236aa9879e9	3/29/2022 9:39:03	30794638	Machine learning models for early sepsis recognition in the neonatal intensive care unit using readily available electronic health record data.	Masino AJ, Harris MC, Forsyth D, Ostapenko S, Srinivasan L, Bonafide CP, Balamuth F, Schmatz M, Grundmeier RW.	PLOS One	2019	2019	10.1371/journal.pone.0212665		Neonatal Intensive Care Unit (NICU) at the Children‚Äôs Hospital of Philadelphia, hospizalized infants with sepsis evaluation (culture positive, clinically positive)	618 infants with 1188 sepsis evaluations, 110 culture positive, 265 clinically positive, 492 negative	NA (there were pre-selection criteria for inclusion)	Yes, Supporting information.	AdaBoost, Gradient boosting, Gaussian process, K-nearest neighbors, logistic regression, naive Bayes, Random forest, SVM (RBF)	No	Mean imputation for missing values, normalization of continuous valued features to zero mean and unit variance.	Ada boost: 3, Gradient Boosting: 2, kNN: 2, Logistic Regression: 1, Random Forest: 3, SVM: 2	36 clinical attributes per patient per time-point	Second feature selection process as part of the hyper-parameter tuning process, referred to as ‚Äúautomated feature selection‚Äù in Fig 1. The automated method is based on the mutual information between each individual feature and sepsis class (case or control) to select top n features, 11 features selected for CPOnly DS, 35 (all) for CP+Clinical dataset.	Nested k-fold cross-validation		Transparent, names of models and parameters are provided	probability score, classification into positive case if p > 0.5		https://github.com/chop-dbhi/sepsis_01, Data is in S3, unclear if project can be fully bootstrapped.	k-fold cross validation, negative control dataset		Ada boost, Gradient Boosting, kNN, Logistic Regression, Random Forest, SVM	NA (The null hypothesis of equal inter-model distributions was rejected by the Friedman rank sum test with p-values of <0.001 for both the CPOnly and CP+Clinical datasets.)	Yes, Supporting information, https://github.com/chop-dbhi/sepsis_01, MIT license (code)	Yes, supporting information		AUC, Specificity, PPV, NPV							
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 15:07:04	32545899	Differential Urinary Proteome Analysis for Predicting Prognosis in Type 2 Diabetes Patients with and without Renal Dysfunction.	Ahn HS, Kim JH, Jeong H, Yu J, Yeom J, Song SH, Kim SS, Kim IJ, Kim K.	International Journal of Molecular Sciences	2020	2020	10.3390/ijms21124236		Proteomes of urine samples from 54 T2D (Type 2 Diabetes) patients from Pusan National University Hospital, South Korea. N_pos = 19 (poor prognosis group (PPG) due to DKD (Diabetic Kidney Disease), N_neg = 35 (good prognosis group (GPG), i.e. no DKD).   Not used in previous papers.	SVM model with linear kernel was generated by a 10 fold repeated three-fold cross validation.  The RF model was generated by a 3-fold cross validation method repeated 100 times.	Not applicable	Yes. Supporting Information.	SVM and RF.	No.	Not reported.	The authors do not mention parameters numbers different from standard.  They mention the value of some parameters, without mentioning how they were chosen. 	The study focused on 412 proteins (of the 1296 identified proteins in each proteome) quantified in more than 80% of urine samples, with missing values filled by local least squares imputation.  From those 412 proteins, 5 proteins (ACP2, CTSA, GM2A, MUC1, and SPARCL1) were selected as significant by an AUC-based random forest method. 	The authors do not mention overfitting issues, although their multivariate AUROCs showed very high values.	Not reported.		No statement about ante-hoc interpretability of the models is made by the authors.   The RF and SVM are generally considered black box.   Post-hoc analysis resulted somewhat interpretable, since the 5 selected features correspond to 5 urinary proteins that are considered likely to be related to DKD.  However, their eventual joint effect remains not interpretable.	Binary classification (PPG or GPG).  The binary results of RF and SVM models were also transformed in disease prediction scores, which ranged from 0 to 1.		Data were analyzed using the publicly available RStudio (version 1.1.456) including R (version 3.6.0). 	Cross-validation.   Since the authors were unable to find a benchmarking study in the discovery of urine protein biomarkers, they evaluated the models with mRNA expression in the kidney.   The SVM and RF models consisting of 5 urine proteins were applied to 4 publicly available GEO datasets:  GSE99339, GSE47185, GSE30122, and GSE96804.  However, the predictions on such datasets were not statistically significant.		The performances of the SVM and RF models were compared to the predicting performance of the albumin-to-creatinine ratio, a simple biomarker for DKD which has been widely used so far.	The authors state that the AUROC of the two classifiers (SVM and RF) differed significantly from albumin-to-creatinine ratio (likelihood ratio test: p-value < 0.05). However, for the RF AUROC (value = 1.0) no confidence intervals are reported, and the confidence intervals for SVM AUROC are not further specified.	No.	No.	Not reported.	AUROC.  Comparison of disease prediction scores.							
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 15:26:30	33005419	FibroBox: a novel noninvasive tool for predicting significant liver fibrosis and cirrhosis in HBV infected patients.	Lu XJ, Yang XJ, Sun JY, Zhang X, Yuan ZX, Li XH.	Biomarker Research	2020	2020	10.1186/s40364-020-00215-2		Clinical data from 4 different hospitals in China (4 different cities) about piatients with chronic B virus hepatitis. N = 1289 (patients from 4 different cities).  N_pos (fibrosis) = 815, N_neg (fibrosis) = 474 ;    N_pos (cirrhosis) = 290, N_neg (cirrhosis) = 999.   Data not used by previous authors.	Training set:   N = 549  (patients from 2 different cities, joined together).  N_pos (fibrosis) = 382 / N_neg (fibrosis) = 167 ;    N_pos (cirrhosis) = 157 // N_neg (cirrhosis) = 392.   Test set Anhui:   N = 408 (independent patients dataset from Anhui city).  N_pos (fibrosis) = 254 // N_neg (fibrosis) = 154 ;    N_pos (cirrhosis) = 59 // N_neg (cirrhosis) = 359.     Test set Beijing:   N = 332 (independent patients dataset from Beijing city).  N_pos (fibrosis) = 179 // N_neg (fibrosis) = 153 ;    N_pos (cirrhosis) = 74 // N_neg (cirrhosis) = 258.        69.6% positives (fibrosis), 28.6% positives (cirrhosis) on training set.   62.3% positives (fibrosis), 14.5% positives (cirrhosis) on Anhui test set.  53.9% positives (fibrosis), 22.3% positives (cirrhosis) on Beijing test set.  	Not applicable.	According to the author's statement, the data are not available because of patients‚Äô privacy.	LightGBM (a gradient boosting framework using tree based learning algorithms) is stated in the Supplementary to have been the algorithm of choice.	No.	For character data field (like sex, pathogenesis), the LabelEncoder method in Python was used (categorical features encoded as a one-hot numeric array).	The number of parameters was the standard for Python implementation of LightGBM.  Parameters were tuned to get good results by means of grid search, random search and the Python library Hyperopt.	Starting from 24 features (clinical measurements commons to the 4 hospitals), 9 features were selected for training, by means of LASSO regression and filter methods (the latter being variance threshold, Pearson Correlation Coefficient, chi-square test and mutual information).	The LightGBM algorithm is stated in its documentation likely to be over-fitting if not used with the appropriate parameters. 	"Yes.  The authors state that, ""to prevent overfitting, the index of colsample_bytree was set to 0.9"".    Other parameters tuning for over-fitting prevention is not mentioned. "		No statement about ante-hoc interpretability of the model is made by the authors.   This LightGBM model looks to me complex enough to result rather black box.   Post-hoc analysis showed e.g. that the contribute of the Transient Elastography (TE) feature to the good predictability was very relevant, which is meaningful.  An explaination for an eventual joint effect of the 9 features was not adressed.	Classification.  Case A: positive and negative samples are non-significant fibrosis vs. significant fibrosis. Case B: positive and negative samples are non-cirrhosis vs. cirrhosis.		The ML algorithms were implemented using Python 3.7.	5-fold cross-validation during training-testing.  Two independent datasets were used as evaluation sets:  the Anhui cohort (n = 408), and the Beijing cohort (n=332).		FibroBox was compared to 3 other pre-existing predicting methods: TE (Transient Elastography), APRI (Aspartate transaminase-to-platelet ratio index), FIB-4 (fibrosis-4 index), the letter two being serum biomarkers. The LightGBM algorithm was coompared to Logistic regression and XGBoost. 	Confidence intervals at 95% for AUROC, statistical significance confirmed for the difference between FibroBox and each of TE, APRI, FIB-4 methods, both for fibrosis and for cyrrhosis predictions.	No.	No.	The run time of FibroBox is mentioned in the Discussion to be only a few seconds.	Precision, recall, F1-score, accuracy,  AUROC.  The latter was used for feature selection, and for comparison with other models. 							
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 15:30:03	32915321	MetaboShiny: interactive analysis and metabolite annotation of mass spectrometry-based metabolomics data.	Wolthuis JC, Magnusdottir S, Pras-Raves M, Moshiri M, Jans JJM, Burgering B, van Mil S, de Ridder J.	 Metabolomics 	2020	2020	10.1007/s11306-020-01717-8		COMMENT:   --  Not Applicable   (A tool for metabolomics analyses is described, and a published ML work is reproduced using the tool, for demonstrative purposes)																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 15:32:27	32002757	Tools for Analysis of the Microbiome.	Galloway-Pe√±a J, Hanson B.	 Digestive Diseases and Sciences	2020	2020	10.1007/s10620-020-06091-y		COMMENT --  Not applicable (Review)																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 15:35:45	31849986	Editorial: Methods and Applications of Computational Immunology.	Chain B, Greiff V, Textor J, Yaari G.	Frontiers in Immunology	2019	2019	10.3389/fimmu.2019.02818		COMMENT  --  Not applicable  (Editorial)																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 15:57:36	22532634	A CD4 T cell gene signature for early rheumatoid arthritis implicates interleukin 6-mediated STAT3 signalling, particularly in anti-citrullinated peptide antibody-negative disease.	Pratt AG, Swan DC, Richardson S, Wilson G, Hilkens CM, Young DA, Isaacs JD.	Annals of the Rheumatic Diseases	2012	2012	10.1136/annrheumdis-2011-200968		CD4 T-cell transcriptomes from 173 UK patients, of which N_pos = 72  (RA, i.e. outcome Rheumatoid Arthritis), N_neg =101 (outcome Non-RA).  Not used in previous papers.	111 patients in training set, of which N_pos_train = 47  (RA), N_neg_train = 64 (Non-RA).    62 patients in testing set, of which N_pos_test = 25  (RA), N_neg_test = 37 (Non-RA).   42.3% positives on training set.   40.3% positives on test set.	Not applicable.	Yes.    Raw and processed microarray data used in this study is available via Gene Expression Omnibus at: http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?token=bviftkociimgsnk&acc=GSE20098	SVM	No.	Not reported.	 The authors do not mention parameters numbers different from standard.  	f = 12.   Starting from 16,205 genes, 12 genes were at the end selected as differentially expressed in RA versus non-RA patients.  Differential expression was defined as a fold-change cut-off of 1.2, combined with a significance level cut-off of p<0.05 (Welch‚Äôs t-test), corrected for multiple testing using the false-discovery-rate method of Benjamini.	Not applicable.	Not applicable.		No statement about ante-hoc interpretability of the model is made by the authors.   SVM is generally considered black box.   Post-hoc analysis indicates that PB CD4 T cells in early RA are characterised by a predominant upregulation of biological pathways involved in cell cycle progression (ACPA-positive) and survival, death and apoptosis (ACPA-negative).  ( ACPA = anti-citrullinated peptide antibodies)	Binary prediction:  RA or non-RA.		Standard algorithms are used.	Test set (independent dataset).		A transcriptional ‚Äòrisk metrics‚Äô for ACPA-negative patients was bild, and the AUROC curve of the 12-gene signature was compared to the existing ‚ÄòLeiden prediction rule‚Äô as a predictor of RA in the test set.   No difference in the performance was seen in this case.  However, by combining all features of the Leiden prediction rule with the 12-gene risk metric, and applying it to the ACPA-negative UA cohort (test set), the AUROC curve value improved from 0.74, SEM=0.08 (original Leiden prediction rule) to 0.84; SEM=0.06 (modified metric incorporating gene signature).                   	AUROC curve (original Leiden prediction rule)=0.74; SEM=0.08 versus area under ROC curve (modified metric incorporating gene signature)=0.84; SEM=0.06; p<0.001 in both cases.	No.	No.	Not reported.	Sensitivity, specificity, positive and negative likelihood ratio.							
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 15:59:53	34034523	The emergence of cooperation by evolutionary generalization.	Geoffroy F, Andr√© JB.	Proceedings of the Royal Society B: Biological Sciences	2021	2021	10.1098/rspb.2021.0338		COMMENT  --  Not Applicable (An ANN is used to model the evolution of a particular social behavior)																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 16:23:02	31857725	Development of PancRISK, a urine biomarker-based risk score for stratified screening of pancreatic cancer patients.	Blyuss O, Zaikin A, Cherepanova V, Munblit D, Kiseleva EM, Prytomanova OM, Duffy SW, Crnogorac-Jurcevic T.	British Journal of Cancer	2020	2020	10.1038/s41416-019-0694-0		Specimens collected at the Royal London Hospital, University College London Hospital, Liverpool University and the CNIO Madrid, Spain, plus further samples obtained from Pancreas Tissue Bank (https://www. bartspancreastissuebank.org.uk).  N_pos = 199 ( pancreatic ductal adenocarcinoma (PDAC) patients), N_neg = 180 (healthy patients). No previously used.	Random division in a 1:1 ratio for train and test.   N_pos_train = 96, N_neg_train = 95,  N_pos_test = 103, N_neg_test = 85.    50.3% positives on training set.   54.8% positives on test set.	Not applicable.	Data available on request from the corresponding author.	Logistic regression.	No.	Not reported.	The authors do not mention parameters numbers different from standard. 	Only 5 predictors available, no selection applied in this work.  The 5 predictors were the result of a selection applied in a previous work (PMID: 21136905), by quantifying differentially expressed proteins in urine proteomes.	Bootstrap cross-validation was used for the internal validation to ensure that overfitting is avoided. Following that, elastic net was used for the regularisation of the coefficients to obtain the final model.  	Yes, use of elastic net.		Logistic Regression is generally considered transparent.  In a previous work (PMID: 26240291) the authors examined the good predicting power of each of the 3 urine biomarkers (LYVE1, REG1A, and TFF1) taken separately.   However, an explaination of the joint effect of the variables has not been attempted.	Binary classification (high PDAC risk or not).		Logistic regression: The ‚Äúglmnet‚Äù package from R was used with elastic net regularisation.    NN: Python packages tensorflow, keras, and scikit-learn.  RF: The ‚Äúparty‚Äù package from R.   SVM:  The ‚ÄúsvmLinear‚Äù method from the ‚Äúcaret‚Äù package in R was used.  NF: The r-algorithm developed by Shor was used with a precision Œµ = 0.001. Software implementation of this approach was developed within the Visual Studio 2013 environment.	Independent dataset.		Logistic regression was compared to neural network (NN), neuro-fuzzy technology (NF), random forest (RF) and support vector machine (SVM).  None of those additional approaches significantly outperformed logistic regression. 	Inference for the ROC curves was based on cluster-robust standard errors that accounted for the serially correlated nature of the samples. It was not possible to create ROC curves and therefore AUC for RF and SVM since the outcome was not continuous. McNemar‚Äôs exact test was used to assess the significance of difference in SN at fixed SP and DeLong‚Äôs test was used to assess the significance of differences in AUC between approaches. Confidence intervals (CI 95%) for AUCs were derived based on the DeLong‚Äôs method to evaluate the uncertainty of an AUC; SN and SP 95% CI were derived using bootstrap replicates. To allow for multiple testing, both types of tests were adjusted using the Bonferroni correction. 	No.	No.	Not reported.	AUROC (except for RF and SVM) and sensitivity at clinically relevant specificity.							
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 16:26:52	32606311	A framework for on-implant spike sorting based on salient feature selection.	Shaeri M, Sodagar AM.	Nature Communications	2020	2020	10.1038/s41467-020-17031-9		COMMENT  --  Not Applicable (ML for wave-shape classification of brain-implant spike waves).																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 16:30:46	25823003	Hierarchical gene selection and genetic fuzzy system for cancer microarray data classification.	Nguyen T, Khosravi A, Creighton D, Nahavandi S.	PLoS One	2015	2015	10.1371/journal.pone.0120364		COMMENT  --  Not applicable (the applied ML protocol is a unsupervised/supervised hybrid).																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 16:33:36	28332994	Predicting Patient-specific Dosimetric Benefits of Proton Therapy for Skull-base Tumors Using a Geometric Knowledge-based Method.	Hall DC, Trofimov AV, Winey BA, Liebsch NJ, Paganetti H.	International Journal of Radiation Oncology Biology Physics	2017	2017	10.1016/j.ijrobp.2017.01.236		COMMENT  --  Not Applicable, in my opinion   (the paper appears to deal more with a statistical model, than with ML, even though the ML terminology is used throughout).																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 16:36:48	33583184	Introduction to Special Issue: Computational Toxicology.	Kleinstreuer NC, Tetko IV, Tong W.	Chemical Research in Toxicology	2021	2021	10.1021/acs.chemrestox.1c00032		COMMENT  --  Not applicable  (Editorial).																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 16:56:35	32711252	Blood speaks: Personalised medicine profiling for heart failure patients.	Firouzi F, Sussman MA.	 EBioMedicine	2020	2020	10.1016/j.ebiom.2020.102900		COMMENT  --  Not Applicable (Commentary)																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 17:19:51	28696170	Predicting Ascospore Release of Monilinia vaccinii-corymbosi of Blueberry with Machine Learning.	Harteveld DOC, Grant MR, Pscheidt JW, Peever TL.	Phytopathology	2017	2017	10.1094/phyto-04-17-0162-r		Total dataset composed of 535 in-field observations, N_pos = 84  (presence of spore-realising apothecia) and N_neg = 352 (absence of spore-realising apothecia).  Dataset not previously used.	The dataset was randomly split into training (70%) and testing (30%) using the ‚ÄúcreateDataPartition‚Äù function part of the caret package in R (version 3.2.4 for iOS).  Each model was trained with 10-fold cross-validation.    The random splitting of the data, model training, and assessment on the test set were performed 100 times to ascertain the variance of each model due to the random data splitting.	Not applicable.	No.	Four approaches were compared: logistic regression (LR), multivariate adaptive regression splines (MARS), artificial neural networks (ANN), random forest (RF). 	No.	Not reported.	For LR, MARS, RF, the authors do not mention parameters numbers different from standard.   For ANN, weights can be deduced to have been in the range of 100. Their number depended on the number of nodes in the hidden layer, which was optimized using 10-fold cross-validation and the AUROC curve for model assessment.	Exploratory data analyses resulted in removal of correlated predictors (¬±0.90).   In the end, 7 predictors were used (i.e. 7 types of environmental data -- air temperature, relative humidity, etc).  The ‚ÄúvarImp‚Äù function contained in the caret package was used to determine the relative predictor importance for each model. Each model was run using 3, 4, 5, 6, and 7 predictors. The most important variables were selected for the development of the final model.	Over-fitting in MARS and ANN was discussed and prevented.   In LR and RF, over-fitting should not have been an issue.  Possible underfitting was probabiy there for LR, which, with a kappa of 0.16, indicated a low degree of similarity, between observed and predicted, beyond random chance.	For MARS, the forward stepwise algorithm leads to an overfitted model which is then run through a backward stepwise algorithm where basis functions that contribute the least are removed (Friedman1991).   For RF,  to reduce overfitting, the tree was often pruned, resulting in a smaller tree with fewer splits. This was accomplished using the Gini index, which is a measure of variance across all classes‚Äîsmaller values mean a more accurate prediction at that node.		No statement about ante-hoc interpretability of the models is made by the authors.   LR and MARS are generally considered interpretable models, while ANN and RF are generally considered not interpretable.    Post-hoc feature importance analysis indicated as the most important ones soil moisture, precipitation, and air temperature (LR model), or soil temperature, soil moisture, and solar radiation (MARS, ANN, RF models) -- all of them in line with conclusions found in experimental literature.	Classification (binary prediction).  The continuous output of the LR, MARS, ANN was assigned as 'close to 1' or 'close to 0'.		 Standard algorithms were used. 	Cross-validation.		Four approaches were compared: LR, MARS, ANN, RF.  Model performance was compared based on the AUROC, kappa-metrics, and Brier score.  The best measures were those of RF.	Model performance was compared based on the AUROC, kappa metrics, and Brier score. The AUROC of the RF model was highest at 0.74, significantly higher than LR (with a value of 0.57) but not significantly different from the ANN or MARS models.   LR had a very low kappa value (0.16), while RF had kappa values between 0.43 and 0.57, higher than ANN and MARS values of between 0.35 and 0.5 and, therefore, has the best prediction potential among the four models tested in this study based on the kappa metric.	No.	No	Not reported.	Accuracy, sensitivity, specificity, AUROC.							
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 17:45:46	25175491	A three-gene panel that distinguishes benign from malignant thyroid nodules.	Zheng B, Liu J, Gu J, Lu Y, Zhang W, Li M, Lu H.	International Journal of Cancer	2015	2015	10.1002/ijc.29172		Source:   Four published datasets from the gene expression omnibus (GEO)  series  GSE29315, GSE33630,  GSE27155 and GSE3678.      N_pos=176 patients, N_neg=113 patients.   GSE29315 already used in (Finley et al, Ann Surg, 2004)  GSE27155 already used in (Giordano et al, Oncogene, 2005, and Giordano et al, Clin Cancer Res 2006).	Training set, GSE29315: N_pos_train=31, N_neg_train=40.         Testing sets, GSE33630: N_pos_test=60, N_neg_test=45.    GSE27155: N_pos_test=78, N_neg_test=21.  GSE3678:  N_pos_test=7, N_neg_test=7.    43.7% positives on training set,   57.1% positives on testing set GSE33630 ,  78.8% positives on testing set GSE27155,  50.0% positives on testing set GSE3678.	Not applicable.	Yes.  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE29315, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE33630, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE27155, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE3678   	Iterative Bayesian Model Averaging (BMA) algorithm.	No.	Not reported.	The authors do not mention parameters numbers different from standard. 	f=3.   The feature selection method to distinguish benign from malignant samples consisted of two steps: a LIMMA linear model, and an iterative BMA algorithm.   The R package LIMMA was used  to  select  significantly  differentially  expressed  genes (fold-change cutoff of >=2 and a p-value<0.01). To minimize the number of signature genes, the iterative BMA R package was applied, which accounts for model uncertainty and the dependency between signature genes.    The BMA step was applied to further reduce the number of signature genes from 43 to 3, and thus the costs associated with microarrays and time-consuming data analysis.	 Over- or under- fit could probably be excluded a posteriori by the good predictive performance in independent test sets and novel experiments. 	No.		No statement about ante-hoc interpretability of the model is made by the authors.   The model looks to me black box.   Post-hoc interpretability for the ipeptidylprolyl peptidase 4 (DPP4) gene is supported e.g. by literature reports that this gene significant increases in differentiated carcinomas vs. normal or benign thyroid nodules at average 46 times.   However, the low univariate rankings of 2 of the 3 genes indicated that it was the genes combination, that resulted in good predictive power, and no attempt was made to explain such joint effect.	Binary classification between benign and malignant thyroid tumors.		Publicly available R packages.	Independent datasets and novel experiment.     Independent dataset: GSE33630,  GSE27155 and GSE3678.   Novel experiment:   Thyroid tissue specimens excised intraoperatively from 70 patients undergoing primary thyroidectomies in Renji Hospital		Despite the small number of genes in the panel, the ability to predict different categories of thyroid nodules was similar to that of published data from over 100 genes.	Confidence Intervals are reported, by which a performance similarity between the 3 genes panel and the 100 genes panel is claimed.	No.	No.	Not reported.	Sensitivity, specificity, accuracy.							
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 17:48:29	30822279	Age-dependent co-dependency structure of biomarkers in the general population of the United States.	Le Goallec A, Patel CJ.	Aging	2019	2019	10.18632/aging.101842		COMMENT  --  Not Applicable, in my opinion.  An elastic net algorithm is used just to produce a measure of predictability (coefficient of determination, R-squared) for 50 biomarkers as a function of patient's age.																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 17:51:20	33497380	Dysregulation of excitatory neural firing replicates physiological and functional changes in aging visual cortex.	Talyansky S, Brinkman BAW.	PLoS Computational Biology	2021	2021	10.1371/journal.pcbi.1008620		COMMENT  --  Not Applicable (parameters are changed in a computational model, simulating a network of firing neurons, with the aim of qualitatively reproducing the loss of physiological functions observed in real neuronal tissues with aging).																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 17:53:58	32437685	Lattice Light-Sheet Microscopy Multi-dimensional Analyses (LaMDA) of T-Cell Receptor Dynamics Predict T-Cell Signaling States.	Rosenberg J, Cao G, Borja-Prieto F, Huang J.	Cell Systems	2020	2020	10.1016/j.cels.2020.04.006		COMMENT  --  Not Applicable, in my opinion.  ML in applied to 4D image processing.																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 17:58:08	24895853	Structural bioinformatics of the interactome.	Petrey D, Honig B.	 Annual Review of Biophysics	2014	2014	10.1146/annurev-biophys-051013-022726		Not Applicable  (Review)																														
paola.turina@unibo.it	65faa4f792c76639b82bab29	5/20/2022 18:00:21	28678787	Classification and analysis of a large collection of in vivo bioassay descriptions.	Zwierzyna M, Overington JP.	PLoS Computational Biology	2017	2017	10.1371/journal.pcbi.1005641		COMMENT  --  Not Applicable (ML in text-mining).																														
patrick.ruch@hesge.ch	6312169df3794236aa987a36	1/28/2022 0:13:56	16524483	Machine learning approaches to supporting the identification of photoreceptor-enriched genes based on expression data.	Wang H, Zheng H, Simpson D, Azuaje F.	 BMC Bioinformatics  .	2006	2006	10.1186/1471-2105-7-116		Yes,  Prof. Connie Cepko at Harvard Medical School, claimed publicly available	Yes	Yes, cross-validation	Yes but need to contact the authors apparently	KStar (K-NN ?), Not novel, Multilayer perceptron, C4.5	No	Gene expression data	Depends on algorithms tested.	No feature selection.		None.		Black box	Classification		Weka	Cross validation		KStar, comparison vs. MLP, C4.5	Yes	Yes.	No	No	Rappel/Precision, AUR							
patrick.ruch@hesge.ch	6312169df3794236aa987a36	1/31/2022 8:45:48	28678787	Classification and analysis of a large collection of in vivo bioassay descriptions.	Zwierzyna M, Overington JP.	 PLoS Comput Biol  .	2017	2017	10.1371/journal.pcbi.1005641		Yes, CheMBL	Yes	Yes	Yes	Word2Vec + Random Forest	No	Doc2Vec	No	Word2Vec	No	No		Black box	Multiclass Multilabel Classification		Soft available separately.	Cross-validation		No	No	Yes	No	No	precision, recall, F1-score							
patrick.ruch@hesge.ch	6312169df3794236aa987a36	3/8/2022 10:24:58	28624633	From flamingo dance to (desirable) drug discovery: a nature-inspired approach.	S√°nchez-Rodr√≠guez A, P√©rez-Castillo Y, Sch√ºrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M.	Drug Discov Today. 	2017	2017	10.1016/j.drudis.2017.05.008		Yes	Yes	Yes	Yes	SVM with RBF kernel	No	QSAR	No	Yes, SMILES Chem structures with 250 fragments selected by MI		Yes - intrinsic to SVM		Black box but voting schema is applied	Classification		Yes	Cross validation		Local baseline	Yes	Yes	Yes	No	AUR							
patrick.ruch@hesge.ch	6312169df3794236aa987a36	3/8/2022 10:53:29	26495028	KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.	Rodr√≠guez-Escobedo JG, Garc√≠a-Sep√∫lveda CA, Cuevas-Tello JC.	 Comput Math Methods Med	2015	2015	10.1155/2015/141363		Yes	Control & clinical sets (300 healthy individuals and 43 patients)	Yes	No	Decision tree (C4.5)	No	Unclear		Unclear				Black box (~large decision-tree)	Statistical analysis: association between features and disease		Yes			No	Yes	No	Yes	Partially	P-value of association							
patrick.ruch@hesge.ch	6312169df3794236aa987a36	3/30/2022 16:46:29	31148311	Machine learning identifies unaffected first-degree relatives with functional network patterns and cognitive impairment similar to those of schizophrenia patients.	Jing R, Li P, Ding Z, Lin X, Zhao R, Shi L, Yan H, Liao J, Zhuo C, Lu L, Fan Y.	Hum Brain Mapp	2019	2019	10.1002/hbm.24678		 distinguish 32 patients from 30 healthy control	 distinguish 32 patients from 30 healthy control	Independance	?	SVM	No	Yes, e.g. voxel resolution	Yes	Yes	No	No		Black box	Binary classification		No	Cross validation		No	No	No	No	No	ROC curve							
patrick.ruch@hesge.ch	6312169df3794236aa987a36	3/30/2022 16:22:15	27127534	The Virtual Screening of the Drug Protein with a Few Crystal Structures Based on the Adaboost-SVM.	Wang MY, Li P, Qiao PL.	 Comput Math Methods Med	2016	2016	10.1155/2016/4809831		PDB	100 pos, 2000 neg	Independence	Yes	Ensemble, incl. Adaboost Random Forrest, and SVM	No	Compounds	Protocol is clear	No	Class imbalance is compensated	No but kernel: RBF		Black box	Binary classification but evaluated a ranker: ROC		No	Cross validation				Yes	No	Yes	ROC curve							
pierluigi.martelli@unibo.it	6312169df3794236aa9879fe	3/6/2022 17:08:06	26068103	A Ranking Approach to Genomic Selection.	Blondel M, Onogi A, Iwata H, Ueda N.	Plos ONE	2015	2015	10.1371/journal.pone.0128570		Arabidopsis: 417 lines, 3 traits, 69 Simple Sequence Repeats, External dataset Barley: 381 lines, 3945 SNPs, External dataset Maize: 264 lines, 1076 SNPs, External dataset Rice: 383 lines, 34 traits, 1311 SNPs, External dataset Wheat (CIMMYT): 599 lines, 4 evironments, 1279 markers, External dataset Wheat (P√©rez-Rodr√¨guez): 306 lines, 2 traits, 1695 markers, External dataset	Regression problem (no positive/negative examples). 10 fold cross-validation	Random split among cross-validation sets. No similarity threshold applied.	Partially available: primary data available from external sources. Processed input data are unavailable (after filtering, missing data imputation and consistency check). External dataset: Arabidopsis: http://publiclines.versailles.inra.fr/page/33 Barley: http://triticeaetoolbox.org Maize and Wheat (P√©rez-Rodr√¨guez) : https://www.uni-giessen.de/fbz/fb09/institute/pflbz2/population-genetics/downloads (No longer available) Rice: http://www.ricediversity.org/data/index.cfm Wheat (CIMMYT): part of the R package BLR (https://cran.r-project.org/web/packages/BLR/index.html)	Regression methods: Ridge, RKHS, Bayesian methods, Random Forests. Ranking based regression methods: McRank (poinwise, multiclass, ordinal), RankSVM, LambdaMART.	No	Genotype: 0/1 for each marker, SNP or repeat.	Unclear	69 to 3945 depending on the set. Random feature selection (60%) for random forests	in this problem n_data << p	Small learning rate adopted		scarcely interpretable	regression-ranking		External softwares are adopted	Cross-validation		Different methods are compared: reproducing kernel Hilbert space regression, Stochastic search variable selection, Bayesian mixture regression model, Random forests, LambdaMART, Bayesian lasso, Ordinal McRank, BayesC, RankSVM, Gradient boosted regression trees, Extended Bayesian lasso, Weighted Bayesian shrinkage regression, Ridge	No confidence interval provided	No	No		Pearson's correlation, Kendall's correlation, normalized discounted cumulative gain (new index introduced in the paper)							
pierluigi.martelli@unibo.it	6312169df3794236aa9879fe	3/6/2022 18:09:45	33953201	CopulaNet: Learning residue co-evolution directly from multiple sequence alignment for protein structure prediction.	Ju F, Zhu J, Shao B, Kong L, Liu TY, Zheng WM, Bu D.	Nature Communications	2021	2021	10.1038/s41467-021-22869-8		PDB, CATH, CASP13.  31,247 non-redundant domains + 104 domains from CASP13 (test). The number of contacts (positive) and non contacts (negative) is not reported	Training: 29,247 domains; Validation: 1,820 domains; Test: 104 domains. Number of positive and negative not reported.	Training/Validation: 35% sequence similarity cluster representatives of CATH (Mar 16, 2018). Test set released after 2018. Similarity with Training/Validation unclear	Yes, but the server is not working: http://protein.ict.ac.cn/ProFOLD	Deep neural network, end-to-end learning	No	Multiple sequence alignment	6.46 M to 16.46 M parameters. Performance evaluated on the validation set.	Given the MSA, for each pair target-homologous sequences, each position is encoded with a 41-valued vector. Total encoding = Sequence length x Number of homologous sequences in MSA (Max 1000) x 41. No feature selection applied.	MSA sampling and distance matrix cropping in training process is adopted to avoid potential overfitting as well	Not mentioned		Black box	classification (interresidue contacts) and regression (interresidue distance)		https://github.com/fusong-ju/ProFOLD	Independent test set 		RaptorX, AlphaFold, trRosetta	No confidence intervals nor statistical significance reported	No	The overall architecture is available in supporting information and released in github (https://github.com/fusong-ju/ProFOLD). Webserver is indicated but not functional (http://protein.ict.ac.cn/ProFOLD)		Precision of contact predictions at different thresholds							
pierluigi.martelli@unibo.it	6312169df3794236aa9879fe	3/6/2022 19:15:35	30388153	Predicting bacterial growth conditions from mRNA and protein abundances.	Caglar MU, Hockenberry AJ, Wilke CO.	Plos ONE	2018	2018	10.1371/journal.pone.0206634		Previous publication: 155 E. coli samples (102 have both mRNA and protein abundance data; 50 have only mRNA abundance data; 3 have only protein abundance data).  External validation performed on 5 samples from a different publication.	Diffent conditions are considered: carbon sources (glucose, glycerol, gluconate, and lactate),  sodium concentrations (base and high), and magnesium concentrations (low, base, and high). Different splits are therefore adopted. Splitting: training/validation set:test set=80:20. Training:validation=75:25 (x 10 independent runs). Semi-random split preserving the ratios of different conditions between the training/validation and the test subsets. 	No measure of independence provided	All processed data are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)	SVM	No	level of transcripts/proteins expression	Kernel selected with a grid search and performance evaluation on the validation set	Number of transcripts/proteins in E.coli unspecified. Feature selection performed on training data with PCA: 10 features retained	f = 10, N_train ‚âà 90 - Low dimensional SVM	No		Black box	classification		Allanalysis scripts are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)	Independent test set + externa test set		Different kernels are used. Random forests are used.	Distributions over the samples are reported, but no statistical evaluation is computed.	no	All analysis scripts are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)		F1 score							
pierluigi.martelli@unibo.it	6312169df3794236aa9879fe	3/13/2022 11:00:59	31362694	IRESpy: an XGBoost model for prediction of internal ribosome entry sites.	Wang J, Gribskov M.	BMC Bioinformatics	2019	2019	10.1186/s12859-019-2999-7		Training dataset (dataset 2): high throughput experimental data (doi: 10.1126/science.aad4939), filtered and annotated as in (doi:10.1371/journal.pcbi.1005734) describing an available predictor.  20872 examples: 2129 positive, 18743 negative. Testing dataset (dataset 1): low throughput experimental data extracted from a public database (https://doi. org/10.1093/nar/gkp981). 167 examples: 116 positive, 51 negative.	Random split of dataset 2 in 90% training and 10% testing.	Random split. Overall similarity in the dataset 2 was checked: 7.56% sequences have more than 80% identity, 15.3% sequences have more than 50% identity, and 17.02% sequences have more than 30% identity. There are no sequences with 100% identity- Similarity between dataset 1 and dataset 2 is not reported.	Bitbucket available (https://bitbucket.org/alexeyg-com/irespredictor/src). Datasets non clearly labelled	XGBoost	No	340 global kmer features + 5440 local kmer features	The final model includes 1281 individual trees and each tree incorporates 340 features. The maximum depth of each tree is set to be 6	The final model includes 1281 individual trees and each tree incorporates 340 features. Features selected by XGBoost feature importance	not provided	No		Feature interpreted by XGBoost feature importance	Classification		Model available on bitbucket (https://bitbucket.org/alexeyg-com/irespredictor/src/v2/)	Independent set		Compared with IRESpred	Not provided	No	Hyperparameter values reported in the paper. Model available in bitbucket (https://bitbucket.org/alexeyg-com/irespredictor/src/v2/)	Not provided 	Accuracy, sensitivity, specificity, precision, Matthews correlation							
piero.fariselli@unito.it	6312169df3794236aa987a0a	2/2/2022 10:53:38	34372798	Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.	Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ.	BMC Cancer	2021	2021	10.1186/s12885-021-08647-1		Downloaded from public sources	Train set of 134 samples, test of 45 samples, and a validation sets consisting of 86 samples. No mention to N_pos or N_neg.	No similarity check	No. However, raw data can be downloaded  as data sets can be of GSE53625 from GEO (https://www.ncbi.nlm.nih.gov/geo/) and 37 ESCC cases with Asian ancestry from TCGA (UCSC Xena, https://xena.ucsc.edu/).	Generalized Linear models, SVM, NN, Random Forests and XGBoost,	No	Normalization according to an external reference Gut. 2014;63(11):1700‚Äì10. https://doi.org/10.1136/gutjnl-2013-305806.	No description	No description	No description	No		Linear models and ensemble methods	both regression and classification		No	one training set, one test set and one validation set.		No comparison	Unpaired or paired Student t-test and log-rank tests for Kaplan-Meier	No	No	No description	ROC-AUC							
ptrck.rch@gmail.com	6312169df3794236aa9879f4	2/2/2022 10:08:47	28624633	From flamingo dance to (desirable) drug discovery: a nature-inspired approach.	S√°nchez-Rodr√≠guez A, P√©rez-Castillo Y, Sch√ºrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M.	 Drug discovery today	2017	2017	10.1016/j.drudis.2017.05.008		Yes (ChEMBL-NTD Novartis dataset and dataset from previous publication)	Yes: N_pos and N_neg for training, test and external test sets	Yes, independent training, test and external test sets generated using sphere exclusion algorithms	Yes, in supporting information	LSSVM	Yes: model aggregation (ensemble modeling) and multi-criteria decision making Trained on the same dataset	Fragments of atoms and bonds (ISIDA Fragmentor software) scaled to the interval [0-1]	2 LSSVM parameters (RBF kernel (œÉ2) and regularization (Œ≥))  Minimization of the misclassification rate of the 10-fold cross-validated training dataset	Yes: 5-25 features per model, randomly selected among 250 most informative on training dataset (removal of features returning nearly constant values (about for 99%) and selection of top-250 according to Mutual Information Quotient score (Minimal Redundancy Maximal Relevance mRMR algorithm))	No	Yes: Œ≥ parameter (LSSVM) 		Black box	Classification and score based on LSSVM scores		No	Independent dataset		No	No	No	No	No	Accuracy (Acc), Sensitivity (Se), Specificity (Sp) and Balanced Classification Rate (BCR) Area Under the Accumulation Curve (AUAC); Area under the Receiver Operating Characteristic Curve (ROC); Enrichment factor (EF) and Boltzmann-enhanced discrimination of ROC (BEDROC)							
ptrck.rch@gmail.com	6312169df3794236aa9879f4	2/8/2022 15:10:18	26495028	KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.	Rodr√≠guez-Escobedo JG, Garc√≠a-Sep√∫lveda CA, Cuevas-Tello JC.	Comput Math Methods Med	2015	2015	10.1155/2015/141363		Yes (Mexican Reference Genomic DNA Collection (MGDC-REF) ). Source of data and number of positives and negatives given, negative dataset was used by a previous paper.	Yes: number of N_pos and N_neg No data splits. Only training set	No, only training set	No	‚ÄúA priori‚Äù algorithm	No	Yes: Presence/absence of genes	2 parameters (minimum support threshold and confidence levels)	Yes (13 features)	No exclusion	No		Transparent: 24 most frequent rules generated by the apriori algorithm are detailed	Binary prediction (statistical classifier)		Yes (URL http://www.cs.waikato.ac.nz/~ml/weka/index.html)	Evaluation on the training dataset		Univariate statistical analysis (Fishers‚Äô exact test) and decision tree classifier (J48 ID3)	Chi-squared test p-value comparison	Yes: confusion matrix in publication	No	No	chi-squared test							
ptrck.rch@gmail.com	6312169df3794236aa9879f4	2/8/2022 16:25:04	30295871	Multi-omic and multi-view clustering algorithms: review and cancer benchmark.	Rappoport N, Shamir R.	Nucleic Acids Res	2018	2018	10.1093/nar/gky889		Yes (The Cancer Genome Atlas)	No dataset split  (unsupervised machine learning) Labels used to assess performance are given in raw datasets	No dataset split  (unsupervised machine learning)	Yes (supporting information and website URL)	Multi-view clustering methods (early and late integration, similarity based, dimension reduction and statistical methods)	No	No, not in detail. Class of feature used are described (gene sequence, expression and methylation) but no detail on encoding (only reference to source of data)	Number of clusters: algorithm for selection is presented (elbow method)  Other parameters are not directly given but protocol used to select them are given (= if available: adherence to the guidelines given by the packages developers) 	Yes, indirectly: processed raw data and algorithm for feature selection are given	No exclusion mentioned	Yes, regularization may be used by some methods (but not clear in the publication what was really implemented in the used packages) e.g. Least Absolute Shrinkage and Selection Operator regularization is used by iCluster Nuclear norm regularization is used by LRACluster A regularization term is used by rMKL-LPP Sparsity regularization is used by Canonical Correlation Analysis (CCA)		Black box	Produces clusters		Yes (GitHub)	Extrinsic measures (clinical labels)		Comparison of logranks‚Äô test p-values and number of enriched clinical parameters	No. But no claiming of performance difference	Yes (supporting information)	No	Yes (runtime in seconds on Windows desktop for eight methods and Linux cluster for one methods)	Logrank test (differential survival between clusters) Chi-squared test and Kruskal-Wallis (clinical labels (six) enrichement in clusters)							
ptrck.rch@gmail.com	6312169df3794236aa9879f4	2/8/2022 16:40:46	32850117	Recent advances in phenotypic drug discovery.	Swinney DC, Lee JA.	F1000Research	2020	2020	10.12688/f1000research.25813.1		NA (review)																														
ptrck.rch@gmail.com	6312169df3794236aa9879f4	2/9/2022 14:43:24	33126851	m5CPred-SVM: a novel method for predicting m5C sites of RNA.	Chen X, Xiong Y, Liu Y, Chen Y, Bi S, Zhu X.	BMC Bioinformatics	2020	2020	10.1186/s12859-020-03828-4		Yes: source of data. Used by previous papers.	Yes: size of training, validation and test sets as well as distribution of N_pos and N_neg are given.	Yes: procedure to remove sequences with similarity >70% is applied in negative and positive datasets	Yes, supposedly. Datasets are supposed to be available through URL (https://zhulab.ahu.edu.cn/m5CPred-SVM/) but link does not respond	SVM (FITCSVM)	No	Yes: specific sequence features (k-nucleotide frequency (KNF), k-spaced nucleotide pair frequency (KSNPF), position-specific nucleotide propensity (PSNP), k-spaced position-specific dinucleotide propensity (KSPSDP), pseudo dinucleotide composition (PseDNC), Chemical property with density (CPD)) 	Yes: 2 (box constraint and kernel scale) Selected through grid search on ten-fold cross-validation dataset	Yes: number of features and feature selection on the ten-fold cross-validation dataset using sequential forward feature selection (SFS)	No exclusion mentioned	Yes (sequential forward feature selection (SFS) to reduce redundant features)		Transparent at the level of the feature selection (evaluation results for different combinations of features), put in connection with mean sequence difference between positive and negative sets	Classification		Website URL (but link is broken)	Independent test set		Comparison of SVM with other classifiers (KNN, Adaboost, random forests, decision tree, logistic regression and XGBoost) on the same cross-validation dataset. Comparison of their best method (SVM) with five other existing methods with webserver availability (RNAm5Cfinder, iRNA-m5C, iRNAm5C-PseDNC and RNAm5Cpred, PEA-m5C). Table presenting algorithm class and features used by these methods is presented.	List of so-called ‚Äúsignificantly higher‚Äú performance metric values in favor of their method, but without confidence interval or explicit p-values or even name of test performed. 	No	No. URL given for model availability but link is broken (not sure what exact information was available in the URL)	No	Accuracy, sensitivity, specificity, precision, Matthews correlation coefficient and F1-score. Area under ROC and PRC							
ptrck.rch@gmail.com	6312169df3794236aa9879f4	3/18/2022 15:31:10	33953534	Computational Methods for Structure-to-Function Analysis of Diet-Derived Catechins-Mediated Targeting of In Vitro Vasculogenic Mimicry.	Uthamacumaran A, Suarez NG, Banir√© Diallo A, Annabi B.	Cancer Informatics	2021	2021	10.1177/11769351211009229		Yes: dataset generated by own experiment	~Yes but not very clear: 12 pos and 12 neg images, duplicated (image divided into four quadrant)->48 images pos and 48 images neg. divided: 80% cross-validation training set and 20% testing set.	No	No	Yes: SVM	No	Yes: images features (fractal dimension, 2D wavelet coefficients, percolation score)	No	No	No	No		~Yes: comparison between different features	Regression		No	independent dataset		No	No	No	No	No	Yes: accuracy = R-square and RMSE							
ptrck.rch@gmail.com	6312169df3794236aa9879f4	3/18/2022 11:23:23	33126851	m5CPred-SVM: a novel method for predicting m5C sites of RNA.	Chen X, Xiong Y, Liu Y, Chen Y, Bi S, Zhu X.	BMC Bioinformatics	2020	2020	10.1186/s12859-020-03828-4		Yes: used by previous papers. N_pos and N_neg are given.	Yes: Size of N_pos and N_neg for training and test sets.	Yes: random selection with redundancy removal in pos and neg sets (>70% sequence identity CD-HIT)	Yes: Supp data of referenced publication,  and GEO query	Yes: SVM (compared to KNN, adaboost, random forest, decision tree, logistic regression and XGBoost)	No	Yes: sequence features (KNF/NC, KSNPF, PSNP, KSPSDP, PseDNC, CPD)	Yes: box constraint and kernel scale, optimised by a grid search	Yes: 6 f. Wrapper method (sequence forward selection). ten-fold cross-validation on training dataset.	No	Yes:  box constraint parameter		~Yes: Results for different feature selections	Classification		No. Link to project (https://zhulab.ahu.edu.cn/m5CPred-SVM/) is broken	independent datasets		Yes: RNAm5Cfinder, iRNA-m5C, iRNAm5C-PseDNC, RNAm5CPred, PEA-m5C	No. Justification based only on evaluation values difference (acc, sn, sp, pre, mcc, f1, AUROC)	No	No	No	 accuracy, sensitivity, specificity, precision, Matthews correlation coefficient and F1-score, AUROC							
ptrck.rch@gmail.com	6312169df3794236aa9879f4	3/18/2022 15:33:59	33194817	Multiomics Study of Gut Bacteria and Host Metabolism in Irritable Bowel Syndrome and Depression Patients.	Xu C, Jia Q, Zhang L, Wang Z, Zhu S, Wang X, Liu Y, Li M, Zhang J, Wang X, Zhang J, Sun Q, Wang K, Zhu H, Duan L.	Front Cell Infect Microbiol.	2020	2020	10.3389/fcimb.2020.580980		NA: No machine learning																														
ptrck.rch@gmail.com	6312169df3794236aa9879f4	3/18/2022 14:48:58	31137222	Identification of hormone binding proteins based on machine learning methods.	Tan JX, Li SH, Zhang ZM, Chen CX, Chen W, Tang H, Lin H.	Mathematical Biosciences and Engineering	2019	2019	10.3934/mbe.2019123		Yes: previous paper	Yes, size of training and test set, including distribution N_pos N_neg	Yes: exclusion of identical sequences between testing and training datasets. Reduced redundancy within testing dataset (sequence identity >60% CD-HIT).	Yes: website url (http://lin-group.cn/server/HBPred2.0/download.html)	Yes: SVM	No	Yes: sequence features (NVM, g-gap, TPC) and composition properties (CTD, pseAAC) 	Yes: parameters C and g, optimised by grid search space	Yes: 5 types of features (NVM, g-gap, TPC, CTD, pseAAC). Feature selection using ANOVA for g-gap and pseAAC, binomial distribution for TPC and Incremental feature selection. and size of vectors (21, 60, 81, 400, 8000 depending on the feature extraction method...)	No	Yes: Parameter C, optimised by grid search space		Black box	Classification		No, only a prediction web service	Yes: on 5-fold training dataset and also on independent dataset		Yes: Comparison with other classifiers: J48, Bagging, Random Forest, Naive Bayes Comparison with other published methods: HBPred, iGHBP, HBPred2.0	No: only comparing difference between performance measures 	No	No	No	Yes: Sensitivity, Specificity, Accuracy, Matthew correlation coefficient, AUC							
sermarcue@gmail.com	6312169df3794236aa9879e7	3/29/2022 22:22:24	34229736	Machine learning model for identifying important clinical features for predicting remission in patients with rheumatoid arthritis treated with biologics.	Koo BS, Eun S, Shin K, Yoon H, Hong C, Kim DH, Hong S, Kim YG, Lee CK, Yoo B, Oh JS.	Arthritis Research & Therapy	2021	2021	10.1186/s13075-021-02567-y		This study used data from the KOBIO registry, which is a nationwide multicenter cohort in Korea that was established to evaluate the effectiveness and side effects of biologic therapies in patients with RA [13]. Patients in the registry were recruited from 38 hospitals since 2012, and their demographics, medications, comorbidities, extra-articular manifestations, disease activities, radiographic findings, and laboratory findings performed within 4 weeks prior to the patient‚Äôs visit were recorded with the date. The data from patients who were followed up annually were recorded on the KOBIO website (http://www.kobio.or.kr/kobio/), and these patients provided informed consent prior to registration. Ethical approval of the KOBIO-RA was obtained from the institutional review boards of all 38 participating institutions, including the Institutional Review Board of Inje University Seoul Paik Hospital (PAIK 2018-11-005).	 the training and test sets were divided in a 7:3 ratio, and the models were trained with the training set		Yes, Data are available from the Clinical Research Committee of KOBIO under the Korean College of Rheumatology for researchers who meet the criteria for access to confidential data	the models included lasso and ridge based on linear relationships [14], support vector machine using kernel methods [15], tree-based random forest [16], and Xgboost	no	Dimension reduction was performed to avoid the ‚Äúcurse of dimensionality‚Äù caused by a large number of variables compared with the size of the data. 	a grid search was conducted to evaluate all possible combinations of the hyperparameters. The grid search found optimal hyperparameters with the objective function of determining the area under the receiver operating characteristics (AUROC) in each model	Among the 64 variables, we selected variables that are frequently encountered in clinical practice for prescription of biologics and excluded variables that are not referenced when prescribing biologics. As a result, 15 variables known to be of clinical importance were preselected (i.e., sex, age, baseline DAS28-ESR, methotrexate dose, steroid dose, erythrocyte sedimentation rate [ESR], C-reactive protein [CRP], rheumatoid factor [RF], anti-cyclic citrullinated peptide antibody [ACPA], anti-nuclear antibody [ANA], and five comorbidities). Subsequently, 20 variables that were highly correlated with the drug response (remission) of each bDMARD were selected. After selecting variables based on data, we created a prediction model by training with a fixed set of 35 variables. Missing data for variables (Additional file: Table S3) were replaced with the median value for each variable. With a similar logic, binary variables such as comorbidities were coded as 1 if ‚Äúyes‚Äù and 0 if ‚Äúno‚Äù or ‚Äúno test‚Äù because ‚Äúno‚Äù was the most common value.	To avoid overfitting problems, the training and test sets were divided in a 7:3 ratio, and the models were trained with the training set; then, the prediction results were verified using the test set. For the training dataset, a 5-fold cross validation was performed to tune the hyperparameters determined as outside models (Additional file: Table S1 and Table S2). In this procedure, a grid search was conducted to evaluate all possible combinations of the hyperparameters. The grid search found optimal hyperparameters with the objective function of determining the area under the receiver operating characteristics (AUROC) in each model. Bootstrapping (random sampling with replacement) was also performed to obtain a median value for the AUROC curve and to determine the accuracy for reducing measurement variances caused by small samples when dividing between the training and test sets.	no		transparent	classification		na	CV		The no information rate, which is the largest proportion of the observed classes, was used as a baseline to determine the overall distribution of the classification and to compare with those of the machine learning models	na	no	yes, SI	na	Bootstrapping (random sampling with replacement) was also performed to obtain a median value for the AUROC curve and to determine the accuracy for reducing measurement variances caused by small samples when dividing between the training and test sets.							
sermarcue@gmail.com	6312169df3794236aa9879e7	3/29/2022 7:28:13	32286325	Computational analysis of pathological images enables a better diagnosis of TFE3 Xp11.2 translocation renal cell carcinoma.	Cheng J, Han Z, Mehra R, Shao W, Cheng M, Feng Q, Ni D, Huang K, Cheng L, Zhang J.	Nature Communications	2020	2020	10.1038/s41467-020-15671-5		The quantitative image features extracted from H&E stained whole-slide images are available from GitHub. No access to raw data provided			yes, processed, not raw	Logistic regression, SVM with linear or Gaussian kernels, and random forest were used to conduct supervised machine learning	no			Due to the high dimensionality of the image features and relatively small sample size, overfitting of the data is likely; therefore, before building classification models, we performed feature selection to avoid the overfitting problem. Feature dimensionality was reduced by the mRMR algorithm42 using R package mRMRe. mRMR has been shown to be a robust feature selection algorithm in various tasks43,44,45. The mRMR algorithm was applied to all image features with regard to the class label of sample (i.e., TFE3-RCC or ccRCC) to select an informative and non-redundant set of features.	See Features	Yes, see Features		transparent	classification		https://github.com/chengjun583/tRCC-ccRCC-classification	In dataset 1, five-fold cross-validation was used. To further validate our method using an external validation set, classification models were trained using dataset 1 and evaluated using dataset 2					no		AUC and confidence intervals were computed with the R package pROC.							
sermarcue@gmail.com	6312169df3794236aa9879e7	3/28/2022 23:21:09	30008861	Cross talk of chromosome instability, CpG island methylator phenotype and mismatch repair in colorectal cancer.	Zhang TM, Huang T, Wang RF.	Oncology Letters	2018	2018	10.3892/ol.2018.8860		GEO GSE39582	Within the 585 colon patients, there were 369 CIN+ and 112 CIN-, 93 CIMP+ and 420 CIMP-, 77 dMMR and 459 pMMR		yes, GEO GSE39582	SVM	no	The probes corresponding to the same gene were averaged. The gene expression data was preprocessed with quantile normalization				no		transparent, listed in the The CIN-associated gene selection section in Methods	classification		na	na		na	na	yes, Figure 1	no	na	Accuracy, sensitivity, specificity, mcc							
sermarcue@gmail.com	6312169df3794236aa9879e7	3/28/2022 23:06:53	25404408	What do all the (human) micro-RNAs do?	Ultsch A, L√∂tsch J.	BMC Genomics	2014	2014	10.1186/1471-2164-15-976		Dataset links provided in Table 1	Some details provided in Additional information		Yes, website URL	TargetScan - non-ML algorithm	No		params provided in additional info			No		black box	probability score		https://www.targetscan.org/vert_80/					no	no									
sfragkoul@certh.gr	6312169df3794236aa987a1b	1/18/2022 17:50:21	32933477	Seagull: lasso, group lasso and sparse-group lasso regularization for linear regression models via proximal gradient descent.	Klosa J, Simon N, Westermark PO, Liebscher V, Wittenburg D.	BMC Bioinformatics	2020	2020	10.1186/s12859-020-03725-w		The data set is publicly available and described in detail in https://doi.org/10.1016/j.cmet.2017.03.016  141 data points, problem of regression for predicting chronological age of mice based on their methylation profiles.	training (n = 75) and validation(n = 66)	Œëll age classes appeared almost equally in both sets.	Yes. https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE80672	accelerated generalized gradient descent. 	No	SVD for groups' separation	p=6. penalty parameter Œª,  Œ± ‚àà [0, 1] is the mixing parameter which convexly links the penalties, Œµ_rel relative accuracy,  groups from SVD, weights for each explanatory variable, proportion Œæ Œªmin = ŒæŒªmax.	Not applicable	No	Yes. Regularization paths for the lasso, group lasso, sparse-group lasso, and IPF-lasso for linear regression models		transparent. 	regression of methylation age of mice. Eventually, seagull provides a sequence of penalty parameters and calculates the corresponding path of solutions.		yes in Additional files and https://github.com/jklosa/seagull	independent dataset		comparison of the outcome of seagull to that of the established R package SGL 1.3	the results of seagull and SGL were very similar (R^2 > 0.99)	No	no	20'-5h compared to 45h of previous methods	MSE of predicted age based on methylation data, squared correlation coefficient R^2 between predicted and chronological age, the number of features with an estimated effect different from zero, the execution time needed to compute the entire regularization path.							
sfragkoul@certh.gr	6312169df3794236aa987a1b	1/26/2022 11:27:05	27362985	Detecting Pairwise Interactive Effects of Continuous Random Variables for Biomarker Identification with Small Sample Size.	Adl AA, Lee HS, Qian X.	IEEE/ACM Trans Comput Biol Bioinform .	2017	2017	10.1109/tcbb.2016.2586042		1) We simulate random datasets by extending a casecontrol model adopted in https://doi.org/10.1186/1752-0509-2-10, for evaluation of all methods. 2)USA dataset for breast cancer metastasis	1) Randomly assignment of outcome variable y uniformly distributed in {0, 1}. Generation of input variables: random generation of 50 input variables, randomly select six of them to simulate the individual effects and another six distinct pairs of other variables from all 1, 225 possible variable pairs to simulate significant interactive effects on disease outcome y. Creation of 1,000 datasets for each one of the following sample sizes: 20, 40, 60, 80, 100, 120, and 140. 2) USA(train): n=286, 107 metastasis cases Netherlands(test): n=295, 79  metastasis cases	1) Simulation of three different types of interaction patterns between two interacting variables xi, xj and the outcome y: ‚Äúsimple‚Äù, ‚Äúcomplex‚Äù, and ‚Äúvery complex‚Äù. Among six pairs of interacting variables, simulation of the data by including two pairs of each pattern. Depending on the outcome then they assigned a value drawn from an equally weighted Mixture-of-Gaussian with various Gaussian components for each pattern case. 2) not applicable	1) No 2) No	1) various methods for classification and clustering. Both supervised and unsupervised. 2) first network-based feature ranking method for selection of top genes, then SVM for classification	1) yes. Some in similar ways. Some other vary from unsupervised to supervised learning. 2) No	1) Not applicable 2) Not applicable	1) based on the complexity of each pattern 2) p=2, with complexity parameter C = 100 and RBF kernel with œÉ = 1	1)50 and 200 input variables. 2) 6,168 genes as input features for network-based feature ranking method, and then top T (1,5,10...,50)	1) average over a wide range of K to avoid overfitting for KNN-based methods 2) Not applicable	1) No 2) No		1) transparent since results are based on statistics. 2) transparent since results are based on statistics.	1) regression 2) classification 		1)No 2) No	1) Not applicable 2) 10-fold cross-validation and independent Dataset		1) LASSO. The performance of LASSO is worse than all the other non-linear methods when we have relatively small numbers of samples. 2) Not applicable	1)All the measurements are based on the statistics estimated from data. 2) p-values	1) No 2) No	1) No 2) No	1) a few seconds 2) not applicable	1) AUC (area under ROC curve) values 2) AUC and p-values							
sfragkoul@certh.gr	6312169df3794236aa987a1b	1/26/2022 14:34:16	30046299	An Extreme Learning Machine Based on Artificial Immune System.	Tian HY, Li SJ, Wu TQ, Yao M.	Computational Intelligence and Neuroscience	2018	2018	10.1155/2018/3635845		1) Ecoli, Pima Indians Diabetes (Diabetes), Epileptic Seizure, Iris, Heart Disease, Glass Identification (Glass), Image Segmentation (Image), and Statlog (Satellite) 2) Breast Cancer, Parkinson, SinC, Servo, and Yacht Hydro (Yacht)	1) Ecoli train: 180 val:78 test:78, Diabetes train: 384 val:22 test:192, Epileptic Seizure train: 6000 val:2750 test:2750, Heart Disease train: 150 val:76 test:76, Iris train: 70 val:40  test:40, Glass train: 100 val:57 test:57, Image train: 1200 val:555 test:555, Satellite train: 3435 val:1500 test:1500 2)Breast Cancer train:98 val:50 test:50, Parkinson train:500 val:270 test:270,  SinC train:5000 val:2500 test:2500, Servo train:384 val:192 test:192,  Yacht Hydro train:150 val:79 test:79	all datasets are without overlap, kept coincident for each trial of the algorithms.	http://archive.ics.uci.edu/ml/index.php	AIS-ELM is compared with DS-ELM, PSOELM, SaE-ELM, traditional ELM,SVM, and Back Propagation.	No	All the inputs have been normalized into the range [-1, 1] for fairness.	p=5, the parameters for AIS-ELM are set as follows: ùëé(antibody population) =10,ùëè = 50(bit position of the last ‚Äúon‚Äù bit starting from the most significant bit),ùúÄ = 0.1(stimulus region),ùëò = 5(number of bits that must be flipped to mutate),ùëü = 0.2(mutation probability)	1) Ecoli 7, Diabetes 8, Epileptic Seizure 179, Heart Disease 75, Iris 4, Glass 9, Image 19, Satellite 36 2)Breast Cancer 32, Parkinson 26,  SinC 1, Servo 4,  Yacht Hydro 13	Not applicable	No		Black Box	1) classification 2) regression 		No	20-fold cross validation		-	better timing and accuracy	No	No	1) 1-37 seconds 2) 13-33 seconds	Means and Standard Deviation and training time							
sfragkoul@certh.gr	6312169df3794236aa987a1b	1/26/2022 14:42:39	25280899	Genetic networks governing heart development.	Waardenberg AJ, Ramialison M, Bouveret R, Harvey RP.	Cold Spring Harbor Perspectives in Medicine	2014	2014	10.1101/cshperspect.a013839		not applicable	not applicable	not applicable	not applicable	not applicable	not applicable	not applicable	not applicable	not applicable	not applicable	not applicable		not applicable	not applicable		not applicable	not applicable		not applicable	not applicable	not applicable	not applicable	not applicable	not applicable							
sfragkoul@certh.gr	6312169df3794236aa987a1b	1/31/2022 11:13:16	22408447	Using support vector machine and evolutionary profiles to predict antifreeze protein sequences.	Zhao X, Ma Z, Yin M.	International Journal of Molecular Sciences	2012	2012	10.3390/ijms13022196		source: 10.1016/j.jtbi.2010.10.037 481 antifreeze proteins and 9493 non-antifreeze proteins	training dataset contains 300 antifreeze proteins randomly selected from the 481 antifreeze proteins and 300 non-antifreeze proteins randomly selected from the 9493 non-antifreeze proteins. The test dataset contains the remaining 181 antifreeze proteins and 9193 non-antifreeze proteins.	To get rid of redundancy and homology bias, the sequences with ‚â•40% sequence similarity have been removed using program CD-HIT	http://www3.ntu.edu.sg/home/EPNSugan/index_files/AFP_Pred.htm	SVM	4 SVM models based on amino acids composition, dipeptides composition, Chou‚Äôs PseAAC and PSSM-400	Evolutionary Information, Amino Acid and Dipeptide Composition, Chou‚Äôs Pseudo Amino acid Composition	p=2, regularization parameter C and the kernel width parameter Œ≥.	400, PSSM-400 (composition of occurrences of each type of amino acid corresponding to each type of amino acids in protein sequence)	No	No			classficiation		No	Ten-fold cross validation & independent testing dataset		comparison with work from 10.1016/j.jtbi.2010.10.037. this study obtains accuracy	Model's accuracy	No	http: //59.73.198.144/AFP_PSSM/	20 seconds for 500 amino acids sequences	sensitivity (S_n), specificity (S_p), and accuracy (Acc), ROC							
sfragkoul@certh.gr	6312169df3794236aa987a1b	2/9/2022 15:02:29	33240258	Circulating Neutrophil Extracellular Traps Signature for Identifying Organ Involvement and Response to Glucocorticoid in Adult-Onset Still's Disease: A Machine Learning Study.	Jia J, Wang M, Ma Y, Teng J, Shi H, Liu H, Sun Y, Su Y, Meng J, Chi H, Chen X, Cheng X, Ye J, Liu T, Wang Z, Wan L, Zhou Z, Wang F, Yang C, Hu Q.	Frontiers Media S.A.	2020	2020	10.3389/fimmu.2020.563335		they created the dataset	training set: 40 (23 active and 17 inactive) patients & 24 healthy, validation set: 26 (18 active and 8 inactive) patients & 16 healthy	not applicable	in supplementary files	SVM	No	global features invlude various clinical characteristis of sampes.	Grid search and Gaussian radial basis function kernels were implemented for tuning parameters.	4(Plasma samples were used to measure cell-free DNA, NE-DNA, MPO-DNA, and citH3-DNA complexes from training and validation sets.)	Not applicable	Not applicable		Black box	classification: binary predictions		no	indipendent dataset		novel approach	svms accuracy	no	No	not mentioned	ROC, AUC, sensitivity, specificity							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/24/2022 11:27:01	34526509	Causality in digital medicine.		 nature communications	2021	2021	10.1038/s41467-021-25743-9		Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note		Document type: Note	Document type: Note		Document type: Note	Document type: Note		Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note	Document type: Note							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/22/2022 11:54:11	32344344	Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.	Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S.	Food Chemistry	2020	2020	10.1016/j.foodchem.2020.126864		316 sweet compounds from SweetenersDB dataset. https://doi.org/10.1016/j.foodchem.2016.10.145	64 diverse compounds (20.3%) were selected for the test set, leaving 252 compounds in the training set	The updated SweetenersDB was split in training and test sets using a Sphere Exclusion clustering algorithm. 	https://github.com/chemosim-lab/SweetenersDB	Random Forest, Support Vector Machine (SVM), Adaptative Boosting with a Decision Tree base estimator (AdaBoost Tree), and k-Nearest Neighbors. AdaBoost Tree was selected	no	Every compound in the datasets were collected as SMILES strings and sanitized with RDKit. The resulting datasets consisted of 635 descriptors for the Dragon dataset, and 506 features for the ‚Äúopen-source‚Äù dataset. 	default	Five-fold cross validation was performed with hyperparameter tuning using a grid search.  The optimal percentile of features was tuned as a parameter of the Grid Search. 32 descriptors for the ‚ÄúDragon‚Äù model, and 51descriptors for the ‚Äúopen source‚Äù model	To avoid any model bias due to overfitting, the number of features used by the model is a hyperparameter that has been optimized.	Structures were standardized using the ‚Äústandardizer‚Äù from Python.		direct correlation between compound and sweetness	regression to predict the logSw (relative sweetness)		http://chemosimserver.unice.fr/predisweet/	independent dataset 		e-Sweet platform (Zheng et al., 2019) is based on a consensus model of various machine learning protocols.  The performance of BitterSweet is comparable to e-Sweet and Predisweet (R2 of 0.72 on our test set) but the protocol is still unpublished, and seven molecules of the test set has not been considered as sweet.	statistical metrics	no	no	not mentioned	predictive performance was evaluated based on criteria previously defined by: https://doi.org/10.1016/S1093-3263(01)00123-1. correlation coefficient,  coefficient of determination,  slopes of the regression lines through the origin for the observed vs. predicted and predicted vs. observed values respectively, corresponding coefficients of determination,  root mean squared error,  mean absolute error							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/23/2022 11:05:15	32298292	Development of a prediction model for hypotension after induction of anesthesia using machine learning.	Kang AR, Lee J, Jung W, Lee M, Park SY, Woo J, Kim SH.	Plos One	2020	2020	10.1371/journal.pone.0231172		made their own dataset	Among 222 patients, 126 developed postinduction hypotension	not applicable	yes in Supporting information section	Na√Øve Bayes, logistic regression, random forest, and artificial neural network models	no	not applicable	default	performed feature selection using the caret R package. from 89 initial features, redundant features were removed, attributes with an absolute correlation coefficient of 0.5 or greater were also removed. Last, specific features were selected using the recursive feature elimination (RFE) method. 20 features were finally selected. 	not applicable	not applicable		Black box	classification 		no	cross-validation		not mentioned	ML algorithms metrics	no	no	not mentioned	precision, recall, accuracy							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/23/2022 11:07:07	33260881	A Customizable Analysis Flow in Integrative Multi-Omics.	Lancaster SM, Sanghi A, Wu S, Snyder MP.	Biomolecules	2020	2020	10.3390/biom10121606		review	review	review	review	review	review	review	review	review	review	review		review	review		review	review		review	review	review	review	review	review							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/24/2022 11:32:52	16634365	Mixed connective tissue disease.	Venables PJ.	Frontiers in Aging Neuroscience	2020	2006	10.1191/0961203306lu2283rr		Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper		Document type: Data Paper	Document type: Data Paper		Document type: Data Paper	Document type: Data Paper		Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper	Document type: Data Paper							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/23/2022 10:25:57	30819107	MaGIC: a machine learning tool set and web application for monoallelic gene inference from chromatin.	Vinogradova S, Saksena SD, Ward HN, Vigneau S, Gimelbrant AA.	 BMC Bioinformatics	2019	2019	10.1186/s12859-019-2679-7		https://doi.org/10.7554/eLife.01256.001, https://doi.org/10.1534/g3.115.018853	253 MAE genes and 1127 BAE genes	In order to avoid excessive numbers of false positive calls due to this imbalance, we trained the models to optimize the metric Kappa rather than accuracy, as Kappa accounts for imbalanced number of genes belonging to each class in training data	yes	various	authors recommend to choose the model with the highest F1-score	processing of signals and the resulting values are converted to quantile rank.	not clearly  stated	defaults classification labels lists or can be provided by the user	no	no		various methods to directly determine class of genes	classification 		https://github.com/gimelbrantlab/magic	Cross-validation and independent dataset		not mentioned	qualitative description of the advantages of the presented pipeline	no	no	not mentioned	 precision and recall							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/28/2022 12:30:56	31479437	Benchmarking network propagation methods for disease gene identification.	Picart-Armada S, Barrett SJ, Will√© DR, Perera-Lluna A, Gutteridge A, Dessailly BH.	PLoS Computational Biology	2019	2019	10.1371/journal.pcbi.1007276		Open Targets platform,  at least 1,000 Open Targets associations. 22 diseases were considered	genetic association with disease. Based on given score some  associations were considered positive.	none	https://github.com/b2slab/genedise	Diffusion (propagation) methods, Purer ML-based methods and naive baseline methods	no	Associations were binarised	not mentioned	22	none	none		black box	regression: ranking of genes in terms of their association scores to the disease		https://github.com/b2slab/genedise	Cross-validation		network topology, basic GBA approach	The rankings produced by the different algorithms were qualitatively compared using Spearman‚Äôs footrule	no	no	not mentioned	20 hits, AUPRC, AUROC 							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/22/2022 13:13:16	29720103	Prediction of plant lncRNA by ensemble machine learning classifiers.	Simopoulos CMA, Weretilnyk EA, Golding GB.	 BMC Genomics	2018	2018	10.1186/s12864-018-4665-2		positive: lncRNAdb v2.0, lncRNAdisease , total of 436 unique, validated lncRNA sequences // negative: Ensembl, Araportv11 	 8 different combinations of negative data from multiple species	variety of training datasets was used to maximize model diversity and samples were equally and randomly selected to get a balanced training	(http://lncrnadb.org), (http://www.cuilab.cn/lncrnadisease), (http://www.ensembl.org), (https://araport-dev.tacc.utexas.edu)	 random forest and gradient boosting. Also ensemble method from different classifiers, Two separate values were used for the creation of each ensemble model ‚Äì scores sij and predictions pij where i represents model number and j transcript.  The four ensemble approaches included both algebraic combiners and voting methods as non-trainable methods, and a stacking generalizer as a meta-learner.	no	Diamond alignment in SwissProt database	 gradient boosting parameters :  learning_rate, max_depth, subsample, n_estimators.  Random forest parameters: only change from default parameters being n_estimators and min_samples_leaf.	9 features were extracted using a combination of custom Python scripts and known software CPAT, Diamond, RepeatMasker.	not applicable	not applicable			classification  binary if a transcript was or was not predicted as a lncRNA and stacking with logistic regression for ensemble method		https://github.com/gbgolding/crema	10-fold cross-validation		compared to GreeNC (uses a transcript filtering method, rather than a machine learning approaches).	(qualitative explanation) An important consideration of this tool is that it is not constrained by preconceived rules that may or may not appropriately classify lncRNA properties and the stacking generalizer model based on gradient boosting models will facilitate lncRNA identification without imposing arbitrary rules for lncRNA detection.	no	no	measured in minutes	 accuracy, sensitivity, specificity and AUC values							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/23/2022 13:41:44	29036374	Gating mass cytometry data by deep learning.	Li H, Shaham U, Stanton KP, Yao Y, Montgomery RR, Kluger Y.	Bioinformatics (Oxford, England)	2017	2017	10.1093/bioinformatics/btx448		 three CyTOF datasets consisting of 56, 136 and 16 PBMC samples	none	none	https://github.com/ KlugerLab/deepcytof.git.	NN	no	sample denoising, calibration between target samples and a single reference source sample and finally cell classification. We implement each of these tasks using the following three neural nets: (i) a denoising autoencoder (DAE) for handling missing data; (ii) an MMD-ResNet for calibrating between the target samples and a reference source sample; (iii) a depth-4 feed-forward neural net for classifying/gating cell types trained on a reference source sample.	depth-4 feed-forward neural nets	4	none	logarithmic transform, followed by rescaling		black box	 cell classification		https://github.com/ KlugerLab/deepcytof.git.	 independent dataset		no	comparison with manually performed task	no	"yes, in ""savedmodels"" folder in https://github.com/KlugerLab/deepcytof.git."	not mentioned 	 F-measure statistic (the harmonic mean of precision and recall)							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/23/2022 12:35:43	27491922	A Random Forest Model for Predicting Allosteric and Functional Sites on Proteins.	Chen AS, Westwood NJ, Brear P, Rogers GW, Mavridis L, Mitchell JB.	Molecular Informatics	2016	2016	10.1002/minf.201500108		data were primarily collected from the online Allosteric Database (ASD)	allosteric sites (59), regular sites (99), orthosteric sited (159)	selection of negative and positive for balanced datasets	no	Random Forest	no	random sample of (number of descriptors) ^(1/2) until the tree can no longer grow	default	existing protein-ligand scoring function RF-Score and a new accessibility-like algorithm called CavSeek to compute structurally-based binding descriptors and descriptors pertaining to the composition and flexibility of the clefts.	no	no		transparent since there is a methodological feature selection.	classification		no	out-of-bag set and independent test set		none	Statistical confidence. The times assigned to each class are given so as to express the approximate level of confidence with which a class has been assigned from 100 repeats.	no	no	not mentioned	Gini importance measure, RF-score and CavSeek							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/24/2022 13:42:10	19994907	Selective inhibition of DNA replicase assembly by a non-natural nucleotide: exploiting the structural diversity of ATP-binding sites.	Eng K, Scouten-Ponticelli SK, Sutton M, Berdis A.	Forests	2014	2010	10.1021/cb900218c		RapidEye data were used as the high spatial resolution reflects the spatial heterogeneity of carbon  https://doi.org/10.1016/j.actaastro.2009.06.008	104 in situ inventory plots	not applicable	no	SOMs and kNNs	no	no	k = 5 neighbors;  Euclidean distance d(x1,x2), of 2, and a distance weight w(i),p of 2	10	none	none		Black box	classification 		no	cross-validation		We decided to apply SOM and kNN for the Corg models, as previous methods such as the derivation of Corg stocks from classified vegetation types or the derivation via quantiles in a classification and regression tree (CART) approach had only  limited success.	ML training metrics	no	no	not mentioned	bias and the root mean square error (RMSE)							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/24/2022 11:24:39	22558141	Linking the epigenome to the genome: correlation of different features to DNA methylation of CpG islands.	Wrzodek C, Wrzodek C, B√ºchel F, Hinselmann G, Eichner J, Mittag F, Zell A.	Plos One	2012	2012	10.1371/journal.pone.0035327		NAME21 consortium, ENCODE consortium,  whole-genome catalogue of DNA methylation in human, DOI: 10.1371/journal.pgen.1000438	56 methylated (112 unmethylated) instances for leukocytes, 73 methylated (117 unmethylated) instances for HEK293, 44 methylated (142 unmethylated) instances for HEPG2, 43 methylated (142 unmethylated) instances for fibroblasts, and 32 methylated (137 unmethylated) instances for trisomic fibroblasts	not mentioned	 http://www.cogsys.cs.uni-tuebingen.de/software/dna-methylation/.	decision trees, naive Bayes,  k-nearest neighbor, K*, random decision forest and support vector machines with Gaussian radial basis function and linear kernel	no	not mentioned	not mentioned	948 features from 15 categories but each training included a subset of them	not applicable	not applicable		the algorithms were used in order to show the predictive performance of each feature and thus outline the correlation between features and classification	binary classification		 http://www.cogsys. cs.uni-tuebingen.de/software/dna-methylation/.	Cross-validation and  independent dataset		direct comparison is challenging since there are a lot of factors contributing in the final results. Some comparison is indeed presented from other publications.	To ensure a fair comparison, all analyses have been repeated ten times with a ten-fold cross-validation so the mean and standard deviation for each experiment are presented.	no	no	not mentioned	accuracy, Matthews correlation coefficient (MCC) and the area under the receiver operating characteristics curve (AUC), average absolute error (AAE)							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/23/2022 10:30:20	19630524	Radiation metabolomics. 3. Biomarker discovery in the urine of gamma-irradiated rats using a simplified metabolomics protocol of gas chromatography-mass spectrometry combined with random forests machine learning algorithm.	Lanz C, Patterson AD, Slav√≠k J, Krausz KW, Ledermann M, Gonzalez FJ, Idle JR.	Radiation Research	2009	2009	10.1667/rr1796.1		without open access	without open access	without open access	without open access	without open access	without open access	without open access	without open access	without open access	without open access	without open access		without open access	without open access		without open access	without open access		without open access	without open access	without open access	without open access	without open access	without open access							
sfragkoul@certh.gr	6312169df3794236aa987a1b	3/24/2022 13:09:43	18221567	Gene function prediction using labeled and unlabeled data.	Zhao XM, Wang Y, Chen L, Aihara K.	BMC Bioinformatics	2008	2008	10.1186/1471-2105-9-57		FunCat dataset used by DOI: 10.1093/nar/30.1.31, BioGRID database, SMD, MIPS	1) 13 general functional classes were selected, and 4049 genes have been annotated in total. 2) 82,633 pairs of interactions among 5,299 yeast genes, of which 4049 genes are annotated by the 13 functional classes.  3) 5,132 genes with 278 real value features for gene expression data.	not specified	DOI: 10.1093/nar/gkh894, DOI: 10.1093/nar/gkj109, 	SVM	no	the protein interaction data, gene expression profiles and protein complex data for yeast genes are integrated into one functional linkage graph	not mentioned	SVD technique was employed to reduce the dimensionality and remove noise. 13 features.	to evaluate the functional similarity between a pair of genes, the Czekanowski-Dice distance was employed. After that, the functional similarity between any pair of genes was represented as a real value between 0 and 1	no		Black box	classification		no	cross-validation and independent dataset		The AGPS algorithm is different from existing methods, which have inappropriate assumptions about those genes that have no target annotation.	not mentioned	no	no	not mentioned	precision, recall and F1							
sheriff@ebi.ac.uk	6312169df3794236aa987a77	3/21/2022 11:49:08	25849257	Machine learning assisted design of highly active peptides for drug discovery.	Gigu√®re S, Laviolette F, Marchand M, Tremblay D, Moineau S, Liang X, Biron √â, Corbeil J.	PLoS Computational Biology	2015	2015	10.1371/journal.pcbi.1004074		Data taken from Wade 2002 (101 data points), Ufkes 1982 (31 data points),  its quantitative continuous data - peptide sequence and anti-microbial activity (binding affinity, IC50), hence no positive negative, 	Data is peptide sequence and anti-microbial activity (binding affinity, IC50),  hence no pos and negative control,  first built a model to generate synthetic data and used 1000 of such data for training.	Synthetic data used	No	Novel, graph theory based approach to learn Generic String kernel (G	No	Sequence to binding affinities and IC50	position-specific weight matrix (PSWM)	Sequence (GS kernel), Synthetic data used.	not a binary classification problem, hence positive negative training data not used.	No		Transparent, graph model	Predict a string of amino acids with antimicrobial properties.		link given https://graal.ift.ulaval.ca/peptide-design/, but page not found	kernel ridge regression with training used for validation. Also performed lab experiments.		Pearson correlation of prediction with values in databases)	Correlation coefficient of 0.90 and 0.93 were reported for two different datasets used.	No, URL isn't working.	No	Not reported	Pearson correlation coefficient ( correlation of prediction with values in databases)							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/19/2022 17:28:38	34258160	A Noninvasive Multianalytical Approach for Lung Cancer Diagnosis of Patients with Pulmonary Nodules.	Liu QX, Zhou D, Han TC, Lu X, Hou B, Li MY, Yang GX, Li QY, Pei ZH, Hong YY, Zhang YX, Chen WZ, Zheng H, He J, Dai JG.	Advanced Science	2021	2021	10.1002/advs.202100104		Data is experimentally derived from 125 patients. Training data divided over 84 positive and 41 negative instances. An independent validation set 	Data is split into 96 for training and 29 for validation. The training set consisted of 69 positive and 27 negative, whereas the validation set is divided into 14 negative and 15 positive cases.  	not discussed.	patient clinical information available in SI, as well as the protein biomarker data cfDNA mutation and cfDNA methylation features. Link to raw data also provided (or via author)	SVM	Features are coming from experimental data.  Four different predictors using different data are grouped in a stacked ensemble classifier, using Naive Bayes. 	data normalised, missing data inputed using median value, data standardised using z-scores. 	linear kernel used in SVMs for each independent predictor.  Naive bayes sued to determine the optimal combination of these predictors.	10 clinical features, eight cancer biomarkers 29-gene NGS panel for mutations, 30 methylation-correlated blocks (feature-selected from 697 MCBs). 	parameter smaller than samples, features larger but still smaller than samples pin the training set, but univariate analysis reduced then number of features.	Cross-validations procedures and feature selection are used to reduce chances for over-fitting.  Evaluation based on independent validation set.		partially interpretable but no apart from feature analysis on the baseline predictors, nothing else reported	classification in benign or malignant		not provided	cross validation and independent set		no other methods are compared	not provided	not available	not available 	not discussed	AUC. sensitivity and specificity							
tlenaert@gmail.com	6312169df3794236aa9879f2	2/21/2022 11:17:51	34372798	Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.	Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ.	BMC Cancer	2021	2021	10.1186/s12885-021-08647-1		Pubmed for relevant molecules (48 mol based on 38 articles), GEO (GSE53625 179 data points), TCGA (TCGA-ESCC 82 data points, 37 used for validation) and own clinical samples (86 samples)	179 split into 134 training and 45 testing ESCC cases (randomly), 17 out of 48 moulecues were used as features for the classification.  ESCC cases with survival times more than 3 years were labelled 1 and the others were labelled 0, no information about the number in each set.	No mention made. Separation appears to be done randomly for the GEO set.  All the rest was used as validation.  No mention about the overlap between the sets.	GEO and TCGA data is available. The 86 clinical cases are not provided, neither is the code provided for the ML part of the paper	5 algorithms used, LR, SVM, ANN, RF and XGBoost 	No data is used from other predictors, but the 5 predictors are used together as an ensemble to identify the most predictive features, i.e. the molecules useful for separating cases with good prognosis from bas ones	mRNA data for 17 out 48 relevant molecules was used. The values expressed the difference in expression between the cancer and corresponding adjacent tissue.	No details provided about the ML algorithm parameters	17 features corresponding to the most relevant molecules, which were obtained from literature and an additional network analysis based on String. They tested with each ML algorithm all 2^17-1 (131071) feature combinations to see which ones lead to the best predictions. Selection was done on training set (I assume)	No information about parameters of the model and the model implementation.	not clear.  They claim to have uses cross-validation but it is not explained in detail.		both, they used LR as well as ANN. 	Classification that is used to determine the most relevant set of features out of all 2^17-1 combinations. 		Not available	They claim to have used crossvalidation but it is not explained.  They use independent sets to test their findings and to relate the survival of patients to these findings.		No comparison is made, as this is not the main point of this paper. 	not applicable	not provided	no 	not given	Only AUC was reported for the classifier, which is not the most suitable measure.							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/2/2022 13:51:09	33828982	Improving the Prediction of Benign or Malignant Breast Masses Using a Combination of Image Biomarkers and Clinical Parameters.	Cui Y, Li Y, Xing D, Bai T, Dong J, Zhu J.	Frontiers in Oncology	2021	2021	10.3389/fonc.2021.629321		New cohort of 524 enrolled patients, 988 mammography images divided in 494 malignant and 494 benign masses.Data was preprocessed to be useful for DL work.  An additional validation set from another hospital is also used (58 patients). Not used before	Data split 744 (training) and 244 (test) in a random manner. No details in Pos/Neg split but assumed to be equal.  	No stratification effort	"No download information provided, but article contains statement that ""the data will  be made available without undue reservation"""	Transfer learning with DL to extract features trained with stochastic gradient descent, SVM (linear kernel) for final classification into benign and malignant.	Yes, for the DL feature extraction the VGG16 image-net trained network was used in combination with the Inception-V3 network into a fusion network.	Five preprocessing steps to prepare mammography images (identification of ROI, image and size normalisation, and data augmentation (flipping and rotations). Image size was  224x224x3 	The DL has its weights and layers next to the epoch, learning rate, momentum and weight decay parameters.  All parameters for the fusion network were transferred rom VGG16 and Inception V3 into a DL fusion network.  They added three additional FC layers.	Handcrafted (455), clinical (5) and DL-based features (1024-dimensional vector) are used in the final classifier. MRMR is used for feature selection, reducing the number of features to 30 Hcr and 27 DL features, next to the clinical ones.	There are 7x744 datapoints for training, yet this seems still limited given the complexity of the DL network to extract features. Not considering the DL, and only the SVM, things look better as the feature set is reduced to 62 features in total, so f > p.	SVM hyperparameters were tuned with grid-search and 10-fold cross-validation.  Tests were performed in an independent set and verified in an independent validation set.  Yet no stratification seems to be done.		black box due to DL, but relatively transparent in the final classification step with SVM.  The question is how interpretable the DL features are. 	Benign or malignant mass.		not available 	test set and independent validations set.  Cross-validation when determining the optimal configuration of the SVM. 		No comparison made with other approaches.	yes, Dejong's test	not available	Not available.	not mentioned	Confusion matrix, calculating AUC, accuracy, sensitivity, precision, and F-score. Statistical significance with Delong's test (P<0.05 was considered significant).							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/3/2022 13:08:10	30891794	Combining handcrafted features with latent variables in machine learning for prediction of radiation-induced lung damage.	Cui S, Luo Y, Tseng HH, Ten Haken RK, El Naqa I.	Med. Phys	2019	2019	10.1002/mp.13497		106 patients with non small cell lung cancer, 22 positive (>=2) long radiation pneumotis and 84 (<2) negative patients. Each patient is annotated with 230 features. Patient data comes from another publication 28237401. Data does not seem to be downloadable.	System of inner and outer cross validation (5-fold) with multiple repeats of both loops. Distributions across sets or stratifications were not reported.	not discussed	no 	Several methods are tested to find the optimal feature subset for classification (see fig1 in the paper). Includes multi-layer perceptrons, random forest, SVM and a combination of a VAE with a MLP.	not meta-predictions, everything is performed on the raw data. 	not specified in this article (ref to earlier article)	Not all details provided about the parameters for each model. RF optimised by verifying different depths (yet number of trees was not mentioned). No details about SVM. VAE and MLP are shown in figures	230 features, wrapper method with cross-validation to find the optimal subset.  VAE extraction applied also to data to identify other features	double loop of cross validation (5-fold) and ,multiple runs to obtain statistically robust results. 			dependent on the classification approach.  Most relevant features are explained. An expert should be able to get some understanding from the remaining features,  yet interpreting the latent variables produced by the VAE will be complicated.	binary prediction 		not available	double loop of cross-validations and multiple repeats to overcome the imbalance in the data set.		no other methods compared	DeLong method to compare AUC's 	not available	some parts yes, other parts no	not mentioned	average AUC							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/7/2022 21:14:17	34099697	A deep learning approach to identify gene targets of a therapeutic for human splicing disorders.	Gao D, Morini E, Salani M, Krauson AJ, Chekuri A, Sharma N, Ragavendran A, Erdin S, Logan EM, Li W, Dakka A, Narasimhan J, Zhao X, Naryshkin N, Trotta CR, Effenberger KA, Woll MG, Gabbeta V, Karp G, Yu Y, Johnson G, Paquette WD, Cutting GR, Talkowski ME, Slaugenhaupt SA.	Nature Communications	2021	2021	10.1038/s41467-021-23663-2		RNA-seq data produced by the authors. The set includes 934 exon triplets responding to a BPN15477b treatment. 245 with increased exon inclusion and 680 with increased exclusion. They added 382 exon triplets which did not trigger a response (negative set). Data is used for a three-class predictor. 	Data divided in training (178 inclusion responded, 478 exclusion responded and 268 unchanged), validation (51inclusion responded, 136 exclusion responded and 76 unchanged) and test set (25 inclusion responded, 68 exclusion responded and 38 unchanged). the data is split randomly over these 3 sets. 	No stratification wa reported	Data is provided as supplementary information (supplementary data 1) and via GEO	CNN, explained in Methods and figure in SI. Predicts a value between 0 and 1 for each of the three classes: inclusion, exclusion and unchanged. Aim is to predict splicing size changes (including no change) after BPN15477 treatment.	No data from other predictors is used	Onehot encoding of concatenated triplets of 3 exons (details see paper)	Huge number of network parameters (2.5 million trainable parameters as mentioned by the authors). 	400x4 matrix for each exon triplet. No feature selection performed	used L-1 regularisation to avoid overfitting (coefficient =0.6) in the convolutional layer and dropout strategy im the hidden layer	Overfitting limited through limitation on number of training epochs (12th epoch).  Comparison to 1000 other models with same structure using different random initialisations.  Evaluations done on separate validation and test sets		Method is black box but they provide an exhaustive evaluation of the predictions (compared to 1000 other models) and performed an analysis of the data, through other methods and experiments.	classification (values between 0 and 1 for each class)		via GitHub	Data split in training, validation and testing. Experimental verification of predictions.		not relevant for this work,	Provided in detail (see statistical analysis section)	didn't find it	Code is available on GitHub (haven't checked it)	not mentioned	AUC and precision recall							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/12/2022 19:15:18	32681213	Using neuronal extracellular vesicles and machine learning to predict cognitive deficits in HIV.	Pulliam L, Liston M, Sun B, Narvid J.	Journal of Neural Virology	2020	2020	10.1007/s13365-020-00877-6		In house produce experimental and clinical data (neurophysiological tests, age, education, ethnicity.  20 normal  and 40 neurologically impaired patients. New data not used in other studies.	They employed 6-fold cross-validation (repeated 10 times), not needing split between training and test set.  they did not provide a validation set.  Pos=40, Neg=20 patients.	not specified, although they claim that data leakage (which I assume is bad stratification) between folds was precluded.  No details on how.  I assume random fold separation, hence the 10 times repetition.	data is not provided.	SVM, Adaboost with decision trees, Ensemble KNN, Random forest	No, all raw data	some data were transformed either by binning or one-hot encoding .  	They are not specified (number of KNN in the ensemble, RF settings, adaboost)	It's is unclear which features are exactly used. There is no clear summary table.  They used clinical test and patient data next to protein concentration information (HMGB1, NFL, p-181-tau).  Missing values were filled up with K-NN imputation.  They examine always 7 models (in terms of the feature set used), M1 is only clinical data the others use M1 plus a subset of the 3 proteins.	number if features is smaller than number of samples. Cross-validation (I assume with random splits) to avoid over-fitting.	no validation set used.		They performed a feature importance analysis for the best models (M3 and M4) and showed partial dependency plots between classification and a series ofd features. No details on how this was produced.	classification in two classes (impaired versus normal)		not available 	cross validation		4 different methods were compared. No comparison with other method on their data.	paired t-test with p<0.05	not available 	no available	not mentioned	area under the curve							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/12/2022 20:11:43	33946997	Comparison of Targeted and Untargeted Approaches in Breath Analysis for the Discrimination of Lung Cancer from Benign Pulmonary Diseases and Healthy Persons.	Koureas M, Kalompatsios D, Amoutzias GD, Hadjichristodoulou C, Gourgoulianis K, Tsakalof A.	Molecules	2021	2021	10.3390/molecules26092609		"Data comes from a previous paper : Koureas, Michalis, et al. ""Target analysis of volatile organic compounds in exhaled breath for lung cancer discrimination from other pulmonary diseases and healthy persons."" Metabolites 10.8 (2020): 317. 85 patients (49Ca+ and 36 Ca-) and 52 control group individuals."	No split in training/test /validation.  The splitting is done within a 10-fold cross-validation procedure. Three classes are possible, and predictors are designed for pairs of classes. 	No mentioned how stratification is done in the cross-validation procedure.  Feature elimination is performed	previous publication gives some data but not the raw data	Weka platform used,  naive bases, logistic regression and random forests.  Only the latter is shown given its better performance. 	no 	Not discussed explicitly.  metabolic data per patient was used,	Not detailed what the parameters were for the random forest. 	mass spectrum data is used.   Either focussing on a specific subset fo know compounds or the full VOC data (requiring extensive feature selection , see Fig2 of paper)	not specified	Thorough feature selection procedure (wrapper based) and two step cross-validation (10-fol)		No analysis provided 	classification (Ca+ vs HC, CA- vs HC and Ca+ vs Ca-)		not available	cross-validation		focus on RF as performance of others is low (obvious for NB and regression)	not provided 	not available	not available	not mentioned	AUC and accuracry							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/13/2022 19:09:08	27592011	A D3R prospective evaluation of machine learning for protein-ligand scoring.	Sunseri J, Ragoza M, Collins J, Koes DR.	J Comput Aided Mol Des .	2016	2016	10.1007/s10822-016-9960-x		1) regression data : 355 compounds from ChEMBL bioactivity database for training the regressor, 2) classification data : DUD-E dataset (102 target proteins, 20000 active molecules and more than a million decoy molecules); classes active/decoy. The validation/testing of the predictive methods is done on the D3R data form HSP90 and MAP4K4. They generate 29K poses for the former to test their predictors and 5329 poses for the latter. No mention of which ones are active fits and which ones are decoys. 	The training and test set are completely separate (see explanations above).  Note imbalance in dataset for the classifier, which they overcome by also creating a balanced dataset for training. In the HSP90 test set there were 136 active and 44 inactive compounds (threshold set by authors on affinity).	The DUD-E set consists of a HSP90 target.  the authors make an independent set with this information, I assume to checkt the influence of the presence of this information own the classification.	they do not provide themselves the data they used in their regressor and classifier.	1) Elastic net linear model for affinity prediction, 2) linear regression models (linear and logistic) and neural network for pose prediction (active versus decoy).  The linear model was submitted for D3R	They use a number of other methods to infer the feature that are used by the regressor and classification algorithm.  Not clerk what the overlap is.	1) training data is transformed into Boolean fingerprints, 2) training data for classifier is translated into numerical vectors	1) two parameters alpha and rho. 2) 1 for regressor and 20 hidden node/2 output node NN.decay and momentum parameters for training the network.	no feature selection was performed. 2) classifier has 61 features and 1) size of bit pattern defines number of features in the regressor (2048 or more)	classifier has less parameters than samples.  	Cross-validation performed to determine the generalisation of the predictions.		the weights of the regressor explain the importance of the features.  The NN is black box 	both, 		no	Cross-validation when training the classifiers and the test set is independent as it is provided by the D3R challenge		they compare only their own approaches	confidence bars given in bart plots. Significance is mentioned but no p-values are provided	no data	no	not mentioned but linear regression is fast 	only AUC							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/19/2022 20:19:10	33349236	Analysis of heterogeneous genomic samples using image normalization and machine learning.	Basodi S, Baykal PI, Zelikovsky A, Skums P, Pan Y.	BMC genomics	2020	2020	10.1186/s12864-020-6661-6		Comes from two of other publications [13] and [8]. Note that the purpose of this article is to show a new data representation for classification. First data set consist of 365 NGS samples, 108 are recently infected hosts and 257 are chronically infected hosts. The second set consists of 335 infected persons, 142 correspond to outbreaks with more than one person and 193 are isolated cases. the latter is used for clustering, so not further considered here	"no separate validation set. Cross-validation is used, both classic 10-fold and ""leave-one-outbreak-out"", also under sampling of the larger set (chronically affected) is tested."	No stratification explicitly discussed, yet leave-one-outbreak out aims to resolve overlaps between the folds used for training and testing.	from other papers, and requests can be made to the senior author. Data also available via GitHub link	A series of classification methods, all from scimitar learn ; including SVM (best performance), RF and NB. 	not features coming from other predictors, all raw data 	The paper proposed sequence image normalisation for encoding.  yet very poorly explained and thus difficult to understand	ML parameters are optmized, e.g.  regularization parameter c for SVM and number of trees for RF.  Not all parameters are systematically mentioned 	RGB matrices encoding sequences, yet unclear how this works exactly.	many more features, if one considers that every RGB value as a feature.  	Cross-validation approaches		no obvious interpretation	binary classification		yes via GitHub	Cross-validation 		method in ref [32], which has significantly worse performance.  	not provided	might be part of the githuv rep 	not	not mentioned	Accuracy, AUC, presicion and recall							
tlenaert@gmail.com	6312169df3794236aa9879f2	3/15/2022 11:52:26	24977146	enDNA-Prot: identification of DNA-binding proteins by applying ensemble learning.	Xu R, Zhou J, Liu B, Yao L, He Y, Zou Q, Wang X.	Biomed research international	2014	2014	10.1155/2014/294279		four datasets are used, two for training and two for testing. The first set consist of 146 positive and 250 negative cases.  They were obtained from two earlier publications on the same topic.  The second set is an expansion of the first, adding more negative instances. Te negative set is increases to 2125 instances. The third set is obtained from another publication, consisting of 92 positive and 100 negative instances.  The last set contains 823 positive and 823 negative instances, also extracted from another publication. 	Data set 1 and.2 are used for training, dataset 3 and 4 for testing. 	With the data sets, sequences with a pairwise identity larger or equal to 25% were removed.  All sequences in the test sets that had a pairwise sequence identity larger or equal to 40% were removed from the test sets (using CD-HIT).  	all data is made available via Supplementary information	Heterogeneous ensemble classifier baed on adaboost (but for unbalanced data), with 20 different based classifiers  including rule-based, SVM, tree-based and KNN-based classifiers.	There is not sufficient information.  They calculate a 188 feature vector with properties about the sequence composition, distribution and physiochemical properties, but they not provide details on whether these are predictions or actual calculations.	188 feature vector for each protein sequence with information on composition, distribution and physiochemical properties	Details on the parameters of each independent learner  in the ensemble are not provided. Their ensemble method uses a weight for each negative sample in the training set to tune the sampling of the negative instances	188 features per sequence. No feature selection appears to be performed.	Nothing reported except for the claim that their method of selecting negative cases in function of their difficulty leads to less over-fitting.  No feature selection was performed, no cross-validation	not really		no interpretation provided, only performance assessment.  Remains black box as it is based on 20 different learners. 	binary (I assume based on the pseudocode provided)		platform  : http://bliulab.net/Ensemble-DNA-Prot/index.jsp	independent data sets only		Compared to other methods : DNAbinder, DNA-prot, iDNA-prot They were all reimplemented in house on the same data sets.	value comparison, no statistical tests 	no 	Not available, but there is a platform for the tool 	not mentioned	ACC, MCC, SE, SP and F1							
