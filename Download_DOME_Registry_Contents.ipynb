{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python script to download latest DOME Registry contents, related full text papers & provide DOME Registry entries metadata read out (20241220)**\n",
    "1. DOME Registry contents will be downloaded by API call providing the json file of DOME Registry data\n",
    "2. DOME Registry data json will be flattened and converted into TSV for working with entries data (row based data)\n",
    "3. DOME Registry TSV will be checked and used to produce a metadata readout file (+ graphs)\n",
    "4. DOME Registry DOIs of articles will be converted to PMCIDs and Europe PMC IDs for full text retrieval \n",
    "5. DOME Registry entries will be downloaded as full text PDF files using EPMC API\n",
    "6. DOME Registry supplementary files will be downloaded using EPMC API\n",
    "7. DOME Registry title and abstracts enriched in TSV from EPMC to support data analysis\n",
    "8. Metadata and graphs produced on available DOME Registry articles retrieval\n",
    "\n",
    "#### To do: dockerise & put into simple run script vs jupyter notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Latest DOME Registry contents will be downloaded by DOME Registry API call providing the .json file of DOME Registry data for the given day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists for storing DOME Registry JSON files, files will be stored here\n",
      "Downloading new file...\n",
      "DOME Registry data downloaded and saved to 'DOME_Registry_JSON_Files/DOME_Registry_Contents_2025-11-20.json'\n",
      "Using file: DOME_Registry_JSON_Files/DOME_Registry_Contents_2025-11-20.json\n",
      "Block 1 complete.\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the DOME API to download all entries of the DOME Registry and store them in a json file \n",
    "import os\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# Define the URL for the call\n",
    "url = \"https://registry.dome-ml.org/api/review?skip=0&limit=250&text=%20&public=true&sort=publication.year&asc=true\"\n",
    "\n",
    "# Make an API request to the URL to check the response\n",
    "response = requests.get(url, headers={'accept': '*/*'})\n",
    "\n",
    "# Create folder to store all JSON files\n",
    "if not os.path.exists('DOME_Registry_JSON_Files'):\n",
    "    os.makedirs('DOME_Registry_JSON_Files')\n",
    "    print('Created folder for storing DOME Registry JSON files')\n",
    "else:\n",
    "    print('Folder already exists for storing DOME Registry JSON files, files will be stored here')\n",
    "\n",
    "# Specify the desired folder path for JSON files\n",
    "json_folder_path = \"DOME_Registry_JSON_Files\"\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the current date in ISO format for file naming\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create the output file name \n",
    "    file_name = f\"DOME_Registry_Contents_{current_date}.json\"\n",
    "    json_file_path = os.path.join(json_folder_path, file_name)\n",
    "\n",
    "    # Check if the file pathway already exists\n",
    "    if os.path.exists(json_file_path):\n",
    "        print(f\"File already exists for today's date: {json_file_path}\")\n",
    "        print('Skipping download. Delete the file manually if you want to re-download.')\n",
    "        print('Continuing with existing file...')\n",
    "    else:\n",
    "        print('Downloading new file...')\n",
    "        # Save the content to a file\n",
    "        with open(json_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"DOME Registry data downloaded and saved to '{json_file_path}'\")\n",
    "    \n",
    "    print(f\"Using file: {json_file_path}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the data. Status code: {response.status_code}\")\n",
    "    # Set json_file_path to None to prevent errors in subsequent cells\n",
    "    json_file_path = None\n",
    "\n",
    "print(\"Block 1 complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DOME Registry data .json file will be flattened and converted into TSV for easier working with entries data (row and column based data format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read in JSON file.\n",
      "Flattened JSON data saved to 'DOME_Registry_JSON_Files/flattened_DOME_Registry_Contents_2025-11-20.json'\n",
      "Folder already exists for storing DOME Registry TSV files\n",
      "JSON data written to 'DOME_Registry_TSV_Files/flattened_DOME_Registry_Contents_2025-11-20.tsv'\n"
     ]
    }
   ],
   "source": [
    "# 2. Produce DOME Registry contents metadata .tsv file and data visualisation\n",
    "import json\n",
    "\n",
    "# 2.1 Pretty print DOME Registry contents JSON file for inspection to ensure all looks as expected \n",
    "# remove comment to activate print and debug where needed\n",
    "\n",
    "# Function to read in and pretty-print the JSON DOME Registry file entry\n",
    "def pretty_print_json(file_name):\n",
    "    try:\n",
    "        # Open and read the JSON file\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Pretty-print the JSON data\n",
    "        print('Successfully read in JSON file.')\n",
    "        #print(json.dumps(data, indent=4))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the JSON file: {e}\")\n",
    "\n",
    "# Call the function to pretty-print the JSON file\n",
    "pretty_print_json(json_file_path)\n",
    "\n",
    "\n",
    "# 2.2 Flatten the JSON for easier data processing and write to a new .json file \n",
    "# Function to read JSON data\n",
    "def read_json(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to flatten JSON\n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "# Function to save flattened JSON to a file\n",
    "def save_flattened_json(flattened_data, output_file_name):\n",
    "    try:\n",
    "        with open(output_file_name, 'w', encoding='utf-8') as file:\n",
    "            json.dump(flattened_data, file, indent=4)\n",
    "        print(f\"Flattened JSON data saved to '{output_file_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the flattened JSON file: {e}\")\n",
    "\n",
    "# Read JSON data\n",
    "data = read_json(json_file_path)\n",
    "\n",
    "# Flatten JSON data and save to a new JSON file\n",
    "if data:\n",
    "    flattened_data = [flatten_json(entry) for entry in data]\n",
    "    flattened_file_name = (\"flattened_\"+file_name)\n",
    "    # Make file path to save flattened JSON file\n",
    "    json_folder_path = \"DOME_Registry_JSON_Files\"\n",
    "    json_file_path = os.path.join(json_folder_path, flattened_file_name)\n",
    "    save_flattened_json(flattened_data, json_file_path)\n",
    "    # Print the flattened JSON data to view it\n",
    "\n",
    "else:\n",
    "    print(\"No data to process.\")\n",
    "\n",
    "#2.3 Convert flattened json to tsv \n",
    "# Function to read flattened JSON data\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Function to read flattened JSON data\n",
    "def read_flattened_json(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the flattened JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# TSV folders created to store tsv\n",
    "if not os.path.exists('DOME_Registry_TSV_Files'):\n",
    "    print('Creating folder to store DOME Registry TSV files')\n",
    "    os.makedirs('DOME_Registry_TSV_Files')\n",
    "else:\n",
    "    print('Folder already exists for storing DOME Registry TSV files')\n",
    "\n",
    "# Function to write JSON data to a TSV file\n",
    "def write_json_to_tsv(json_data, tsv_file_name):\n",
    "    try:\n",
    "        # Determine all possible headers from the entire dataset\n",
    "        headers = set()\n",
    "        for entry in json_data:\n",
    "            headers.update(entry.keys())\n",
    "        headers = list(headers)\n",
    "        \n",
    "        # Write data to TSV file\n",
    "        with open(tsv_file_name, 'w', newline='', encoding='utf-8') as tsvfile:\n",
    "            writer = csv.DictWriter(tsvfile, fieldnames=headers, delimiter='\\t')\n",
    "            writer.writeheader()\n",
    "            for entry in json_data:\n",
    "                writer.writerow(entry)\n",
    "        \n",
    "        print(f\"JSON data written to '{tsv_file_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to the TSV file: {e}\")\n",
    "\n",
    "# Read flattened JSON data\n",
    "flattened_data = read_flattened_json(json_file_path)\n",
    "\n",
    "# Create TSV file name and file pathway\n",
    "tsv_file_name = flattened_file_name[:-5]+'.tsv'\n",
    "tsv_file_path = os.path.join('DOME_Registry_TSV_Files', tsv_file_name)\n",
    "\n",
    "# Process JSON data into TSV\n",
    "if flattened_data:\n",
    "    write_json_to_tsv(flattened_data, tsv_file_path)\n",
    "else:\n",
    "    print(\"No data to process.\")\n",
    "\n",
    "tsv_file_name = flattened_file_name[:-5]+'.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DOME Registry TSV data file will be formatted with shortid as the row index and other fields cleaned (publication data) and ordered by D O M E fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordered TSV data saved to 'DOME_Registry_TSV_Files/flattened_DOME_Registry_Contents_2025-11-20.tsv'\n"
     ]
    }
   ],
   "source": [
    "#3 Reorder TSV using pandas data frame \n",
    "import pandas as pd\n",
    "\n",
    "# Read the TSV file as a DataFrame using pandas\n",
    "df = pd.read_csv(tsv_file_path, sep='\\t')\n",
    "\n",
    "# Define the prefixes to match and group tsv data\n",
    "prefix_publications_cols = 'publication_'\n",
    "prefix_tags_cols = 'publication_tags_'\n",
    "prefix_data_cols = 'matches_data'\n",
    "prefix_optimization_cols = 'matches_optimization'\n",
    "prefix_model_cols = 'matches_model'\n",
    "prefix_evaluation_cols = 'matches_evaluation'\n",
    "\n",
    "# Separate columns based on whether they start with the prefix\n",
    "publication_columns = [col for col in df.columns if col.startswith(prefix_publications_cols) and not col.startswith(prefix_tags_cols)]\n",
    "publication_tags_columns = [col for col in df.columns if col.startswith(prefix_tags_cols)]\n",
    "# Sort tags columns numerically (e.g., publication_tags_0, publication_tags_1, ...)\n",
    "publication_tags_columns = sorted(publication_tags_columns, key=lambda x: int(x.split('_')[-1]) if x.split('_')[-1].isdigit() else 0)\n",
    "matches_data_columns = [col for col in df.columns if col.startswith(prefix_data_cols)]\n",
    "matches_optimization_columns = [col for col in df.columns if col.startswith(prefix_optimization_cols)]\n",
    "matches_model_columns = [col for col in df.columns if col.startswith(prefix_model_cols)]\n",
    "matches_evaluation_columns = [col for col in df.columns if col.startswith(prefix_evaluation_cols)]\n",
    "other_columns = [col for col in df.columns if not col.startswith('matches_') and not col.startswith('publication_')]\n",
    "\n",
    "# Reorder columns\n",
    "reordered_columns = (other_columns + publication_columns + publication_tags_columns + matches_data_columns +\n",
    "                     matches_optimization_columns + matches_model_columns + matches_evaluation_columns)\n",
    "df = df[reordered_columns]\n",
    "\n",
    "# Print the reordered DataFrame\n",
    "#print(df.head())\n",
    "\n",
    "df = pd.DataFrame(df).set_index('shortid')\n",
    "df.to_csv(tsv_file_path, sep='\\t', index=True, encoding='utf-8') \n",
    "\n",
    "print(f\"Reordered TSV data saved to '{tsv_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DOME Registry data tsv will have columns added with PMCIDs and Europe PMC IDs returned from DOI search using NCBI E-Utilities API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with mapped PMCIDs and Europe PMC IDs saved to 'DOME_Registry_TSV_Files/PMCIDs_DOME_Registry_Contents_2025-11-16.tsv'\n"
     ]
    }
   ],
   "source": [
    "# 4. From DOIs get PMCIDs and Europe PMC IDs for full text search\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Read in DOME Entries TSV as dataframe via pandas library functions\n",
    "df = pd.read_csv(tsv_file_path, sep='\\t')\n",
    "\n",
    "# Extract DOIs from the DataFrame\n",
    "dois = df['publication_doi'].dropna().unique()\n",
    "\n",
    "# Function to clean and normalize DOI strings\n",
    "def clean_doi(doi_string):\n",
    "    \"\"\"\n",
    "    Clean DOI string by removing common prefixes and URLs.\n",
    "    Handles formats like:\n",
    "    - https://doi.org/10.1038/nature123\n",
    "    - http://dx.doi.org/10.1016/j.cell.2020\n",
    "    - doi:10.1126/science.abc456\n",
    "    - 10.1002/anie.202100001\n",
    "    \n",
    "    Returns clean DOI like: 10.1038/nature123\n",
    "    \"\"\"\n",
    "    if pd.isna(doi_string):\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and strip whitespace\n",
    "    doi_string = str(doi_string).strip()\n",
    "    \n",
    "    # Remove common URL prefixes\n",
    "    doi_string = re.sub(r'^https?://doi\\.org/', '', doi_string, flags=re.IGNORECASE)\n",
    "    doi_string = re.sub(r'^https?://dx\\.doi\\.org/', '', doi_string, flags=re.IGNORECASE)\n",
    "    doi_string = re.sub(r'^https?://www\\.doi\\.org/', '', doi_string, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove 'doi:' prefix\n",
    "    doi_string = re.sub(r'^doi:\\s*', '', doi_string, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Strip any remaining whitespace\n",
    "    doi_string = doi_string.strip()\n",
    "    \n",
    "    # Validate that it starts with '10.' (all DOIs start with 10.)\n",
    "    if not doi_string.startswith('10.'):\n",
    "        print(f\"Warning: Potentially invalid DOI format: {doi_string}\")\n",
    "    \n",
    "    return doi_string\n",
    "\n",
    "# Clean the DOIs\n",
    "dois = [clean_doi(doi) for doi in dois if clean_doi(doi) is not None]\n",
    "\n",
    "print(f\"Cleaned {len(dois)} DOIs for processing\")\n",
    "\n",
    "# Map DOIs to PMCIDs and Europe PMC IDs using NCBI E-utilities API\n",
    "def map_dois_to_ids(dois, batch_size=1):\n",
    "    id_mapping = {}\n",
    "    for i in range(0, len(dois), batch_size):\n",
    "        batch = dois[i:i + batch_size]\n",
    "        doi_str = ','.join(batch)\n",
    "        url = f\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?tool=my_tool&email=my_email@example.com&ids={doi_str}&format=json\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            records = data.get('records', [])\n",
    "            if records:\n",
    "                for record in records:\n",
    "                    doi = record.get('doi')\n",
    "                    pmcid = record.get('pmcid')\n",
    "                    pmid = record.get('pmid')\n",
    "                    # Europe PMC ID is typically the PMCID without the 'PMC' prefix, or the PMID\n",
    "                    europepmc_id = pmcid if pmcid else (f\"MED/{pmid}\" if pmid else None)\n",
    "                    id_mapping[doi] = {\n",
    "                        'pmcid': pmcid,\n",
    "                        'europepmc_id': europepmc_id,\n",
    "                        'pmid': pmid\n",
    "                    }\n",
    "        else:\n",
    "            for doi in batch:\n",
    "                id_mapping[doi] = {'pmcid': None, 'europepmc_id': None, 'pmid': None}\n",
    "    return id_mapping\n",
    "\n",
    "# Map DOIs to PMCIDs and Europe PMC IDs\n",
    "doi_to_id_mapping = map_dois_to_ids(dois)\n",
    "\n",
    "# Add the mapped IDs to the DataFrame\n",
    "df['mapped_pmcid'] = df['publication_doi'].apply(lambda x: doi_to_id_mapping.get(x.replace('https://doi.org/', '') if pd.notna(x) else None, {}).get('pmcid'))\n",
    "df['mapped_europepmc_id'] = df['publication_doi'].apply(lambda x: doi_to_id_mapping.get(x.replace('https://doi.org/', '') if pd.notna(x) else None, {}).get('europepmc_id'))\n",
    "df['mapped_pmid'] = df['publication_doi'].apply(lambda x: doi_to_id_mapping.get(x.replace('https://doi.org/', '') if pd.notna(x) else None, {}).get('pmid'))\n",
    "\n",
    "# Save the updated DataFrame to a new TSV file\n",
    "output_tsv_file_name = f'DOME_Registry_TSV_Files/PMCIDs_DOME_Registry_Contents_{current_date}.tsv'\n",
    "df.to_csv(output_tsv_file_name, sep='\\t', index=False)\n",
    "print(f\"Updated DataFrame with mapped PMCIDs and Europe PMC IDs saved to '{output_tsv_file_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use EPMC API to download full text PDFs of all DOME Registry entries and store in folder named DOME_Registry_PMC_PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF for PMCID PMC1421439 not yet downloaded.\n",
      "PDF for PMCID PMC1892091 not yet downloaded.\n",
      "PDF for PMCID PMC2213690 not yet downloaded.\n",
      "PDF for PMCID PMC1847686 not yet downloaded.\n",
      "PDF for PMCID PMC2561051 not yet downloaded.\n",
      "PDF for PMCID PMC2275242 not yet downloaded.\n",
      "PDF for PMCID PMC2665034 not yet downloaded.\n",
      "PDF for PMCID PMC2638158 not yet downloaded.\n",
      "PDF for PMCID PMC2752621 not yet downloaded.\n",
      "PDF for PMCID PMC2660303 not yet downloaded.\n",
      "PDF for PMCID PMC3169429 not yet downloaded.\n",
      "PDF for PMCID PMC3009519 not yet downloaded.\n",
      "PDF for PMCID PMC3340366 not yet downloaded.\n",
      "PDF for PMCID PMC3292016 not yet downloaded.\n",
      "PDF for PMCID PMC3396452 not yet downloaded.\n",
      "PDF for PMCID PMC3542245 not yet downloaded.\n",
      "PDF for PMCID PMC3912131 not yet downloaded.\n",
      "PDF for PMCID PMC4058174 not yet downloaded.\n",
      "PDF for PMCID PMC3967921 not yet downloaded.\n",
      "PDF for PMCID PMC4289375 not yet downloaded.\n",
      "PDF for PMCID PMC4507953 not yet downloaded.\n",
      "PDF for PMCID PMC4315436 not yet downloaded.\n",
      "PDF for PMCID PMC4315323 not yet downloaded.\n",
      "PDF for PMCID PMC4606520 not yet downloaded.\n",
      "PDF for PMCID PMC4589233 not yet downloaded.\n",
      "PDF for PMCID PMC4466774 not yet downloaded.\n",
      "PDF for PMCID PMC4388847 not yet downloaded.\n",
      "PDF for PMCID PMC4706063 not yet downloaded.\n",
      "PDF for PMCID PMC5120500 not yet downloaded.\n",
      "PDF for PMCID PMC4894951 not yet downloaded.\n",
      "PDF for PMCID PMC5113897 not yet downloaded.\n",
      "PDF for PMCID PMC5104375 not yet downloaded.\n",
      "PDF for PMCID PMC5034704 not yet downloaded.\n",
      "PDF for PMCID PMC5079830 not yet downloaded.\n",
      "PDF for PMCID PMC4931851 not yet downloaded.\n",
      "PDF for PMCID PMC5042084 not yet downloaded.\n",
      "PDF for PMCID PMC4773135 not yet downloaded.\n",
      "PDF for PMCID PMC4834164 not yet downloaded.\n",
      "PDF for PMCID PMC5860114 not yet downloaded.\n",
      "PDF for PMCID PMC5860171 not yet downloaded.\n",
      "PDF for PMCID PMC5870574 not yet downloaded.\n",
      "PDF for PMCID PMC5550971 not yet downloaded.\n",
      "PDF for PMCID PMC5610945 not yet downloaded.\n",
      "PDF for PMCID PMC5650527 not yet downloaded.\n",
      "PDF for PMCID PMC5773889 not yet downloaded.\n",
      "PDF for PMCID PMC5821114 not yet downloaded.\n",
      "PDF for PMCID PMC5656045 not yet downloaded.\n",
      "PDF for PMCID PMC5517062 not yet downloaded.\n",
      "PDF for PMCID PMC5738356 not yet downloaded.\n",
      "PDF for PMCID PMC5775817 not yet downloaded.\n",
      "PDF for PMCID PMC5487762 not yet downloaded.\n",
      "PDF for PMCID PMC6091426 not yet downloaded.\n",
      "PDF for PMCID PMC6277570 not yet downloaded.\n",
      "PDF for PMCID PMC5910428 not yet downloaded.\n",
      "PDF for PMCID PMC5821274 not yet downloaded.\n",
      "PDF for PMCID PMC6242780 not yet downloaded.\n",
      "PDF for PMCID PMC6036478 not yet downloaded.\n",
      "PDF for PMCID PMC5930664 not yet downloaded.\n",
      "PDF for PMCID PMC6214495 not yet downloaded.\n",
      "PDF for PMCID PMC6214550 not yet downloaded.\n",
      "PDF for PMCID PMC5976622 not yet downloaded.\n",
      "PDF for PMCID PMC6237755 not yet downloaded.\n",
      "PDF for PMCID PMC6036855 not yet downloaded.\n",
      "PDF for PMCID PMC6172579 not yet downloaded.\n",
      "PDF for PMCID PMC7212484 not yet downloaded.\n",
      "PDF for PMCID PMC6594643 not yet downloaded.\n",
      "PDF for PMCID PMC6982787 not yet downloaded.\n",
      "PDF for PMCID PMC6548586 not yet downloaded.\n",
      "PDF for PMCID PMC6737184 not yet downloaded.\n",
      "PDF for PMCID PMC6386402 not yet downloaded.\n",
      "PDF for PMCID PMC6510637 not yet downloaded.\n",
      "PDF for PMCID PMC6817842 not yet downloaded.\n",
      "PDF for PMCID PMC6732622 not yet downloaded.\n",
      "PDF for PMCID PMC6679781 not yet downloaded.\n",
      "PDF for PMCID PMC6629660 not yet downloaded.\n",
      "PDF for PMCID PMC6923882 not yet downloaded.\n",
      "PDF for PMCID PMC6929456 not yet downloaded.\n",
      "PDF for PMCID PMC6743778 not yet downloaded.\n",
      "PDF for PMCID PMC6436896 not yet downloaded.\n",
      "PDF for PMCID PMC6457539 not yet downloaded.\n",
      "PDF for PMCID PMC6664791 not yet downloaded.\n",
      "PDF for PMCID PMC6690680 not yet downloaded.\n",
      "PDF for PMCID PMC6459551 not yet downloaded.\n",
      "PDF for PMCID PMC6478501 not yet downloaded.\n",
      "PDF for PMCID PMC6908647 not yet downloaded.\n",
      "PDF for PMCID PMC6657583 not yet downloaded.\n",
      "PDF for PMCID PMC6715517 not yet downloaded.\n",
      "PDF for PMCID PMC6902683 not yet downloaded.\n",
      "PDF for PMCID PMC6851483 not yet downloaded.\n",
      "PDF for PMCID PMC6708480 not yet downloaded.\n",
      "PDF for PMCID PMC6495231 not yet downloaded.\n",
      "PDF for PMCID PMC6394031 not yet downloaded.\n",
      "PDF for PMCID PMC9328381 not yet downloaded.\n",
      "PDF for PMCID PMC7692026 not yet downloaded.\n",
      "PDF for PMCID PMC7035778 not yet downloaded.\n",
      "PDF for PMCID PMC7682087 not yet downloaded.\n",
      "PDF for PMCID PMC7602301 not yet downloaded.\n",
      "PDF for PMCID PMC7446623 not yet downloaded.\n",
      "PDF for PMCID PMC7794018 not yet downloaded.\n",
      "PDF for PMCID PMC7156652 not yet downloaded.\n",
      "PDF for PMCID PMC7751093 not yet downloaded.\n",
      "PDF for PMCID PMC7933593 not yet downloaded.\n",
      "PDF for PMCID PMC7352871 not yet downloaded.\n",
      "PDF for PMCID PMC7735824 not yet downloaded.\n",
      "PDF for PMCID PMC7718328 not yet downloaded.\n",
      "PDF for PMCID PMC7596958 not yet downloaded.\n",
      "PDF for PMCID PMC7648120 not yet downloaded.\n",
      "PDF for PMCID PMC7406221 not yet downloaded.\n",
      "PDF for PMCID PMC7068237 not yet downloaded.\n",
      "PDF for PMCID PMC7680913 not yet downloaded.\n",
      "PDF for PMCID PMC8545175 not yet downloaded.\n",
      "PDF for PMCID PMC7734183 not yet downloaded.\n",
      "PDF for PMCID PMC7237030 not yet downloaded.\n",
      "PDF for PMCID PMC7591939 not yet downloaded.\n",
      "PDF for PMCID PMC7725002 not yet downloaded.\n",
      "PDF for PMCID PMC7721480 not yet downloaded.\n",
      "PDF for PMCID PMC7493359 not yet downloaded.\n",
      "PDF for PMCID PMC7569858 not yet downloaded.\n",
      "PDF for PMCID PMC7162491 not yet downloaded.\n",
      "PDF for PMCID PMC7142336 not yet downloaded.\n",
      "PDF for PMCID PMC7442807 not yet downloaded.\n",
      "PDF for PMCID PMC7054390 not yet downloaded.\n",
      "PDF for PMCID PMC7520974 not yet downloaded.\n",
      "PDF for PMCID PMC7333383 not yet downloaded.\n",
      "PDF for PMCID PMC7073919 not yet downloaded.\n",
      "PDF for PMCID PMC7297119 not yet downloaded.\n",
      "PDF for PMCID PMC8668950 not yet downloaded.\n",
      "PDF for PMCID PMC8553642 not yet downloaded.\n",
      "PDF for PMCID PMC8295265 not yet downloaded.\n",
      "PDF for PMCID PMC8371605 not yet downloaded.\n",
      "PDF for PMCID PMC8162250 not yet downloaded.\n",
      "PDF for PMCID PMC8553134 not yet downloaded.\n",
      "PDF for PMCID PMC7876317 not yet downloaded.\n",
      "PDF for PMCID PMC8554859 not yet downloaded.\n",
      "PDF for PMCID PMC8352508 not yet downloaded.\n",
      "PDF for PMCID PMC8261512 not yet downloaded.\n",
      "PDF for PMCID PMC8175075 not yet downloaded.\n",
      "PDF for PMCID PMC8093828 not yet downloaded.\n",
      "PDF for PMCID PMC8351329 not yet downloaded.\n",
      "PDF for PMCID PMC8192578 not yet downloaded.\n",
      "PDF for PMCID PMC8019900 not yet downloaded.\n",
      "PDF for PMCID PMC8042551 not yet downloaded.\n",
      "PDF for PMCID PMC8100172 not yet downloaded.\n",
      "PDF for PMCID PMC8125376 not yet downloaded.\n",
      "PDF for PMCID PMC8328792 not yet downloaded.\n",
      "PDF for PMCID PMC8385175 not yet downloaded.\n",
      "PDF for PMCID PMC7845959 not yet downloaded.\n",
      "PDF for PMCID PMC8469072 not yet downloaded.\n",
      "PDF for PMCID PMC8204819 not yet downloaded.\n",
      "PDF for PMCID PMC7860026 not yet downloaded.\n",
      "PDF for PMCID PMC8485143 not yet downloaded.\n",
      "PDF for PMCID PMC8182908 not yet downloaded.\n",
      "PDF for PMCID PMC8259419 not yet downloaded.\n",
      "PDF for PMCID PMC8230313 not yet downloaded.\n",
      "PDF for PMCID PMC8067080 not yet downloaded.\n",
      "PDF for PMCID PMC8185002 not yet downloaded.\n",
      "PDF for PMCID PMC8100175 not yet downloaded.\n",
      "PDF for PMCID PMC7816647 not yet downloaded.\n",
      "PDF for PMCID PMC8843059 not yet downloaded.\n",
      "PDF for PMCID PMC8225676 not yet downloaded.\n",
      "PDF for PMCID PMC8336795 not yet downloaded.\n",
      "PDF for PMCID PMC9580958 not yet downloaded.\n",
      "PDF for PMCID PMC9757591 not yet downloaded.\n",
      "PDF for PMCID PMC9329459 not yet downloaded.\n",
      "PDF for PMCID PMC9252801 not yet downloaded.\n",
      "PDF for PMCID PMC9681730 not yet downloaded.\n",
      "PDF for PMCID PMC10483879 not yet downloaded.\n",
      "PDF for PMCID PMC10821710 not yet downloaded.\n",
      "PDF for PMCID PMC10716825 not yet downloaded.\n",
      "PDF for PMCID PMC10646871 not yet downloaded.\n",
      "PDF for PMCID PMC10673642 not yet downloaded.\n",
      "PDF for PMCID PMC10600917 not yet downloaded.\n",
      "PDF for PMCID PMC10603766 not yet downloaded.\n",
      "PDF for PMCID PMC10541796 not yet downloaded.\n",
      "PDF for PMCID PMC10441000 not yet downloaded.\n",
      "PDF for PMCID PMC10367125 not yet downloaded.\n",
      "PDF for PMCID PMC10653424 not yet downloaded.\n",
      "PDF for PMCID PMC10174551 not yet downloaded.\n",
      "PDF for PMCID PMC10684096 not yet downloaded.\n",
      "PDF for PMCID PMC9805592 not yet downloaded.\n",
      "PDF for PMCID PMC10730818 not yet downloaded.\n",
      "PDF for PMCID PMC10776382 not yet downloaded.\n",
      "PDF for PMCID PMC10659119 not yet downloaded.\n",
      "PDF for PMCID PMC10087011 not yet downloaded.\n",
      "PDF for PMCID PMC12532322 not yet downloaded.\n",
      "PDF for PMCID PMC10762911 not yet downloaded.\n",
      "PDF for PMCID PMC11837757 not yet downloaded.\n",
      "PDF for PMCID PMC11816797 not yet downloaded.\n",
      "PDF for PMCID PMC11878767 not yet downloaded.\n",
      "PDF for PMCID PMC11734293 not yet downloaded.\n",
      "PDF for PMCID PMC11653894 not yet downloaded.\n",
      "PDF for PMCID PMC11659981 not yet downloaded.\n",
      "PDF for PMCID PMC11659980 not yet downloaded.\n",
      "PDF for PMCID PMC11423353 not yet downloaded.\n",
      "PDF for PMCID PMC11345537 not yet downloaded.\n",
      "PDF for PMCID PMC11959188 not yet downloaded.\n",
      "PDF for PMCID PMC11299106 not yet downloaded.\n",
      "PDF for PMCID PMC11238428 not yet downloaded.\n",
      "PDF for PMCID PMC11258913 not yet downloaded.\n",
      "PDF for PMCID PMC11034027 not yet downloaded.\n",
      "PDF for PMCID PMC10940896 not yet downloaded.\n",
      "PDF for PMCID PMC10783149 not yet downloaded.\n",
      "PDF for PMCID PMC11629979 not yet downloaded.\n",
      "PDF for PMCID PMC11340644 not yet downloaded.\n",
      "PDF for PMCID PMC12366053 not yet downloaded.\n",
      "PDF for PMCID PMC12330522 not yet downloaded.\n",
      "PDF for PMCID PMC12596181 not yet downloaded.\n",
      "\n",
      "Need to download 207 PDFs out of 207 total entries.\n",
      "\n",
      "[1/207] Processing PMC1421439...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[2/207] Processing PMC1892091...\n",
      "[2/207] Processing PMC1892091...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[3/207] Processing PMC2213690...\n",
      "[3/207] Processing PMC2213690...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[4/207] Processing PMC1847686...\n",
      "[4/207] Processing PMC1847686...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[5/207] Processing PMC2561051...\n",
      "[5/207] Processing PMC2561051...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[6/207] Processing PMC2275242...\n",
      "[6/207] Processing PMC2275242...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[7/207] Processing PMC2665034...\n",
      "[7/207] Processing PMC2665034...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[8/207] Processing PMC2638158...\n",
      "[8/207] Processing PMC2638158...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[9/207] Processing PMC2752621...\n",
      "[9/207] Processing PMC2752621...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[10/207] Processing PMC2660303...\n",
      "[10/207] Processing PMC2660303...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[11/207] Processing PMC3169429...\n",
      "[11/207] Processing PMC3169429...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[12/207] Processing PMC3009519...\n",
      "[12/207] Processing PMC3009519...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[13/207] Processing PMC3340366...\n",
      "[13/207] Processing PMC3340366...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[14/207] Processing PMC3292016...\n",
      "[14/207] Processing PMC3292016...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[15/207] Processing PMC3396452...\n",
      "[15/207] Processing PMC3396452...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[16/207] Processing PMC3542245...\n",
      "[16/207] Processing PMC3542245...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[17/207] Processing PMC3912131...\n",
      "[17/207] Processing PMC3912131...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[18/207] Processing PMC4058174...\n",
      "[18/207] Processing PMC4058174...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[19/207] Processing PMC3967921...\n",
      "[19/207] Processing PMC3967921...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[20/207] Processing PMC4289375...\n",
      "[20/207] Processing PMC4289375...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[21/207] Processing PMC4507953...\n",
      "[21/207] Processing PMC4507953...\n",
      "  ✗ Could not retrieve PDF (status: 404)\n",
      "  ✗ Could not retrieve PDF (status: 404)\n",
      "[22/207] Processing PMC4315436...\n",
      "[22/207] Processing PMC4315436...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[23/207] Processing PMC4315323...\n",
      "[23/207] Processing PMC4315323...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[24/207] Processing PMC4606520...\n",
      "[24/207] Processing PMC4606520...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[25/207] Processing PMC4589233...\n",
      "[25/207] Processing PMC4589233...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[26/207] Processing PMC4466774...\n",
      "[26/207] Processing PMC4466774...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[27/207] Processing PMC4388847...\n",
      "[27/207] Processing PMC4388847...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[28/207] Processing PMC4706063...\n",
      "[28/207] Processing PMC4706063...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[29/207] Processing PMC5120500...\n",
      "[29/207] Processing PMC5120500...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[30/207] Processing PMC4894951...\n",
      "[30/207] Processing PMC4894951...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[31/207] Processing PMC5113897...\n",
      "[31/207] Processing PMC5113897...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[32/207] Processing PMC5104375...\n",
      "[32/207] Processing PMC5104375...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[33/207] Processing PMC5034704...\n",
      "[33/207] Processing PMC5034704...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[34/207] Processing PMC5079830...\n",
      "[34/207] Processing PMC5079830...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[35/207] Processing PMC4931851...\n",
      "[35/207] Processing PMC4931851...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[36/207] Processing PMC5042084...\n",
      "[36/207] Processing PMC5042084...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[37/207] Processing PMC4773135...\n",
      "[37/207] Processing PMC4773135...\n",
      "  ✗ Could not retrieve PDF (status: 500)\n",
      "  ✗ Could not retrieve PDF (status: 500)\n",
      "[38/207] Processing PMC4834164...\n",
      "[38/207] Processing PMC4834164...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[39/207] Processing PMC5860114...\n",
      "[39/207] Processing PMC5860114...\n",
      "  ✗ Could not retrieve PDF (status: 500)\n",
      "  ✗ Could not retrieve PDF (status: 500)\n",
      "[40/207] Processing PMC5860171...\n",
      "[40/207] Processing PMC5860171...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[41/207] Processing PMC5870574...\n",
      "[41/207] Processing PMC5870574...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[42/207] Processing PMC5550971...\n",
      "[42/207] Processing PMC5550971...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[43/207] Processing PMC5610945...\n",
      "[43/207] Processing PMC5610945...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[44/207] Processing PMC5650527...\n",
      "[44/207] Processing PMC5650527...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[45/207] Processing PMC5773889...\n",
      "[45/207] Processing PMC5773889...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[46/207] Processing PMC5821114...\n",
      "[46/207] Processing PMC5821114...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[47/207] Processing PMC5656045...\n",
      "[47/207] Processing PMC5656045...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[48/207] Processing PMC5517062...\n",
      "[48/207] Processing PMC5517062...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[49/207] Processing PMC5738356...\n",
      "[49/207] Processing PMC5738356...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[50/207] Processing PMC5775817...\n",
      "[50/207] Processing PMC5775817...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[51/207] Processing PMC5487762...\n",
      "[51/207] Processing PMC5487762...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[52/207] Processing PMC6091426...\n",
      "[52/207] Processing PMC6091426...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[53/207] Processing PMC6277570...\n",
      "[53/207] Processing PMC6277570...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[54/207] Processing PMC5910428...\n",
      "[54/207] Processing PMC5910428...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[55/207] Processing PMC5821274...\n",
      "[55/207] Processing PMC5821274...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[56/207] Processing PMC6242780...\n",
      "[56/207] Processing PMC6242780...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[57/207] Processing PMC6036478...\n",
      "[57/207] Processing PMC6036478...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[58/207] Processing PMC5930664...\n",
      "[58/207] Processing PMC5930664...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[59/207] Processing PMC6214495...\n",
      "[59/207] Processing PMC6214495...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[60/207] Processing PMC6214550...\n",
      "[60/207] Processing PMC6214550...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[61/207] Processing PMC5976622...\n",
      "[61/207] Processing PMC5976622...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[62/207] Processing PMC6237755...\n",
      "[62/207] Processing PMC6237755...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[63/207] Processing PMC6036855...\n",
      "[63/207] Processing PMC6036855...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[64/207] Processing PMC6172579...\n",
      "[64/207] Processing PMC6172579...\n",
      "  ✗ Could not retrieve PDF (status: 404)\n",
      "  ✗ Could not retrieve PDF (status: 404)\n",
      "[65/207] Processing PMC7212484...\n",
      "[65/207] Processing PMC7212484...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[66/207] Processing PMC6594643...\n",
      "[66/207] Processing PMC6594643...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[67/207] Processing PMC6982787...\n",
      "[67/207] Processing PMC6982787...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[68/207] Processing PMC6548586...\n",
      "[68/207] Processing PMC6548586...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[69/207] Processing PMC6737184...\n",
      "[69/207] Processing PMC6737184...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[70/207] Processing PMC6386402...\n",
      "[70/207] Processing PMC6386402...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[71/207] Processing PMC6510637...\n",
      "[71/207] Processing PMC6510637...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[72/207] Processing PMC6817842...\n",
      "[72/207] Processing PMC6817842...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[73/207] Processing PMC6732622...\n",
      "[73/207] Processing PMC6732622...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[74/207] Processing PMC6679781...\n",
      "[74/207] Processing PMC6679781...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[75/207] Processing PMC6629660...\n",
      "[75/207] Processing PMC6629660...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[76/207] Processing PMC6923882...\n",
      "[76/207] Processing PMC6923882...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[77/207] Processing PMC6929456...\n",
      "[77/207] Processing PMC6929456...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[78/207] Processing PMC6743778...\n",
      "[78/207] Processing PMC6743778...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[79/207] Processing PMC6436896...\n",
      "[79/207] Processing PMC6436896...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[80/207] Processing PMC6457539...\n",
      "[80/207] Processing PMC6457539...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[81/207] Processing PMC6664791...\n",
      "[81/207] Processing PMC6664791...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[82/207] Processing PMC6690680...\n",
      "[82/207] Processing PMC6690680...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[83/207] Processing PMC6459551...\n",
      "[83/207] Processing PMC6459551...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[84/207] Processing PMC6478501...\n",
      "[84/207] Processing PMC6478501...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[85/207] Processing PMC6908647...\n",
      "[85/207] Processing PMC6908647...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[86/207] Processing PMC6657583...\n",
      "[86/207] Processing PMC6657583...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[87/207] Processing PMC6715517...\n",
      "[87/207] Processing PMC6715517...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[88/207] Processing PMC6902683...\n",
      "[88/207] Processing PMC6902683...\n",
      "  ✗ Could not retrieve PDF (status: 404)\n",
      "  ✗ Could not retrieve PDF (status: 404)\n",
      "[89/207] Processing PMC6851483...\n",
      "[89/207] Processing PMC6851483...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[90/207] Processing PMC6708480...\n",
      "[90/207] Processing PMC6708480...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[91/207] Processing PMC6495231...\n",
      "[91/207] Processing PMC6495231...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[92/207] Processing PMC6394031...\n",
      "[92/207] Processing PMC6394031...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[93/207] Processing PMC9328381...\n",
      "[93/207] Processing PMC9328381...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[94/207] Processing PMC7692026...\n",
      "[94/207] Processing PMC7692026...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[95/207] Processing PMC7035778...\n",
      "[95/207] Processing PMC7035778...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[96/207] Processing PMC7682087...\n",
      "[96/207] Processing PMC7682087...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[97/207] Processing PMC7602301...\n",
      "[97/207] Processing PMC7602301...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[98/207] Processing PMC7446623...\n",
      "[98/207] Processing PMC7446623...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[99/207] Processing PMC7794018...\n",
      "[99/207] Processing PMC7794018...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[100/207] Processing PMC7156652...\n",
      "[100/207] Processing PMC7156652...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[101/207] Processing PMC7751093...\n",
      "[101/207] Processing PMC7751093...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[102/207] Processing PMC7933593...\n",
      "[102/207] Processing PMC7933593...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[103/207] Processing PMC7352871...\n",
      "[103/207] Processing PMC7352871...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[104/207] Processing PMC7735824...\n",
      "[104/207] Processing PMC7735824...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[105/207] Processing PMC7718328...\n",
      "[105/207] Processing PMC7718328...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[106/207] Processing PMC7596958...\n",
      "[106/207] Processing PMC7596958...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[107/207] Processing PMC7648120...\n",
      "[107/207] Processing PMC7648120...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[108/207] Processing PMC7406221...\n",
      "[108/207] Processing PMC7406221...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[109/207] Processing PMC7068237...\n",
      "[109/207] Processing PMC7068237...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[110/207] Processing PMC7680913...\n",
      "[110/207] Processing PMC7680913...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[111/207] Processing PMC8545175...\n",
      "[111/207] Processing PMC8545175...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[112/207] Processing PMC7734183...\n",
      "[112/207] Processing PMC7734183...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[113/207] Processing PMC7237030...\n",
      "[113/207] Processing PMC7237030...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[114/207] Processing PMC7591939...\n",
      "[114/207] Processing PMC7591939...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[115/207] Processing PMC7725002...\n",
      "[115/207] Processing PMC7725002...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[116/207] Processing PMC7721480...\n",
      "[116/207] Processing PMC7721480...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[117/207] Processing PMC7493359...\n",
      "[117/207] Processing PMC7493359...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[118/207] Processing PMC7569858...\n",
      "[118/207] Processing PMC7569858...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[119/207] Processing PMC7162491...\n",
      "[119/207] Processing PMC7162491...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[120/207] Processing PMC7142336...\n",
      "[120/207] Processing PMC7142336...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[121/207] Processing PMC7442807...\n",
      "[121/207] Processing PMC7442807...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[122/207] Processing PMC7054390...\n",
      "[122/207] Processing PMC7054390...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[123/207] Processing PMC7520974...\n",
      "[123/207] Processing PMC7520974...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[124/207] Processing PMC7333383...\n",
      "[124/207] Processing PMC7333383...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[125/207] Processing PMC7073919...\n",
      "[125/207] Processing PMC7073919...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[126/207] Processing PMC7297119...\n",
      "[126/207] Processing PMC7297119...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[127/207] Processing PMC8668950...\n",
      "[127/207] Processing PMC8668950...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[128/207] Processing PMC8553642...\n",
      "[128/207] Processing PMC8553642...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[129/207] Processing PMC8295265...\n",
      "[129/207] Processing PMC8295265...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[130/207] Processing PMC8371605...\n",
      "[130/207] Processing PMC8371605...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[131/207] Processing PMC8162250...\n",
      "[131/207] Processing PMC8162250...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[132/207] Processing PMC8553134...\n",
      "[132/207] Processing PMC8553134...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[133/207] Processing PMC7876317...\n",
      "[133/207] Processing PMC7876317...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[134/207] Processing PMC8554859...\n",
      "[134/207] Processing PMC8554859...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[135/207] Processing PMC8352508...\n",
      "[135/207] Processing PMC8352508...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[136/207] Processing PMC8261512...\n",
      "[136/207] Processing PMC8261512...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[137/207] Processing PMC8175075...\n",
      "[137/207] Processing PMC8175075...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[138/207] Processing PMC8093828...\n",
      "[138/207] Processing PMC8093828...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[139/207] Processing PMC8351329...\n",
      "[139/207] Processing PMC8351329...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[140/207] Processing PMC8192578...\n",
      "[140/207] Processing PMC8192578...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[141/207] Processing PMC8019900...\n",
      "[141/207] Processing PMC8019900...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[142/207] Processing PMC8042551...\n",
      "[142/207] Processing PMC8042551...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[143/207] Processing PMC8100172...\n",
      "[143/207] Processing PMC8100172...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[144/207] Processing PMC8125376...\n",
      "[144/207] Processing PMC8125376...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[145/207] Processing PMC8328792...\n",
      "[145/207] Processing PMC8328792...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[146/207] Processing PMC8385175...\n",
      "[146/207] Processing PMC8385175...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[147/207] Processing PMC7845959...\n",
      "[147/207] Processing PMC7845959...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[148/207] Processing PMC8469072...\n",
      "[148/207] Processing PMC8469072...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[149/207] Processing PMC8204819...\n",
      "[149/207] Processing PMC8204819...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[150/207] Processing PMC7860026...\n",
      "[150/207] Processing PMC7860026...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[151/207] Processing PMC8485143...\n",
      "[151/207] Processing PMC8485143...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[152/207] Processing PMC8182908...\n",
      "[152/207] Processing PMC8182908...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[153/207] Processing PMC8259419...\n",
      "[153/207] Processing PMC8259419...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[154/207] Processing PMC8230313...\n",
      "[154/207] Processing PMC8230313...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[155/207] Processing PMC8067080...\n",
      "[155/207] Processing PMC8067080...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[156/207] Processing PMC8185002...\n",
      "[156/207] Processing PMC8185002...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[157/207] Processing PMC8100175...\n",
      "[157/207] Processing PMC8100175...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[158/207] Processing PMC7816647...\n",
      "[158/207] Processing PMC7816647...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[159/207] Processing PMC8843059...\n",
      "[159/207] Processing PMC8843059...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[160/207] Processing PMC8225676...\n",
      "[160/207] Processing PMC8225676...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[161/207] Processing PMC8336795...\n",
      "[161/207] Processing PMC8336795...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[162/207] Processing PMC9580958...\n",
      "[162/207] Processing PMC9580958...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[163/207] Processing PMC9757591...\n",
      "[163/207] Processing PMC9757591...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[164/207] Processing PMC9329459...\n",
      "[164/207] Processing PMC9329459...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[165/207] Processing PMC9252801...\n",
      "[165/207] Processing PMC9252801...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[166/207] Processing PMC9681730...\n",
      "[166/207] Processing PMC9681730...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[167/207] Processing PMC10483879...\n",
      "[167/207] Processing PMC10483879...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[168/207] Processing PMC10821710...\n",
      "[168/207] Processing PMC10821710...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[169/207] Processing PMC10716825...\n",
      "[169/207] Processing PMC10716825...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[170/207] Processing PMC10646871...\n",
      "[170/207] Processing PMC10646871...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[171/207] Processing PMC10673642...\n",
      "[171/207] Processing PMC10673642...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[172/207] Processing PMC10600917...\n",
      "[172/207] Processing PMC10600917...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[173/207] Processing PMC10603766...\n",
      "[173/207] Processing PMC10603766...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[174/207] Processing PMC10541796...\n",
      "[174/207] Processing PMC10541796...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[175/207] Processing PMC10441000...\n",
      "[175/207] Processing PMC10441000...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[176/207] Processing PMC10367125...\n",
      "[176/207] Processing PMC10367125...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[177/207] Processing PMC10653424...\n",
      "[177/207] Processing PMC10653424...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[178/207] Processing PMC10174551...\n",
      "[178/207] Processing PMC10174551...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[179/207] Processing PMC10684096...\n",
      "[179/207] Processing PMC10684096...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[180/207] Processing PMC9805592...\n",
      "[180/207] Processing PMC9805592...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[181/207] Processing PMC10730818...\n",
      "[181/207] Processing PMC10730818...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[182/207] Processing PMC10776382...\n",
      "[182/207] Processing PMC10776382...\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "  ✓ Downloaded main PDF from publisher\n",
      "[183/207] Processing PMC10659119...\n",
      "[183/207] Processing PMC10659119...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[184/207] Processing PMC10087011...\n",
      "[184/207] Processing PMC10087011...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[185/207] Processing PMC12532322...\n",
      "[185/207] Processing PMC12532322...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[186/207] Processing PMC10762911...\n",
      "[186/207] Processing PMC10762911...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[187/207] Processing PMC11837757...\n",
      "[187/207] Processing PMC11837757...\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "  ✗ Error downloading main PDF: HTTPSConnectionPool(host='europepmc.org', port=443): Read timed out. (read timeout=30)\n",
      "[188/207] Processing PMC11816797...\n",
      "[188/207] Processing PMC11816797...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[189/207] Processing PMC11878767...\n",
      "[189/207] Processing PMC11878767...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[190/207] Processing PMC11734293...\n",
      "[190/207] Processing PMC11734293...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[191/207] Processing PMC11653894...\n",
      "[191/207] Processing PMC11653894...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[192/207] Processing PMC11659981...\n",
      "[192/207] Processing PMC11659981...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[193/207] Processing PMC11659980...\n",
      "[193/207] Processing PMC11659980...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[194/207] Processing PMC11423353...\n",
      "[194/207] Processing PMC11423353...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[195/207] Processing PMC11345537...\n",
      "[195/207] Processing PMC11345537...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[196/207] Processing PMC11959188...\n",
      "[196/207] Processing PMC11959188...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[197/207] Processing PMC11299106...\n",
      "[197/207] Processing PMC11299106...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[198/207] Processing PMC11238428...\n",
      "[198/207] Processing PMC11238428...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[199/207] Processing PMC11258913...\n",
      "[199/207] Processing PMC11258913...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[200/207] Processing PMC11034027...\n",
      "[200/207] Processing PMC11034027...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[201/207] Processing PMC10940896...\n",
      "[201/207] Processing PMC10940896...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[202/207] Processing PMC10783149...\n",
      "[202/207] Processing PMC10783149...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[203/207] Processing PMC11629979...\n",
      "[203/207] Processing PMC11629979...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[204/207] Processing PMC11340644...\n",
      "[204/207] Processing PMC11340644...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[205/207] Processing PMC12366053...\n",
      "[205/207] Processing PMC12366053...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "[206/207] Processing PMC12330522...\n",
      "[206/207] Processing PMC12330522...\n",
      "[207/207] Processing PMC12596181...\n",
      "[207/207] Processing PMC12596181...\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "  ✓ Downloaded main PDF from PMC OA service\n",
      "\n",
      "============================================================\n",
      "DOWNLOAD SUMMARY\n",
      "============================================================\n",
      "Main PDFs successfully downloaded: 186\n",
      "Main PDFs failed/not available: 20\n",
      "Supplementary files downloaded: 0\n",
      "============================================================\n",
      "\n",
      "Updating TSV with PDF download status...\n",
      "✓ Updated TSV with PDF download status saved to 'DOME_Registry_TSV_Files/PMCIDs_DOME_Registry_Contents_2025-11-16.tsv'\n",
      "\n",
      "Block 5 complete.\n",
      "\n",
      "============================================================\n",
      "DOWNLOAD SUMMARY\n",
      "============================================================\n",
      "Main PDFs successfully downloaded: 186\n",
      "Main PDFs failed/not available: 20\n",
      "Supplementary files downloaded: 0\n",
      "============================================================\n",
      "\n",
      "Updating TSV with PDF download status...\n",
      "✓ Updated TSV with PDF download status saved to 'DOME_Registry_TSV_Files/PMCIDs_DOME_Registry_Contents_2025-11-16.tsv'\n",
      "\n",
      "Block 5 complete.\n"
     ]
    }
   ],
   "source": [
    "# 5. Download full text PDFs using PMCIDs from Europe PMC\n",
    "# Note: Europe PMC does not directly provide PDFs through REST API - we need to use alternative methods\n",
    " \n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Read in DOME Entries TSV as dataframe via pandas library functions\n",
    "df = pd.read_csv(output_tsv_file_name, sep='\\t')\n",
    "\n",
    "# Extract PMCIDs from the DataFrame\n",
    "pmcids = df['mapped_pmcid'].dropna().unique()\n",
    "\n",
    "# Define the output folder for PDF files\n",
    "output_folder = 'DOME_Registry_PMC_PDFs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Track which PMCIDs need downloading (skip already downloaded)\n",
    "to_download_pmcid = []\n",
    "for pmcid in pmcids:\n",
    "    if os.path.exists(f'{output_folder}/{pmcid}_main.pdf'):\n",
    "        print(f\"PDF for PMCID {pmcid} already downloaded.\")\n",
    "    else:\n",
    "        print(f\"PDF for PMCID {pmcid} not yet downloaded.\")\n",
    "        to_download_pmcid.append(pmcid)\n",
    "\n",
    "print(f\"\\nNeed to download {len(to_download_pmcid)} PDFs out of {len(pmcids)} total entries.\\n\")\n",
    "\n",
    "# Function to download full text PDF and supplementary materials\n",
    "def download_pdfs(pmcids):\n",
    "    \"\"\"\n",
    "    Download PDFs from Europe PMC. \n",
    "    Note: Direct PDF downloads are not always available through Europe PMC REST API.\n",
    "    We'll try multiple approaches:\n",
    "    1. Try to get PDF link from article metadata\n",
    "    2. Download supplementary files if available\n",
    "    3. Construct publisher URLs where possible\n",
    "    \"\"\"\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    supp_count = 0\n",
    "    \n",
    "    for idx, pmcid in enumerate(pmcids, 1):\n",
    "        print(f\"[{idx}/{len(pmcids)}] Processing {pmcid}...\")\n",
    "        \n",
    "        # Clean PMCID (remove 'PMC' prefix for some API calls)\n",
    "        clean_pmcid = pmcid.replace('PMC', '') if pmcid.startswith('PMC') else pmcid\n",
    "        \n",
    "        # Try Method 1: Get article metadata to find PDF link\n",
    "        try:\n",
    "            metadata_url = f\"https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=PMCID:{pmcid}&resultType=core&format=json\"\n",
    "            metadata_response = requests.get(metadata_url, timeout=30)\n",
    "            \n",
    "            if metadata_response.status_code == 200:\n",
    "                metadata = metadata_response.json()\n",
    "                \n",
    "                if metadata.get('hitCount', 0) > 0:\n",
    "                    result = metadata['resultList']['result'][0]\n",
    "                    \n",
    "                    # Try to get PDF link from fullTextUrlList\n",
    "                    if 'fullTextUrlList' in result and result['fullTextUrlList']:\n",
    "                        for url_info in result['fullTextUrlList']['fullTextUrl']:\n",
    "                            if url_info.get('documentStyle') == 'pdf' or url_info.get('availabilityCode') == 'OA':\n",
    "                                pdf_url = url_info.get('url')\n",
    "                                \n",
    "                                if pdf_url and '.pdf' in pdf_url.lower():\n",
    "                                    # Try to download the PDF\n",
    "                                    pdf_response = requests.get(pdf_url, timeout=30, allow_redirects=True)\n",
    "                                    \n",
    "                                    if pdf_response.status_code == 200 and pdf_response.headers.get('Content-Type', '').startswith('application/pdf'):\n",
    "                                        output_file = os.path.join(output_folder, f\"{pmcid}_main.pdf\")\n",
    "                                        with open(output_file, 'wb') as file:\n",
    "                                            file.write(pdf_response.content)\n",
    "                                        print(f\"  ✓ Downloaded main PDF from publisher\")\n",
    "                                        success_count += 1\n",
    "                                        break\n",
    "                    \n",
    "                    # If no PDF found yet, try PMC OA service\n",
    "                    if not os.path.exists(f'{output_folder}/{pmcid}_main.pdf'):\n",
    "                        # Try Europe PMC OA PDF service (different endpoint)\n",
    "                        pmc_oa_url = f\"https://europepmc.org/articles/{pmcid}?pdf=render\"\n",
    "                        pmc_response = requests.get(pmc_oa_url, timeout=30, allow_redirects=True)\n",
    "                        \n",
    "                        if pmc_response.status_code == 200 and len(pmc_response.content) > 1000:\n",
    "                            # Check if it's actually a PDF\n",
    "                            if pmc_response.content[:4] == b'%PDF':\n",
    "                                output_file = os.path.join(output_folder, f\"{pmcid}_main.pdf\")\n",
    "                                with open(output_file, 'wb') as file:\n",
    "                                    file.write(pmc_response.content)\n",
    "                                print(f\"  ✓ Downloaded main PDF from PMC OA service\")\n",
    "                                success_count += 1\n",
    "                            else:\n",
    "                                print(f\"  ✗ Could not retrieve PDF (not openly available)\")\n",
    "                                fail_count += 1\n",
    "                        else:\n",
    "                            print(f\"  ✗ Could not retrieve PDF (status: {pmc_response.status_code})\")\n",
    "                            fail_count += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error downloading main PDF: {str(e)}\")\n",
    "            fail_count += 1\n",
    "        \n",
    "        # Try to download supplementary files\n",
    "        try:\n",
    "            supp_url = f\"https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/supplementaryFiles\"\n",
    "            supp_response = requests.get(supp_url, timeout=30)\n",
    "            \n",
    "            if supp_response.status_code == 200:\n",
    "                try:\n",
    "                    supp_data = supp_response.json()\n",
    "                    \n",
    "                    if 'supplementaryFiles' in supp_data and supp_data['supplementaryFiles']:\n",
    "                        for idx_supp, supp_file in enumerate(supp_data['supplementaryFiles'], 1):\n",
    "                            file_url = supp_file.get('url')\n",
    "                            \n",
    "                            if file_url:\n",
    "                                # Download all supplementary files (not just PDFs)\n",
    "                                try:\n",
    "                                    file_response = requests.get(file_url, timeout=30, allow_redirects=True)\n",
    "                                    \n",
    "                                    if file_response.status_code == 200:\n",
    "                                        # Determine file extension from URL or content-type\n",
    "                                        file_ext = ''\n",
    "                                        if '.pdf' in file_url.lower():\n",
    "                                            file_ext = '.pdf'\n",
    "                                        elif '.xlsx' in file_url.lower() or '.xls' in file_url.lower():\n",
    "                                            file_ext = '.xlsx'\n",
    "                                        elif '.docx' in file_url.lower() or '.doc' in file_url.lower():\n",
    "                                            file_ext = '.docx'\n",
    "                                        elif '.zip' in file_url.lower():\n",
    "                                            file_ext = '.zip'\n",
    "                                        else:\n",
    "                                            # Try to get from content-type\n",
    "                                            content_type = file_response.headers.get('Content-Type', '')\n",
    "                                            if 'pdf' in content_type:\n",
    "                                                file_ext = '.pdf'\n",
    "                                            elif 'excel' in content_type or 'spreadsheet' in content_type:\n",
    "                                                file_ext = '.xlsx'\n",
    "                                            else:\n",
    "                                                file_ext = '.dat'  # Default extension\n",
    "                                        \n",
    "                                        supp_output_file = os.path.join(output_folder, f\"{pmcid}_supp_{idx_supp}{file_ext}\")\n",
    "                                        with open(supp_output_file, 'wb') as file:\n",
    "                                            file.write(file_response.content)\n",
    "                                        print(f\"  ✓ Downloaded supplementary file {idx_supp}{file_ext}\")\n",
    "                                        supp_count += 1\n",
    "                                \n",
    "                                except Exception as e_supp:\n",
    "                                    print(f\"  ⚠ Could not download supplementary file {idx_supp}: {str(e_supp)}\")\n",
    "                \n",
    "                except json.JSONDecodeError:\n",
    "                    pass  # No supplementary files available\n",
    "        \n",
    "        except Exception as e:\n",
    "            pass  # Supplementary files not critical, continue\n",
    "        \n",
    "        # Rate limiting - be respectful to the API\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DOWNLOAD SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Main PDFs successfully downloaded: {success_count}\")\n",
    "    print(f\"Main PDFs failed/not available: {fail_count}\")\n",
    "    print(f\"Supplementary files downloaded: {supp_count}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Download PDFs for each PMCID that hasn't been downloaded yet\n",
    "if to_download_pmcid:\n",
    "    download_pdfs(to_download_pmcid)\n",
    "else:\n",
    "    print(\"All PDFs already downloaded. Skipping download step.\")\n",
    "\n",
    "# Update the TSV with download status\n",
    "print(\"Updating TSV with PDF download status...\")\n",
    "pdf_downloadable = []\n",
    "\n",
    "for pmcid in df['mapped_pmcid']:\n",
    "    if pd.notna(pmcid) and os.path.exists(f'{output_folder}/{pmcid}_main.pdf'):\n",
    "        pdf_downloadable.append('yes')\n",
    "    else:\n",
    "        pdf_downloadable.append('no')\n",
    "\n",
    "# Add the new column of download status to the DataFrame and save\n",
    "df['pdf_downloadable'] = pdf_downloadable\n",
    "df.to_csv(output_tsv_file_name, sep='\\t', index=False)\n",
    "print(f\"✓ Updated TSV with PDF download status saved to '{output_tsv_file_name}'\")\n",
    "\n",
    "print(\"\\nBlock 5 complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download supplementary files (PDFs and DOC files) using Europe PMC supplementary files API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_tsv_file_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Read in DOME Entries TSV as dataframe\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(output_tsv_file_name, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Extract PMIDs from the DataFrame\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmapped_pmid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_tsv_file_name' is not defined"
     ]
    }
   ],
   "source": [
    "# 6. Download supplementary files (PDF and DOC only) using PMID from NCBI PubMed FTP\n",
    " \n",
    "import pandas as pd\n",
    "import os\n",
    "from ftplib import FTP\n",
    "import time\n",
    "\n",
    "# Read in DOME Entries TSV as dataframe\n",
    "df = pd.read_csv(output_tsv_file_name, sep='\\t')\n",
    "\n",
    "# Extract PMIDs from the DataFrame\n",
    "if 'mapped_pmid' in df.columns:\n",
    "    df['mapped_pmid'] = df['mapped_pmid'].apply(lambda x: str(int(x)) if pd.notna(x) else None)\n",
    "    pmids = df['mapped_pmid'].dropna().unique()\n",
    "    print(f\"Found {len(pmids)} PMIDs to process for supplementary files\")\n",
    "else:\n",
    "    print(\"Error: 'mapped_pmid' column not found in TSV.\")\n",
    "    pmids = []\n",
    "\n",
    "# Define the output folder for supplementary files\n",
    "supp_output_folder = 'DOME_Registry_PMC_Supplementary'\n",
    "os.makedirs(supp_output_folder, exist_ok=True)\n",
    "\n",
    "# Track which PMIDs need downloading\n",
    "to_download_pmids = []\n",
    "for pmid in pmids:\n",
    "    existing_files = [f for f in os.listdir(supp_output_folder) if f.startswith(f\"PMID{pmid}_supp_\")]\n",
    "    if existing_files:\n",
    "        print(f\"Supplementary files for PMID {pmid} already downloaded ({len(existing_files)} files).\")\n",
    "    else:\n",
    "        to_download_pmids.append(pmid)\n",
    "\n",
    "print(f\"\\nNeed to check {len(to_download_pmids)} PMIDs for supplementary files.\\n\")\n",
    "\n",
    "# Function to download supplementary files from NCBI PubMed FTP\n",
    "def download_supp_from_ftp(pmids):\n",
    "    \"\"\"\n",
    "    Download supplementary PDF and DOC files from NCBI PubMed FTP server.\n",
    "    FTP structure: ftp.ncbi.nlm.nih.gov/pub/pmc/oa_package/\n",
    "    Files are organized by PMID in subdirectories.\n",
    "    \"\"\"\n",
    "    total_files_downloaded = 0\n",
    "    entries_with_supp = 0\n",
    "    entries_without_supp = 0\n",
    "    \n",
    "    # Connect to NCBI FTP server\n",
    "    ftp_host = 'ftp.ncbi.nlm.nih.gov'\n",
    "    \n",
    "    for idx, pmid in enumerate(pmids, 1):\n",
    "        print(f\"[{idx}/{len(pmids)}] Processing PMID {pmid}...\")\n",
    "        \n",
    "        try:\n",
    "            # Connect to FTP\n",
    "            ftp = FTP(ftp_host, timeout=30)\n",
    "            ftp.login()  # Anonymous login\n",
    "            \n",
    "            # Navigate to PubMed Central OA package directory\n",
    "            # PMC files are typically in /pub/pmc/oa_package/ or manuscript directory\n",
    "            base_path = '/pub/pmc/manuscript/'\n",
    "            \n",
    "            try:\n",
    "                # Try to find the PMID directory\n",
    "                # PMC organizes by PMC ID, so we need to search\n",
    "                # Typically format: /pub/pmc/manuscript/PMC[pmcid]/\n",
    "                \n",
    "                # Get PMCID for this PMID from our dataframe\n",
    "                pmcid = df[df['mapped_pmid'] == pmid]['mapped_pmcid'].iloc[0]\n",
    "                \n",
    "                if pd.notna(pmcid):\n",
    "                    pmcid_clean = pmcid.replace('PMC', '')\n",
    "                    article_path = f\"{base_path}PMC{pmcid_clean}/\"\n",
    "                    \n",
    "                    # Try to change to this directory\n",
    "                    ftp.cwd(article_path)\n",
    "                    \n",
    "                    # List all files in directory\n",
    "                    files = ftp.nlst()\n",
    "                    \n",
    "                    # Filter for PDF and DOC files only\n",
    "                    supp_files = [f for f in files if f.lower().endswith(('.pdf', '.doc', '.docx'))]\n",
    "                    \n",
    "                    if supp_files:\n",
    "                        print(f\"  Found {len(supp_files)} supplementary file(s)\")\n",
    "                        \n",
    "                        for file_idx, filename in enumerate(supp_files, 1):\n",
    "                            # Download the file\n",
    "                            local_filename = os.path.join(supp_output_folder, f\"PMID{pmid}_supp_{file_idx}_{filename}\")\n",
    "                            \n",
    "                            with open(local_filename, 'wb') as local_file:\n",
    "                                ftp.retrbinary(f'RETR {filename}', local_file.write)\n",
    "                            \n",
    "                            file_size = os.path.getsize(local_filename)\n",
    "                            print(f\"  ✓ Downloaded: {filename} ({file_size:,} bytes)\")\n",
    "                            total_files_downloaded += 1\n",
    "                        \n",
    "                        entries_with_supp += 1\n",
    "                    else:\n",
    "                        print(f\"  ℹ No PDF/DOC supplementary files found\")\n",
    "                        entries_without_supp += 1\n",
    "                else:\n",
    "                    print(f\"  ✗ No PMCID found for PMID {pmid}\")\n",
    "                    entries_without_supp += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  ℹ No supplementary files accessible via FTP: {str(e)}\")\n",
    "                entries_without_supp += 1\n",
    "            \n",
    "            ftp.quit()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ FTP connection error: {str(e)}\")\n",
    "            entries_without_supp += 1\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUPPLEMENTARY FILES DOWNLOAD SUMMARY (FTP)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total supplementary files downloaded: {total_files_downloaded}\")\n",
    "    print(f\"Entries with supplementary files: {entries_with_supp}\")\n",
    "    print(f\"Entries without supplementary files: {entries_without_supp}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Download supplementary files\n",
    "if to_download_pmids:\n",
    "    download_supp_from_ftp(to_download_pmids)\n",
    "else:\n",
    "    print(\"All supplementary files already checked/downloaded.\")\n",
    "\n",
    "# Update TSV with supplementary files information\n",
    "if 'mapped_pmid' in df.columns:\n",
    "    print(\"Updating TSV with supplementary files information...\")\n",
    "    \n",
    "    supp_file_count = []\n",
    "    supp_file_names = []\n",
    "    \n",
    "    for pmid in df['mapped_pmid']:\n",
    "        if pd.notna(pmid):\n",
    "            supp_files = [f for f in os.listdir(supp_output_folder) if f.startswith(f\"PMID{pmid}_supp_\")]\n",
    "            count = len(supp_files)\n",
    "            supp_file_count.append(count)\n",
    "            \n",
    "            if supp_files:\n",
    "                supp_file_names.append('; '.join(supp_files))\n",
    "            else:\n",
    "                supp_file_names.append(None)\n",
    "        else:\n",
    "            supp_file_count.append(0)\n",
    "            supp_file_names.append(None)\n",
    "    \n",
    "    df['supplementary_file_count'] = supp_file_count\n",
    "    df['supplementary_file_names'] = supp_file_names\n",
    "    \n",
    "    df.to_csv(output_tsv_file_name, sep='\\t', index=False)\n",
    "    print(f\"✓ Updated TSV saved to '{output_tsv_file_name}'\")\n",
    "    \n",
    "    total_supp_files = sum(supp_file_count)\n",
    "    entries_with_supp = sum(1 for count in supp_file_count if count > 0)\n",
    "    \n",
    "    print(f\"\\nSupplementary Files Statistics:\")\n",
    "    print(f\"  Total supplementary files: {total_supp_files}\")\n",
    "    print(f\"  Entries with supplementary files: {entries_with_supp}/{len(df)}\")\n",
    "\n",
    "print(\"\\nBlock 6 complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Enrich TSV with title and abstract data from Europe PMC for all DOME Registry entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Enrich the TSV file with title and abstract columns from Europe PMC\n",
    " \n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Read in DOME Entries TSV as dataframe via pandas library functions\n",
    "df = pd.read_csv(output_tsv_file_name, sep='\\t')\n",
    "\n",
    "# Check if title and abstract columns already exist\n",
    "if 'article_title' in df.columns and 'article_abstract' in df.columns:\n",
    "    print(\"Title and abstract columns already exist in TSV.\")\n",
    "    print(\"Checking for entries that need to be enriched...\")\n",
    "    # Count how many entries already have data\n",
    "    existing_count = df['article_title'].notna().sum()\n",
    "    print(f\"{existing_count} out of {len(df)} entries already have title/abstract data.\")\n",
    "else:\n",
    "    print(\"Adding new columns for title and abstract...\")\n",
    "    df['article_title'] = None\n",
    "    df['article_abstract'] = None\n",
    "\n",
    "# Function to fetch article details from Europe PMC\n",
    "def fetch_article_details(pmcid):\n",
    "    \"\"\"\n",
    "    Fetch title and abstract for a given PMCID from Europe PMC.\n",
    "    \n",
    "    Args:\n",
    "        pmcid (str): PubMed Central ID\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (title, abstract) or (None, None) if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=PMCID:{pmcid}&resultType=core&format=json\"\n",
    "        response = requests.get(url, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get('hitCount', 0) > 0:\n",
    "                article = data['resultList']['result'][0]\n",
    "                title = article.get('title', None)\n",
    "                abstract = article.get('abstractText', None)\n",
    "                return title, abstract\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error fetching details: {str(e)}\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Process each row and enrich with title/abstract if needed\n",
    "print(\"\\nEnriching TSV with title and abstract data...\")\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "skip_count = 0\n",
    "total_to_process = 0\n",
    "\n",
    "# First, count how many need processing\n",
    "for idx, row in df.iterrows():\n",
    "    pmcid = row.get('mapped_pmcid')\n",
    "    if pd.notna(pmcid):\n",
    "        # Check if this entry already has title/abstract\n",
    "        if pd.isna(row.get('article_title')) or pd.isna(row.get('article_abstract')):\n",
    "            total_to_process += 1\n",
    "\n",
    "print(f\"Need to enrich {total_to_process} entries with title/abstract data.\\n\")\n",
    "\n",
    "# Now process the entries\n",
    "processed = 0\n",
    "for idx, row in df.iterrows():\n",
    "    pmcid = row.get('mapped_pmcid')\n",
    "    \n",
    "    if pd.notna(pmcid):\n",
    "        # Check if this entry already has title/abstract\n",
    "        if pd.isna(row.get('article_title')) or pd.isna(row.get('article_abstract')):\n",
    "            processed += 1\n",
    "            print(f\"[{processed}/{total_to_process}] Processing {pmcid}...\")\n",
    "            \n",
    "            title, abstract = fetch_article_details(pmcid)\n",
    "            \n",
    "            if title and abstract:\n",
    "                df.at[idx, 'article_title'] = title\n",
    "                df.at[idx, 'article_abstract'] = abstract\n",
    "                print(f\"  ✓ Added title and abstract\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"  ✗ Failed to retrieve article details\")\n",
    "                fail_count += 1\n",
    "            \n",
    "            # Rate limiting - be respectful to the API\n",
    "            time.sleep(0.5)\n",
    "        else:\n",
    "            skip_count += 1\n",
    "    else:\n",
    "        # No PMCID available\n",
    "        skip_count += 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TITLE/ABSTRACT ENRICHMENT SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Successfully enriched: {success_count}\")\n",
    "print(f\"Failed/not available: {fail_count}\")\n",
    "print(f\"Skipped (already had data or no PMCID): {skip_count}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Save the enriched TSV\n",
    "df.to_csv(output_tsv_file_name, sep='\\t', index=False)\n",
    "print(f\"✓ Enriched TSV with title and abstract columns saved to '{output_tsv_file_name}'\")\n",
    "\n",
    "# Show a sample of the enriched data\n",
    "print(f\"\\nSample of enriched data (first 3 rows with title/abstract):\")\n",
    "sample_df = df[df['article_title'].notna()][['mapped_pmcid', 'article_title', 'article_abstract']].head(3)\n",
    "if not sample_df.empty:\n",
    "    for idx, row in sample_df.iterrows():\n",
    "        print(f\"\\nPMCID: {row['mapped_pmcid']}\")\n",
    "        print(f\"Title: {row['article_title'][:100]}...\" if len(str(row['article_title'])) > 100 else f\"Title: {row['article_title']}\")\n",
    "        print(f\"Abstract: {str(row['article_abstract'])[:150]}...\" if len(str(row['article_abstract'])) > 150 else f\"Abstract: {row['article_abstract']}\")\n",
    "else:\n",
    "    print(\"No entries with title/abstract data found.\")\n",
    "\n",
    "print(\"\\nBlock 7 complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metadata generated on DOME Entries data TSV such as availability of full text PDF files, supplementary files, title/abstract data, total entries, etc + some graphs of data validity vs expected inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'abstract_title_downloadable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'abstract_title_downloadable'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m pdf_yes \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf_downloadable\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m pdf_no \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf_downloadable\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m abstract_title_yes \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract_title_downloadable\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m abstract_title_no \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract_title_downloadable\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create a metadata DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'abstract_title_downloadable'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Create metadata file readout as a TSV, corresponding text file to explain contents and graphs to go with these\n",
    "# Metadata file readout as TSV and text file to explain contents and graph visualisation of data validation \n",
    "\n",
    "#import libraries\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read in the TSV file\n",
    "df = pd.read_csv(output_tsv_file_name, sep='\\t')\n",
    "\n",
    "# Calculate metadata\n",
    "total_entries = len(df)\n",
    "pdf_yes = df['pdf_downloadable'].value_counts().get('yes', 0)\n",
    "pdf_no = df['pdf_downloadable'].value_counts().get('no', 0)\n",
    "\n",
    "# Check for title/abstract data availability\n",
    "title_abstract_available = (df['article_title'].notna() & df['article_abstract'].notna()).sum()\n",
    "title_abstract_missing = total_entries - title_abstract_available\n",
    "\n",
    "# Check for supplementary files\n",
    "entries_with_supp = (df['supplementary_file_count'] > 0).sum()\n",
    "entries_without_supp = total_entries - entries_with_supp\n",
    "total_supp_files = df['supplementary_file_count'].sum()\n",
    "\n",
    "# Create a metadata DataFrame\n",
    "metadata = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Entries', \n",
    "        'PDF Available (Yes)', \n",
    "        'PDF Available (No)', \n",
    "        'Title/Abstract Available', \n",
    "        'Title/Abstract Missing',\n",
    "        'Entries with Supplementary Files',\n",
    "        'Entries without Supplementary Files',\n",
    "        'Total Supplementary Files Count'\n",
    "    ],\n",
    "    'Count': [\n",
    "        total_entries, \n",
    "        pdf_yes, \n",
    "        pdf_no, \n",
    "        title_abstract_available, \n",
    "        title_abstract_missing,\n",
    "        entries_with_supp,\n",
    "        entries_without_supp,\n",
    "        int(total_supp_files)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Save metadata to a new TSV file\n",
    "metadata_tsv_path = 'DOME_Registry_TSV_Files/DOME_Metadata.tsv'\n",
    "metadata.to_csv(metadata_tsv_path, sep='\\t', index=False)\n",
    "print(f\"Metadata saved to '{metadata_tsv_path}'\")\n",
    "\n",
    "# Plot bar charts\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Bar chart for PDF availability\n",
    "axes[0].bar(['Yes', 'No'], [pdf_yes, pdf_no], color=['green', 'red'])\n",
    "axes[0].set_title('PDF Availability')\n",
    "axes[0].set_xlabel('Availability')\n",
    "axes[0].set_ylabel('Paper count')\n",
    "\n",
    "# Bar chart for title/abstract availability\n",
    "axes[1].bar(['Available', 'Missing'], [title_abstract_available, title_abstract_missing], color=['green', 'red'])\n",
    "axes[1].set_title('Title/Abstract Data Availability')\n",
    "axes[1].set_xlabel('Availability')\n",
    "axes[1].set_ylabel('Paper count')\n",
    "\n",
    "# Bar chart for supplementary files\n",
    "axes[2].bar(['With Supp Files', 'Without Supp Files'], [entries_with_supp, entries_without_supp], color=['blue', 'gray'])\n",
    "axes[2].set_title('Supplementary Files Availability')\n",
    "axes[2].set_xlabel('Availability')\n",
    "axes[2].set_ylabel('Paper count')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as an image file\n",
    "plot_image_path = 'DOME_Registry_TSV_Files/DOME_Metadata_Bar_Charts.png'\n",
    "plt.savefig(plot_image_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Bar charts saved to '{plot_image_path}'\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print detailed summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DOME REGISTRY METADATA SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total entries: {total_entries}\")\n",
    "print(f\"PDFs available: {pdf_yes} ({pdf_yes/total_entries*100:.1f}%)\")\n",
    "print(f\"Title/Abstract available: {title_abstract_available} ({title_abstract_available/total_entries*100:.1f}%)\")\n",
    "print(f\"Entries with supplementary files: {entries_with_supp} ({entries_with_supp/total_entries*100:.1f}%)\")\n",
    "print(f\"Total supplementary files: {int(total_supp_files)}\")\n",
    "if entries_with_supp > 0:\n",
    "    print(f\"Average supplementary files per entry (with supp): {total_supp_files/entries_with_supp:.2f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# To add\n",
    "# 8.2 Turn TSV data into corresponding text file to verbally explain metrics\n",
    "# 8.3 Turn TSV into corresponding graphed data to visualise the metrics\n",
    "\n",
    "print(\"\\nBlock 8 complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
